@article{NAKANO2008280,
title = {A space–time-ensemble parallel nudged elastic band algorithm for molecular kinetics simulation},
journal = {Computer Physics Communications},
volume = {178},
number = {4},
pages = {280-289},
year = {2008},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2007.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0010465507004225},
author = {Aiichiro Nakano},
keywords = {Nudged elastic band method, Transition state theory, Molecular kinetics simulation, Parallel computing},
abstract = {A scalable parallel algorithm has been designed to study long-time dynamics of many-atom systems based on the nudged elastic band method, which performs mutually constrained molecular dynamics simulations for a sequence of atomic configurations (or states) to obtain a minimum energy path between initial and final local minimum-energy states. A directionally heated nudged elastic band method is introduced to search for thermally activated events without the knowledge of final states, which is then applied to an ensemble of bands in a path ensemble method for long-time simulation in the framework of the transition state theory. The resulting molecular kinetics (MK) simulation method is parallelized with a space–time-ensemble parallel nudged elastic band (STEP-NEB) algorithm, which employs spatial decomposition within each state, while temporal parallelism across the states within each band and band-ensemble parallelism are implemented using a hierarchy of communicator constructs in the Message Passing Interface library. The STEP-NEB algorithm exhibits good scalability with respect to spatial, temporal and ensemble decompositions on massively parallel computers. The MK simulation method is used to study low strain-rate deformation of amorphous silica.}
}
@article{HSIAO2021102312,
title = {Who captures whom – Pokémon or tourists? A perspective of the Stimulus-Organism-Response model},
journal = {International Journal of Information Management},
volume = {61},
pages = {102312},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2021.102312},
url = {https://www.sciencedirect.com/science/article/pii/S0268401221000050},
author = {Chun-Hua Hsiao and Kai-Yu Tang},
keywords = {Stimulus-Organism-Response (S-O-R) model, Critical mass, Social interaction, Attachment, Conformity, Tourism, Continuance intention},
abstract = {Since its launch in 2016, Pokémon Go has attracted huge numbers of players, causing a boom in this game market. Although it is not as popular as before, from time to time we still find crowds of players gathered in some spots where Pokémon appear. Numerous reports have explored this Pokémon phenomenon; however, the exact reasons for its popularity remain unknown. The purpose of this study is to explore the post-adoption behavior of Pokémon Go players and its influential factors in the gaming and tourism industries. The theoretical model of stimulus-organism-response was drawn on to examine the impact of the environmental stimuli (social influence and media influence) on players’ internal organisms, which in turn affect their post-experience responses. Moreover, gender differences were also examined in the hypothetical relationships. A total of 342 valid questionnaires from actual gamers were collected in this study, and data analysis was performed using a structural equation model. The results show that stimulus effects, such as social stimuli (critical mass and social interaction) and media stimuli (content timeliness and media richness), have significant impacts on the players’ internal gamified experience (attachment and conformity), which in turn affect their visit intention to catch creatures at certain attractions and to continue playing Pokémon Go. Further, we have also found that players’ intention to visit Pokémon spots is significantly correlated with their intention to continue playing the game. Findings provide links between gamification and tourism literature. Further theoretical and managerial implications are provided.}
}
@article{MCCOY201995,
title = {Machine learning applications in minerals processing: A review},
journal = {Minerals Engineering},
volume = {132},
pages = {95-109},
year = {2019},
issn = {0892-6875},
doi = {https://doi.org/10.1016/j.mineng.2018.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0892687518305430},
author = {J.T. McCoy and L. Auret},
keywords = {Machine learning, Artificial intelligence, Machine vision, Fault detection and diagnosis, Data-based modelling},
abstract = {Machine learning and artificial intelligence techniques have an ever-increasing presence and impact on a wide-variety of research and commercial fields. Disappointed by previous hype cycles, researchers and industrial practitioners may be wary of overpromising and underdelivering techniques. This review aims at equipping researchers and industrial practitioners with structured knowledge on the state of machine learning applications in mineral processing: the supplementary material provides a searchable summary of all techniques reviewed, with fields including nature of case study data (synthetic/laboratory/industrial), level of success, area of application (e.g. milling, flotation, etc), and major problem category (data-based modelling, fault detection and diagnosis, and machine vision). Future directions are proposed, including suggestions on data collection, technique comparison, industrial participation, cost-benefit analyses and the future of mineral engineering training.}
}
@article{FINKEL2017303,
title = {L’analyse cognitive, la psychologie numérique et la formation des enseignants à l’université},
journal = {Pratiques Psychologiques},
volume = {23},
number = {3},
pages = {303-323},
year = {2017},
note = {Préparer la nouvelle génération de psychologues : objectifs, méthodes et ressources dans l'enseignement de la psychologie},
issn = {1269-1763},
doi = {https://doi.org/10.1016/j.prps.2017.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S126917631730055X},
author = {A. Finkel},
keywords = {Pensée informatique, Psychologie numérique, Analyse cognitive, Enseignement, Université, Digital thinking, Computer science, Digital psychology, Cognitive analysis, Teaching, College, University},
abstract = {Résumé
L’analyse cognitive est le fruit d’une réflexion utilisant, entre autres, les principes de la pensée informatique (mathématique, logique et algorithmique) pour repenser des connaissances et des techniques de plusieurs domaines de la psychologie cognitive, de la psychologie sociale, de la psychologie des émotions et de la psychologie de la communication en vue de la formation pédagogique des enseignants d’université. Avant de présenter l’analyse cognitive, je vais rappeler comment l’histoire du calcul depuis 5000 ans peut être vue comme une tentative (réussie) de comprendre, formaliser et automatiser le traitement humain de l’information, thème sur lequel se retrouvent l’informatique et la psychologie. Puis, je montrerai qu’un nouveau comportementalisme, basé sur le comportement numérique mais aussi sur les comportements classiques et sur les zones du cerveau, est en train d’émerger et qu’il produit des modèles psychologiques qui sont utilisés pour connaître les pensées et les intentions des personnes observées, pour mieux leur vendre des objets et pour prédire leurs actions par exemple ; une psychologie numérique émerge. Bien que chacun d’entre nous utilise son ordinateur portable et internet comme une extension de son esprit (lire « Petite Poucette » de Michel Serres), nous n’avons pas encore intégré explicitement la pensée informatique. Nous expliciterons donc quelques éléments de la pensée informatique et nous présenterons enfin l’analyse cognitive en soulignant comment elle utilise à la fois la pensée informatique et des connaissances de psychologie.
Cognitive analysis is the result of an afterthought using, amongst other things, principles from computer science (maths, logic and algorithmic) to rethink techniques and knowledge of several areas of psychology: cognitive psychology, social psychology, psychology of emotions and communication. The aim is pedagogy training for university teachers. Before explaining what cognitive analysis is, I will tell you how the history of calculation since 5000 years may be seen as a (successful) stab at understanding, formalizing and automating human processing of data, which is where computer science and psychology meet. Then, I will demonstrate that a new behavioralism, based on digital and classical behavior and specific areas of the brain, is starting to emerge and produces psychological models that are used to know the thoughts and intents of the people observed, to better sell them stuff and predict their actions. A digital psychology emerges. Although all of us use a laptop and Internet as an extension of our minds (read “Petite Poucette” by Michel Serres), the digital thought remains implicit. We will explicit several components of digital thinking and will show how cognitive analysis uses digital thinking and knowledge from psychology.}
}
@article{PROFETA2018111,
title = {Bernstein’s levels of movement construction: A contemporary perspective},
journal = {Human Movement Science},
volume = {57},
pages = {111-133},
year = {2018},
issn = {0167-9457},
doi = {https://doi.org/10.1016/j.humov.2017.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S0167945717305717},
author = {Vitor L.S. Profeta and Michael T. Turvey},
keywords = {Bernstein, Control, Coordination, Synergy, Movement construction},
abstract = {Explanation of how goal-directed movements are made manifest is the ultimate aim of the field classically referred to as “motor control”. Essential to the sought-after explanation is comprehension of the supporting functional architecture. Seven decades ago, the Russian physiologist and movement scientist Nikolai A. Bernstein proposed a hierarchical model to explain the construction of movements. In his model, the levels of the hierarchy share a common language (i.e., they are commensurate) and perform complementing functions to bring about dexterous movements. The science of the control and coordination of movement in the phylum Craniata has made considerable progress in the intervening seven decades. The contemporary body of knowledge about each of Bernstein’s hypothesized functional levels is both more detailed and more sophisticated. A natural consequence of this progress, however, is the relatively independent theoretical development of a given level from the other levels. In this essay, we revisit each level of Bernstein’s hierarchy from the joint perspectives of (a) the ecological approach to perception-action and (b) dynamical systems theory. We review a substantial and relevant body of literature produced in different areas of study that are accommodated by this ecological-dynamical version of Bernstein’s levels. Implications for the control and coordination of movement and the challenges to producing a unified theory are discussed.}
}
@article{IIVARI2023100600,
title = {Computational empowerment of children: Design research on empowering and impactful designs by children},
journal = {International Journal of Child-Computer Interaction},
volume = {37},
pages = {100600},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2023.100600},
url = {https://www.sciencedirect.com/science/article/pii/S2212868923000375},
author = {Netta Iivari and Leena Ventä-Olkkonen and Heidi Hartikainen and Sumita Sharma and Essi Lehto and Jenni Holappa and Tonja Molin-Juustila},
keywords = {Children, Empowerment, Impact, Critical design, Critical making, Bullying, Design research},
abstract = {Prioritizing children’s empowerment in and through design has been on the agenda of child–computer interaction (CCI) research for a long time. Recently, the notion of the computational empowerment of children has received attention. However, there are still open issues in our understanding and advocacy of it. A related development is the recent interest in the longer-term impacts of our work. Fast and furious participation of children in design sessions is considered inadequate. We should advocate for longer-term trajectories and possibilities for children to make changes that will influence our world. However, the literature is limited in addressing longer-term impacts. This study taps into these two research gaps and showcases how we have addressed the computational empowerment of children in a project tackling bullying at school through critical design and making. In this paper, we examine in detail the children’s designs and their trajectories from the viewpoint of empowerment and impact: whether and how these children’s designs show potential for the empowerment of those bullied and whether and how their designs have had an impact in the realm of digital technology development. Our study has interesting conceptual and methodological implications for CCI research and practice on the computational empowerment of children and on our design research practice.}
}
@article{ESTEFO2019226,
title = {The Robot Operating System: Package reuse and community dynamics},
journal = {Journal of Systems and Software},
volume = {151},
pages = {226-242},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.02.024},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219300342},
author = {Pablo Estefo and Jocelyn Simmonds and Romain Robbes and Johan Fabry},
keywords = {Robot Operating System, Package management, Software ecosystems},
abstract = {ROS, the Robot Operating System, offers a core set of software for operating robots that can be extended by creating or using existing packages, making it possible to write robotic software that can be reused on different hardware platforms. With thousands of packages available per stable distribution, encapsulating algorithms, sensor drivers, etc., it is the de facto middleware for robotics. Like any software ecosystem, ROS must evolve in order to keep meeting the requirements of its users. In practice, packages may end up being abandoned between releases: no one may be available to update a package, or newer packages offer similar functionality. As such, we wanted to identify and understand the evolution challenges faced by the ROS ecosystem. In this article, we report our findings after interviewing 19 ROS developers in depth, followed by a focus group (4 participants) and an online survey of 119 ROS community members. We specifically focused on the issues surrounding package reuse and how to contribute to existing packages. To conclude, we discuss the implications of our findings, and propose five recommendations for overcoming the identified issues, with the goal of improving the health of the ROS ecosystem.}
}
@article{DESPEAUX2007359,
title = {Abstracts},
journal = {Historia Mathematica},
volume = {34},
number = {3},
pages = {359-374},
year = {2007},
issn = {0315-0860},
doi = {https://doi.org/10.1016/j.hm.2007.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0315086007000353},
author = {Sloan Evans Despeaux and Laura Martini and Kim Plofker}
}
@article{KOLODNY2015252,
title = {The problem of multimodal concurrent serial order in behavior},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {56},
pages = {252-265},
year = {2015},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2015.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0149763415001943},
author = {Oren Kolodny and Shimon Edelman},
keywords = {Embodied cognition, Stimulus-response, Multimodality, Concurrency, Hierarchy, Language, Sensorimotor integration, Multidimensionality, Events, parallel computation, sequential behavior, Lashley, Serial order, Superior colliculus, Hippocampus, Basal ganglia, Unity of consciousness},
abstract = {The “problem of serial order in behavior,” as formulated and discussed by Lashley (1951), is arguably more pervasive and more profound both than originally stated and than currently appreciated. We spell out two complementary aspects of what we term the generalized problem of behavior: (i) multimodality, stemming from the disparate nature of the sensorimotor variables and processes that underlie behavior, and (ii) concurrency, which reflects the parallel unfolding in time of these processes and of their asynchronous interactions. We illustrate these on a number of examples, with a special focus on language, briefly survey the computational approaches to multimodal concurrency, offer some hypotheses regarding the manner in which brains address it, and discuss some of the broader implications of these as yet unresolved issues for cognitive science.}
}
@article{LAW2021100321,
title = {Augmented reality applications for K-12 education: A systematic review from the usability and user experience perspective},
journal = {International Journal of Child-Computer Interaction},
volume = {30},
pages = {100321},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100321},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000477},
author = {Effie Lai-Chong Law and Matthias Heintz},
keywords = {Augmented reality, Education, Usability, User experience, Systematic review},
abstract = {In the past two decades, we have witnessed soaring efforts in applying Augmented Reality (AR) technology in education. Several systematic literature reviews (SLRs) were conducted to study AR educational applications (AREAs) and associated methodologies, primarily from the pedagogical rather than from the human–computer interaction (HCI) perspective. These reviews vary in goal, scale, scope, technique, outcome and quality. To bridge the gaps identified in these SLRs, ours is to meet fourfold objectives: to ground the analysis deeper in the usability and user experience (UX) core concepts and methods; to study the learning effect and usability/UX of AREAs and their relations by learner age; to reflect on the prevailing SLR process and propose improvement; to draw implications for the future development of AREAs. Our searches in four databases returned 714 papers of which 42, together with 7 from three existing SLRs, were included in the final analysis. Several intriguing findings have been identified: (i) the insufficient grounding in usability/UX frameworks indicates that there seems a disconnection between the HCI and technology-enhanced learning community; (ii) a lack of innovative AR-specific usability/UX evaluation methods and the continuing reliance on questionnaire may hamper the advances of AREAs; (iii) the learner age seems not a significant factor in determining the perceived usability and UX or the learning effect of AREAs; (iv) a limited number of studies at home suggests the missed opportunity of mobilizing parents to support children to deploy AREAs in different settings; (v) the number of AREAs for children with special needs remains disappointedly low; (vi) the threat of predatory journals to the quality of bibliometric sources amplifies the need for a robust approach to the quality assessment for SLR and transparency of interim results. Implications of these issues for future research and practice on AREAs are drawn.}
}
@article{STEPHENS2021103466,
title = {Landscape changes and their hydrologic effects: Interactions and feedbacks across scales},
journal = {Earth-Science Reviews},
volume = {212},
pages = {103466},
year = {2021},
issn = {0012-8252},
doi = {https://doi.org/10.1016/j.earscirev.2020.103466},
url = {https://www.sciencedirect.com/science/article/pii/S0012825220305122},
author = {C.M. Stephens and U. Lall and F.M. Johnson and L.A. Marshall},
abstract = {Human activities have extensively altered landscapes throughout the world and further changes are expected in the future. Anthropogenic impacts such as land use change, groundwater extraction and dam construction, along with the effects of climate change, interact with natural factors including soil weathering and erosion. Together, these processes create a constantly shifting, dynamic terrestrial environment that violates the assumption of stationarity commonly applied in hydrology. Consequently, hydrologists need to rethink both statistical and calibrated models to account for complex environmental processes. We review the literature on human-landscape-hydrological interactions to identify processes and feedbacks that influence water balances. Most of the papers covered consider only a few of these processes at a time and focus on structural attributes of the interactions rather than the short and long-term dynamics. We identify challenges in representing the scale-dependence, environmental connectivity and human-water interactions that characterize complex, dynamic landscapes. A synthesis of the findings posits connections between different landscape changes, as well as the associated timescales and level of certainty. A case study explores how different processes could combine to drive long-term shifts in catchment behavior. Recognizing that some important questions remain unaddressed by traditional approaches, we suggest the concept of ‘big laboratories’ in which multifaceted experiments are conducted in the environment by artificially inducing landscape change. These experiments would be accompanied by mechanistic modeling to both untangle experimental results and improve the theoretical basis of environmental models. An ambitious program of physical and virtual experimentation is needed to progress hydrologic prediction for dynamic landscapes.
Plain language summary
The Earth’s surface is constantly changing due to human-driven and natural processes. Shifts may be driven by humans directly (e.g. via land use change) or indirectly (e.g. by driving climate change that causes shifts in ecological communities). Other changes are natural, such as certain soil processes that lead to shifts in texture and properties over time. In many places, landscape change is now occurring at unprecedented rates. This impacts the water cycle, creating a need for models that are robust under changing conditions. Our paper synthesizes a wide range of literature on key aspects of landscape change that have wide-ranging implications for hydrology. We focus on the impacts of processes at different spatial and temporal scales, along with feedbacks between various environmental and anthropogenic shifts. We discuss connections between different landscape changes and the timescales over which they each affect the water cycle. A case study is presented to highlight the potential for cascading landscape disturbances that could alter long-term catchment response. Recognizing limitations in traditional data collection and modeling, we introduce the concept of ‘big laboratories’ to conduct environmental experiments under landscape change, providing an avenue for addressing the complex questions around hydrology in a changing world.}
}
@article{OZTOP201343,
title = {Mirror neurons: Functions, mechanisms and models},
journal = {Neuroscience Letters},
volume = {540},
pages = {43-55},
year = {2013},
note = {The Mirror Neuron System},
issn = {0304-3940},
doi = {https://doi.org/10.1016/j.neulet.2012.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0304394012013183},
author = {Erhan Oztop and Mitsuo Kawato and Michael A. Arbib},
keywords = {Mirror neuron, Computational model, Action recognition, imitation, language evolution, Mirror neuron development, Direct matching},
abstract = {Mirror neurons for manipulation fire both when the animal manipulates an object in a specific way and when it sees another animal (or the experimenter) perform an action that is more or less similar. Such neurons were originally found in macaque monkeys, in the ventral premotor cortex, area F5 and later also in the inferior parietal lobule. Recent neuroimaging data indicate that the adult human brain is endowed with a “mirror neuron system,” putatively containing mirror neurons and other neurons, for matching the observation and execution of actions. Mirror neurons may serve action recognition in monkeys as well as humans, whereas their putative role in imitation and language may be realized in human but not in monkey. This article shows the important role of computational models in providing sufficient and causal explanations for the observed phenomena involving mirror systems and the learning processes which form them, and underlines the need for additional circuitry to lift up the monkey mirror neuron circuit to sustain the posited cognitive functions attributed to the human mirror neuron system.}
}
@incollection{CARETTE202215,
title = {Chapter Two - Embracing the laws of physics: Three reversible models of computation},
editor = {Ali R. Hurson},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {126},
pages = {15-63},
year = {2022},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2021.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0065245821000838},
author = {Jacques Carette and Roshan P. James and Amr Sabry},
keywords = {Reversible programming, Reversible Boolean circuits, Monoidal categories, Type isomorphisms, Commutative semirings, Homotopy-type theory, Quantum circuits, Permutations},
abstract = {Our main models of computation (the Turing Machine and the RAM) and most modern computer architectures make fundamental assumptions about which primitive operations are realizable on a physical computing device. The consensus is that these primitive operations include logical operations like conjunction, disjunction and negation, as well as reading and writing to a large collection of memory locations. This perspective conforms to a macro-level view of physics and indeed these operations are realizable using macro-level devices involving thousands of electrons. This point of view is however incompatible with computation realized using quantum devices or analyzed using elementary thermodynamics as both these fundamental physical theories imply that information is a conserved quantity of physical processes and hence of primitive computational operations. Our aim is to redevelop foundational computational models in a way that embraces the principle of conservation of information. We first define what information is and what its conservation means in a computational setting. We emphasize the idea that computations must be reversible transformations on data. One can think of data as modeled using topological spaces and programs as modeled by reversible deformations of these spaces. We then illustrate this idea using three notions of data and their associated reversible computational models. The first instance only assumes unstructured finite data, i.e., discrete topological spaces. The corresponding notion of reversible computation is that of permutations. We show how this simple model subsumes conventional computations on finite sets. We then consider a modern structured notion of data based on the Curry–Howard correspondence between logic and type theory. We develop the corresponding notion of reversible deformations using a sound and complete programming language for witnessing type isomorphisms and proof terms for commutative semirings. We then “move up a level” to examine spaces that treat programs as data, which is a crucial notion for any universal model of computation. To derive the corresponding notion of reversible programs between programs, i.e., reversible program equivalences, we look at the “higher dimensional” analog to commutative semirings: symmetric rig groupoids. The coherence laws for these groupoids turn out to be exactly the sound and complete reversible program equivalences we seek. We conclude with some possible generalizations inspired by homotopy type theory and survey several open directions for further research.}
}
@incollection{WU2022293,
title = {Chapter 8 - Chronotopologic krigology},
editor = {Jiaping Wu and Junyu He and George Christakos},
booktitle = {Quantitative Analysis and Modeling of Earth and Environmental Data},
publisher = {Elsevier},
pages = {293-344},
year = {2022},
isbn = {978-0-12-816341-2},
doi = {https://doi.org/10.1016/B978-0-12-816341-2.00003-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128163412000034},
author = {Jiaping Wu and Junyu He and George Christakos},
keywords = {Geostatistical Kriging, Space-time ordinary, Simple, Indicator chronoblock and functional Kriging, Accuracy indicators, Cross-validation},
abstract = {Various types of chronotopologic Kriging are presented, including ordinary, simple and indicator Kriging of natural attribute distributions, as well as chronoblock and functional Kriging. Their specific properties, links to chronotopologic mapping and real-world application ranges are reviewed. Interpolation accuracy indicators and cross-validation tests are analyzed. The benefits and concerns of applied Krigology are outlined.}
}
@article{ALFOUDARI2021104282,
title = {Understanding socio-technological challenges of smart classrooms using a systematic review},
journal = {Computers & Education},
volume = {173},
pages = {104282},
year = {2021},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2021.104282},
url = {https://www.sciencedirect.com/science/article/pii/S0360131521001597},
author = {Aisha M. Alfoudari and Christopher M. Durugbo and Fairouz M. Aldhmour},
keywords = {Smart classroom, Systematic review, Socio-technological challenges, Technology-supported learning},
abstract = {Smart classrooms are paradigm innovations for enhanced learning behavior in digital learning environments. These environments offer benefits for inclusive and virtual learning, underscoring the need for assessments of current practices. Although research on smart classrooms propose models and systems for enhancing socio-technological integration, knowledge on socio-technological challenges of smart classrooms remains limited. This article applies a systematic review methodology in line with the PRISMA protocol and analyzes current social and technological challenges based on 105 articles published between 2000 and 2019. The review identifies social challenges that facilitate personalization for external factors and teaching methods, stimulate learner-oriented content, instructor, peer, and technology forms of engagement, and boost interactivity depending on the willingness of learners and instructors. The review also finds technological challenges that concern designing learning environments and integrating intelligent systems, analytical tools and analysis, system models and ontology, and mobile and social media applications. The review suggests areas for future research involving smart classroom design for continuity and consistency, quality attributes of smart classrooms, efficiency and sustainability of smart classroom infrastructure, and the development of a smart classroom modelling language.}
}
@article{REISENZEIN20096,
title = {Emotions as metarepresentational states of mind: Naturalizing the belief–desire theory of emotion},
journal = {Cognitive Systems Research},
volume = {10},
number = {1},
pages = {6-20},
year = {2009},
note = {Modeling the Cognitive Antecedents and Consequences of Emotion},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2008.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041708000272},
author = {Rainer Reisenzein},
keywords = {Emotion, Belief–desire theory, Metacognition, Affective computing, BDI},
abstract = {Describes the outlines of a computational explication of the belief–desire theory of emotion, a variant of cognitive emotion theory. According to the proposed explication, a core subset of emotions including surprise are nonconceptual products of hardwired mechanisms whose primary function is to subserve the monitoring and updating of the central representational system of humans, the belief–desire system. The posited emotion-producing mechanisms are analogous to sensory transducers; however, instead of sensing the world, they sense the state of the belief–desire system and signal important changes in this system, in particular the fulfillment and frustration of desires and the confirmation and disconfirmation of beliefs. Because emotions represent this information about the state of the representational system in a nonconceptual format, emotions are nonconceptual metarepresentations. It is argued that this theory of emotions provides for a deepened understanding of the role of emotions in cognitive systems and solves several problems of psychological emotion theory.}
}
@article{HORVATH2015161,
title = {Ubiquitous computer aided design: A broken promise or a Sleeping Beauty?},
journal = {Computer-Aided Design},
volume = {59},
pages = {161-175},
year = {2015},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2014.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0010448514002358},
author = {Imre Horváth and Regine W. Vroom},
keywords = {Ubiquitous computing, Computer aided design, Ubiquitous design enablers, Competing technology exploitation, Ubiquitous CAD applications},
abstract = {As a novel computational approach, ubiquitous computing was emerging at the beginning of the 1980s and has reached a rather mature level by now. It assumes that computing can be available anywhere, anytime and in any context due to technological developments, social demands and calm implementations. Over the years, the opportunities of this computing paradigm have been explored and the benefits have been exploited successfully in many application fields. This survey paper addresses ubiquitous computing from the perspective of enabling computer aided design. The specific objectives of the reported survey are to: (i) give an overall account of the current status of ubiquitous computing and technologies, (ii) cast light on how ubiquitous computing has influenced the development of CAD systems, tools, and methods, and (iii) critically investigate future development opportunities of ubiquitous computing enabled computer aided design. First, the paper discusses the principles and typical technologies of ubiquitous computing. Then, the development and spectrum of the so-called standard computer aided design tasks are analyzed from a computational point of view. Afterwards, the already implemented design enabling functionalities are discussed and some additional functional possibilities are considered. The literature provides evidence that ubiquitous computing has not managed to revolutionize the methodologies or the systems of computer aided design so far, though many researchers intensively studied the affordances and the application possibilities of ubiquitous technologies. One reason is that ubiquitous computing technologies had in the last two decades to compete with other kinds of computational technologies, such as high-capacity computing, high-speed networking, immersive virtual reality, knowledge ontologies, smart software agents, mobile communication, etc., which had a much stronger influence on the development of computer aided design methods and systems. In combination with the rather conservative and conventionalist industrial practice of CAD system development and application, this may explain why the ubiquitous computing revolution remained weak in computer aided design. The literature clearly indicates that application of ubiquitous technologies did not lead to radically new functionalities that could have been exploited by the concerned industries. Consequently, it seems to be possible that computer aided design simply steps over the paradigm of ubiquitous computing and expects new functionalities from the emerging new computing paradigms, such as brain–computer interfacing, cyber–physical computing, biological computing, or quantum computing.}
}
@article{2017iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {112},
pages = {iii-xvii},
year = {2017},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 21st International Conference, KES-20176-8 September 2017, Marseille, France},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(17)31783-0},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917317830}
}
@incollection{KIRK201771,
title = {Chapter 4 - Memory and data locality},
editor = {David B. Kirk and Wen-mei W. Hwu},
booktitle = {Programming Massively Parallel Processors (Third Edition)},
publisher = {Morgan Kaufmann},
edition = {Third Edition},
pages = {71-101},
year = {2017},
isbn = {978-0-12-811986-0},
doi = {https://doi.org/10.1016/B978-0-12-811986-0.00004-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128119860000042},
author = {David B. Kirk and Wen-mei W. Hwu},
keywords = {Memory bandwidth, memory-bound, on-chip memory, tiling, strip-mining, shared memory, private memory, scope, lifetime, occupancy},
abstract = {This chapter introduces the concepts of memory bound application. It uses matrix multiplication to illustrate opportunities for reducing the number of global memory accesses. It then introduces the tiling technique where barrier synchronization is used to coordinate the timing of executing threads for improved locality and reduced global memory accesses. The tiling techniques, however, involve additional complexities in boundary checks. The chapter uses matrix multiplication to illustrate the additional boundary checks needed for a tiled kernel to be applicable to arbitrary matrix sizes. The chapter concludes with an overview of how usage of shared memory and registers can affect the number of thread blocks that can be accommodated in each Streaming Multiprocessor.}
}
@article{KHALAJZADEH2025107570,
title = {Accessibility of low-code approaches: A systematic literature review},
journal = {Information and Software Technology},
volume = {177},
pages = {107570},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2024.107570},
url = {https://www.sciencedirect.com/science/article/pii/S0950584924001757},
author = {Hourieh Khalajzadeh and John Grundy},
keywords = {Systematic literature review, Low-code, Visual languages, Block-based programming, Accessibility},
abstract = {Context:
Model-driven approaches are increasingly used in different domains, such as education, finance and app development, in order to involve non-developers in the software development process. Such tools are hugely dependent on visual elements and thus might not be accessible for users with specific challenges, e.g., visual impairments.
Objectives:
To locate and analyse existing literature on the accessibility of low-code approaches, their strengths and weaknesses and key directions for future research.
Methods:
We carried out a systematic literature review and searched through five leading databases for primary studies. We used both quantitative and qualitative methods for data synthesis.
Results:
After reviewing and filtering 918 located studies, and conducting both backward and forward snowballing, we identified 38 primary studies that were included in our analysis. We found most papers focusing on accessibility of visual languages and block-based programming.
Conclusion:
Limited work has been done on improving low code programming environment accessibility. The findings of this systematic literature review will assist researchers and developers in understanding the accessibility issues in low-code approaches and what has been done so far to develop accessible approaches.}
}
@article{MELVILLE202198,
title = {Abstracts},
journal = {Historia Mathematica},
volume = {55},
pages = {98-114},
year = {2021},
issn = {0315-0860},
doi = {https://doi.org/10.1016/j.hm.2021.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0315086021000021},
author = {Duncan J. Melville and Laura Martini and Kim Plofker}
}
@article{SMITH1991251,
title = {The owl and the electric encyclopedia},
journal = {Artificial Intelligence},
volume = {47},
number = {1},
pages = {251-288},
year = {1991},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(91)90056-P},
url = {https://www.sciencedirect.com/science/article/pii/000437029190056P},
author = {Brian Cantwell Smith},
abstract = {A review of “On the thresholds of knowledge”, by D.B. Lenat and E.A. Feigenbaum.}
}
@article{LEECULTURA2022100355,
title = {Children’s play and problem-solving in motion-based learning technologies using a multi-modal mixed methods approach},
journal = {International Journal of Child-Computer Interaction},
volume = {31},
pages = {100355},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100355},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000647},
author = {Serena Lee-Cultura and Kshitij Sharma and Michail Giannakos},
keywords = {Multimodal data, MMLA, Learning Analytics, Sensors, Cognitive Load Theory, Educational Technologies, Embodied Interaction, Multi-Modal mixed methods approach},
abstract = {Motion-Based Learning Technologies (MBLT) offer a promising approach for integrating play and problem-solving behaviour within children’s learning. The proliferation of sensor technology has driven the field of learning technology towards the development of tools and methods that may benefit from the produced Multi-Modal Data (MMD). Such data can be used to uncover cognitive, affective and physiological processes during learning activities. Combining MMD with more traditionally exercised assessment tools, such as video content analysis, provides a more holistic understanding of children’s learning experiences and has the potential to enable the design of educational technologies capable of harmonising children’s cognitive, affective and physiological processes, while promoting appropriately balanced play and problem-solving efforts. However, the use of an MMD mixed methods approach that combines qualitative and MMD data to understand children’s behaviours during engagement with MBLT is rather unexplored. We present an in-situ study where 26 children, ages 10–12, solved a motion-based sorting task for learning geometry. We continuously and unobtrusively monitored children’s learning experiences using MMD collection via eye-trackers, wristbands, Kinect joint tracking, and a web camera. We devised SP3, a novel observational scheme that can be used to understand children’s solo interactions with MBLT, and applied it to identify and extract children’s evoked play and problem-solving behaviour. Collective analysis of the MMD and video codes provided explanations of children’s task performance through consideration of their holistic learning experience. Lastly, we applied predictive modelling to identify the synergies between various MMD measurements and children’s play and problem-solving behaviours. This research sheds light on the opportunities offered in the confluence of video coding (a traditional method in learning sciences) and MMD (an emerging method that leverages sensors proliferation) for investigating children’s behaviour with MBLT.}
}
@incollection{WANG2021157,
title = {Chapter 5 - Battery state-of-charge estimation methods},
editor = {Shunli Wang and Yongcun Fan and Daniel-Ioan Stroe and Carlos Fernandez and Chunmei Yu and Wen Cao and Zonghai Chen},
booktitle = {Battery System Modeling},
publisher = {Elsevier},
pages = {157-198},
year = {2021},
isbn = {978-0-323-90472-8},
doi = {https://doi.org/10.1016/B978-0-323-90472-8.00009-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323904728000093},
author = {Shunli Wang and Yongcun Fan and Daniel-Ioan Stroe and Carlos Fernandez and Chunmei Yu and Wen Cao and Zonghai Chen},
keywords = {State-of-charge estimation, Coordinate transformation, Binary iterative algorithm, Extended Kalman filtering, Equivalent modeling, Correction strategy, Thermal influencing effect, Time-varying current condition, Complex current rate verification},
abstract = {With the large-scale promotion of new energy vehicles, the demand for power batteries such as the lithium-ion type has increased. Its service lifespan is closely related to the service condition. The important embodiment of the service condition is the battery state of charge, which can reflect its residual capacity. Through accurate residual capacity, the battery application strategy can be planned to realize the battery operation of the best condition. The long service lifespan can be realized by adjusting the voltage and current. Therefore, real-time accurate state estimation has a significant effect on battery management. The extended Kalman filtering algorithm is introduced to estimate the state value under complex working conditions. The overview of the state-of-charge estimation is first conducted. After that, the equivalent modeling construction method is explored. The coordinate transformation treatment is implemented in the binary iterative calculation algorithm, according to which the algorithm is implemented. In the extended calculation process, the iterative prediction and correction strategies are introduced into the test. Consequently, the pulse-power characteristic test is conducted to obtain the estimation features, considering a thermal influencing effect, a time-varying current condition, and a complex current rate verification.}
}
@article{BARFAR2021113442,
title = {Peak cubes in service operations: Bringing multidimensionality into decision support systems},
journal = {Decision Support Systems},
volume = {140},
pages = {113442},
year = {2021},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2020.113442},
url = {https://www.sciencedirect.com/science/article/pii/S0167923620301974},
author = {Arash Barfar and Balaji Padmanabhan and Alan Hevner},
keywords = {Multidimensional decision support, Peak-end rule, Peak cubes, Pareto frontiers, Skylines, Shapley values},
abstract = {Companies like Ritz Carlton, Disney and Verizon are among many who have invested in analytics to improve their customers' service experiences with the firms. Extensive data are collected on all aspects of how customers interact or experience the products or services. Research has shown the importance of the “peak-end” rule in service design; that is, providing a customer with good “peak” service levels and “ending” the service experience with high quality can enhance customer satisfaction and build loyalty. However, previous studies have examined this phenomenon only in contexts with unidimensional service levels. We introduce peak cubes, which enable service designers and scholars to pinpoint prominent service levels in multidimensional service experience profiles—thereby extending current research on behavioral economics and service design to more general settings. Results indicate the potential of multidimensional peak-end models to better predict customer satisfaction in various service scenarios. Using Shapley values in coalitional game theory, the resulting models can also inform service designers about the quality dimensions that are critical from the perspective of multidimensional peak-end heuristic and customer satisfaction. Our research contributions and proposed methodology will enhance decision support systems with multidimensional capabilities and have applications to fields as diverse as service operations and healthcare.}
}
@incollection{2023861,
title = {Index},
editor = {Robert J Tierney and Fazal Rizvi and Kadriye Ercikan},
booktitle = {International Encyclopedia of Education (Fourth Edition)},
publisher = {Elsevier},
edition = {Fourth Edition},
address = {Oxford},
pages = {861-952},
year = {2023},
isbn = {978-0-12-818629-9},
doi = {https://doi.org/10.1016/B978-0-12-818630-5.18001-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186305180017}
}
@article{SALAJ2024298,
title = {Competencies for Smart City Challenges},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {3},
pages = {298-303},
year = {2024},
note = {22nd IFAC Conference on Technology, Culture and International Stability TECIS 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.07.167},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324002507},
author = {Alenka Temeljotov Salaj and Olav Torp and Elham Andalib},
keywords = {smart solutions, competencies, AI, education},
abstract = {It is acknowledged that technological innovation is needed in all sectors to cope with new demands. From social innovations, it introduces novel ideas, whether products, services, or models, to fulfil societal needs and foster new partnerships or collaborations. The aim is to enhance social interactions and elevate human well-being. Development of cutting-edge digital technologies is reality. The challenge is on human resource side, how quickly we can prepare employees to adapt to the requirements of Industry 4.0 and Society 5.0. In the paper, the new competencies were identified with the business stakeholders by conducting a survey among industry partners to recognize the requirements for the future labor market. The stakeholders in the construction field act as target groups for monitoring and development of the competencies. The focus of the result part is on the competencies companies mostly miss from their employees from digital perspectives, e.g. reason to hire highly educated people, training possibilities for digitally upskilling employees, lacking appropriate competencies (critical thinking, systems and analytical thinking, information management, advanced computer/IT skills (AI), ensuring security). Digital skills Advanced data/IT skills were the competencies in that companies defined as key competencies expected to be developed in 21st-century higher education employees. It is highly important to consider the job market needs for development and to adopt the engineering education system to be responsive to the needs of labor market.}
}
@article{WOOD1990317,
title = {Verification of rule-based expert systems},
journal = {Expert Systems with Applications},
volume = {1},
number = {3},
pages = {317-322},
year = {1990},
note = {Special Issue: Verification and Validation of Knowledge-Based Systems},
issn = {0957-4174},
doi = {https://doi.org/10.1016/0957-4174(90)90010-R},
url = {https://www.sciencedirect.com/science/article/pii/095741749090010R},
author = {William T. Wood and Elaine N. Frankowski},
abstract = {We are investigating the problem of establishing computational rather than syntactic properties of forward-chaining rule-based expert systems. We model an expert system as a computation on working memory, define its execution semantics, and present proof techniques suitable for those semantics. Specifically, we model execution as a Dijkstra guarded-do construct, and use Dijkstra's Invariance Theorem and weakest precondition predicate transformers to establish invariants (safety properties) and postconditions (liveness properties). Our approach is an application of well-developed methods developed by Dijkstra and others for the verification of procedural programs. This paper introduces the approach, reports some initial results, and discusses future work.}
}
@article{LI2022100980,
title = {RETRACTED: Studying creativity and critical thinking skills at university and students' future income},
journal = {Thinking Skills and Creativity},
volume = {43},
pages = {100980},
year = {2022},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100980},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121001954},
author = {Weijuan Li},
abstract = {This article has been retracted: please see Elsevier Policy on Article Withdrawal (https://www.elsevier.com/about/our-business/policies/article-withdrawal). This article has been retracted at the request of the Editors-in-Chief. After a thorough investigation, the Editors have concluded that the acceptance of this article was partly based upon the positive advice of one illegitimate reviewer report. The report was submitted from an email account which was provided to the journal as a suggested reviewer during the submission of the article. Although purportedly a real reviewer account, the Editors have concluded that this was not of an appropriate, independent reviewer. This manipulation of the peer-review process represents a clear violation of the fundamentals of peer review, our publishing policies, and publishing ethics standards. Apologies are offered to the reviewer whose identity was assumed and to the readers of the journal that this deception was not detected during the submission process.}
}
@incollection{KOLTAY20161,
title = {Chapter 1 - Shifting Research Paradigms Toward Research 2.0},
editor = {Tibor Koltay and Sonja Špiranec and László Z. Karvalics},
booktitle = {Research 2.0 and the Future of Information Literacy},
publisher = {Chandos Publishing},
pages = {1-59},
year = {2016},
isbn = {978-0-08-100075-5},
doi = {https://doi.org/10.1016/B978-0-08-100075-5.00001-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780081000755000018},
author = {Tibor Koltay and Sonja Špiranec and László Z. Karvalics},
keywords = {Research paradigms, Research 2.0, Researchers’ skills and abilities, Open science, Open access, The data-intensive paradigm of scientific research, Alternative metrics of scientific output},
abstract = {This chapter discusses how Research 2.0 came into existence and how it developed into a leading paradigm of our era. This requires an outline of the socio-technical changes brought about by the development and widespread use of information and communications technologies, based on computers and leading to the appearance of social media. There is no one who would deny that researchers are central figures in research, so their skills and abilities will be briefly examined. Research 2.0 is closely connected to the idea of open science that will be described, giving especial attention to its main constituent that is open access. Open science also comprises the data-intensive paradigm of scientific research, which we consider in detail. A wider uptake of Research 2.0 is inhibited by a number of the factors of scholarly communication, so we will enumerate them.}
}
@article{GAJDZIK202268,
title = {Smart Production Workers in Terms of Creativity and Innovation: The Implication for Open Innovation},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
volume = {8},
number = {2},
pages = {68},
year = {2022},
issn = {2199-8531},
doi = {https://doi.org/10.3390/joitmc8020068},
url = {https://www.sciencedirect.com/science/article/pii/S2199853122000099},
author = {Bożena Gajdzik and Radosław Wolniak},
keywords = {Industry 4.0 (I4.0), skills, education, steel sector, innovativeness, creativity, open innovation},
abstract = {ABSTRACT
This paper presents a framework of employee skills and competencies useful for developing occupational profiles for employees of companies transitioning towards Industry 4.0. The paper consists of a discussion of the theoretical and practical parts of case studies. The theoretical portion was created on the basis of a review of scientific literature and research studies regarding the competencies and skills of employees in the ongoing fourth industrial revolution. This part focuses on the skills profile of an Industry 4.0 employee and an Operator 4.0 (O4.0) from a creativity and innovativeness point of view. The link between the theoretical part and the case study analysis was a general framework for building the competencies and skills of the steelworker in the emerging fourth industrial revolution. The case study analysis covered the framework of competencies and skills of a metallurgist in smart manufacturing built into the organization of steel mills. Recruitment offers of a steel company implementing smart manufacturing (SM) projects and educational programmes of technical universities in the field of metallurgy were analysed. The aim of the study was to develop a framework for the profile of an employee working in an innovative company transforming to I4.0. The publication posed the following research questions (purposes/hypotheses): P1. To what extent do Polish companies in the metallurgical sector pay attention to creativity and innovation issues when looking for employees? P2. To what extent do the profile (portfolio) of metallurgy graduates of Polish technical universities turn their attention to the issues related to creativity and innovation?}
}
@article{ROBSON2022101018,
title = {Searching for the principles of a less artificial A.I.},
journal = {Informatics in Medicine Unlocked},
volume = {32},
pages = {101018},
year = {2022},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2022.101018},
url = {https://www.sciencedirect.com/science/article/pii/S2352914822001617},
author = {B. Robson and G. Ochoa-Vargas},
keywords = {AI, Algorithms, X factor, Emergent properties, Consciousness, Quantum effects},
abstract = {What would it take to build a computer physician that can take its place amongst human peers? Currently, Neural Nets, especially as so-called “Deep Learning” nets, dominate what is popularly called “Artificial Intelligence”, but to many critics they seem to be little more than powerful data-analytic tools inspired by some of the more basic functions and regions of the human brain such as those involved in early processes in biological vision, classification, and categorization. The deeper nature of human intelligence as the term is normally meant, including relating to consciousness, has been the domain of philosophers, psychologists, and some neuroscientists. Now, attention is turning to neuronal mechanisms in humans and simpler organisms as a basis of a truer AI with far greater potential. Arguably, the approach required should be rooted in information theory and algorithmic science. But as discussed in this paper, caution is required: “just any old information” might not do. The information might need to be of a particular dynamical and actioning nature, and that might significantly impact the kind of computation and computer hardware required. Overall, however, the authors do not favor emergent properties such as those based on complexity and quantum effects. Despite the possible difficulties, such studies could, in return, have substantial benefits for biology and medicine beyond the computational tools that they produce to serve those disciplines.}
}
@article{BARRICELLI2019101,
title = {End-user development, end-user programming and end-user software engineering: A systematic mapping study},
journal = {Journal of Systems and Software},
volume = {149},
pages = {101-137},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.11.041},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218302577},
author = {Barbara Rita Barricelli and Fabio Cassano and Daniela Fogli and Antonio Piccinno},
keywords = {Systematic mapping study, End-user development, End-user programming, End-user software engineering},
abstract = {End-User Development (EUD), End-Programming (EUP) and End-User Software Engineering (EUSE) are three related research fields that study methods and techniques for empowering end users to modify and create digital artifacts. This paper presents a systematic mapping study aimed at identifying and classifying scientific literature about EUD, EUP and EUSE in the time range January 2000–May 2017. We selected 165 papers found through a manual selection of papers from specific conferences, journal special issues, and books, integrated with an automatic search on the most important digital libraries. The answer to our research question was built through a classification of the selected papers on seven dimensions: type of approach, interaction technique, phase in which the approach is adopted, application domain, target use, class of users, and type of evaluation. Our findings suggest that EUD, EUP and EUSE are active research topics not only in Human–Computer Interaction, but also in other research communities. However, little cross-fertilization exists among the three themes, as well as unifying frameworks and approaches for guiding novice designers and practitioners. Other findings highlight trends and gaps related to the analysis’ dimensions, which have implications on the design of future tools and suggest open issues for further investigations.}
}
@article{ALDAAJEH2022102754,
title = {The role of national cybersecurity strategies on the improvement of cybersecurity education},
journal = {Computers & Security},
volume = {119},
pages = {102754},
year = {2022},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2022.102754},
url = {https://www.sciencedirect.com/science/article/pii/S0167404822001493},
author = {Saleh AlDaajeh and Heba Saleous and Saed Alrabaee and Ezedin Barka and Frank Breitinger and Kim-Kwang {Raymond Choo}},
keywords = {Cybersecurity strategic plan, Cybersecurity education, NICE framework, Cybersecurity curricula, GQO+Strategies paradigm},
abstract = {Digital information and telecommunication technologies have not only become essential to individuals’ daily lives but also to a nation’s sustained economic growth, societal well-being, critical infrastructure resilience, and national security. Consequently, the protection of a nation’s cyber sovereignty from malicious acts is a major concern. This signifies the importance of cybersecurity education in facilitating the creation of a resilient cybersecurity ecosystem and in supporting cyber sovereignty. This study reviews a sample from world-leading countries National Cybersecurity Strategic Plans (NCSPs) and analyzes the associated existing cybersecurity education and training improvement initiatives. Furthermore, a proposal to adopt the Goal-Question-Outcomes(GQO)+Strategies paradigm into cybersecurity education and training programs curricula improvement to national cybersecurity strategic goals is presented. The proposal maps cybersecurity strategic goals to cybersecurity skills and competencies using the National Initiative for Cybersecurity Education (NICE) framework. The newly proposed cybersecurity education and training programs’ curricula learning outcomes were generated from the GQO+Strategies paradigm based on the three major cybersecurity strategic goals: Development of secure digital and information technology infrastructure and services, defending from sophisticated cyber threats, and enrichment of individuals’ cybersecurity maturity and awareness. It is highly recommended that cybersecurity university program administrators utilize the proposed GQO+Strategies to align their program’s curriculum to NCSP. Hence, closing the gap that exists with the relevant skills and sustain national cybersecurity workforces.}
}
@article{BRINSON2015218,
title = {Learning outcome achievement in non-traditional (virtual and remote) versus traditional (hands-on) laboratories: A review of the empirical research},
journal = {Computers & Education},
volume = {87},
pages = {218-237},
year = {2015},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2015.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0360131515300087},
author = {James R. Brinson},
keywords = {Distance education and telelearning, Distributed learning environments, Evaluation of CAL systems, Simulations, Teaching/learning strategies},
abstract = {This review presents the first attempt to synthesize recent (post-2005) empirical studies that focus on directly comparing learning outcome achievement using traditional lab (TL; hands-on) and non-traditional lab (NTL; virtual and remote) participants as experimental groups. Findings suggest that most studies reviewed (n = 50, 89%) demonstrate student learning outcome achievement is equal or higher in NTL versus TL across all learning outcome categories (knowledge and understanding, inquiry skills, practical skills, perception, analytical skills, and social and scientific communication), though the majority of studies (n = 53, 95%) focused on outcomes related to content knowledge, with most studies (n = 40, 71%) employing quizzes and tests as the assessment instrument. Scientific inquiry skills was the least assessed learning objective (n = 4, 7%), and lab reports/written assignments (n = 5, 9%) and practical exams (n = 5, 9%) were the least common assessment instrument. The results of this review raise several important concerns and questions to be addressed by future research.}
}
@incollection{2020729,
title = {Index},
editor = {Steven Pritzker and Mark Runco},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {729-744},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-815614-8.18001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128156148180016}
}
@article{WAITE2020103838,
title = {Difficulties with design: The challenges of teaching design in K-5 programming},
journal = {Computers & Education},
volume = {150},
pages = {103838},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103838},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520300385},
author = {Jane Waite and Paul Curzon and William Marsh and Sue Sentance},
keywords = {K-5 computing education, Teachers, Design, Programming},
abstract = {Teachers in England are required to ensure that learners from the age of five are taught about algorithms and program design. Yet, there is evidence that despite teachers reporting that design is important, they are not converting this into classroom practice. This paper describes a survey study, in which we explored teachers’ difficulties in using design. We surveyed 207 teachers asking them free-text questions on their use of design in teaching programming and their views of pupils’ responses to using design. In the survey, we also investigated teachers’ understanding of the term algorithm, an essential concept which may be a contributing factor in their difficulties with design. We provide underpinning data on the difficulties of using design that teachers of pupils aged from 5 to 11 years old (Grades K to 5) have in teaching programming. Difficulties with design identified include pupil resistance, a lack of time, a lack of pupil and teacher expertise, conflicting pedagogical choices and a general confusion over what an algorithm is. There were statistically significant differences in selection of the term ‘algorithm’ to describe programming artefacts whether a teacher was a specialist or a generalist, what training they had received on programming or design, the age group taught and programming language used. Teachers were more likely to call a complex code snippet an ‘algorithm’ than a simpler one and more likely to select the term to describe code snippets than a design artefact. We make suggestions of how to alleviate the problems including that teachers are introduced to the idea of ambiguous representations of algorithms and a process which refines the representation from ambiguous to unambiguous as the design progresses.}
}
@article{CANNAVO2020102450,
title = {A visual editing tool supporting the production of 3D interactive graphics assets for public exhibitions},
journal = {International Journal of Human-Computer Studies},
volume = {141},
pages = {102450},
year = {2020},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2020.102450},
url = {https://www.sciencedirect.com/science/article/pii/S1071581920300525},
author = {Alberto Cannavò and Francesco De Pace and Federico Salaroglio and Fabrizio Lamberti},
keywords = {End-user development (EUD), Visual programming languages (VPLs), Interactive assets, 3D Graphics, Virtual reality (VR), Augmented reality (AR), Human-machine interaction (HMI), Natural user interfaces (NUIs)},
abstract = {The introduction of interactive assets in public exhibitions is capable to significantly enhance the visitors’ user experience. However, the creation of interactive applications could represent a challenging task, especially for users lacking computer skills. Visual programming languages (VPLs) – one of the instruments belonging to the broad categories of methods and tools devised to support end-user development (EUD) – promise to offer an intuitive way to overcome these limitations, by providing easy-to-use and efficient interfaces for encoding applications’ logic. Moving from these considerations, this paper first analyses pros and cons of tools devised so far to support the generation of interactive contents. Then, it presents the design of a new tool named Visual Scene Editor (VSE), which allows users with little to no programming skills to create 3D interactive applications by combining available assets through an interactive, visual process. Both objective and subjective measurements have been collected with both skilled and unskilled users to evaluate the performance of the proposed tool. A comparison with existing solutions shows a reduction in the time required to complete the assigned tasks, of the complexity of the logic created, as well as of the number of errors made, confirming the suitability of the VSE for the said purpose.}
}
@article{WEINTROP2019103646,
title = {Transitioning from introductory block-based and text-based environments to professional programming languages in high school computer science classrooms},
journal = {Computers & Education},
volume = {142},
pages = {103646},
year = {2019},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2019.103646},
url = {https://www.sciencedirect.com/science/article/pii/S036013151930199X},
author = {David Weintrop and Uri Wilensky},
keywords = {Evaluation of CAL systems, Interactive learning environments, Programming and programming languages, Secondary education, Teaching/learning strategies},
abstract = {Block-based programming languages are becoming increasingly common in introductory computer science classrooms across the K-12 spectrum. One justification for the use of block-based environments in formal educational settings is the idea that the concepts and practices developed using these introductory tools will prepare learners for future computer science learning opportunities. This view is built on the assumption that the attitudinal and conceptual learning gains made while working in the introductory block-based environments will transfer to conventional text-based programming languages. To test this hypothesis, this paper presents the results of a quasi-experimental classroom study in which programming novices spent five-week using either a block-based or text-based programming environment. After five weeks in the introductory tool, students transitioned to Java, a conventional text-based programming language. The study followed students for 10 weeks after the transition. Over the course of the 15-week study, attitudinal and conceptual assessments were administered and student-authored programs were collected. Conceptual learning, attitudinal shifts, and changes in programming practices were analyzed to evaluate how introductory modality impacted learners as they transitioned to a professional, text-based programming language. The findings from this study build on earlier work that found a difference in performance on content assessments after the introductory portion of the study (Weintrop & Wilensky, 2017a). This paper shows the difference in conceptual learning that emerged after five weeks between the block-based and text-based conditions fades after 10 weeks in Java. No differences in programming practices were found between the two conditions while working in Java. Likewise, differences in attitudinal measures that emerged after working in the introductory environments also faded after 10 weeks in Java, resulting in no difference between the conditions after 15 weeks. The contribution of this work is to advance our understanding of the benefits and limits of block-based programming tools in preparing students for future computer science learning. This paper presents the first quasi-experimental study of the transfer of knowledge between block-based and text-based environments in a high school setting. The lack of significant differences between the two introductory programming modalities after learners transition to professional programming languages is discussed along with the implications of these findings for computer science education researchers and educators, as well as for the broader community of researchers studying the role of technology in education.}
}
@incollection{FISHWICK2017557,
title = {Chapter 21 - Aesthetic Computing*},
editor = {Myounghoon Jeon},
booktitle = {Emotions and Affect in Human Factors and Human-Computer Interaction},
publisher = {Academic Press},
address = {San Diego},
pages = {557-587},
year = {2017},
isbn = {978-0-12-801851-4},
doi = {https://doi.org/10.1016/B978-0-12-801851-4.00021-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128018514000215},
author = {Paul A. Fishwick}
}
@article{BLACKWELL201952,
title = {Fifty years of the psychology of programming},
journal = {International Journal of Human-Computer Studies},
volume = {131},
pages = {52-63},
year = {2019},
note = {50 years of the International Journal of Human-Computer Studies. Reflections on the past, present and future of human-centred technologies},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2019.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S1071581919300795},
author = {Alan F. Blackwell and Marian Petre and Luke Church},
keywords = {Psychology of programming, Programming languages, Attention investment},
abstract = {This paper reflects on the evolution (past, present and future) of the ‘psychology of programming' over the 50 year period of this anniversary issue. The International Journal of Human-Computer Studies (IJHCS) has been a key venue for much seminal work in this field, including its first foundations, and we review the changing research concerns seen in publications over these five decades. We relate this thematic evolution to research taking place over the same period within more specialist communities, especially the Psychology of Programming Interest Group (PPIG), the Empirical Studies of Programming series (ESP), and the ongoing community in Visual Languages and Human-Centric Computing (VL/HCC). Many other communities have interacted with psychology of programming, both influenced by research published within the specialist groups, and in turn influencing research priorities. We end with an overview of the core theories that have been developed over this period, as an introductory resource for new researchers, and also with the authors’ own analysis of key priorities for future research.}
}
@article{WANG2017182,
title = {Bee and Frog Co-Evolution Algorithm and its application},
journal = {Applied Soft Computing},
volume = {56},
pages = {182-198},
year = {2017},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2017.02.030},
url = {https://www.sciencedirect.com/science/article/pii/S1568494617301096},
author = {Hong-bo Wang and Xue-Na Ren and Xu-yan Tu},
keywords = {Artificial Bee Colony, Shuffled Frog Leaping, Evolutionary computing, Resources scheduling},
abstract = {In order to obtain better generalization abilities and mitigate the impacts of the best and worst individuals during the process of optimization, this paper suggests Bee and Frog Co-Evolution Algorithm (abbreviation for BFCEA), which combines Mnemonic Shuffled Frog Leaping algorithm With Cooperation and Mutation (abbreviation for MSFLACM) with improved Artificial Bee Colony (abbreviation for ABC). The contrast experimental study about different iteratively updating strategies was acted in BFCEA, including strategy of integrating with ABC, regeneration of the worst frog and its leaping step. The key techniques focus on the first 10 and the last 10 frogs evolving ABC in BFCEA, namely, the synchronous renewal strategy for those winner and loser should be applied, after certain G times’ MSFLACM-running, so as to avoid trapping local optimum in later stage. The ABC evolution process will be called between all memes’ completing inner iteration and all frogs’ outer shuffling, the crossover operation is removed from MSFLACM for its little effect on time-consuming and convergence in this novel algorithm. Besides, in ABC, the scout bee is generated by Cauchy mutating instead at random. The performance of proposed approach is examined by well-known 16 numerical benchmark functions, and obtained results are compared with basic Shuffled Frog Leaping algorithm (abbreviation for SFLA), ABC and four other variants. The experimental results and related application in cloud resource scheduling show that the proposed algorithm is effective and outperforms other variants, in terms of solution quality and convergence, and the improved variants can obtain a lower degree of unbalanced load and relatively stable scheduling strategy of resources in complicated cloud computing environment.}
}
@article{ANTLE2022100374,
title = {Research in Child–Computer Interaction: Provocations and envisioning future directions},
journal = {International Journal of Child-Computer Interaction},
volume = {32},
pages = {100374},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100374},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000787},
author = {Alissa N. Antle and Juan Pablo Hourcade},
keywords = {Child–computer interaction, Review, Future, Vision, Research agenda, Provocations},
abstract = {In the 21st century the academic field of Child–Computer Interaction (CCI) arose alongside burgeoning interactive technology and digital media industries that targeted children. We believe that the field of CCIU is at an important point in its development, analogous to when a child becomes a teen. Over the last few years we have each had many informal conversations with other CCI researchers in which we discuss issues such as, what is our responsibility as researchers beyond academe? What values underlie our conceptions of a ”good” childhood and the role of interactive technology in it? And, how do we ensure that our field continues to grow and evolve in ways that are consistent with our responsibilities and values? To address these and other complex questions that have been drawing our attention we came together to reflect, discuss and create a position paper for our community, in which we outline some of the issues we see facing our community at this time. To inform our deliberations with opinions beyond our own we conducted an informal consultation with 25 members of the CCI community. Our responders spanned junior to senior researchers, represented diverse geographies and included industry practitioners. These diverse responses provided further content for our reflections, and helped us see perspectives beyond our own. The result of this informal process is this speculative paper in which we propose a series of seven provocations that aim to disrupt some of the normative assumptions held in our field. Our goal in doing this is to open up dialogue in our community about these issues and promote consideration of the alternative visions we present for where we might focus our attention and efforts. We see our contribution not as truth or a definitive statement of a vision for the field, but rather as our opinion about some of the complex issues we face and that we think should be considered through dialogue as we move into the next phase of our development as an academic and scholarly community. We believe that it is urgent and critical for our field that we take up these questions, explore diverse perspectives, and critically work towards decisions and actions that will define our identity and the value of our contributions as we move forward into the next 20 years of research in CCI.}
}
@article{PINSKI2024100062,
title = {AI literacy for users – A comprehensive review and future research directions of learning methods, components, and effects},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100062},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100062},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000227},
author = {Marc Pinski and Alexander Benlian},
keywords = {Systematic literature review, Scoping literature review, Artificial intelligence literacy, Learning methods, AI literacy components, AI literacy effects},
abstract = {The rapid advancement of artificial intelligence (AI) has brought transformative changes to various aspects of human life, leading to an exponential increase in the number of AI users. The broad access and usage of AI enable immense benefits but also give rise to significant challenges. One way for AI users to address these challenges is to develop AI literacy, referring to human proficiency in different subject areas of AI that enable purposeful, efficient, and ethical usage of AI technologies. This study aims to comprehensively understand and structure the research on AI literacy for AI users through a systematic, scoping literature review. Therefore, we synthesize the literature, provide a conceptual framework, and develop a research agenda. Our review paper holistically assesses the fragmented AI literacy research landscape (68 papers) while critically examining its specificity to different user groups and its distinction from other technology literacies, exposing that research efforts are partly not well integrated. We organize our findings in an overarching conceptual framework structured along the learning methods leading to, the components constituting, and the effects stemming from AI literacy. Our research agenda – oriented along the developed conceptual framework – sheds light on the most promising research opportunities to prepare AI users for an AI-powered future of work and society.}
}
@article{KUGEL1986137,
title = {Thinking may be more than computing},
journal = {Cognition},
volume = {22},
number = {2},
pages = {137-198},
year = {1986},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(86)90057-0},
url = {https://www.sciencedirect.com/science/article/pii/0010027786900570},
author = {Peter Kugel},
abstract = {The uncomputable parts of thinking (if there are any) can be studied in much the same spirit that Turing (1950) suggested for the study of its computable parts. We can develop precise accounts of cognitive processes that, although they involve more than computing, can still be modelled on the machines we call ‘computers’. In this paper, I want to suggest some ways that this might be done, using ideas from the mathematical theory of uncomputability (or Recursion Theory). And I want to suggest some uses to which the resulting models might be put. (The reader more interested in the models and their uses than the mathematics and its theorems, might want to skim or skip the mathematical parts.)
Résumé
Les éléments du raisonnement ne relevant pas du calculable (uncomputable), (s'il en existe), peuvent s'etudier dans I'optique suggérée par Turing (1950) pour l'étude des éléments calculables (computable). On peut rendre compte avec précision des processus cognitifs qui, bien qu'impliquant plus que des calculs, peuvent cependant être modélisés sur ordinateurs. Dans cet article l'auteur propose des modalités pour arriver à ces résultats en utilisant les idées de la théorie mathdmatique de la Récursion (uncomputability). L'auteur suggère aussi des utilisations pour les modéles que en découlent (Il est possible au lecteur plus intéressé par les modèles et leurs utilisations que par les mathématiques et les théorèmes de passer rapidement sur la partie mathématique ou d'omettre de la lire.)}
}
@article{PDELOPE2021100429,
title = {A novel UML-based methodology for modeling adventure-based educational games},
journal = {Entertainment Computing},
volume = {38},
pages = {100429},
year = {2021},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2021.100429},
url = {https://www.sciencedirect.com/science/article/pii/S1875952121000264},
author = {Rafael {P. De Lope} and Nuria Medina-Medina and Matías Urbieta and Alejandra B. Lliteras and Antonio {Mora García}},
keywords = {Computers and education, Adventure-based educational games, Design tools and techniques, Modelling language},
abstract = {In the last years, serious games have been successfully exploited in different areas. However, in spite of the powerful tool that this kind of video games has proved to be in the classroom, a few methodological efforts have been conducted in order to involve pedagogues or educators in the design loop of these games or, one step further, include students in the co-design process to promote learning through design as a context. With this objective, this paper presents a set of metamodels that could facilitate the conceptual design of this type of games. To this end, a complete graphical notation based on the UML standard (with adaptations) is defined for representing the components of this type of games; having in mind to improve the collaboration between the team of educators/students and the technical team during the design process. Finally, the design diagrams defined during the production of a specific serious game, titled Uranus, are illustrated, in order to show the feasibility of the proposal. In addition, a validation experience was conducted with educators and computer engineering students in order to test the value of the proposed graphic notation to design educational games.}
}
@incollection{KIRK2017305,
title = {Chapter 14 - Application case study—non-Cartesian magnetic resonance imaging: An introduction to statistical estimation methods},
editor = {David B. Kirk and Wen-mei W. Hwu},
booktitle = {Programming Massively Parallel Processors (Third Edition)},
publisher = {Morgan Kaufmann},
edition = {Third Edition},
pages = {305-329},
year = {2017},
isbn = {978-0-12-811986-0},
doi = {https://doi.org/10.1016/B978-0-12-811986-0.00014-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128119860000145},
author = {David B. Kirk and Wen-mei W. Hwu},
keywords = {Statistical estimation methods, matrix–vector multiplication, linear solvers, iterative methods, MRI, non-Cartesian scan trajectory, error bounds, signal-to-noise ratio, trigonometry functions, floating-point precision and accuracy},
abstract = {This chapter presents an application study on using CUDA C and GPU computing to accelerate an iterative solver for reconstruction of an MRI image from Non-Cartesian scan data. It covers the process of identifying the appropriate type of parallelism, loop transformations, mapping data into constant memory, mapping data into registers, data layout transformations, using special hardware instructions, and experimental tuning. It also demonstrates a process of validating the design choices with domain-specific criteria.}
}
@incollection{2017535,
title = {Index},
editor = {David B. Kirk and Wen-mei W. Hwu},
booktitle = {Programming Massively Parallel Processors (Third Edition)},
publisher = {Morgan Kaufmann},
edition = {Third Edition},
pages = {535-550},
year = {2017},
isbn = {978-0-12-811986-0},
doi = {https://doi.org/10.1016/B978-0-12-811986-0.00038-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128119860000388}
}
@incollection{SEYMOURE2021315,
title = {Chapter 18 - Conservation behavior: effects of light pollution on insects},
editor = {Heather Zimbler-DeLorenzo and Susan W. Margulis},
booktitle = {Exploring Animal Behavior in Laboratory and Field (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {315-335},
year = {2021},
isbn = {978-0-12-821410-7},
doi = {https://doi.org/10.1016/B978-0-12-821410-7.00001-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128214107000017},
author = {Brett Seymoure and Elizabeth K. Peterson and Rachel Y. Chock},
keywords = {Activity, Conservation behavior, Foraging, Light pollution, Madagascar hissing cockroach},
abstract = {In this experiment, we will study the impact of light pollution on the activity and foraging behaviors using Madagascar hissing cockroaches as the model system. You will develop your own hypotheses using the background information provided. You will then test your hypotheses, evaluate the results of your experiment, and revise and retest your experiment up to three times.}
}
@article{CHEN2020100002,
title = {Application and theory gaps during the rise of Artificial Intelligence in Education},
journal = {Computers and Education: Artificial Intelligence},
volume = {1},
pages = {100002},
year = {2020},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2020.100002},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X20300023},
author = {Xieling Chen and Haoran Xie and Di Zou and Gwo-Jen Hwang},
keywords = {Artificial intelligence in education, Systematic review, Application gap, Theory gap},
abstract = {Considering the increasing importance of Artificial Intelligence in Education (AIEd) and the absence of a comprehensive review on it, this research aims to conduct a comprehensive and systematic review of influential AIEd studies. We analyzed 45 articles in terms of annual distribution, leading journals, institutions, countries/regions, the most frequently used terms, as well as theories and technologies adopted. We also evaluated definitions of AIEd from broad and narrow perspectives and clarified the relationship among AIEd, Educational Data Mining, Computer-Based Education, and Learning Analytics. Results indicated that: 1) there was a continuingly increasing interest in and impact of AIEd research; 2) little work had been conducted to bring deep learning technologies into educational contexts; 3) traditional AI technologies, such as natural language processing were commonly adopted in educational contexts, while more advanced techniques were rarely adopted, 4) there was a lack of studies that both employ AI technologies and engage deeply with educational theories. Findings suggested scholars to 1) seek the potential of applying AI in physical classroom settings; 2) spare efforts to recognize detailed entailment relationships between learners’ answers and the desired conceptual understanding within intelligent tutoring systems; 3) pay more attention to the adoption of advanced deep learning algorithms such as generative adversarial network and deep neural network; 4) seek the potential of NLP in promoting precision or personalized education; 5) combine biomedical detection and imaging technologies such as electroencephalogram, and target at issues regarding learners’ during the learning process; and 6) closely incorporate the application of AI technologies with educational theories.}
}
@article{CRUJEIRAS2013208,
title = {Challenges in the implementation of a competency-based curriculum in Spain},
journal = {Thinking Skills and Creativity},
volume = {10},
pages = {208-220},
year = {2013},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2013.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S187118711300045X},
author = {Beatriz Crujeiras and María Pilar Jiménez-Aleixandre},
keywords = {Scientific competency, Epistemic practices, Higher-order thinking, Policy},
abstract = {This paper addresses some of the challenges involved in implementing the new approach established in the Spanish National Curriculum in 2006, which brought as a major change a focus on the development of key competencies. The paper focuses on scientific competency and the challenges involved in the itinerary from policy documents to classrooms are addressed in three sections: (i) an analysis is made of the changes in the science curriculum as a consequence of the emphasis on scientific competency, comparing the assessment criteria in the previous and current steering documents; (ii) trends in teacher education are discussed; (iii) the findings of the diagnostic evaluation are analyzed. The paper is framed in a theoretical approach, viewing students’ participation in scientific practices, and the development of higher-order thinking as necessary goals of science education. We argue that the focus on competencies, characterized as the ability to apply knowledge and skills in new contexts, involves a major change towards knowledge transfer and higher-order thinking skills. Some issues emerging from the analysis relate to the implications of assessment criteria and the challenges involved in its implementation, to the trends in teacher professional development and the difficulties related to the current economic crisis and to the results of the diagnostic evaluation and time frame needed for reforms to have an impact. It is argued that the development of both competencies and higher-order thinking requires students’ prolonged engagement.}
}
@article{CHIU2013142,
title = {WISEngineering: Supporting precollege engineering design and mathematical understanding},
journal = {Computers & Education},
volume = {67},
pages = {142-155},
year = {2013},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2013.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0360131513000936},
author = {Jennifer L. Chiu and Peter T. Malcolm and Deborah Hecht and Crystal J. DeJaegher and Edward A. Pan and Michael Bradley and M. David Burghardt},
keywords = {Evaluation of CAL systems, Improving classroom teaching, Interactive learning environments, Interdisciplinary projects, Multimedia/hypermedia systems},
abstract = {Introducing engineering into precollege classroom settings has the potential to facilitate learning of science, technology, engineering, and mathematics (STEM) concepts and to increase interest in STEM careers. Successful engineering design projects in secondary schools require extensive support for both teachers and students. Computer-based learning environments can support both teachers and students to implement and learn from engineering design projects. However, there is a dearth of empirical research on how engineering approaches can augment learning in authentic K-12 settings. This paper presents research on the development and pilot testing of WISEngineering, a new web-based engineering design learning environment. Three middle school units were developed using a knowledge integration learning perspective and a scaffolded, informed engineering approach with the goal of improving understanding of standards-based mathematical concepts and engineering ideas. Seventh grade math students from two teachers in a socioeconomically diverse and low-performing district participated in three WISEngineering units over the course of a semester. Students significantly improved their mathematical scores from pretest to posttest for all three projects and on state standardized tests. Student, teacher, and administrator interviews reveal that WISEngineering projects promoted collaboration, tolerance, and development of pro-social skills among at-risk youth. Results demonstrate that informed engineering design projects facilitated through the WISEngineering computer-based environment can help students learn Common Core mathematical concepts and principles. Additionally, results suggest that WISEngineering projects can be particularly beneficial for at-risk and diverse student populations.}
}
@article{BEDEWY2023101299,
title = {STEAM + X - Extending the transdisciplinary of STEAM-based educational approaches: A theoretical contribution},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101299},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101299},
url = {https://www.sciencedirect.com/science/article/pii/S187118712300069X},
author = {Shereen El Bedewy and Zsolt Lavicza},
keywords = {STEAM, Design-based research, Culture, Technology, Design principles},
abstract = {This design-based research methodological paper is proposing a theoretical understanding in the form of STEAM + X framework that emerged from the empirical findings of implementing transdisciplinary STEAM practices featuring architecture, culture, and history. This paper shows how the proposed STEAM practices, involving creativities, to promote the integration of various disciplines with multiple cross-cultural iterations. These STEAM practices allow teachers to integrate cultural, architectural, environmental, or technological options into mathematics teaching and learning. These STEAM practices foster creativity and thinking skills in connecting disciplines in a transdisciplinary learning approach. Moreover, this paper introduces the study outcomes including the developed design principles and a framework that connects the underlying theoretical framework with emerging themes from our qualitative data analysis.}
}
@article{GRAY2019124,
title = {BrainQuest: The use of motivational design theories to create a cognitive training game supporting hot executive function},
journal = {International Journal of Human-Computer Studies},
volume = {127},
pages = {124-149},
year = {2019},
note = {Strengthening gamification studies: critical challenges and new opportunities},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2018.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S1071581918304555},
author = {Stuart Iain Gray and Judy Robertson and Andrew Manches and Gnanathusharan Rajendran},
keywords = {Gamification, Motivational theory, Game design, Cognitive training games, Executive functions},
abstract = {For children to yield greater mental performance abilities in real world settings, training approaches should offer practice in problems which have an affective component requiring social interactions, and be motivating over a sustained period. Current cognitive training games often overlook the important relationship between cognition and emotion, characterised by ‘hot executive function’, and correlated with fundamental academic and life outcomes. Here, we present robust qualitative evidence from a case study which documents the social relationships, motivation and engagement of a class of ten-year-old children who used an active smartphone cognitive training game called BrainQuest in their physical education lessons over a period of 5 weeks. Game design elements which are intended to move beyond simple gamification of cognitive tests are presented, along with a discussion of how these design elements worked in practice. The paper also presents and discusses the impact of the game upon the cognitive and emotional regulatory skills, characterised by executive function skills, based on the findings of this initial work. We conclude with recommendations for the designers of cognitive training games in the future and discussion of appropriate research methods for future gamification studies.}
}
@article{IIVARI2022100408,
title = {Critical agenda driving child–computer interaction research—Taking a stock of the past and envisioning the future},
journal = {International Journal of Child-Computer Interaction},
volume = {32},
pages = {100408},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100408},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000957},
author = {Netta Iivari and Sumita Sharma and Leena Ventä-Olkkonen and Tonja Molin-Juustila and Kari Kuutti and Jenni Holappa and Essi Kinnunen},
keywords = {Critical, Critical research, Critical design, Critical agenda, Children},
abstract = {There is a revitalized interest in power and politics around design and technology in the Human–Computer Interaction (HCI) field. Child–Computer Interaction (CCI) research community has also shown arousing interest towards the topic. However, despite this emerging interest, the CCI research community has remained quite silent about the potential of a critical agenda for CCI. Few studies have explicitly addressed critical research or critical design. This study introduces the notion of a critical agenda for CCI research and identifies CCI studies that are linked with the critical agenda, revealing that there are CCI studies showing emerging interests and seeds for addressing the critical agenda. Overall, this study explores the state-of-the-art critical research tradition in CCI and explicates the potential of this tradition for making the world a better place through design and technology in collaboration with children.}
}
@article{FIGL201596,
title = {Influence factors for local comprehensibility of process models},
journal = {International Journal of Human-Computer Studies},
volume = {82},
pages = {96-110},
year = {2015},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2015.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S1071581915001019},
author = {Kathrin Figl and Ralf Laue},
keywords = {Deductive reasoning, Business process models, Model comprehension, Cognitive complexity},
abstract = {The main aim of this study is to investigate human understanding of process models and to develop an improved understanding of its relevant influence factors. Aided by assumptions from cognitive psychology, this article attempts to address specific deductive reasoning difficulties based on process models. The authors developed a research model to capture the influence of two effects on the cognitive difficulty of reasoning tasks: (i) the presence of different control-flow patterns (such as conditional or parallel execution) in a process model and (ii) the interactivity of model elements. Based on solutions to 61 different reasoning tasks by 155 modelers, the results from this study indicate that the presence of certain control-flow patterns influences the cognitive difficulty of reasoning tasks. In particular, sequence is relatively easy, while loops in a model proved difficult. Modelers with higher process modeling knowledge performed better and rated subjective difficulty of loops lower than modelers with lower process modeling knowledge. The findings additionally support the prediction that interactivity between model elements is positively related to the cognitive difficulty of reasoning. Our research contributes to both academic literature on the comprehension of process models and practitioner literature focusing on cognitive difficulties when using process models.}
}
@incollection{MOORE2024493,
title = {Chapter 17 - The application of knowledge in soil microbiology, ecology, and biochemistry (SMEB) to the solution of today’s and future societal needs},
editor = {Eldor A. Paul and Serita D. Frey},
booktitle = {Soil Microbiology, Ecology and Biochemistry (Fifth Edition)},
publisher = {Elsevier},
edition = {Fifth Edition},
pages = {493-536},
year = {2024},
isbn = {978-0-12-822941-5},
doi = {https://doi.org/10.1016/B978-0-12-822941-5.00017-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012822941500017X},
author = {John C. Moore and Nathaniel Mueller},
keywords = {Biogeochemistry, climate change, science literacy, microbial communities, soil organic matter, food webs, sustainability development goals},
abstract = {This chapter presents an ecosystem-based framework for applying soil microbiology, ecology, and biochemistry (SMEB) principles and processes to address the preservation and sustainability of global soils to meet societal needs in the face of environmental change. The approach is organized around the UN Sustainable Development Goals, focusing on ecosystem services provided by soil microbes and soil biota at the nexus of food, water, and energy. The role of soil biota in ecosystem processes and the impacts of human activities on those processes are presented. The approach promotes conservation and regenerative methods that manage natural SMEB processes to optimize ecosystem services and minimize alterations in natural processes. Adoption and application of sound SMEB science will require a high degree of literacy among different stakeholders to codevelop management practices and regulatory policy. The approach also advocates promoting SMEB science literacy within the education system through reforms in science standards and curricula.}
}
@article{KHRENNIKOV2006225,
title = {Quantum-like brain: “Interference of minds”},
journal = {Biosystems},
volume = {84},
number = {3},
pages = {225-241},
year = {2006},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2005.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0303264705001942},
author = {Andrei Khrennikov},
abstract = {We present a contextualist statistical realistic model for quantum-like representations in physics, cognitive science, and psychology. We apply this model to describe cognitive experiments to check quantum-like structures of mental processes. The crucial role is played by interference of probabilities for mental observables. Recently one such experiment based on recognition of images was performed. This experiment confirmed our prediction on the quantum-like behavior of mind. In our approach “quantumness of mind” has no direct relation to the fact that the brain (as any physical body) is composed of quantum particles. We invented a new terminology “quantum-like (QL) mind.” Cognitive QL-behavior is characterized by a nonzero coefficient of interference λ. This coefficient can be found on the basis of statistical data. There are predicted not only cos⁡θ-interference of probabilities, but also hyperbolic cosh⁡θ-interference. This interference was never observed for physical systems, but we could not exclude this possibility for cognitive systems. We propose a model of brain functioning as a QL-computer (there is a discussion on the difference between quantum and QL computers).}
}
@article{GURBAN2016186,
title = {Global trends in education: Russia case study},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {6},
pages = {186-193},
year = {2016},
note = {11th IFAC Symposium on Advances in Control Education ACE 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.07.175},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316303809},
author = {I.A. Gurban and A.A. {Tarasyev, Jr.}},
keywords = {globalization, professional education, global trends, trends, professions, skills, competencies, graduates, levels of education.},
abstract = {An improved system of Russian vocational education is seen as a major factor in the country’s economic development. It is currently recognized that the global labour market is emerging as a consequence of globalization processes, which significantly affect the establishment of national educational systems. The paper discusses global educational trends, with a particular focus on the tendencies in the demand for labour both in Russia and in the world. The paper aims to describe changes in attitudes towards the relevance of specialist qualifications and the sufficiency of professional competencies acquired through education. In addition, the analysis of structural changes in the Russian system of vocational education starting from 1990 to the present day is given. The research is carried out using the methods of comparative and statistical analysis. The competency maps of future are drawn (Institute for the Future, Palo Alto, the USA), including the description of trends that alter the habitual context for the labour force, as well as key skills needed for a successful career. The ‘Atlas of New Professions’ describing most promising professions in the field of education is reviewed. It is shown that the country’s role in the international division of labour can be used as an objective criterion to assess the performance of the country’s educational system. In this respect, the data on Russia’s position in the world rankings of competitiveness, innovation development and human development index, as well as the comparative data on the rate that Russian companies demonstrate in terms of innovative activity and technology exports are provided. The analysis of disproportions in the structure of graduates both in terms of levels and specialities of vocational education for the period 1990–2013 is given. Key problems faced by the Russian vocational education system are considered, including a weak focus on the actual needs of national economy and global changes in the labour market, a decline in the quality of training and the number of working specialities, as well as the low flexibility of educational programs.}
}
@article{DUTTAMOSCATO201412,
title = {Creating a pipeline of talent for informatics: STEM initiative for high school students in computer science, biology, and biomedical informatics},
journal = {Journal of Pathology Informatics},
volume = {5},
number = {1},
pages = {12},
year = {2014},
issn = {2153-3539},
doi = {https://doi.org/10.4103/2153-3539.129448},
url = {https://www.sciencedirect.com/science/article/pii/S2153353922002814},
author = {Joyeeta Dutta-Moscato and Vanathi Gopalakrishnan and Michael T. Lotze and Michael J. Becich},
keywords = {Bioinformatics, education, medical informatics, science, technology, engineering, and math education},
abstract = {This editorial provides insights into how informatics can attract highly trained students by involving them in science, technology, engineering, and math (STEM) training at the high school level and continuing to provide mentorship and research opportunities through the formative years of their education. Our central premise is that the trajectory necessary to be expert in the emergent fields in front of them requires acceleration at an early time point. Both pathology (and biomedical) informatics are new disciplines which would benefit from involvement by students at an early stage of their education. In 2009, Michael T Lotze MD, Kirsten Livesey (then a medical student, now a medical resident at University of Pittsburgh Medical Center (UPMC)), Richard Hersheberger, PhD (Currently, Dean at Roswell Park), and Megan Seippel, MS (the administrator) launched the University of Pittsburgh Cancer Institute (UPCI) Summer Academy to bring high school students for an 8 week summer academy focused on Cancer Biology. Initially, pathology and biomedical informatics were involved only in the classroom component of the UPCI Summer Academy. In 2011, due to popular interest, an informatics track called Computer Science, Biology and Biomedical Informatics (CoSBBI) was launched. CoSBBI currently acts as a feeder program for the undergraduate degree program in bioinformatics at the University of Pittsburgh, which is a joint degree offered by the Departments of Biology and Computer Science. We believe training in bioinformatics is the best foundation for students interested in future careers in pathology informatics or biomedical informatics. We describe our approach to the recruitment, training and research mentoring of high school students to create a pipeline of exceptionally well-trained applicants for both the disciplines of pathology informatics and biomedical informatics. We emphasize here how mentoring of high school students in pathology informatics and biomedical informatics will be critical to assuring their success as leaders in the era of big data and personalized medicine.}
}
@article{SERHOLT2018250,
title = {Breakdowns in children's interactions with a robotic tutor: A longitudinal study},
journal = {Computers in Human Behavior},
volume = {81},
pages = {250-264},
year = {2018},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.12.030},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217307100},
author = {Sofia Serholt},
keywords = {Child–robot interaction, Education, Robotic tutor, Breakdowns, Interaction analysis, Thematic analysis},
abstract = {In recent years, there has been a growing research interest towards exploring the benefit of Child–Robot Interaction for educational purposes through the use of social robotics. Despite the label, such robots are typically only social within scripted activities. The current study takes a critical look at the case of a robotic tutor which was implemented in an elementary school for 3.5 months, where children repeatedly took turns interacting with the robot individually as well as in pairs. The aim of the study was to explore what caused breakdowns in children's interactions with the robotic tutor. In this qualitative study, over 14 h of video recordings of children's interaction sessions were analyzed in-depth through interaction analysis and thematic analysis. The results comprise four themes to explain why children's interactions with the robotic tutor break down: (1) the robot's inability to evoke initial engagement and identify misunderstandings, (2) confusing scaffolding, (3) lack of consistency and fairness, and finally, (4) controller problems. The implications of these breakdowns for the educational use of robots are discussed, and it is concluded that several challenges need to be rigorously addressed in order for robotic tutors to be able to feature in education.}
}
@article{BARRON2010178,
title = {Predictors of creative computing participation and profiles of experience in two Silicon Valley middle schools},
journal = {Computers & Education},
volume = {54},
number = {1},
pages = {178-189},
year = {2010},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2009.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S036013150900195X},
author = {Brigid Barron and Sarah E. Walter and Caitlin Kennedy Martin and Colin Schatz},
keywords = {Digital divide, Learning ecology, Home access},
abstract = {Examination of the “digital divide” has increasingly gone beyond the study of differences in physical access to computers to focus on individuals’ use of technological tools for empowered and generative uses. In this research study, we investigated the relationship between access to tools and experience with creative production activities. Our participants included 160 8th grade learners from two public middle schools. The local communities represented by the two schools differed in parent education levels, proportion of recent immigrants, and average family income. Findings indicated substantial variability in students’ history of creative production experiences within both communities. Three sets of analyses were completed. First, the two school populations were compared with respect to average levels of student creative production experience, access to tools at home, use of learning resources, frequency of technology use, and access to computing outside of their home. Second, correlates of variability in individuals’ breadth of experience with creative production activities were explored across both schools through a regression analysis. The resulting model indicated that students’ experience was best predicted by the number of technology tools available at home, number of learning resources used, frequency of computer use at home, and non-home access network size. In a third analysis, profiles of experience were created based on both breadth and depth of experience; the resulting four groups of students were compared. More experienced students utilized a broader range of learning resources, had access to more tools at home, taught a wider range of people, and were more confident in their computing skills. The groups did not differ in their self-reports of interest in learning more about technology.}
}
@incollection{KIRK201395,
title = {Chapter 5 - CUDA Memories},
editor = {David B. Kirk and Wen-mei W. Hwu},
booktitle = {Programming Massively Parallel Processors (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {95-121},
year = {2013},
isbn = {978-0-12-415992-1},
doi = {https://doi.org/10.1016/B978-0-12-415992-1.00005-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780124159921000055},
author = {David B. Kirk and Wen-mei W. Hwu}
}
@incollection{WILLIAMS202351,
title = {Part Two—The international benchmarking exercise},
editor = {David Baker and Lucy Ellis and Caroline Williams and Cliff Wragg},
booktitle = {Benchmarking Library, Information and Education Services},
publisher = {Chandos Publishing},
pages = {51-107},
year = {2023},
isbn = {978-0-323-95662-8},
doi = {https://doi.org/10.1016/B978-0-323-95662-8.00015-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956628000151},
author = {Caroline Williams and Cliff Wragg}
}
@article{LOUSTAU2022100544,
title = {Characterizing the research-practice gap in children’s interactive storytelling systems},
journal = {International Journal of Child-Computer Interaction},
volume = {34},
pages = {100544},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100544},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000629},
author = {Trystan Loustau and Sharon Lynn Chu},
keywords = {Child–computer interaction, Interactive storytelling, Research-practice gap},
abstract = {Storytelling support has been and continues to be a recurring theme in child–computer interaction research, especially as it pertains to education. This work has spilled over into practice, and, in the last few decades, a large number of storytelling systems for children have been developed—both as research prototypes and commercial applications. However, through a systematic analysis of 75 research-based storytelling systems and 39 commercial systems, we find that there remains a problematic gap between research and practice with respect to products in interactive storytelling and child–computer interaction, echoing the well-documented research-practice gap in the general HCI field. We characterize the nature of this gap, highlighting design themes promoted by research-based systems that are not as prevalent in commercial systems, such as tangibility and narrative scaffolds, and vice-versa. Understanding the main areas of discrepancy between research and practice can help focus efforts to close the research-practice gap in storytelling systems for children.}
}
@article{CASCIO2016103,
title = {The search for global competence: From international HR to talent management},
journal = {Journal of World Business},
volume = {51},
number = {1},
pages = {103-114},
year = {2016},
note = {The World of Global Business 1965-2015},
issn = {1090-9516},
doi = {https://doi.org/10.1016/j.jwb.2015.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1090951615000814},
author = {Wayne F. Cascio and John W. Boudreau},
keywords = {International HR Management, Global business trends, Talent management, Global talent management, Global competence, Business strategy},
abstract = {This article describes the evolution of the search for global competence through a 50-year content analysis and review of published research in the field of International HR Management (IHRM), and more recently, Talent Management (TM), with special emphasis on the Journal of World Business. We present a detailed examination of the IHRM/TM content of the Journal of World Business from its inception in 1965 through 2014. To put the results of that review into perspective, we review key themes in global business and strategy from 1965 to the present, noting where IHRM/TM research and business trends correspond, diverge, and lag. Next, we present a brief history of IHRM and TM, showing how the emerging theme of TM offers challenges and promise for connecting future IHRM/TM research with emerging business, strategy, and social trends. We conclude with the implications of our findings for future research, and the importance of the search for global competence.}
}
@incollection{PAYDAR2023165,
title = {Chapter 3 - Nuclear power reactions driven radiation hardening environments},
editor = {Ali Zamani Paydar and Seyed Kamal Mousavi Balgehshiri and Bahman Zohuri},
booktitle = {Advanced Reactor Concepts (ARC)},
publisher = {Elsevier},
pages = {165-233},
year = {2023},
isbn = {978-0-443-18989-0},
doi = {https://doi.org/10.1016/B978-0-443-18989-0.00003-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044318989000003X},
author = {Ali Zamani Paydar and Seyed Kamal Mousavi Balgehshiri and Bahman Zohuri},
keywords = {Nuclear power plants, Design basis accident, Loss of coolant accident, Shielding, Neutron reflector, Nuclear submarines, Halving thickness values, Artificial intelligence},
abstract = {Radiation hardening, also known as “rad hardening,” and radiation survivability testing are of critical importance to defense, aerospace, and energy industries. Everyone knows that excessive exposure to radiation can cause severe damage to living things, but high radiation levels can also cause radiation damage to other objects, especially electronics. Ionizing radiation in particular, including directly ionizing radiation such as alpha and beta particles and indirectly ionizing radiation such as gamma rays and neutron radiation, is profoundly damaging to the semiconductors that make up the backbone of all modern electronics. Just one charged particle can interfere with thousands of electrons, causing signal noise, disrupting digital circuits, and even causing permanent physical radiation damage. Radiation hardening involves designing radiation-tolerant electronics and components that are tolerant of the massive levels of ionizing radiation, such as cosmic outer space radiation, X-ray radiation in medical or security environments, and high energy radiation within nuclear power plants. In order to test these components and determine whether they are sufficiently hardened, radiation-hardened electronics manufacturers perform rigorous testing as part of their product manufacturing processes. Components which pass these tests go into production and can be described as “radiation-hardened”; components that do not go back to design.}
}
@article{MEYER202013,
title = {Changing Design Education for the 21st Century},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {6},
number = {1},
pages = {13-49},
year = {2020},
note = {Design Education. Part I},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2019.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S2405872620300046},
author = {Michael W. Meyer and Don Norman},
keywords = {Design education, Design-driven transformation, Design thinking, Design doing, Major societal challenges, Complex sociotechnical systems, DesignX},
abstract = {Designers are entrusted with increasingly complex and impactful challenges. However, the current system of design education does not always prepare students for these challenges. When we examine what and how our system teaches young designers, we discover that the most valuable elements of the designer’s perspective and process are seldom taught. Instead, some designers grow beyond their education through their experience working in industry, essentially learning by accident. Many design programs still maintain an insular perspective and an inefficient mechanism of tacit knowledge transfer. Meanwhile, skills for developing creative solutions to complex problems are increasingly essential. Organizations are starting to recognize that designers bring something special to this type of work, a rational belief based upon numerous studies that link commercial success to a design-driven approach. So, what are we to do? Other learned professions such as medicine, law, and business provide excellent advice and guidance embedded within their own histories of professionalization. In this article, we borrow from their experiences to recommend a course of action for design. It will not be easy: it will require a study group to make recommendations for a roster of design and educational practices that schools can use to build a curriculum that matches their goals and abilities. And then it will require a conscious effort to bootstrap the design profession toward both a robust practitioner community and an effective professoriate, capable together of fully realizing the value of design in the 21st century. In this article, we lay out that path.}
}
@article{FRIENDSOFAJPM2013687,
title = {Notes from the Field: Planting, Nurturing, and Watching Things Grow},
journal = {American Journal of Preventive Medicine},
volume = {45},
number = {6},
pages = {687-702},
year = {2013},
issn = {0749-3797},
doi = {https://doi.org/10.1016/j.amepre.2013.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S074937971300500X},
author = { {Friends of AJPM}}
}
@incollection{HAMILTON2023371,
title = {Chapter 16 - Natural Language Processing},
editor = {Julien Delarue and J. Ben Lawlor},
booktitle = {Rapid Sensory Profiling Techniques (Second Edition)},
publisher = {Woodhead Publishing},
edition = {Second Edition},
pages = {371-410},
year = {2023},
series = {Woodhead Publishing Series in Food Science, Technology and Nutrition},
isbn = {978-0-12-821936-2},
doi = {https://doi.org/10.1016/B978-0-12-821936-2.00004-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128219362000042},
author = {Leah Marie Hamilton and Jacob Lahne},
keywords = {Natural Language Processing, Machine learning, Deep learning, Text analysis, Computational linguistics, Sensory evaluation, Descriptive analysis},
abstract = {Sensory evaluation is predicated on the use and interpretation of human language. We ask our subjects to describe their sensory experiences and affective responses, which we cannot directly observe. This formulation of sensory science encourages direct engagement with linguistics and in particular, a recent subfield of linguistics, computer science, and artificial intelligence called “Natural Language Processing” (NLP, sometimes “computational linguistics”). In this chapter we will provide an introduction to Natural Language Processing (NLP) for sensory scientists who wish to employ NLP as a rapid method for sensory evaluation. Because NLP is a large, diverse, and rapidly evolving field, we will begin with a brief, pragmatic overview of the discipline, with an emphasis on key historical and current methods and applications. We will then briefly discuss the linguistic perspective and its application to sensory evaluation, with an aim to motivating the remaining chapter. Following that, we will discuss key areas of NLP, from data collection to processing to analysis to advanced applications. Throughout the chapter, we will use a consistent case study of natural-language descriptions for a food product to provide examples and illustrate NLP methods.}
}
@incollection{DOMINOWSKI19941,
title = {CHAPTER 1 - History of Research on Thinking and Problem Solving},
editor = {Robert J. Sternberg},
booktitle = {Thinking and Problem Solving},
publisher = {Academic Press},
address = {San Diego},
pages = {1-35},
year = {1994},
volume = {2},
series = {Handbook of Perception and Cognition},
isbn = {978-0-08-057299-4},
doi = {https://doi.org/10.1016/B978-0-08-057299-4.50007-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780080572994500074},
author = {Roger L. Dominowski and Lyle E. Bourne},
abstract = {Publisher Summary
The two problems that characterize the modern psychology of thinking are mental representation and mental computation. Throughout the history of psychology, there has been an agreement that the essential features of a problem are that an organism has a goal but lacks a clear or well-learned route to the goal. Thus the emphasis in research on problem solving has been on response discovery—how the organism arrives at an effective, goal-attaining behavior. There have often been controversies over the role of learning or past experiences in problem solving. This chapter illustrates the conflict between emphases on learning and emphases on perception as central components of problem solving. Because a problem solver must find a solution, it might seem inevitable that an essential activity tries different approaches makes errors until the right approach is found. Earlier in problem-solving research, trial and error became associated with the view that acquiring a solution was a gradual, undirected process that did not involve perception or comprehension of problem requirements or structure.}
}
@article{201943,
title = {Literature Listing},
journal = {World Patent Information},
volume = {56},
pages = {43-59},
year = {2019},
issn = {0172-2190},
doi = {https://doi.org/10.1016/j.wpi.2019.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S017221901830156X}
}
@article{TAN2020101793,
title = {A graph-theoretic approach for the detection of phishing webpages},
journal = {Computers & Security},
volume = {95},
pages = {101793},
year = {2020},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2020.101793},
url = {https://www.sciencedirect.com/science/article/pii/S016740482030078X},
author = {Choon Lin Tan and Kang Leng Chiew and Kelvin S.C. Yong and San Nah Sze and Johari Abdullah and Yakub Sebastian},
keywords = {Phishing detection, Hyperlinks, Web graph, Graph features, Machine learning},
abstract = {Over the years, various technical means have been developed to protect Internet users from phishing attacks. To enrich the anti-phishing efforts, we capitalise on concepts from graph theories, and propose a set of novel graph features to improve the phishing detection accuracy. The initial phase of the proposed technique involved the extraction of hyperlinks in the webpage under scrutiny and fetching the corresponding neighbourhood webpages. During this process, the page linking data were collected, and used to construct a web graph which models the overall hyperlink and network structure of the webpage. From the web graph, graph measures were computed and extracted as graph features to derive a classifier for detecting phishing webpages. Experimental results show that the proposed graph features achieve an improved overall accuracy of 97.8% when C4.5 was utilised as classifier, outperforming the existing conventional features derived from the same data samples. Unlike conventional features, the proposed graph features leverage inherent phishing patterns that are only visible at a higher level of abstraction, thus making it robust and difficult to be evaded by direct manipulations on the webpage contents. Our proposed graph-based technique also shows promising results when benchmarked against a prominent phishing detection technique. Hence, the proposed technique is an important contribution to the existing anti-phishing research towards improving the detection performance.}
}
@article{GRAPIN201971,
title = {Precision: Toward a meaning-centered view of language use with English learners in the content areas},
journal = {Linguistics and Education},
volume = {50},
pages = {71-83},
year = {2019},
issn = {0898-5898},
doi = {https://doi.org/10.1016/j.linged.2019.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0898589818303140},
author = {Scott E. Grapin and Lorena Llosa and Alison Haas and Marcelle Goggins and Okhee Lee},
keywords = {Precision, English learners, Language and content integration, English language proficiency standards, Content standards},
abstract = {To support English learners (ELs) in attaining rigorous content standards, U.S. federal legislation requires that English language proficiency (ELP) standards align with content standards. Whereas language use in content learning has traditionally been defined in terms of structure, content and language educators have devoted increased attention to precision. Precision goes beyond the structural elements of language to the disciplinary meaning that those elements communicate. In this article, we define precision and distinguish it from vocabulary, accuracy, and complexity. Then, we highlight divergent conceptions of precision in content standards and ELP standards. In light of these divergent conceptions, we present work samples from an elementary science classroom to illustrate how precision of disciplinary meaning is essential to engaging in disciplinary practices of content standards. We close by proposing the need for a more meaning-centered view of language use with ELs in the content areas.}
}
@article{ROMEROORGANVIDEZ2024112029,
title = {Data visualization guidance using a software product line approach},
journal = {Journal of Systems and Software},
volume = {213},
pages = {112029},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112029},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224000724},
author = {David Romero-Organvidez and Jose-Miguel Horcas and José A. Galindo and David Benavides},
keywords = {Effective communication, Graphs, Tables, Software product line, Variability, Visualization},
abstract = {Data visualization aims to convey quantitative and qualitative information effectively by determining which techniques and visualizations are most appropriate for different situations and why. Various software solutions can produce numerous visualizations of the same data set. However, data visualization encompasses a wide range of visual configurations that depend on factors such as the type of data being displayed, the different displays (e.g., scatter plots, line graphs, and pie charts), the visual components used to represent the data (e.g., lines, dots, and bars), and the specific visual attributes of those components (e.g., color, shape, size, and length). A similar problem arises when designing data tables, where the dimensionality of the data and its complexity influence the choice of the most appropriate structure (e.g., unidirectional, bidirectional). Often, this broad spectrum of configurations requires a visualization expert who knows which techniques are best for which type of data source and what is to be conveyed. Typically, researchers and developers lack knowledge of data visualization best practices and must learn the design principles that enable effective communication and the technical details of the specific software tool they use to generate visualizations. This paper proposes a software product line approach to model and realize the variability of the visualization design process, using feature models to encode knowledge about design best practices in graphs and charts. Our approach involves solving visualization design variability through a stepwise configuration process and evaluating the proposal for a specific software visualization tool. Our solution facilitates effective communication of quantitative results by helping researchers and developers select and generate the most effective visualizations for each case. This approach opens up new opportunities for research at the intersection of data visualization and variability.}
}
@article{PARHI2022108062,
title = {Factors affecting Industry 4.0 adoption – A hybrid SEM-ANN approach},
journal = {Computers & Industrial Engineering},
volume = {168},
pages = {108062},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2022.108062},
url = {https://www.sciencedirect.com/science/article/pii/S0360835222001322},
author = {Shreyanshu Parhi and Kanchan Joshi and Thorsten Wuest and Milind Akarte},
keywords = {Industry 4.0, Smart Manufacturing, Driving Factors, Indian Manufacturing Industry, SEM, ANN},
abstract = {Industry 4.0 is a technology-driven digital transformation to enable data-driven decision-making based on real-time data to enhance the competitiveness of traditional manufacturing. Moving forward, adopting Industry 4.0 is an evident requirement for manufacturers to remain competitive. Currently, in the early stages of adoption in most industries and countries, there is an evident lack of foundational Industry 4.0 knowledge among decision-makers. There are few studies on the adoption of Industry 4.0; however, they focus on specific domains like cloud computing, virtual reality, IoT, etc., and are primarily set in developed countries. This research proposes a multi-stage hybrid analytic approach whereby the research model was tested using Structural Equation Modelling (SEM). The SEM results were used as inputs for the Artificial Neural Networks (ANN) to determine significant predictors for the adoption of Industry 4.0 in Indian manufacturing industries. A comprehensive sample of 350 responses from various Indian manufacturers was collected and analyzed. Results revealed that the factors viz. Software Infrastructure (SI), System Flexibility (SF), Operational Accuracy (OA), and the Technical Capabilities (TC) play a dominant role in the successful adoption intentions of Industry 4.0 in India. Manufacturers from India and other emerging economies will benefit from the findings of this study by concentrating and improving on the dominant adoption factors of Industry 4.0. Concluding, we discuss the study’s results and derive lessons learned for stakeholders, including managers, consultants, policymakers, and regulatory authorities.}
}
@article{SMITH20189,
title = {Participatory design for sustainable social change},
journal = {Design Studies},
volume = {59},
pages = {9-36},
year = {2018},
note = {Participatory Design},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2018.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X18300425},
author = {Rachel Charlotte Smith and Ole Sejer Iversen},
keywords = {participatory design, design process, user participation, design practice, educational technology},
abstract = {Tendencies in contemporary participatory design suggest a move away from engagement of limited stakeholders in preconfigured design processes and predefined technology outcomes, towards more complex and long-term engagement with heterogeneous communities and larger ecologies of social and technological transformation. Building on core values of participatory design, we introduce three dimensions of engagement of scoping, developing and scaling that we argue can be essential in developing a holistic approach to participatory design as a sustainable practice of social change. The dimensions foreground central aspects of participatory design research that are discussed in relation to a long-term project exploring design and digital fabrication technologies in Danish primary and secondary education.}
}
@article{KADERAVEK201527,
title = {SCIIENCE: The creation and pilot implementation of an NGSS-based instrument to evaluate early childhood science teaching},
journal = {Studies in Educational Evaluation},
volume = {45},
pages = {27-36},
year = {2015},
issn = {0191-491X},
doi = {https://doi.org/10.1016/j.stueduc.2015.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0191491X15000218},
author = {Joan N. Kaderavek and Tamala North and Regina Rotshtein and Hoangha Dao and Nicholas Liber and Geoff Milewski and Scott C. Molitor and Charlene M. Czerniak},
keywords = {Discourse analysis, Teacher assessment, Language of science in classrooms, Validity/reliability},
abstract = {This paper describes the development, testing and implementation of the Systematic Characterization of Inquiry Instruction in Early LearNing Classroom Environments (SCIIENCE). The SCIIENCE instrument was designed to capture best practices outlined in the National Research Council's Framework for K-12 Science Education as they occur within a science lesson. The goals of the SCIIENCE instrument are to (a) assess the quality of science instruction in PK-3 classrooms, (b) capture teacher behaviors and instructional practices that engage students in the lesson, promote scientific studies, encourage higher-level thinking, and (c) provide a feedback mechanism for guiding professional development of PK-3 teachers. Science educators can apply this instrument to teacher behaviors and use the data to improve classroom inquiry instructional methodology.}
}
@article{MOHDAMINUDDIN2023103582,
title = {The rise of website fingerprinting on Tor: Analysis on techniques and assumptions},
journal = {Journal of Network and Computer Applications},
volume = {212},
pages = {103582},
year = {2023},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2023.103582},
url = {https://www.sciencedirect.com/science/article/pii/S1084804523000012},
author = {Mohamad Amar Irsyad {Mohd Aminuddin} and Zarul Fitri Zaaba and Azman Samsudin and Faiz Zaki and Nor Badrul Anuar},
keywords = {Security, Privacy, Anonymity, Tor, Traffic analysis, Website fingerprinting},
abstract = {Tor is one of the most popular anonymity networks that allows Internet users to hide their browsing activity. Hiding browsing activity is essential for Internet users to increase their privacy. Only Tor users should know the website they are browsing. However, an attacker can utilise the Website Fingerprinting (WF) attack to identify webpages browsed by Tor users. WF is a significant threat to Internet users' privacy as Tor should conceal the browsed webpages' information. Existing WF studies focused on the investigation to improve the identification capabilities, overlooking the systematic discussion and assessment of existing techniques. In addition, existing surveys and analyses reviewed insufficient variation of WF on Tor techniques. Therefore, this survey paper aims to provide a systematic and thorough review of various WF on Tor techniques. First, we discuss WF on Tor techniques in five primary aspects: threat model, victim target, website realm, traffic feature, and traffic classifier. We analyse and classify the reviewed studies on each WF aspect. The classification facilitates in-depth understanding and comparison between WF on Tor techniques. Furthermore, this paper investigates nine assumptions exercised in WF on Tor: closed-world, sequential browsing, isolated traffic, replicability, traffic parsing, passive webpage, disabled cache, static content, and single webpage. These assumptions limit the WF on Tor's practicality in real-world scenarios. Our analysis and classification indicate that most WF on Tor studies apply these assumptions despite being only suitable in controlled environments or laboratory experiments. In addition, most reviewed studies often lack transparency on the assumptions exercised in their studies, risking misunderstanding the WF on Tor techniques' actual practicality. At the end of this survey, we present WF on Tor taxonomy and highlight 21 WF on Tor research's limitations and gaps with plausible recommendations. We also discuss the WF on Tor studies' contribution category and development phase.}
}
@article{1994505,
title = {News of IMACS},
journal = {Mathematics and Computers in Simulation},
volume = {36},
number = {4},
pages = {505-516},
year = {1994},
issn = {0378-4754},
doi = {https://doi.org/10.1016/0378-4754(94)90082-5},
url = {https://www.sciencedirect.com/science/article/pii/0378475494900825}
}
@article{CORDASCO201815,
title = {Distributed MASON: A scalable distributed multi-agent simulation environment},
journal = {Simulation Modelling Practice and Theory},
volume = {89},
pages = {15-34},
year = {2018},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2018.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X18301230},
author = {Gennaro Cordasco and Vittorio Scarano and Carmine Spagnuolo},
keywords = {Agent-based simulation, Parallel computing, Distributed computing, Scalable computational science, Cloud computing},
abstract = {Computational Social Science (CSS) involves interdisciplinary fields and exploits computational methods, such as social network analysis as well as computer simulation with the goal of better understanding social phenomena. Agent-Based Models (ABMs) represent an effective research tool for CSS and consist of a class of models, which, aim to emulate or predict complex phenomena through a set of simple rules (i.e., independent actions, interactions and adaptation), performed by multiple agents. The efficiency and scalability of ABMs systems are typically obtained distributing the overall computation on several machines, which interact with each other in order to simulate a specific model. Unfortunately, the design of a distributed simulation model is particularly challenging, especially for domain experts who sporadically are computer scientists and are not used to developing parallel code. D-MASON framework is a distributed version of the MASON library for designing and executing ABMs in a distributed environment ensuring scalability and easiness. D-MASON enable the developer to exploit the computing power of distributed environment in a transparent manner; the developer has to do simple incremental modifications to existing MASON models, without re-designing them. This paper presents several novel features and architectural improvements introduced in the D-MASON framework: an improved space partitioning strategy, a distributed 3D field, a distributed network field, a decentralized communication layer, a novel memory consistency mechanism and the integration to cloud environments. Full documentation, additional tutorials, and other material can be found at https://github.com/isislab-unisa/dmason where the framework can be downloaded.}
}
@incollection{ZEYER2015235,
title = {11 - For the mutual benefit: Health information provision in the science classroom},
editor = {Catherine {Arnott Smith} and Alla Keselman},
booktitle = {Meeting Health Information Needs Outside Of Healthcare},
publisher = {Chandos Publishing},
pages = {235-261},
year = {2015},
isbn = {978-0-08-100248-3},
doi = {https://doi.org/10.1016/B978-0-08-100248-3.00011-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780081002483000111},
author = {Albert Zeyer and Daniel M. Levin and Alla Keselman},
keywords = {Health education, Health literacy, Information, Knowledge, Science education},
abstract = {In this chapter, the authors argue that the school science classroom should help students deal with complex real-life information about health and disease. They also discuss means by which curriculum and instruction in science education can be tied to these issues. The chapter reviews opportunities and challenges presented to individuals by the expectations of participatory health care, focusing on models of health literacy that can help understand and address the challenges. The authors argue that the problem of ensuring effective information use often lies in a transmission approach to health information provision. Transmitted knowledge is often not understood nor applied, as demonstrated in studies of human papillomavirus vaccination education. An alternative to knowledge transmission is the approach that aims to foster critical literacy, which is grounded in critical thinking essential to the practice of science. The chapter reviews a number of interdisciplinary science education activities that introduce health issues in the context of biology, physics, and chemistry education, ensuring deep understanding needed for developing critical literacy. It also discusses science education approaches and theories that encourage the development of deep, culturally meaningful science knowledge. Finally, the chapter reviews professional development and the role of various professionals, including teachers and librarians, in the collaborative endeavor of effective health information provision.}
}
@article{AOKI2013310,
title = {Propagation & level: Factors influencing in the ICT composite index at the school level},
journal = {Computers & Education},
volume = {60},
number = {1},
pages = {310-324},
year = {2013},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2012.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0360131512001741},
author = {Hiroyuki Aoki and JaMee Kim and WonGyu Lee},
keywords = {ICT level, ICT composite index, Media in education, Pedagogical issue,  component and  component},
abstract = {Many nations are greatly affected by their education policies, and the educational level of different schools is relevant to a nation’s ICT policy. In the area of ICT, Korea has achieved quite high levels of competency. This study analyzed the level of ICT competency of 4490 elementary and 2419 middle schools in Korea within the context of the Korean educational system and social circumstances. The findings are as follows: first, differences in ICT level were greater among elementary schools than among middle schools; and secondly, ICT usage had a great impact on the ICT composite index for both elementary and middle schools. For both elementary and middle schools, the indicators that were found to have the greatest impact on the ICT composite index were ‘effort to make use of computers and ICT resources’ and ‘teaching of ICT-related subjects.’ Another variable that affected ICT competency was the level of ICT competency among the teachers and their willingness to use ICT in their lessons. This study found that merely the building of an ICT infrastructure is not enough to enhance the ICT level of schools. In addition to an ICT infrastructure the efforts of the teachers and administration were more important than any other factors. The findings of this study might provide useful suggestions to other nations that are endeavoring to enhance the ICT levels of their schools.}
}
@incollection{CAIRNS19863,
title = {CHAPTER 1 - A Contemporary Perspective on Social Development},
editor = {Phillip S. Strain and Michael J. Guralnick and Hill M. Walker},
booktitle = {Children's Social Behavior},
publisher = {Academic Press},
pages = {3-47},
year = {1986},
isbn = {978-0-12-673455-3},
doi = {https://doi.org/10.1016/B978-0-12-673455-3.50005-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780126734553500051},
author = {Robert B. Cairns}
}
@article{ALE2022100478,
title = {A systematic survey on embodied cognition: 11 years of research in child–computer interaction},
journal = {International Journal of Child-Computer Interaction},
volume = {33},
pages = {100478},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100478},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000174},
author = {Moyosore Ale and Miriam Sturdee and Elisa Rubegni},
keywords = {Embodied cognition, Children, Child–computer interaction, Systematic literature review, Embodied interaction},
abstract = {Embodied cognition is a concept that has been extensively explored by scholars within the Child–Computer Interaction community. However, there is a lack of a synthesis of this research to clarify the field’s benefits and drawbacks. This paper presents a survey of articles published between 2010 and 2020 in the Interaction Design and Children (IDC) conference and the International Journal of Child–Computer Interaction (IJCCI). We retrieved 158 papers using the keyword ”embodied cognition” and its derivatives. Further screening narrowed these down to 43. The purpose of this review is to provide an overview of the current landscape of ‘embodied’ research by reporting the most common subject areas of application, forms, and modes of embodiment, and the role of children and adults. Our contribution is twofold: we highlight the main trends around these themes within the field, and we provide eight critical areas of future research. By illustrating new challenges and opportunities, we aim to support the growth of this area of research within the CCI community.}
}
@article{GROSSMAN201718,
title = {Pedagogy and tools for teaching parallel computing at the sophomore undergraduate level},
journal = {Journal of Parallel and Distributed Computing},
volume = {105},
pages = {18-30},
year = {2017},
note = {Keeping up with Technology: Teaching Parallel, Distributed and High-Performance Computing},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2016.12.026},
url = {https://www.sciencedirect.com/science/article/pii/S0743731517300047},
author = {Max Grossman and Maha Aziz and Heng Chi and Anant Tibrewal and Shams Imam and Vivek Sarkar},
keywords = {Autograding, Parallel, MPI, Java, JVM, Education, Multi-threading, Tools, Pedagogy},
abstract = {As the need for multicore-aware programmers rises in both science and industry, Computer Science departments in universities around the USA are having to rethink their parallel computing curriculum. At Rice University, this rethinking took the shape of COMP 322, an introductory parallel programming course that is required for all Bachelors students. COMP 322 teaches students to reason about the behavior of parallel programs, educating them in both the high level abstractions of task-parallel programming as well as the nitty gritty details of working with threads in Java. In this paper, we detail the structure, principles, and experiences of COMP 322, gained from 6 years of teaching parallel programming to second-year undergraduates. We describe in detail two particularly useful tools that have been integrated into the curriculum: the HJlibparallel programming library and the Habanero Autograder for parallel programs. We present this work with the hope that it will help augment improvements to parallel computing education at other universities.}
}
@article{YURKOFSKY20191,
title = {Expanding outcomes: Exploring varied conceptions of teacher learning in an online professional development experience},
journal = {Teaching and Teacher Education},
volume = {82},
pages = {1-13},
year = {2019},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2019.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X17308247},
author = {Maxwell M. Yurkofsky and Sarah Blum-Smith and Karen Brennan},
keywords = {Teacher learning, Professional development, Learning outcomes, Online learning},
abstract = {Online technologies hold promise to support more personalized teacher professional development (PD) experiences, but fulfilling this promise requires heightened attention to what teachers value about the outcomes of their learning. This paper uses the example of the Creative Computing Online Workshop (CCOW) to explore outcomes that teachers described as valuable: exposure to new ideas, rethinking classroom practice, and new relationships with their surrounding world. We discuss how the diversity, specificity, and nonlinearity of these outcomes extend teacher PD research, and suggest implications of this expanded framework for the design and evaluation of PD in both in-person and online contexts.}
}
@article{ADORNI2024100466,
title = {Development of algorithmic thinking skills in K-12 education: A comparative study of unplugged and digital assessment instruments},
journal = {Computers in Human Behavior Reports},
volume = {15},
pages = {100466},
year = {2024},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100466},
url = {https://www.sciencedirect.com/science/article/pii/S245195882400099X},
author = {Giorgia Adorni and Igor Artico and Alberto Piatti and Elia Lutz and Luca Maria Gambardella and Lucio Negrini and Francesco Mondada and Dorit Assaf},
keywords = {Teaching/learning strategies, 21st century abilities, Evaluation methodologies, Elementary education, Secondary education},
abstract = {In the rapidly evolving landscape of digital competencies, the need for a robust and universal method to assess students’ algorithmic thinking (AT) skills has become increasingly pronounced. Algorithmic thinking refers to the ability to analyse a problem and develop a step-by-step process to solve it. This research investigates the efficacy of the Cross Array Task (CAT) as an assessment tool for AT skills within Switzerland’s compulsory education system. Originally conceptualised as an unplugged activity, where students performed the task without digital technologies (e.g., by using gestures on paper) and an administrator manually assessed them, the CAT evolved into a digital activity that runs on an iPad. The CAT’s digital transformation has automated the scoring of student responses and data collection, streamlining the assessment processes and facilitating efficient large-scale assessments. It has also enhanced scalability, making the CAT suitable for widespread use in educational settings. Furthermore, it provides immediate feedback to students and educators, supporting timely interventions and personalised learning experiences. Our study aims to comprehensively investigate algorithmic competencies in compulsory education, examining their variations and influencing factors. This research examines key variables, such as age, sex, educational environment and school characteristics (e.g., the level and grade of education), and regional factors (e.g., the canton of the school) in Switzerland, and characteristics related to the specific assessment tool, including the type of artefact used, the complexity of the algorithms generated, and the level of autonomy. Additionally, it seeks to analyse the effectiveness of the unplugged and digital approaches in assessing AT skills, specifically comparing the unplugged and virtual CAT versions, aiming to provide insights into their advantages and potential synergies. This investigation delineates the developmental progression of AT skills across compulsory education, emphasising the influence of age on algorithm development and problem-solving strategies. Furthermore, we reveal the impact of artefacts and the potential of digital tools to facilitate advanced AT skill development across diverse age groups. Finally, our investigation delves into the influence of school environments and sex disparities on AT performance, alongside the significant individual variability influenced by personal abilities and external circumstances. These findings underscore the importance of tailored educational interventions and equitable practices to accommodate diverse learning profiles and optimise student outcomes in AT across educational settings.}
}
@article{MCCART2013235,
title = {Goal attainment on long tail web sites: An information foraging approach},
journal = {Decision Support Systems},
volume = {55},
number = {1},
pages = {235-246},
year = {2013},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2013.01.025},
url = {https://www.sciencedirect.com/science/article/pii/S0167923613000535},
author = {J.A. McCart and B. Padmanabhan and D.J. Berndt},
keywords = {Information Foraging Theory, Long tail, Data mining, Clickstream analysis},
abstract = {The long tail has attracted substantial theoretical as well as practical interest, yet there have been few empirical studies that have explicitly examined the factors that drive online conversions at these sites. This research tests several hypotheses derived from Information Foraging Theory (IFT) that pertain to goal achievement on long tail Web sites. IFT introduced concepts of information patches and information scent to model information seeking behavior of individuals, but has mostly been tested in production rule environments where the theory is used to simulate user behavior. Testing IFT-driven hypotheses on real data required learning information patches and scents using an inductive approach and in this paper we adapt existing algorithms for these discovery tasks. Our results based on clickstream data from forty-seven small business Web sites show both the existence of valuable information patches and information scent trails as well as their importance in explaining conversion on these sites. The majority of the hypotheses were supported and we discuss the implications of this for researchers and practitioners.}
}
@article{CHAO2016202,
title = {Exploring students' computational practice, design and performance of problem-solving through a visual programming environment},
journal = {Computers & Education},
volume = {95},
pages = {202-215},
year = {2016},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2016.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0360131516300161},
author = {Po-Yao Chao},
keywords = {Computer programming, Visual problem solving, Students programming patterns},
abstract = {This study aims to advocate that a visual programming environment offering graphical items and states of a computational problem could be helpful in supporting programming learning with computational problem-solving. A visual problem-solving environment for programming learning was developed, and 158 college students were conducted in a computational problem-solving activity. The students' activities of designing, composing, and testing solutions were recorded by log data for later analysis. To initially unveil the students' practice and strategies exhibited in the visual problem-solving environment, this study proposed several indicators to quantitatively represent students' computational practice (Sequence, Selection, Simple iteration, Nested iteration, and Testing), computational design (Problem decomposition, Abutment composition, and Nesting composition), and computational performance (Goal attainment and Program size). By the method of cluster analysis, some empirical patterns regarding the students' programming learning with computational problem-solving were identified. Furthermore, comparisons of computational design and computational performance among the different patterns of computational practice were conducted. Considering the relations of students' computational practice to computational design and performance, evidence-based suggestions on the design of supportive programming environments for novice programmers are discussed.}
}
@article{WU201535,
title = {What makes an item more difficult? Effects of modality and type of visual information in a computer-based assessment of scientific inquiry abilities},
journal = {Computers & Education},
volume = {85},
pages = {35-48},
year = {2015},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2015.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0360131515000329},
author = {Hsin-Kai Wu and Che-Yu Kuo and Tsung-Hau Jen and Ying-Shao Hsu},
keywords = {Architectures for educational technology system, Secondary education, Applications in subject areas},
abstract = {Effects of multiple external representations on teaching and learning have been widely researched; however, relatively little is understood about how different types of representations used for item presentation influence students' performances in computer-based assessments, particularly in those evaluating complex abilities. We designed a multimedia-based assessment for secondary school students that focused on scientific inquiry abilities (i.e., questioning, experimenting, analyzing, and explaining). Through the participation of 1218 students (561 8th graders and 657 11th graders), the balanced arrangement of test booklets, and the use of a generalized partial credit Rasch model, this study aimed at investigating how the modality of representations for item presentation (i.e., dynamic and static) and type of visual information (i.e., context and content) conveyed by the representations affected the item difficulty of the multimedia-based assessment. The results showed that overall items became slightly more difficult for students when the item presentation was static. Also, the interaction effect between modality and grade was significant; when item presentation was changed from dynamic to static, the items became easier to the 8th graders, whereas they were more difficult to the 11th graders. The results suggested that older students might have more cognitive resources to retrieve information from dynamic displays to solve the assessment tasks successfully. Additionally, while all interactions between modality and type of information on items with context visuals were not significant, there were significant interactions on four items with content visuals. A further examination of the items suggested that the tasks and the phenomena involved in the items may influence how modality affected the item difficulties when content visuals were used. These results implied that researchers need to pay special attention on the design of content visuals because they appear to be more influential than context ones to students' performances of science assessments.}
}
@incollection{KIRK2013235,
title = {Chapter 11 - Application Case Study: Advanced MRI Reconstruction},
editor = {David B. Kirk and Wen-mei W. Hwu},
booktitle = {Programming Massively Parallel Processors (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {235-264},
year = {2013},
isbn = {978-0-12-415992-1},
doi = {https://doi.org/10.1016/B978-0-12-415992-1.00011-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780124159921000110},
author = {David B. Kirk and Wen-mei W. Hwu}
}
@article{ROSSON2008468,
title = {Design planning by end-user web developers},
journal = {Journal of Visual Languages & Computing},
volume = {19},
number = {4},
pages = {468-484},
year = {2008},
note = {Selected Papers from IEEE Symposium on Visual Languages and Human Centric Computing 2007 (VL/HCC 2007)},
issn = {1045-926X},
doi = {https://doi.org/10.1016/j.jvlc.2008.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S1045926X08000141},
author = {Mary Beth Rosson and Hansa Sinha and Mithu Bhattacharya and Dejin Zhao},
keywords = {End-user programming, Web development, Design, Concept maps},
abstract = {We report an exploratory research project that investigates the impacts of different forms of design planning on end users asked to develop a simple interactive web application. End users created their projects (a Ride Board application) using the CLICK end-user web development tool [J. Rode, User-centered design of end-user web development tool, Ph.D. Dissertation, Department of Computer Science, Virginia Tech, Blacksburg, VA, USA, 2005]. Some participants were asked to create a conceptual map to plan their projects and others to write user interaction scenarios; a third group was asked to do whatever they found useful. We describe the planning that each group underwent, how they approached the web development task, and their reactions to the experience afterwards. The overall pattern of results suggests that while the participants who planned using scenarios felt they better understood the web development task, it was the group who created concept maps that explored and incorporated more of the novel programming features of the CLICK tool. We also discuss the role of gender in the CLICK development task, noting that women were less likely to explore the tool's novel features and perceived themselves as less successful in the task. We conclude with a discussion of design implications and future work.}
}
@article{HUANG2024152294,
title = {Machine learning in energy storage material discovery and performance prediction},
journal = {Chemical Engineering Journal},
volume = {492},
pages = {152294},
year = {2024},
issn = {1385-8947},
doi = {https://doi.org/10.1016/j.cej.2024.152294},
url = {https://www.sciencedirect.com/science/article/pii/S1385894724037811},
author = {Guochang Huang and Fuqiang Huang and Wujie Dong},
abstract = {Energy storage material is one of the critical materials in modern life. However, due to the difficulty of material development, the existing mainstream batteries still use the materials system developed decades ago. Machine learning (ML) is rapidly changing the paradigm of energy storage material discovery and performance prediction due to its ability to solve complex problems efficiently and automatically. Various excellent works are constantly emerging in the field of ML assisted or dominated development of energy storage material, such as exploring of new materials, studying of battery performance, investigating of battery aging mechanism. In this paper, we methodically review recent advances in discovery and performance prediction of energy storage materials relying on ML. After a brief introduction to the general workflow of ML, we provide an overview of the current status and dilemmas of ML databases commonly used in energy storage materials. The typical applications and examples of ML to the finding of novel energy storage materials and the performance forecasting of electrode and electrolyte materials. Furthermore, we explore the dilemmas that will be faced in the development of applied ML-assisted or dominated energy storage materials and propose a corresponding outlook. This review systematically summarizes the current development of ML-assisted energy storage materials research, which is expected to point the way for its further development.}
}
@article{STRYCKER2020e04358,
title = {K-12 art teacher technology use and preparation},
journal = {Heliyon},
volume = {6},
number = {7},
pages = {e04358},
year = {2020},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2020.e04358},
url = {https://www.sciencedirect.com/science/article/pii/S2405844020312020},
author = {Jesse Strycker},
keywords = {Applications in the subject area, Art education, Educational technology, Elementary education, Instructional technology, Post-secondary education, Secondary education, Teaching/learning strategies, Educational development, Evaluation in education, Media education, Pedagogy, Teaching research, Education},
abstract = {Largely absent from educational/instructional technology journals, this study focused on how K-12 art teachers in a southern state used technology to support teaching and learning, uses they found to be the best, and what kinds of technology training they received as part of their initial teacher preparation. Findings indicated that presentation and resource access technologies had transformed the way art teachers in the study work with students and materials. They also had little use of technology to support students with special needs and had limited technology experiences in their own training. Elementary art teachers were found to have more examples of student higher-order thinking skills promoting technology use, while secondary art teachers had more student media creation and a desire to implement digital portfolios. Additional findings and interpretations are offered.}
}
@article{RUAN2019101268,
title = {Soft computing model based financial aware spatiotemporal social network analysis and visualization for smart cities},
journal = {Computers, Environment and Urban Systems},
volume = {77},
pages = {101268},
year = {2019},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2018.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0198971517304829},
author = {Lei Ruan and Chunyan Li and Yan Zhang and Haoxiang Wang},
keywords = {Soft computing model, Financial, Spatiotemporal, Social network analysis, Data visualization, Smart cities, Computing paradigms},
abstract = {The era of intelligence is the development of human science and technology at a higher level, bringing a new layout for the financial market. Then, how to realize the good layout of the financial market in the era of intelligence is an important problem facing all the countries in the world. We in the financial industry as the origin and change as the clue, analyzes the physical outlets as the representative of the financial institutions, banking as standard electronic banking and mobile phone to the bank as the representative of the mobile financial development of three major formats. On this basis, we analyze the current mobile phone terminal model of mobile banking three shortcomings, and propose the new mobile financial formats. This new format is tentatively known as “smart financial format”, it has the equipment personality, wearable, low carbon environmental protection, offline interaction, security, privacy and intelligence, efficiency, and other five major characteristics. In the future, the financial format is likely to be achieved by mobile financial formats to the upgrading of intelligent financial formats, to meet the needs of customers wider and deeper levels. The artificial intelligence method has its advantages in dealing with the problems of the economic system. Therefore, the introduction of artificial intelligence methods into the economic control will become a trend. The proposed model is validated through the public databases to verify the effectiveness.}
}
@incollection{DIETRICH19943,
title = {CHAPTER 1 - Thinking Computers and The Problem of Intentionality},
editor = {Eric Dietrich},
booktitle = {Thinking Computers and Virtual Persons},
publisher = {Academic Press},
pages = {3-34},
year = {1994},
isbn = {978-0-12-215495-9},
doi = {https://doi.org/10.1016/B978-0-12-215495-9.50006-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780122154959500065},
author = {Eric Dietrich},
abstract = {Publisher Summary
This chapter is an attempt to clear the names of artificial intelligence (AI) and computational cognitive science. These two related disciplines have been accused of a conceptual error so profound that their very existence is jeopardized. Sometimes, however, philosophers successfully arrest and lock up the guilty. The best example of this, ironically, is in psychology. Artificial intelligence and computational cognitive science are both committed to the claim that computers can think. The former is committed to the claim that human-made computers can think, while computational cognitive science is committed to the view that naturally occurring computers, brains, think. AI is the field dedicated to building intelligent computers. AI ultimately wants a machine that could solve very difficult, novel problems like proving Fermat's last theorem, correcting the greenhouse effect, or figuring out the fundamental structure of space-time. Historically, AI is associated with computer science, but the compleat AI researcher frequently knows a fair amount of psychology, linguistics, neuroscience, mathematics, and possibly some other discipline.}
}
@article{MARKAUSKAITE2022100056,
title = {Rethinking the entwinement between artificial intelligence and human learning: What capabilities do learners need for a world with AI?},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100056},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100056},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2200011X},
author = {Lina Markauskaite and Rebecca Marrone and Oleksandra Poquet and Simon Knight and Roberto Martinez-Maldonado and Sarah Howard and Jo Tondeur and Maarten {De Laat} and Simon {Buckingham Shum} and Dragan Gašević and George Siemens},
keywords = {Capabilities for AI, AI in education, Postdigital dialogue, Ecological approach},
abstract = {The proliferation of AI in many aspects of human life—from personal leisure, to collaborative professional work, to global policy decisions—poses a sharp question about how to prepare people for an interconnected, fast-changing world which is increasingly becoming saturated with technological devices and agentic machines. What kinds of capabilities do people need in a world infused with AI? How can we conceptualise these capabilities? How can we help learners develop them? How can we empirically study and assess their development? With this paper, we open the discussion by adopting a dialogical knowledge-making approach. Our team of 11 co-authors participated in an orchestrated written discussion. Engaging in a semi-independent and semi-joint written polylogue, we assembled a pool of ideas of what these capabilities are and how learners could be helped to develop them. Simultaneously, we discussed conceptual and methodological ideas that would enable us to test and refine our hypothetical views. In synthesising these ideas, we propose that there is a need to move beyond AI-centred views of capabilities and consider the ecology of technology, cognition, social interaction, and values.}
}
@incollection{GONCALVES2013515,
title = {Chapter 27 - Social Networks, Contagion Processes and the Spreading of Infectious Diseases},
editor = {A.J. Marian Walhout and Marc Vidal and Job Dekker},
booktitle = {Handbook of Systems Biology},
publisher = {Academic Press},
address = {San Diego},
pages = {515-527},
year = {2013},
isbn = {978-0-12-385944-0},
doi = {https://doi.org/10.1016/B978-0-12-385944-0.00027-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780123859440000277},
author = {Bruno Gonçalves and Nicola Perra and Alessandro Vespignani}
}
@incollection{FREWIN2012209,
title = {Chapter 6 - Biocompatibility of SiC for Neurological Applications},
editor = {Stephen E. Saddow},
booktitle = {Silicon Carbide Biotechnology},
publisher = {Elsevier},
address = {Oxford},
pages = {209-256},
year = {2012},
isbn = {978-0-12-385906-8},
doi = {https://doi.org/10.1016/B978-0-12-385906-8.00006-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780123859068000064},
author = {Christopher L. Frewin and Chris Locke and Stephen E. Saddow and Edwin J. Weeber},
keywords = {Central nervous system, glial scarring, biocompatibility, in vitro, PC12, H4, neuron, MTT assay, live cell atomic force microscopy, silicon, 3C-SiC, nanocrystalline diamond, in vivo, long-term implantation},
abstract = {Publisher Summary
This chapter introduces the research that done at the University of South Florida to determine the biocompatibility of single-crystal SiC and related materials with neuronal and glial cells to determine whether they are possible candidate materials for the construction of a neuronal implantation device. It describes the basics about the CNS, how it is organized, and its major cellular constituents are described and their purposes within the CNS. Following this, it considers the research investigating the in vitro biocompatibility of 3C-SiC and a related material, nanocrystalline diamond (NCD), with immortalized neuronal and CNS cell lines. The in vitro reaction of primary derived neurons with 3C-SiC is also detailed, followed by initial in vivo testing of 3C-SiC within the brain of a wild-type mouse. The central nervous system (CNS) is composed of the brain and spinal cord. Blood is not in direct contact with the extracellular fluid within the CNS because of restrictive endothelial cells that create a tight junction known as the blood–brain barrier. Any physical biomedical device that would interact with the CNS has to deal with cells that perform functions similar to their leukocyte counterparts found within the bloodstream. The therapeutic utility provided by these devices is that they could be utilized as a platform for drug delivery behind the blood–brain barrier to specific CNS areas, or to transport neuronal factors or even other cells to the CNS to assist in the repair of the neural system damaged by trauma and disease.}
}