@INPROCEEDINGS{1261500,
  author={Riley and Riley},
  booktitle={Proceedings of the 2003 Winter Simulation Conference, 2003.}, 
  title={SPADES - a distributed agent simulation environment with software-in-the-loop execution}, 
  year={2003},
  volume={1},
  number={},
  pages={817-825 Vol.1},
  abstract={Simulations are used extensively for studying artificial intelligence. However, the simulation technology in use by and designed for the artificial intelligence community often fails to take advantage of much of the work by the larger simulation community to produce distributed, repeatable, and efficient simulations. We present the system for parallel agent discrete event simulation, (SPADES), which is a simulation environment for the artificial intelligence community. SPADES focuses on the agent as a fundamental simulation component. The thinking time of an agent is tracked and reflected in the results of the agents' actions by using a software-in-the-loop mechanism. SPADES supports distributed execution of the agents across multiple systems, while at the same time producing repeatable results regardless of network or system load. We discuss the design of SPADES and give experimental results. SPADES is flexible enough for a variety of application domains in the artificial intelligence research community.},
  keywords={Computational modeling;Artificial intelligence;Discrete event simulation;Computer simulation;Design engineering;Concurrent computing;Distributed computing;Computer science;Machine learning;Educational institutions},
  doi={10.1109/WSC.2003.1261500},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{894685,
  author={Traver, V.J. and del Pobil, A.P. and Perez-Francisco, M.},
  booktitle={Proceedings. 2000 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2000) (Cat. No.00CH37113)}, 
  title={Making service robots human-safe}, 
  year={2000},
  volume={1},
  number={},
  pages={696-701 vol.1},
  abstract={This paper first reviews the literature about the very important but neglected issue of safety in service-robots applications. Most of the few existing approaches are limited because they lack flexibility. We argue that human-tailored safety schemes are greatly needed, and propose two strategies in the line we think human-safe robots should be conceived. A fast method to derive the robot's incremental movements given a workspace force applied to the robot constitutes the basis of the robot behaviors that underlie the proposed strategies. Our simulations show that our strategies are safe, human-friendly and exhibit real-time performance. Finally, we discuss the many ways in which our work can be extended.},
  keywords={Service robots;Safety;Humans;Intelligent robots;Industrial accidents;Machinery;Laboratories;Computational modeling;Computer science;Injuries},
  doi={10.1109/IROS.2000.894685},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9725687,
  author={Gupta, Ashulekha and Parmar, Rishabh and Suri, Pradeep and Kumar, Rajiv},
  booktitle={2021 3rd International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)}, 
  title={Determining Accuracy Rate of Artificial Intelligence Models using Python and R-Studio}, 
  year={2021},
  volume={},
  number={},
  pages={889-894},
  abstract={Research investigation in this study, an Artificial-Neural-Network (ANN) castoff to conjecture monetary market conduct. Our primary objective is to build up a neural system to see whether a stock pays a profit or not utilizing RStudio and Python. We propose and execute Artificial Neural Network to estimate monetary market conduct. This apparatus can be utilized for top to bottom examination of the securities exchange. Utilizing ANN, we foresee the reliance of the needy variable profit on the other autonomous factors like free income per share (fcfps), profit development, obligation to value proportion (de), showcase capitalization (mcap), and current proportion. We have prepared the neural system utilizing the neuralnet library and tried the precision of the model. We make the perplexity framework to think about the true/false positives and negatives. We yield an exactness rate of the neural system that estimate in deciding if a stock pays a profit or not.},
  keywords={Computational modeling;Artificial neural networks;Data models;Libraries;Security;Artificial intelligence;Logistics;Artificial neural network;stock market;machine learning;BSE},
  doi={10.1109/ICAC3N53548.2021.9725687},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{215383,
  author={Barrington, D.A.M.},
  booktitle={[1992] Proceedings of the Seventh Annual Structure in Complexity Theory Conference}, 
  title={Quasipolynomial size circuit classes}, 
  year={1992},
  volume={},
  number={},
  pages={86-93},
  abstract={Circuit complexity theory has tried to understand which problems can be solved by 'small' circuits of constant depth. Normally 'small' has meant 'polynomial in the input size', but a number of recent results have dealt with circuits of size 2 to the log n/sup 0(1)/ power, or quasipolynomial size. The author summarizes the reasons for thinking about the complexity classes so introduced, surveys these results and gives an overview of these classes. He also shows that the Barrington-Immerman-Straubing uniformity definition for polynomial-size classes can easily be extended to quasipolynomial size as well, with most of the key results remaining true in the uniform setting.<>},
  keywords={Polynomials;Turing machines;Computer science;Testing;Robustness;Computational modeling;Automata;Logic circuits},
  doi={10.1109/SCT.1992.215383},
  ISSN={},
  month={June},}@INPROCEEDINGS{5429423,
  author={Tako, Antuela A. and Robinson, Stewart},
  booktitle={Proceedings of the 2009 Winter Simulation Conference (WSC)}, 
  title={Comparing model development in Discrete Event Simulation and System Dynamics}, 
  year={2009},
  volume={},
  number={},
  pages={979-991},
  abstract={This paper provides an empirical study on the comparison of model building in Discrete-Event Simulation (DES) and System Dynamics (SD). Verbal Protocol Analysis (VPA) is used to study the model building process of ten expert modellers (5 SD and 5 DES). Participants are asked to build a simulation model based on a prison population case study and to think aloud while modelling. The generated verbal protocols are divided into 7 modelling topics: problem structuring, conceptual modelling, data inputs, model coding, validation & verification, results & experimentation and implementation and then analyzed. Our results suggest that all modellers switch between modelling topics, however DES modellers follow a more linear progression compared to SD modellers. DES modellers focus significantly more on model coding and verification & validation, whereas SD modellers on conceptual modelling. This quantitative analysis of the processes followed by expert modellers contributes towards the comparison of DES and SD modelling.},
  keywords={Discrete event simulation;Protocols;Computational modeling;Switches;Buildings;Analytical models;Computer simulation;Stochastic processes;Statistical distributions;Problem-solving},
  doi={10.1109/WSC.2009.5429423},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{6883402,
  author={Xu, Chuan and Zhao, Guofeng and Xie, Gaogang and Yu, Shui},
  booktitle={2014 IEEE International Conference on Communications (ICC)}, 
  title={Detection on application layer DDoS using random walk model}, 
  year={2014},
  volume={},
  number={},
  pages={707-712},
  abstract={Application Layer Distributed Denial of Service (ALDDoS) attacks have been increasing rapidly with the growth of Botnets and Ubiquitous computing. Differentiate to the former DDoS attacks, ALDDoS attacks cannot be efficiently detected, as attackers always adopt legitimate requests with real IP address, and the traffic has high similarity to legitimate traffic. In spite of that, we think, the attackers' browsing behavior will have great disparity from that of the legitimate users'. In this paper, we put forward a novel user behavior-based method to detect the application layer asymmetric DDoS attack. We introduce an extended random walk model to describe user browsing behavior and establish the legitimate pattern of browsing sequences. For each incoming browser, we observe his page request sequence and predict subsequent page request sequence based on random walk model. The similarity between the predicted and the observed page request sequence is used as a criterion to measure the legality of the user, and then attacker would be detected based on it. Evaluation results based on real collected data set has demonstrated that our method is very effective in detecting asymmetric ALDDoS attacks.},
  keywords={Computer crime;Vectors;Probability distribution;Predictive models;Educational institutions;Computational modeling;Information systems;Asymmetric application layer DDoS attack;anomaly detection;random walk model;similarity},
  doi={10.1109/ICC.2014.6883402},
  ISSN={1938-1883},
  month={June},}@ARTICLE{895188,
  author={Goel, A. and Baker, C.A. and Shaffer, C.A. and Grossman, B. and Mason, W.H. and Watson, L.T. and Haftka, R.T.},
  journal={Computing in Science & Engineering}, 
  title={VizCraft: a problem-solving environment for aircraft configuration design}, 
  year={2001},
  volume={3},
  number={1},
  pages={56-66},
  abstract={The VizCraft problem-solving environment aids aircraft designers during conceptual design of a high-speed civil transport (HSCT). It integrates simulation codes that evaluate a design with visualizations for analyzing a design individually or in contrast to other designs. VizCraft provides a graphical user interface to a widely used suite of simulation and analysis codes for HSCT design, and it provides tools for visualizing the outputs of these codes. So, VizCraft provides an environment that combines visualization and computation, encouraging the designer to think in terms of the overall problem-solving task, not simply using the visualization to view the computation's results.},
  keywords={Problem-solving;Aerodynamics;Data visualization;Computational modeling;Analytical models;Geometry;Aircraft propulsion;Graphical user interfaces;Solid modeling;Multidimensional systems},
  doi={10.1109/5992.895188},
  ISSN={1558-366X},
  month={Jan},}@INPROCEEDINGS{9667644,
  author={Durgapal, Ayushman and Vimal, Vrince},
  booktitle={2021 IEEE 8th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)}, 
  title={Prediction of Stock Price Using Statistical and Ensemble learning Models: A Comparative Study}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Prediction of the stock price has always been a challenging task due to irregular patterns of the market. Uncertainty has made researchers think of some new and robust predictive methods. Many studies are available in the literature, with many models to predict the stock price accurately. Statistical, machine learning, deep learning, and other related approaches can create a predictive model. ARIMA model is the most commonly used statistical model for time series prediction. But ensemble learning techniques have not been explored much to predict future stock price. So, the present study stresses comparing statistical methods with ensemble learning methods. This paper compares the ARIMA, Random Forest, and Extreme Gradient Boosting models based on root mean squared error (RMSE) and mean absolute percentage error (MAPE). The subject chosen is Google’s stocks, and the data used is from NASDAQ stock exchange. The analysis results show that the ARIMA model performed fairly well for short-term predictions but relatively high MAPE value. The extreme gradient boosting model gave the best performance with the lowest RMSE and MAPE value. Hence, it is evident that after proper hyperparameter tuning, ensemble learning techniques can be used to create robust stock price-prediction models.},
  keywords={Uncertainty;Computational modeling;Time series analysis;Predictive models;Boosting;Task analysis;Stock markets;Ensemble learning Models;ARIMA;Random Forest Model;Extreme gradient Boosting Model;Stock Price Prediction},
  doi={10.1109/UPCON52273.2021.9667644},
  ISSN={2687-7767},
  month={Nov},}@ARTICLE{9666041,
  author={Yang, Howard H. and Chen, Zihan and Quek, Tony Q. S. and Poor, H. Vincent},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={Revisiting Analog Over-the-Air Machine Learning: The Blessing and Curse of Interference}, 
  year={2022},
  volume={16},
  number={3},
  pages={406-419},
  abstract={We study a distributed machine learning problem carried out by an edge server and multiple agents in a wireless network. The objective is to minimize a global function that is a sum of the agents’ local loss functions. And the optimization is conducted by analog over-the-air model training. Specifically, each agent modulates its local gradient onto a set of waveforms and transmits to the edge server simultaneously. From the received analog signal the edge server extracts a noisy aggregated gradient which is distorted by the channel fading and interference, and uses it to update the global model and feedbacks to all the agents for another round of local computing. Since the electromagnetic interference generally exhibits a heavy-tailed intrinsic, we use the $\alpha$-stable distribution to model its statistic. In consequence, the global gradient has an infinite variance that hinders the use of conventional techniques for convergence analysis that rely on second-order moments’ existence. To circumvent this challenge, we take a new route to establish the analysis of convergence rate, as well as generalization error, of the algorithm. We also show that the training algorithm can be run in tandem with the momentum scheme to accelerate the convergence. Our analyses reveal a two-sided effect of the interference on the overall training procedure. On the negative side, heavy tail noise slows down the convergence rate of the model training: the heavier the tail in the distribution of interference, the slower the algorithm converges. On the positive side, heavy tail noise has the potential to increase the generalization power of the trained model: the heavier the tail, the better the model generalizes. This perhaps counterintuitive conclusion implies that the prevailing thinking on interference – that it is only detrimental to the edge learning system – is outdated and we shall seek new techniques that exploit, rather than simply mitigate, the interference for better machine learning in wireless networks.},
  keywords={Servers;Interference;Training;Convergence;Computational modeling;Machine learning;Fading channels;Distributed machine learning;analog over-the-air computing;heavy-tailed interference;convergence rate;generalization error},
  doi={10.1109/JSTSP.2021.3139231},
  ISSN={1941-0484},
  month={April},}@INPROCEEDINGS{7004261,
  author={Jindal, Alekh and Madden, Samuel},
  booktitle={2014 IEEE International Conference on Big Data (Big Data)}, 
  title={GRAPHiQL: A graph intuitive query language for relational databases}, 
  year={2014},
  volume={},
  number={},
  pages={441-450},
  abstract={Graph analytics is becoming increasingly popular, driving many important business applications from social network analysis to machine learning. Since most graph data is collected in a relational database, it seems natural to attempt to perform graph analytics within the relational environment. However, SQL, the query language for relational databases, makes it difficult to express graph analytics operations. This is because SQL requires programmers to think in terms of tables and joins, rather than the more natural representation of graphs as collections of nodes and edges. As a result, even relatively simple graph operations can require very complex SQL queries. In this paper, we present GRAPHiQL, an intuitive query language for graph analytics, which allows developers to reason in terms of nodes and edges. GRAPHiQL provides key graph constructs such as looping, recursion, and neighborhood operations. At runtime, GRAPHiQL compiles graph programs into efficient SQL queries that can run on any relational database. We demonstrate the applicability of GRAPHiQL on several applications and compare the performance of GRAPHiQL queries with those of Apache Giraph (a popular `vertex centric' graph programming language).},
  keywords={Database languages;Relational databases;Aggregates;Engines;Computational modeling;Vectors},
  doi={10.1109/BigData.2014.7004261},
  ISSN={},
  month={Oct},}@ARTICLE{5978202,
  author={Yu, Yuanlong and Mann, George K. I. and Gosine, Raymond G.},
  journal={IEEE Transactions on Autonomous Mental Development}, 
  title={A Goal-Directed Visual Perception System Using Object-Based Top–Down Attention}, 
  year={2012},
  volume={4},
  number={1},
  pages={87-103},
  abstract={The selective attention mechanism is employed by humans and primates to realize a truly intelligent perception system, which has the cognitive capability of learning and thinking about how to perceive the environment autonomously. The attention mechanism involves the top-down and bottom-up ways that correspond to the goal-directed and automatic perceptual behaviors, respectively. Rather than considering the automatic perception, this paper presents an artificial system of the goal-directed visual perception by using the object-based top-down visual attention mechanism. This cognitive system can guide the perception to an object of interest according to the current task, context and learned knowledge. It consists of three successive stages: preattentive processing, top-down attentional selection and post-attentive perception. The preattentive processing stage divides the input scene into homogeneous proto-objects, one of which is then selected by the top-down attention and finally sent to the post-attentive perception stage for high-level analysis. Experimental results of target detection in the cluttered environments are shown to validate this system.},
  keywords={Computational modeling;Visualization;Visual perception;Feature extraction;Probabilistic logic;Integrated circuits;Context;Cognitive visual perception;goal-directed;integrated competition hypothesis;object-based visual attention;top–down visual attention},
  doi={10.1109/TAMD.2011.2163513},
  ISSN={1943-0612},
  month={March},}@ARTICLE{9507307,
  author={Hoque, Md Naimul and Mueller, Klaus},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Outcome-Explorer: A Causality Guided Interactive Visual Interface for Interpretable Algorithmic Decision Making}, 
  year={2022},
  volume={28},
  number={12},
  pages={4728-4740},
  abstract={The widespread adoption of algorithmic decision-making systems has brought about the necessity to interpret the reasoning behind these decisions. The majority of these systems are complex black box models, and auxiliary models are often used to approximate and then explain their behavior. However, recent research suggests that such explanations are not overly accessible to lay users with no specific expertise in machine learning and this can lead to an incorrect interpretation of the underlying model. In this article, we show that a predictive and interactive model based on causality is inherently interpretable, does not require any auxiliary model, and allows both expert and non-expert users to understand the model comprehensively. To demonstrate our method we developed Outcome Explorer, a causality guided interactive interface, and evaluated it by conducting think-aloud sessions with three expert users and a user study with 18 non-expert users. All three expert users found our tool to be comprehensive in supporting their explanation needs while the non-expert users were able to understand the inner workings of a model easily.},
  keywords={Predictive models;Artificial intelligence;Data models;Biological system modeling;Computational modeling;Machine learning;Decision making;Human computer interaction;Explainable AI;causality;visual analytics;human-computer interaction},
  doi={10.1109/TVCG.2021.3102051},
  ISSN={1941-0506},
  month={Dec},}@ARTICLE{87598,
  author={Kravitz, S.A. and Bryant, R.E. and Rutenbar, R.A.},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
  title={Massively parallel switch-level simulation: a feasibility study}, 
  year={1991},
  volume={10},
  number={7},
  pages={871-894},
  abstract={The feasibility of mapping the COSMOS switch-level simulator onto a computer with thousands of simple processors is addressed. COSMOS preprocesses transistor networks into Boolean behavioral models, capturing the switch-level behavior of a circuit in a set of Boolean formulas. A class of massively parallel computers and a mapping of COSMOS onto these computers are described. The factors affecting the performance of such a massively parallel simulator are discussed, including: the amount of parallelism in the simulation model, performance measures for massively parallel machines, and the impact of event scheduling on simulator performance. Compilation tools that automatically map a MOS circuit onto a massively parallel computer have been developed. Techniques for restructuring Boolean expressions for greater parallelism and mapping Boolean expressions for evaluation on massively parallel machines are described. Massively parallel switch-level simulation is illustrated by a pilot implementation on a 32k-processor Thinking Machines Connection Machine system.<>},
  keywords={Computational modeling;Concurrent computing;Circuit simulation;Discrete event simulation;Logic;Computer simulation;Parallel processing;Parallel machines;Communication switching;Switching circuits},
  doi={10.1109/43.87598},
  ISSN={1937-4151},
  month={July},}@ARTICLE{9911763,
  author={Sharma, Geetanjali and Joshi, Amit M.},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={SzHNN: A Novel and Scalable Deep Convolution Hybrid Neural Network Framework for Schizophrenia Detection Using Multichannel EEG}, 
  year={2022},
  volume={71},
  number={},
  pages={1-9},
  abstract={In the field of neuroscience, brain activity measurement and analysis are considered crucial areas. Schizophrenia (Sz) is a brain disorder that severely affects the thinking, behavior, and feelings of people worldwide. Thus, an accurate and rapid detection method is needed for proper care and quality treatment of the patients. Electroencephalography (EEG) is proved to be an efficient biomarker in Sz detection as it records brain activities. This article aims to improve the performance of EEG-based Sz detection using a deep-learning approach in remote applications. A hybrid deep-learning model identified as schizophrenia hybrid neural network (SzHNN), which is a combination of convolutional neural networks (CNNs) and long short-term memory (LSTM), has been proposed wherein the CNN for local feature extraction and LSTM for classification is utilized. In this article, the proposed model has been compared with several deep-learning and machine-learning-based models. All the models have been evaluated on two different datasets wherein dataset 1 consists of 19 subjects and dataset 2 consists of 16 subjects. The proposed model is also implemented with the Internet-of-Medical-Things (IoMT) framework for smart healthcare and remote-based applications. Several experiments have been conducted using various parametric settings on different frequency bands and different sets of electrodes on the scalp. Based on all the experiments, it is evident that the proposed hybrid model (SzHNN) provides the highest classification accuracy of 99.9% compared to other implemented models and existing models of previous papers. The proposed model overcomes the influence of different frequency bands and shows a better accuracy of 96.10% (dataset 1) and 91.00% (dataset 2) with only five electrodes. Subject-wise testing is also done for SzHNN, which proposes an accuracy of 90.11% and 89.60% for datasets 1 and 2, respectively.},
  keywords={Electroencephalography;Brain modeling;Feature extraction;Convolutional neural networks;Deep learning;Computational modeling;Medical services;Abnormal brain activity;electroencephalography (EEG);hybrid neural network;Internet of Medical Things (IoMT);schizophrenia (Sz)},
  doi={10.1109/TIM.2022.3212040},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{4117798,
  author={Talcott, Carolyn},
  booktitle={Proceedings of the 2006 Winter Simulation Conference}, 
  title={Symbolic Modeling of Signal Transduction in Pathway Logic}, 
  year={2006},
  volume={},
  number={},
  pages={1656-1665},
  abstract={Pathway logic is a step towards a vision of symbolic systems biology. It is an approach to modeling cellular processes based on formal methods. In particular, formal executable models of processes such as signal transduction, metabolic pathways, and immune system cell-cell signaling are developed using the rewriting logic language Maude and a variety of formal tools are used to query these models. An important objective of Pathway Logic is to reflect the ways that biologists think about problems using informal models, and to provide bench biologists with tools for computing with and analyzing these models that are natural. In this paper we describe the pathway logic approach to the modeling and analysis of signal transduction, and the use of the pathway logic assistant tool to browse and query these models. The Rac1 signaling pathway is used to illustrate the concepts},
  keywords={Logic;Biological system modeling;Biological processes;Proteins;Systems biology;Signal processing;Biology computing;Predictive models;Cognitive science;Computational modeling},
  doi={10.1109/WSC.2006.322940},
  ISSN={1558-4305},
  month={Dec},}@ARTICLE{9459713,
  author={García-Holgado, Alicia and Vázquez-Ingelmo, Andrea and García-Peñalvo, Francisco J. and Conde, MªJosé Rodríguez},
  journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, 
  title={Improvement of Learning Outcomes in Software Engineering: Active Methodologies Supported Through the Virtual Campus}, 
  year={2021},
  volume={16},
  number={2},
  pages={143-153},
  abstract={There are some subjects that are seen as a challenge by both students and teachers. One of these subjects is Software Engineering, where the novelty of its concepts and the need of applying abstract thinking need major efforts to understand new paradigms of design and development of information systems. Due to these difficulties, students face the subject with low motivation. The present work describes a series of teaching methodology changes carried out during the last three academic years, specially the implementation carried out during the 2017-18 year. The analysis of the results shows a high correlation between the students' participation and the success ratio of the subject by comparing the results obtained by students studying the active methodology in 2017-18 and the results for the academic year 2013-14.},
  keywords={Software engineering;Collaborative work;Software;Education;Conferences;Proposals;Computational modeling;Active methodology;collaborative learning;virtual campus;software engineering;PBL;technological ecosystem},
  doi={10.1109/RITA.2021.3089926},
  ISSN={1932-8540},
  month={May},}@INPROCEEDINGS{10075649,
  author={Brown, Eli T. and Yarlagadda, Sriram and Cook, Kristin A. and Chang, Remco and Endert, Alex},
  booktitle={2018 IEEE Workshop on Machine Learning from User Interaction for Visualization and Analytics (MLUI)}, 
  title={ModelSpace: Visualizing the Trails of Data Models in Visual Analytics Systems}, 
  year={2018},
  volume={},
  number={},
  pages={1-11},
  abstract={User interactions with visualization systems have been shown to encode a great deal of information about the the users’ thinking processes, and analyzing their interaction trails can teach us more about the users, their approach, and how they arrived at insights. This deeper understanding is critical to improving their experience and outcomes, and there are tools available to visualize logs of interactions. It can be difficult to determine the structurally interesting parts of interaction data, though, like what set of button clicks constitutes an action that matters. In the case of visual analytics systems that use machine learning models, there is a convenient marker of when the user has significantly altered the state of the system via interaction: when the model is updated based on new information. We present a method for numerical analytic provenance using high-dimensional visualization to show and compare the trails of these sequences of model states of the system. We evaluate this approach with a prototype tool, ModelSpace, applied to two case studies on experimental data from model-steering visual analytics tools. ModelSpace reveals individual user’s progress, the relationships between their paths, and the characteristics of certain regions of the space of possible models.},
  keywords={Human computer interaction;Analytical models;Visual analytics;Computational modeling;Conferences;Data visualization;Prototypes;Human-centered computing;Visualization;Visualization design and evaluation methods},
  doi={10.1109/MLUI52768.2018.10075649},
  ISSN={},
  month={Oct},}@ARTICLE{6579596,
  author={Salako, Kizito and Strigini, Lorenzo},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={When Does "Diversity"' in Development Reduce Common Failures? Insights from Probabilistic Modeling}, 
  year={2014},
  volume={11},
  number={2},
  pages={193-206},
  abstract={Fault tolerance via diverse redundancy, with multiple "versions"' of a system in a redundant configuration, is an attractive defence against design faults. To reduce the probability of common failures, development and procurement practices pursue "diversity"' between the ways the different versions are developed. But difficult questions remain open about which practices are more effective to this aim. About these questions, probabilistic models have helped by exposing fallacies in "common sense" judgements. However, most make very restrictive assumptions. They model well scenarios in which diverse versions are developed in rigorous isolation from each other: A condition that many think desirable, but is unlikely in practice. We extend these models to cover nonindependent development processes for diverse versions. This gives us a rigorous way of framing claims and open questions about how best to pursue diversity, and about the effects--negative and positive--of commonalities between developments, from specification corrections to the choice of test cases. We obtain three theorems that, under specific scenarios, identify preferences between alternative ways of seeking diversity. We also discuss nonintuitive issues, including how expected system reliability may be improved by creating intentional "negative"' dependences between the developments of different versions.},
  keywords={Phase frequency detector;Software;Reliability;Random variables;Computational modeling;Correlation;Probabilistic logic;Common-mode failure;software diversity;fault tolerance;multiversion software;probability of failure on demand;reliability},
  doi={10.1109/TDSC.2013.32},
  ISSN={1941-0018},
  month={March},}@INPROCEEDINGS{6328190,
  author={Cocco, Luisanna and Mannaro, Katiuscia and Concas, Giulio},
  booktitle={2012 38th Euromicro Conference on Software Engineering and Advanced Applications}, 
  title={A Model for Global Software Development with Cloud Platforms}, 
  year={2012},
  volume={},
  number={},
  pages={446-452},
  abstract={Cloud Computing (CC) is a technological phenomenon that is becoming more and more important. Also Small and Medium Enterprises (SMEs) can increase their competitiveness by taking advantage of CC. This new computing approach promises to provide many advantages, and many SMEs are encouraged to use it. However, CC is still in its early stage - for this reason we think that it is very important to study and assess its impact on SMEs' management processes. In this paper we propose a model for studying how Global Software Development can be facilitated using Cloud development environments, compared to a more traditional development environment. We use system dynamics to model and simulate how effective Cloud-based software development environments are for Global Software Development performed by a SMEs. Both studied environments assume a development process based on Scrum agile methodology. The proposed model could be used as a tool by the project managers to understand how Cloud Development Environments might facilitate Global Software Development.},
  keywords={Analytical models;Planning;Computational modeling;Cloud computing;Delay;Hardware;System Dynamics;Modeling;Simulation;Cloud System;Scrum;Global Software Development},
  doi={10.1109/SEAA.2012.67},
  ISSN={2376-9505},
  month={Sep.},}@INPROCEEDINGS{6051784,
  author={Moser, Dominik and Riener, Andreas and Zia, Kashif and Ferscha, Alois},
  booktitle={2011 IEEE/ACM 15th International Symposium on Distributed Simulation and Real Time Applications}, 
  title={Comparing Parallel Simulation of Social Agents Using Cilk and OpenCL}, 
  year={2011},
  volume={},
  number={},
  pages={88-97},
  abstract={Recent advances in wireless/mobile communication and body worn sensors, together with ambient intelligence and seamless integrated pervasive technology have paved the way for applications operating based on social signals, i.e., sensing and processing of group behavior, interpersonal relationships, or emotions. Thinking in large, it should be apparent that modeling social systems allowing to study crowd behavior emerging from individual entities' (agents') condition and/or characteristics is, in fact, a challenging task. To address the heterogeneity, analytical agent-based models (ABMs) are gaining popularity due to its capability of directly representing individual entities and their interactions, unfortunately, ABMs (in which each agent has unique behavior) are not very well suited for large populations, expressed by exponentially rising simulation time. To solve this problem, the questions (i) how does the parallel execution of such models scale with capabilities of both the machine (number of cores, cluster size, etc.) and agents (behavioral adaptation function, interaction extent, etc.) and (ii) what is, in comparison, the performance coefficient applying the approach of model execution on graphical processors (GPUs) with its different pipelining architecture, need answers. To this end, we have performed simulation runs with parameter variation on a real parallel and distributed hardware platform using Cilk as well as on a GPU employing OpenCL. Simulation efficiency for two realistic models with varying complexity on a scale of 107 agents has shown the usefulness of both approaches.},
  keywords={Graphics processing unit;Adaptation models;Computational modeling;Object oriented modeling;Instruction sets;Sensors;Biological system modeling;Parallel distributed simulation;Shared memory architecture;GPU execution;Multi-core cluster;Agent-based modeling;GPGPU},
  doi={10.1109/DS-RT.2011.12},
  ISSN={1550-6525},
  month={Sep.},}@INPROCEEDINGS{6405443,
  author={Kull, Andres},
  booktitle={2012 IEEE 23rd International Symposium on Software Reliability Engineering Workshops}, 
  title={Automatic GUI Model Generation: State of the Art}, 
  year={2012},
  volume={},
  number={},
  pages={207-212},
  abstract={Modeling has been one of the most significant obstacles to why model-based testing has not been taken into use by industry on a large scale. Therefore, generating models automatically is an attractive way of thinking. In well-structured application domains, such as graphical user interface (GUI), this method can be used successfully. This paper gives a state-of-the-art overview of GUI model generation methods. The paper analyzes the methods from the point of view of model-based testing of GUI applications, where generated GUI models are used for generating the tests.},
  keywords={Graphical user interfaces;Testing;Reverse engineering;Computational modeling;Analytical models;Instruments;Manuals;Model-based testing;automatic GUI model generation;GUI model},
  doi={10.1109/ISSREW.2012.23},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7033637,
  author={Zakay, Netanel and Feitelson, Dror G.},
  booktitle={2014 IEEE 22nd International Symposium on Modelling, Analysis & Simulation of Computer and Telecommunication Systems}, 
  title={Preserving User Behavior Characteristics in Trace-Based Simulation of Parallel Job Scheduling}, 
  year={2014},
  volume={},
  number={},
  pages={51-60},
  abstract={Evaluating the performance of a computer system requires the use of representative workloads. Therefore it is customary to use recorded job traces in simulations to evaluate the performance of proposed parallel job schedulers. We argue that this practice retains unimportant attributes of the workload, at the expense of other more important attributes. Specifically, using traces in open-system simulations retains the exact timestamps at which jobs are submitted. But in a real system these times depend on how users react to the performance of previous jobs, and it is more important to preserve the logical structure of dependencies between jobs than the specific timestamps. Using dependency information extracted from traces, we show how a simulation can preserve these dependencies. To do so we also extract user behavior, in terms of sessions and think times between the termination of one batch of jobs and the submission of a subsequent batch.},
  keywords={Throughput;Load modeling;Computational modeling;Analytical models;Reliability;Measurement;Time factors;Workload trace;Feedback;Simulation},
  doi={10.1109/MASCOTS.2014.15},
  ISSN={2375-0227},
  month={Sep.},}@INPROCEEDINGS{9313119,
  author={Li, Mengze and Kuang, Kun and Zhu, Qiang and Chen, Xiaohong and Guo, Qing and Wu, Fei},
  booktitle={2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={IB-M: A Flexible Framework to Align an Interpretable Model and a Black-box Model}, 
  year={2020},
  volume={},
  number={},
  pages={643-649},
  abstract={Both interpretation and accuracy are very important for a predictive model in real applications, but most of previous works, no matter interpretable models or black-box models, cannot simultaneously achieve both of them, resulting in a tradeoff between model interpretation and model accuracy. To break this trade-off, in this paper, we propose a flexible framework, named IB-M, to align an $\underline{I}$nterpretable model and a $\underline{B}$lack-box $\underline{M}$odel for simultaneously optimizing model interpretation and model accuracy. Generally, we think most of samples that are well-clustered or away from the true decision boundary can be easily interpreted by an interpretable model. Removing those samples can help to learn a more accurate black-box model by focusing on the left samples around the true decision boundary. Inspired by this, we propose a data re-weighting based framework to align an interpretable model and a black-box model, letting them focus on the samples what they are good at, hence, achieving both interpretation and accuracy. We implement our IB-M framework for a real medical problem of ultrasound thyroid nodule diagnosis. Extensive experiments demonstrate that our proposed framework and algorithm can achieve a more interpretable and more accurate diagnosis than a single interpretable model and a single black-box model.},
  keywords={Data models;Predictive models;Thyroid;Medical diagnostic imaging;Computational modeling;Deep learning;Ultrasonic imaging;Interpretable model;Black-box model;Thyroid nodules},
  doi={10.1109/BIBM49941.2020.9313119},
  ISSN={},
  month={Dec},}@ARTICLE{9230430,
  author={Zahálka, Jan and Worring, Marcel and Van Wijk, Jarke J.},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={II-20: Intelligent and pragmatic analytic categorization of image collections}, 
  year={2021},
  volume={27},
  number={2},
  pages={422-431},
  abstract={In this paper, we introduce 11–20 (Image Insight 2020), a multimedia analytics approach for analytic categorization of image collections. Advanced visualizations for image collections exist, but they need tight integration with a machine model to support the task of analytic categorization. Directly employing computer vision and interactive learning techniques gravitates towards search. Analytic categorization, however, is not machine classification (the difference between the two is called the pragmatic gap): a human adds/redefines/deletes categories of relevance on the fly to build insight, whereas the machine classifier is rigid and non-adaptive. Analytic categorization that truly brings the user to insight requires a flexible machine model that allows dynamic sliding on the exploration-search axis, as well as semantic interactions: a human thinks about image data mostly in semantic terms. 11–20 brings three major contributions to multimedia analytics on image collections and towards closing the pragmatic gap. Firstly, a new machine model that closely follows the user's interactions and dynamically models her categories of relevance. II-20's machine model, in addition to matching and exceeding the state of the art's ability to produce relevant suggestions, allows the user to dynamically slide on the exploration-search axis without any additional input from her side. Secondly, the dynamic, 1-image-at-a-time Tetris metaphor that synergizes with the model. It allows a well-trained model to analyze the collection by itself with minimal interaction from the user and complements the classic grid metaphor. Thirdly, the fast-forward interaction, allowing the user to harness the model to quickly expand (“fast-forward”) the categories of relevance, expands the multimedia analytics semantic interaction dictionary. Automated experiments show that II-20's machine model outperforms the existing state of the art and also demonstrate the Tetris metaphor's analytic quality. User studies further confirm that II–20 is an intuitive, efficient, and effective multimedia analytics tool.},
  keywords={Analytical models;Semantics;Pragmatics;Computational modeling;Task analysis;Visual analytics;Multimedia analytics;image data;analytic categorization;pragmatic gap},
  doi={10.1109/TVCG.2020.3030383},
  ISSN={1941-0506},
  month={Feb},}@ARTICLE{9169672,
  author={Wang, Bo and Zhao, Mengnan and Wang, Wei and Wei, Fei and Qin, Zhan and Ren, Kui},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Are You Confident That You Have Successfully Generated Adversarial Examples?}, 
  year={2021},
  volume={31},
  number={6},
  pages={2089-2099},
  abstract={Deep neural networks (DNNs) have seen extensive studies on image recognition and classification, image segmentation, and related topics. However, recent studies show that DNNs are vulnerable in defending adversarial examples. The classification network can be deceived by adding a small amount of perturbation to clean samples. There are challenges when researchers want to design a general approach to defend against a wide variety of adversarial examples. To solve this problem, we introduce a defensive method to prevent adversarial examples from generating. Instead of designing a stronger classifier, we built a more robust classification system that can be viewed as a structural black box. After adding a buffer to the classification system, attackers can be efficiently deceived. The real evaluation results of the generated adversarial examples are often contrary to what the attacker thinks. Additionally, we do not assume a specific attack method premise. This incognizance to underlying attacks demonstrates the generalizability of the buffer to potential adversarial attacks. Extensive experiments indicate that the defense method greatly improves the security performance of DNNs.},
  keywords={Perturbation methods;Iterative methods;Computational modeling;Neural networks;Security;Training;Robustness;Deep neural networks;adversarial examples;structural black box;buffer},
  doi={10.1109/TCSVT.2020.3017006},
  ISSN={1558-2205},
  month={June},}@ARTICLE{7544618,
  author={Qi, Xiaokang and Ye, Dexin and Sun, Yongzhi and Li, Changzhi and Ran, Lixin},
  journal={IEEE Transactions on Magnetics}, 
  title={Simulations to True Animals’ Long-Distance Geomagnetic Navigation}, 
  year={2017},
  volume={53},
  number={1},
  pages={1-8},
  abstract={How animals navigate in their cross-continental migration has puzzled scientists for centuries. To date, the mechanism behind this mysterious navigation remains unclear. In this paper, a hypothesis is developed and computer simulations have been performed to investigate long-distance animal navigation. Simulation results show that animals may be able to complete their long-distance navigation by observing a spatial angle included by the geomagnetic field line and a geographic direction, without necessarily knowing any prior landmark information. Our results not only match existing observation reports in detail on the long-distance migration routes of animals, but also are able to explain the conflicting evidence on the role of geomagnetic field in animal navigation. We think our results could help reveal the actual mechanism of animal navigation. This paper also provides a potential solution for global and local area navigation of mankind and machines assisted by artificial sensors.},
  keywords={Navigation;Kalman filters;Computational modeling;Computer simulation;Birds;Prediction algorithms;Animal navigation;biological informatics;geomagnetic field;Kalman filter},
  doi={10.1109/TMAG.2016.2600540},
  ISSN={1941-0069},
  month={Jan},}@INPROCEEDINGS{7889991,
  author={Patel, Jigar and Chouhan, Ankit},
  booktitle={2016 International Conference on Communication and Electronics Systems (ICCES)}, 
  title={An approach to introduce basics of Salesforce.com: A cloud service provider}, 
  year={2016},
  volume={},
  number={},
  pages={1-8},
  abstract={In a recent scenario, IT industries are growing with the help of proper Utilization of available resources. The IT giants like Microsoft, Infosys, IBM, Oracle, & TCS are switching from theirs on premises IT setups to the cloud. Cloud computing is replacing the traditional model in which software applications installed on on-premise hardware, from desktop computers to server rooms, depending on the size of the business. The proposed work is about the cloud platform which is going to change all the traditional views of software, application, and product development Technologies. Salesforce.com is one of the best cloud providers available in the recent scenario. There are number of reasons why IT industries are switching to the Cloud. And there are number of reasons why Industries have to think to adopt Salesforce.com cloud. The proposed work is about to focus on important and common features of salsforce.com. These features are common for any developer to learn and use in to software, application and product development in salesforce.com. The goal of this proposed work is to show the available resources in the salesforce.com which are still new for the developers. This an approach to make people familiar with the salesforce.com cloud provider.},
  keywords={Cloud computing;Computational modeling;Software as a service;Customer relationship management;Servers;Cloud Computing;Iaas;Paas;Saas;Salesforce.com;force.com},
  doi={10.1109/CESYS.2016.7889991},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{1574323,
  author={Andradottir, S. and Goldsman, D. and Schruben, L.W. and Schmeiser, B.W. and Yucesan, E.},
  booktitle={Proceedings of the Winter Simulation Conference, 2005.}, 
  title={Analysis methodology: are we done? [discrete-event simulation]}, 
  year={2005},
  volume={},
  number={},
  pages={7 pp.-},
  abstract={Since 1967, the Winter Simulation Conference has been a forum for the introduction of innovative approaches to effectively analyze discrete-event simulation experiments. The goal of this panel is to bring together key contributors to analysis methodology research in order to clarify areas that they think are essentially complete, and identify areas that need more work. In doing so, we hope to help provide direction to younger researchers looking for the "right" problems to work on.},
  keywords={Computational modeling;Analytical models;Discrete event simulation;Design optimization;Industrial engineering;Analysis of variance;Computer errors;Random variables;Stochastic processes;Computer simulation},
  doi={10.1109/WSC.2005.1574323},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{6957180,
  author={Li, Xiaosong and Cai, Wentong and Turner, Stephen John},
  booktitle={2014 IEEE/ACM 18th International Symposium on Distributed Simulation and Real Time Applications}, 
  title={Efficient Neighbor Searching for Agent-Based Simulation on GPU}, 
  year={2014},
  volume={},
  number={},
  pages={87-96},
  abstract={This paper introduces a strategy to accelerate neighbor searching in agent-based simulations on GPU platforms. Because of their autonomous nature, agents can be processed by threads concurrently on GPU, and the overall simulation can be accelerated consequently. Each agent will simultaneously carry out a sense-think-act cycle in every time step. The neighbor searching is a crucial part in the sensing stage. Detecting and accessing neighbors is a memory intensive task and often becomes the major time consumer in an agent-based simulation. Our contribution, an enhanced neighbor sharing strategy, greatly speeds up this procedure when comparing with CPU implementations. The strategy is developed from a global-memory-only implementation, and then gradually improved by efficiently utilizing the much faster shared memory. In our case studies, speedups of 89.08 and 11.51 are obtained on an NVIDIA Tesla K20 GPU compared with the sequential implementation and OpenMP parallel implementation respectively on an Intel Xeon E5-2670 CPU.},
  keywords={Graphics processing units;Instruction sets;Arrays;Resource management;Computational modeling;Hardware;Neighbor searching;Shared memory;Speedup},
  doi={10.1109/DS-RT.2014.19},
  ISSN={1550-6525},
  month={Oct},}@INPROCEEDINGS{7561126,
  author={Agrawal, Prakash and Vutukuru, Mythili},
  booktitle={2016 Twenty Second National Conference on Communication (NCC)}, 
  title={Trace based application layer modeling in ns-3}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={Ns-3 is a widely used as a the network simulator of choice by researchers. It contains many well tested and high quality models of network protocols. However, the application layer models of ns-3 are very simplistic, and do not capture all aspects of real life applications. As a result, there is often a huge gap between the results of real experiments and the corresponding simulations. This problem is particularly exacerbated for wireless simulations, where many networking phenomena like wireless channel contention crucially depend on the application traffic characteristics. One way to bridge the gap between experiments and simulations is to incorporate knowledge from network traces into simulations. To this end, our work builds a trace-based application layer simulator in ns-3. Given a network trace collected from a user, our TraceReplay application layer model automatically generates traffic that is faithful to the real application in the ns-3 simulator. TraceReplay infers and replays only application layer delays like user think times, lets the simulator control the lower layer phenomena. TraceReplay extracts application layer characteristics from a single trace, and replays this information across many users in simulation, by using suitable randomization. Our model is also generic enough to replay any application layer protocol. Validation of our simulation model shows that simulation results obtained using TraceReplay are significantly different from those using other models, and are closer to experimental observations.},
  keywords={Delays;Protocols;Servers;Wireless communication;Computational modeling;Simulation;Data transfer},
  doi={10.1109/NCC.2016.7561126},
  ISSN={},
  month={March},}@INPROCEEDINGS{1586360,
  author={Kravitz, S.A. and Bryant, R.E. and Rutenbar, R.A.},
  booktitle={26th ACM/IEEE Design Automation Conference}, 
  title={Massively Parallel Switch-Level Simulation: A Feasibility Study}, 
  year={1989},
  volume={},
  number={},
  pages={91-97},
  abstract={This work addresses the feasibility of mapping the COSMOS switch-level simulator onto a computer with thousands of simple processors. COSMOS preprocesses transistor networks into Boolean behavioral models, capturing the switch-level behavior of a circuit in a set of Boolean formulas. We describe a class of massively parallel computers and a mapping of COSMOS onto these computers. We discuss the factors affecting the performance of such a massively parallel simulator including: the amount of parallelism in the simulation model, performance measures for massively parallel machines, and the impact of event scheduling on simulator performance. We have developed compilation tools which automatically map a MOS circuit onto a massively parallel computer. Massively parallel switch-level simulation is illustrated by describing our pilot implementation on a 32k processor Thinking Machines Connection Machine System.},
  keywords={Computational modeling;Circuit simulation;Concurrent computing;Computer simulation;Discrete event simulation;Logic;Switching circuits;Parallel processing;Parallel machines;Communication switching},
  doi={10.1145/74382.74399},
  ISSN={0738-100X},
  month={June},}@INPROCEEDINGS{9842631,
  author={Khan, Lamia Parven and Anika, Tasfia Tahsin and Hanif, Suraka Iban and Rahman, Rashedur M.},
  booktitle={2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Network Intrusion Detection Using Stack-Ensemble ANN}, 
  year={2022},
  volume={},
  number={},
  pages={1104-1109},
  abstract={Network and security is connected with each other. At present days thinking about communication without the network is impossible. Since the network is a public domain and anyone can use it, some corrupted people and hackers will try to gain profit by intruding others' sensitive information. The network intrusion can be done by some hackers or the network itself. For that reason ensuring security is more challenging than ever before. The proposed model detects the intrusion types currently in the network by using deep learning ANN and stack ensemble techniques. There is no space for compromise in security so it is strongly recommended to use an intrusion detection system that is more accurate and efficient. The reason for using a stacked ensemble is that even though a single deep learning model is strong enough to detect the intrusion, yet by using the stacked ensemble combines multiple deep learning models together to get a more efficient stronger intrusion detection mechanism.},
  keywords={Deep learning;Computer hacking;Computational modeling;Conferences;Network intrusion detection;Software;Security;ANN;stack;ensemble;ReLu;softmax;overfitting},
  doi={10.1109/COMPSAC54236.2022.00173},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{8885193,
  author={Scherzinger, Stefanie and Seifert, Christin and Wiese, Lena},
  booktitle={2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={The Best of Both Worlds: Challenges in Linking Provenance and Explainability in Distributed Machine Learning}, 
  year={2019},
  volume={},
  number={},
  pages={1620-1629},
  abstract={Machine learning experts prefer to think of their input as a single, homogeneous, and consistent data set. However, when analyzing large volumes of data, the entire data set may not be manageable on a single server, but must be stored on a distributed file system instead. Moreover, with the pressing demand to deliver explainable models, the experts may no longer focus on the machine learning algorithms in isolation, but must take into account the distributed nature of the data stored, as well as the impact of any data pre-processing steps upstream in their data analysis pipeline. In this paper, we make the point that even basic transformations during data preparation can impact the model learned, and that this is exacerbated in a distributed setting. We then sketch our vision of end-to-end explainability of the model learned, taking the pre-processing into account. In particular, we point out the potentials of linking the contributions of research on data provenance with the efforts on explainability in machine learning. In doing so, we highlight pitfalls we may experience in a distributed system on the way to generating more holistic explanations for our machine learning models.},
  keywords={Machine learning;Distributed databases;Data models;Decision trees;Computational modeling;Entropy;explainable machine learning;distributed computing;provenance},
  doi={10.1109/ICDCS.2019.00161},
  ISSN={2575-8411},
  month={July},}@INPROCEEDINGS{4581462,
  author={Essabbah, M. and Otmane, S and Mallem, M.},
  booktitle={2008 Conference on Human System Interactions}, 
  title={3D molecular modeling: from theory to applications}, 
  year={2008},
  volume={},
  number={},
  pages={350-355},
  abstract={Genomic sequences are initially known by their linear form. However, they have also a three-dimensional structure which can be useful for genomes analysis. This 3D structure representation brings a new point of view for the sequences analysis. It was established that the importance of the molecular spatial structure has created increasingly a growing interest for 3D modeling molecules. Therefore, several studies have described the design of software for 3D molecular visualization. Some of these tools offer even 3D molecular manipulation through virtual models. But these 3D models are often based on predictive methods leading to a family of so-called predictive models. This constraint has meant that biologists doubt the effectiveness of these models, thinking they lack of structural realism and therefore functional one. The solution that we propose is the confrontation between models and real data. This approach compares 3D virtual models and real microscopic images of the same molecule in order to validate and/or improve the 3D model. User interaction is possible to enhance comparison.},
  keywords={Biological system modeling;Biology;Computational modeling;Three dimensional displays;Solid modeling;Proteins;RNA;Molecular biology;3D modeling;3D visualization;3D interactive systems},
  doi={10.1109/HSI.2008.4581462},
  ISSN={2158-2254},
  month={May},}@INPROCEEDINGS{1574548,
  author={Gustavsson, P.M. and Planstedt, T.},
  booktitle={Proceedings of the Winter Simulation Conference, 2005.}, 
  title={The road towards multi-hypothesis intention simulation agents architecture - fractal information fusion modeling}, 
  year={2005},
  volume={},
  number={},
  pages={10 pp.-},
  abstract={This paper presents the road towards multi-hypothesis intention simulation agents architecture and is focused on the fractal information fusion model (FIF) that are formed to support a systems-thinking in an agent architecture that aligns with the global information grid, NATO net enabled capabilities and Swedish armed force enterprise architecture initiatives. The Joint Directors of Laboratories information fusion model and the Observe, Orient, Decide, Act loop by John Boyd is combined and used as the foundation together with the knowledge model, level of conceptual interoperability shaping the FIF-model. The FIF-model's effect in shaping of the multi-hypothesis intention simulation agents architecture is presented},
  keywords={Fractals;Service oriented architecture;Computer architecture;Roads;Computational modeling;Computer simulation;Force control;Shape control;Communication system control;Grid computing},
  doi={10.1109/WSC.2005.1574548},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{6385704,
  author={Wagner, Alan R.},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Using cluster-based stereotyping to foster human-robot cooperation}, 
  year={2012},
  volume={},
  number={},
  pages={1615-1622},
  abstract={Psychologists note that humans regularly use categories to simplify and speed up the process of person perception [1]. The influence of categorical thinking on interpersonal expectations is commonly referred to as a stereotype. The ability to bootstrap the process of learning about a newly encountered, unknown person is critical for robots interacting in complex and dynamic social situations. This article contributes a novel cluster-based algorithm that allows a robot to create generalized models of its interactive partner. These generalized models, or stereotypes, act as a source of information for predicting the human's behavior and preferences. We show, in simulation and using real robots, that these stereotyped models of the partner can be used to bootstrap the robot's learning about the partner in spite of significant error. The results of this work have potential implications for social robotics, autonomous agents, and possibly psychology.},
  keywords={Robot kinematics;Humans;Clustering algorithms;Mathematical model;Computational modeling;Classification algorithms},
  doi={10.1109/IROS.2012.6385704},
  ISSN={2153-0866},
  month={Oct},}@ARTICLE{9028800,
  author={Wang, Dewen and Zhou, Fangfang and Li, Jiangman},
  journal={Journal of Modern Power Systems and Clean Energy}, 
  title={Cloud-based parallel power flow calculation using resilient distributed datasets and directed acyclic graph}, 
  year={2019},
  volume={7},
  number={1},
  pages={65-77},
  abstract={With the integration of distributed generation and the construction of cross-regional long-distance power grids, power systems become larger and more complex. They require faster computing speed and better scalability for power flow calculations to support unit dispatch. Based on the analysis of a variety of parallelization methods, this paper deploys the large-scale power flow calculation task on a cloud computing platform using resilient distributed datasets (RDDs). It optimizes a directed acyclic graph that is stored in the RDDs to solve the low performance problem of the MapReduce model. This paper constructs and simulates a power flow calculation on a large-scale power system based on standard IEEE test data. Experiments are conducted on Spark cluster which is deployed as a cloud computing platform. They show that the advantages of this method are not obvious at small scale, but the performance is superior to the stand-alone model and the MapReduce model for large-scale calculations. In addition, running time will be reduced when adding cluster nodes. Although not tested under practical conditions, this paper provides a new way of thinking about parallel power flow calculations in large-scale power systems.},
  keywords={Computational modeling;Cloud computing;Newton method;Power grids;Parallel programming;Convergence;Power flow calculation;Parallel programming model;Distributed memory-shared model;Resilient distributed datasets (RDDs);Directed acyclic graph (DAG)},
  doi={10.1007/s40565-018-0406-4},
  ISSN={2196-5420},
  month={January},}@ARTICLE{9677006,
  author={Chen, Fupeng and Yu, Heng and Jiang, Weixiong and Ha, Yajun},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
  title={Quality Optimization of Adaptive Applications via Deep Reinforcement Learning in Energy Harvesting Edge Devices}, 
  year={2022},
  volume={41},
  number={11},
  pages={4873-4886},
  abstract={Applications with adaptability are widely available on the edge devices with energy harvesting capabilities. For their runtime quality optimization, however, current approaches cannot tackle the variations of quality modeling and harvested energy simultaneously. Therefore, in this article, we are the first to propose a deep reinforcement learning (DRL)-based dynamic voltage frequency scaling (DVFS) method that optimizes the application execution quality of energy harvesting edge devices to mitigate the variations. First, we propose a baseline DRL formulation that novelly migrates the objective of quality maximization into a reward function and constructs a DRL quality agent. Second, we devise a long short-term memory (LSTM)-based selector that performs DRL quality agent selection based on the energy harvesting history. Third, we further propose two optimization methods to alleviate the nonnegligible overhead of DRL computations: 1) an improved thinking-while-moving concurrent DRL scheme to compromise the “state drifting” issue during the DRL decision process and 2) a variable interstate duration decision scheme that compromises the DVFS overhead incurred in each action taken. The experiments take an adaptive stereo matching application as a case study. The results show that the proposed DRL-based DVFS method on average achieves 17.9% runtime reduction and 22.05% quality improvement compared to state-of-the-art solutions.},
  keywords={Adaptation models;Energy harvesting;Uncertainty;Optimization;Task analysis;Computational modeling;Runtime;Adaptive application;deep reinforcement learning (DRL);energy harvesting;quality optimization;stereo matching},
  doi={10.1109/TCAD.2022.3142188},
  ISSN={1937-4151},
  month={Nov},}@INPROCEEDINGS{6218402,
  author={Kampichler, Wolfgang and Eier, Dieter},
  booktitle={2012 Integrated Communications, Navigation and Surveillance Conference}, 
  title={Cloud based services in air traffic management}, 
  year={2012},
  volume={},
  number={},
  pages={G5-1-G5-9},
  abstract={Air traffic management (ATM) services are migrating towards a global seamless concept. This requires new thinking not only on the necessary operational changes but also on the technological paradigms that determine our current service architectures. Driven by the availability of more and more bandwidth within wide area ground networks new technologies are emerging such as Cloud Computing. Beyond that, operational concepts of FAA's NEXTGEN and Europe's SESAR include dynamically moving the responsibility for airspace blocks from one facility to another, and ensuring continuity of operation by providing contingency operations. This contribution assesses the applicability of cloud computing in ATM, and the key differences to existing commercial applications. It presents the technical cloud computing elements necessary to achieve a truly global ATM system and addresses harmonization and interoperability aspects such as standardized working procedures and controller working positions equipment for air traffic controllers. Situational awareness is key for the decision making process of controllers and pilots in NEXTGEN. A key element different to commercial cloud applications is the necessity to communicate with aircraft and pilots as cloud participants via narrowband VHF radio communications, SATCOM, or other wireless communications technologies. Situational awareness of these participants is paramount which, in the current system, is automatically provided due to the broadcast nature of voice transmissions from controllers and pilots that can be received and heard by all listeners on a particular frequency nearly simultaneously (propagation delay of the radio signal not considered). To efficiently manage the access to this shared media and limit the access only to “relevant” participants, the concept of ATC sector within a geographical area, with boundaries (horizontal and vertical) aligned with traffic patterns exists today. This paper describes mechanisms that demonstrate how SATCOM, VHF, and various data link technologies can be integrated into a service cloud by virtualizing the sector concept and relaxing or completely removing the dependence on the underlying communications media. The advantage of this concept is that sectors can be dynamically defined based on operational ATM service needs without having to adhere to the coverage limitations of the underlying telecommunications service. The current ATM system is severely limited by the underlying telecommunications service models, most often by programmatic and contractual issues rather than their technical nature. We introduce the concept of a multi-point service within a virtual sector taking into consideration operational NEXTGEN issues and demands related to capacity, performance, and global coverage. Finally we introduce a new communications service model where selected parts of the infrastructure can be selectively and partially outsourced to certified service providers. This concept allows for smoother transition between the existing and next generation technologies, and reduces cost for the taxpayer while maintaining the safety of the flights.},
  keywords={Cloud computing;Aircraft;Computational modeling;Availability;Standards organizations;Organizations},
  doi={10.1109/ICNSurv.2012.6218402},
  ISSN={2155-4951},
  month={April},}@INPROCEEDINGS{9223464,
  author={Mayima, Amandine and Clodic, Aurélie and Alami, Rachid},
  booktitle={2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}, 
  title={Toward a Robot Computing an Online Estimation of the Quality of its Interaction with its Human Partner}, 
  year={2020},
  volume={},
  number={},
  pages={291-298},
  abstract={When we perform a collaborative task with another human, we are able to tell, to a certain extent, how things are going and more precisely if things are going well or not. This knowledge allows us to adapt our behavior. Therefore, we think it is desirable to provide robots with means to measure in real-time the Quality of the Interaction with their human partners. To make this possible, we propose a model and a set of metrics targeting the evaluation of the QoI in collaborative tasks through the measure of the human engagement and the online task effectiveness. These model and metrics have been implemented and tested within the high-level controller of an entertainment robot deployed in a mall. The first results show significant differences in the computed QoI when in interaction with a fully compliant human, a confused human and a non-cooperative one.},
  keywords={Measurement;Adaptation models;Conferences;Computational modeling;Collaboration;Estimation;Entertainment industry},
  doi={10.1109/RO-MAN47096.2020.9223464},
  ISSN={1944-9437},
  month={Aug},}@ARTICLE{9927310,
  author={Li, Keyu and Wang, Nannan and Xin, Jingwei and Jiang, Xinrui and Li, Jie and Gao, Xinbo and Han, Kai and Wang, Yunhe},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Local Means Binary Networks for Image Super-Resolution}, 
  year={2024},
  volume={35},
  number={5},
  pages={6746-6756},
  abstract={The success of modern single image super-resolution (SISR) algorithms is inspired by the development of deep convolutional neural networks (CNNs). However, these CNN-based methods require considerable computation and complexity, making it impossible for these methods to perform real-time calculations in edge devices. Thus, lightweight model design has become a development trend in the super-resolution field, including pruning, quantization, and other methods. The 1-bit quantization is an extreme lightweight method which can reduce the calculation amount of the model in an extreme manner and is friendly to hardware such as edge devices. Most existing binary quantization approaches lead to a large information loss during forward propagation, especially in detailed color information (e.g., edge, texture, and contrast). The loss of color information makes modern binary methods unsuitable for SISR tasks. We think the loss occurs because these methods typically utilize a uniform threshold to quantize the weights and activations. Thus, in this article, we thoroughly analyze the difference between normal classification tasks and SISR tasks, and present a binarization scheme based on local means. The proposed method can maintain more detailed information in feature maps using dynamic thresholds during quantization. Specifically, each value in the full precision activations has a corresponding threshold during the quantization process, and those thresholds are determined by the full precision values of the surroundings. In addition, a gradient approximator is introduced to adaptively optimize the gradient for updating binary weights. We then verify the effectiveness of our method for training binary networks on several SISR benchmarks including VDSR and SRResNet. Experimental results show that the proposed method can outperform the state-of-the-art algorithms to obtain binary networks for image super-resolution with better peak signal-to-noise ratio (PSNR) values and visual quality.},
  keywords={Superresolution;Quantization (signal);Task analysis;Convolution;Training;Computational modeling;Visualization;Binary neural network (BNN);local means;super resolution (SR)},
  doi={10.1109/TNNLS.2022.3212827},
  ISSN={2162-2388},
  month={May},}@INPROCEEDINGS{7396184,
  author={Zakay, Netanel and Feitelson, Dror G.},
  booktitle={2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom)}, 
  title={Semi-Open Trace Based Simulation for Reliable Evaluation of Job Throughput and User Productivity}, 
  year={2015},
  volume={},
  number={},
  pages={413-421},
  abstract={New scheduling algorithms are first evaluated using simulation. In these simulations, the workload has a huge influence on the measured performance of the simulated system. Therefore, it is customary to use workload traces recorded previously from real systems. Such open-system simulations preserve all the jobs' properties. However, preserving the jobs' arrival times actually destroys the logic of the user's workflow, especially dependencies and think times between successive jobs. Furthermore, performance in such simulations is measured by the average wait time and slowdown, under the fixed load and throughput conditions dictated by the trace. Therefore, it is impossible to evaluate the system's effect on throughput and productivity. As an alternative we propose semi-open trace based simulations that include dynamic user activity and internal feedback from the system to the users. In these simulations, like in a real system, users adjust their job-submittal behavior in response to system performance. As a result, the simulations produce different loads and throughputs for different scheduling algorithms or parametrizations. We implemented such a simulation for evaluating the schedulers of parallel job systems. We also developed a novel user-aware scheduler designed specifically to increase users' productivity. While conventional simulations cannot measure this scheduler's influence reliably, and would suggest it is useless, our simulation evaluates it realistically and shows its beneficial effect on the users' productivity and the system's throughput.},
  keywords={Load modeling;Throughput;Productivity;Uninterruptible power systems;Computational modeling;Data models;Cloud computing;simulations;discrete-event simulation;performance evlauation;trace driven simulation;parallel system;scheduling;resampling;feedback},
  doi={10.1109/CloudCom.2015.35},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{1372322,
  author={Wiedenbeck, S. and Engebretson, A.},
  booktitle={2004 IEEE Symposium on Visual Languages - Human Centric Computing}, 
  title={Comprehension Strategies of End-User Programmers in an Event-Driven Application}, 
  year={2004},
  volume={},
  number={},
  pages={207-214},
  abstract={Teachers may engage in end-user programming to support student learning or administrative activities associated with teaching. The objective of this research is to understand strategies used by teachers in program comprehension and to identify specific problems they face. A think-aloud study was conducted of teachers comprehending an event-driven application, consisting of a graphical user interface and the scripts controlling it. We found that end users followed a strongly top-down strategy and breadth-wise exploration of the application. Depth-wise exploration was observed in half the teachers. Teachers varied greatly in their motivations and persistence to dig deeply into the code. Problems of the teachers included difficulties comprehending the event-driven application, given the distributed nature of the code, choosing appropriate inputs for running the program, and reasoning about the results of their test runs.},
  keywords={Programming profession;Educational institutions;Graphical user interfaces;Education;Testing;Mathematics;Application software;Computational modeling;Writing;Web pages},
  doi={10.1109/VLHCC.2004.12},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{5718704,
  author={Kristensson, Per and Gustafsson, Anders and Witell, Lars},
  booktitle={2011 44th Hawaii International Conference on System Sciences}, 
  title={Collaboration with Customers - Understanding the Effect of Customer-Company Interaction in New Product Development}, 
  year={2011},
  volume={},
  number={},
  pages={1-9},
  abstract={Customer co-creation is becoming increasingly popular among companies, and intensive communication with the customer is generally seen as a determinant of new product success. However, there is still limited insight into what interaction with customers really is. The most recent thinking argues for an understanding of value-in-context in order to co-create value with customers. The question, then, is how value-in-context can be captured and how this knowledge can be beneficial in the development process. In essence in order to capture this type of information a company needs to interact and communicate with their customers. However, this communication process has not been properly analyzed. In the present study we analyze customer collaboration based on four separate dimensions - frequency, direction, modality, and content - in order to understand the value of customer collaboration. The data comes from a survey of 207 managers with experience of new service and product development. The paper concludes that three of the four dimensions of customer collaboration have a significant positive effect on New Product Development performance and Market Share development.},
  keywords={Collaboration;Companies;Technological innovation;Computational modeling;Product development},
  doi={10.1109/HICSS.2011.110},
  ISSN={1530-1605},
  month={Jan},}@INPROCEEDINGS{7759410,
  author={Aoki, Tatsuya and Nishihara, Joe and Nakamura, Tomoaki and Nagai, Takayuki},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Online joint learning of object concepts and language model using multimodal hierarchical Dirichlet process}, 
  year={2016},
  volume={},
  number={},
  pages={2636-2642},
  abstract={One of the biggest challenges in intelligent robotics is to build robots that can learn to use language. To this end, we think that the practical long-term on-line concept/word learning algorithm for robots is a key issue to be addressed. In this paper, we develop an unsupervised on-line learning algorithm that uses Bayesian nonparametrics for categorizing multimodal sensory signals such as audio, visual, and haptic information for robots. The robot uses its physical body to grasp and observe an object from various viewpoints as well as listen to the sound during the observation. The most important property of the proposed framework is to learn multimodal concepts and the language model simultaneously. This mutual learning framework of concepts and language significantly improves both speech recognition and multimodal categorization performances. We conducted a long-term experiment where a human subject interacted with a real robot over 100 hours using 499 objects. Some interesting results of the experiment are discussed in this paper.},
  keywords={Speech recognition;Robot sensing systems;Speech;Computational modeling;Data models;Visualization},
  doi={10.1109/IROS.2016.7759410},
  ISSN={2153-0866},
  month={Oct},}@INPROCEEDINGS{8615284,
  author={Muñoz-Carpio, Juan Carlos and Cowling, Michael and Birt, James},
  booktitle={2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)}, 
  title={Framework to Enhance Teaching and Learning in System Analysis and Unified Modelling Language}, 
  year={2018},
  volume={},
  number={},
  pages={91-98},
  abstract={Systems Analysis modelling is considered foundational for Information and Communication Technology (ICT) students, with introductory and advanced units included in nearly all ICT and computer science degrees. Yet despite this, novice systems analysts (learners) find modelling and systems thinking quite difficult to learn and master. This makes the process of teaching the fundamentals frustrating and time intensive. This paper will discuss the foundational problems that learners face when learning Systems Analysis modelling. Through a systematic literature review, a framework will be proposed based on the key problems that novice learners experience. In this proposed framework, a sequence of activities has been developed to facilitate understanding of the requirements, solutions and incremental modelling. An example is provided illustrating how the framework could be used to incorporate visualization and gaming elements into a Systems Analysis classroom; therefore, improving motivation and learning. Through this work, a greater understanding of the approach to teaching modelling within the computer science classroom will be provided, as well as a framework to guide future teaching activities.},
  keywords={Unified modeling language;Analytical models;Education;Object oriented modeling;Visualization;Taxonomy;Computational modeling;systems analysis and design;ICT education;framework;learner performance and learning engagement;active;experiential and game-based learning},
  doi={10.1109/TALE.2018.8615284},
  ISSN={2470-6698},
  month={Dec},}@ARTICLE{9133610,
  author={Tang, Wei and Wu, Bangxu and Zhang, Lu and Zhang, Xiaohui and Li, Jiaxin and Wang, Liang},
  journal={CSEE Journal of Power and Energy Systems}, 
  title={Multi-objective optimal dispatch for integrated energy systems based on a device value tag}, 
  year={2021},
  volume={7},
  number={3},
  pages={632-643},
  abstract={Due to the variety of devices and operating scenarios in an integrated energy system (IES), the optimal dispatch of an IES is usually complicated. An optimal dispatch method for an IES is proposed by defining the scheduling value for each device which can be different under various scenarios. First, thinking over the private and public attributes of each operating equipment, the evaluation system is established with the actual scenarios of economic, environmental and energy-savings being considered. Secondly, the economic, environmental and energy-saving benefits of each operating equipment are quantified by Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS). Therefore, the scheduling value of the device is comprehensively assessed according to the specific scenario. Finally, decomposing the output of the device into direct available energy and indirect available energy, an optimal model is built with the maximum general production benefits as the objective, and is solved by MATLAB and CPLEX. The simulation results show that the evaluation system can reflect multiple values of devices. The proposed model can unify the modeling of optimal dispatch for different scenarios in the IES and can improve dispatch efficiency, while ensuring the accuracy of the results with high computation efficiency.},
  keywords={Economics;Computational modeling;Simulation;Optimal scheduling;Switches;Production;Mathematical models;Dispatching;Indexes;Matlab;Device value tag;integrated energy system;multi-objective;optimal dispatch},
  doi={10.17775/CSEEJPES.2019.02650},
  ISSN={2096-0042},
  month={May},}@INPROCEEDINGS{9483152,
  author={Guan, Yue and Maity, Dipankar and Kroninger, Christopher M. and Tsiotras, Panagiotis},
  booktitle={2021 American Control Conference (ACC)}, 
  title={Bounded-Rational Pursuit-Evasion Games}, 
  year={2021},
  volume={},
  number={},
  pages={3216-3221},
  abstract={We present a framework that incorporates the principle of bounded rationality into a pursuit-evasion game between two aerial vehicles in a stochastic wind field. We initially formulate the problem as a continuous zero-sum stochastic game under perfect rationality. We then discretize the game via the Markov Chain Approximation Method. Leveraging the cognitive hierarchy theory (“level-k thinking”) we relax the perfect rationality assumption and compute the solution of the ensuing discrete game, while taking into consideration the rationality level of each agent. We also present an online algorithm to infer the rationality of the opponent, which enables the agents to deploy appropriate countermeasures. Finally, we verify the efficacy of this framework through simulations.},
  keywords={Adaptation models;Computational modeling;Games;Markov processes;Approximation algorithms;Approximation methods;Game theory},
  doi={10.23919/ACC50511.2021.9483152},
  ISSN={2378-5861},
  month={May},}@ARTICLE{9904444,
  author={Xenopoulos, Peter and Rulff, João and Nonato, Luis Gustavo and Barr, Brian and Silva, Claudio},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Calibrate: Interactive Analysis of Probabilistic Model Output}, 
  year={2023},
  volume={29},
  number={1},
  pages={853-863},
  abstract={Analyzing classification model performance is a crucial task for machine learning practitioners. While practitioners often use count-based metrics derived from confusion matrices, like accuracy, many applications, such as weather prediction, sports betting, or patient risk prediction, rely on a classifier's predicted probabilities rather than predicted labels. In these instances, practitioners are concerned with producing a calibrated model, that is, one which outputs probabilities that reflect those of the true distribution. Model calibration is often analyzed visually, through static reliability diagrams, however, the traditional calibration visualization may suffer from a variety of drawbacks due to the strong aggregations it necessitates. Furthermore, count-based approaches are unable to sufficiently analyze model calibration. We present Calibrate, an interactive reliability diagram that addresses the aforementioned issues. Calibrate constructs a reliability diagram that is resistant to drawbacks in traditional approaches, and allows for interactive subgroup analysis and instance-level inspection. We demonstrate the utility of Calibrate through use cases on both real-world and synthetic data. We further validate Calibrate by presenting the results of a think-aloud experiment with data scientists who routinely analyze model calibration.},
  keywords={Calibration;Reliability;Analytical models;Measurement;Predictive models;Machine learning;Computational modeling;calibration;performance analysis;model understanding;reliability diagram},
  doi={10.1109/TVCG.2022.3209489},
  ISSN={1941-0506},
  month={Jan},}@INPROCEEDINGS{7381831,
  author={Shooman, Martin L.},
  booktitle={2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={Software reliability growth model based on Bohrbugs and Mandelbugs}, 
  year={2015},
  volume={},
  number={},
  pages={381-386},
  abstract={Recent research characterizes two types of program errors. The repeatable class, called Bohrbugs, always cause the same error with the same inputs. Prior thinking and reliability growth models were based on Bohrbugs, (Bbugs). Another class of errors called Mandelbugs, (Mbugs), are difficult to reproduce even with the same inputs, [1], [2]. Mbugs may be an interaction of inputs with computer storage, where computer storage represents the past history of inputs to the computer system [3]. A small fraction of Mbugs which increase with time, aging-related Mbugs, are ignored in the model. This paper formulates a software reliability growth model for predicting operational reliability of the software as development progresses. Based on prior experience, constant and exponentially decreasing error removal models are assumed. The inputs to the model are error removal data for both Bbugs and Mbugs, recorded during development testing and mean time to failure data from simulated operational tests. Simplified values for the model parameters are developed based on moment estimates. More sophisticated estimates using least squares and maximum likelihood techniques are discussed. The potential for improving the accuracy of reliability estimates by using models that incorporate both Bbugs and Mbugs is discussed with respect to two examples.},
  keywords={Computer bugs;Software reliability;Software;Mathematical model;Data models;Computational modeling;software reliability;growth model;Bohrbugs;Mandelbugs;prediction},
  doi={10.1109/ISSRE.2015.7381831},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{4413698,
  author={Jones, S.J. and Rodriguez-Diaz, A. and Hall, L. and Castanon-Puga, M. and Flores-Gutierrez, D.L. and Gaxiola-Pacheco, C.},
  booktitle={2007 IEEE International Conference on Systems, Man and Cybernetics}, 
  title={A cybernetic approach to multi-agent system simulation in Tijuana-San Diego using the Viable Systems Model}, 
  year={2007},
  volume={},
  number={},
  pages={1648-1652},
  abstract={The trans-border region of Tijuana-San Diego with its multi-ethnic, multi-cultural society experiences a broad spectrum of social problems. The use of multi-agent systems to simulate such societies has increasingly been used as social research tool in these contexts, but is constrained by a lack of well defined contextual models. This paper proposes the use of the Viable Systems Model to underpin theory in multi-agent systems research and explores the benefits of using cybernetic thinking to understanding the problems being experienced in the Tijuana-San Diego conurbation.},
  keywords={Cybernetics;Multiagent systems;Context modeling;Stability;Environmental management;Information management;Computational modeling;US Government;Employment;Urban areas},
  doi={10.1109/ICSMC.2007.4413698},
  ISSN={1062-922X},
  month={Oct},}@INPROCEEDINGS{6755926,
  author={Kim, Gunhee and Xing, Eric P.},
  booktitle={2013 IEEE International Conference on Computer Vision Workshops}, 
  title={Discovering Pictorial Brand Associations from Large-Scale Online Image Data}, 
  year={2013},
  volume={},
  number={},
  pages={404-411},
  abstract={In this paper, we study an approach for discovering brand associations by leveraging large-scale online photo collections contributed by the general public. Brand Associations, one of central concepts in marketing, describe customers' top-of-mind attitudes or feelings toward a brand. (e.g. what comes to mind when you think of Burberry?) Traditionally, brand associations are measured by analyzing the text data from consumers' responses to the survey or their online conversation logs. In this paper, we go beyond textual media and take advantage of large-scale photos shared on the Web. More specifically, we jointly achieve the following two fundamental tasks in a mutually-rewarding way: (i) detecting exemplar images as key visual concepts associated with brands, and (ii) localizing the regions of brand in images. For experiments we collect about five millions of images of 48 brands crawled from five popular online photo sharing sites. We then demonstrate that our approach can discover complementary views on the brand associations that are hardly obtained from text data. We also quantitatively show the superior performance of our algorithm for the two tasks over other candidate methods.},
  keywords={Image segmentation;Clustering algorithms;Visualization;Computer vision;Histograms;Computational modeling;Media;Discovery of brand associations;Image cosegmentation;Exemplar detection},
  doi={10.1109/ICCVW.2013.60},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10285983,
  author={Chen, Bo-Wei and Liu, Tsung-Jung and Liu, Kuan-Hsien},
  booktitle={2023 IEEE 33rd International Workshop on Machine Learning for Signal Processing (MLSP)}, 
  title={Lightweight Image Inpainting By Stripe Window Transformer With Joint Attention To CNN}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Image inpainting is an important task in computer vision. As admirable methods are presented, the inpainted image is getting closer to reality. However, the result is still not good enough in the reconstructed texture and structure based on human vision. Although recent advances in computer hardware have enabled the development of larger and more complex models, there is still a need for lightweight models that can be used by individuals and small-sized institutions. Therefore, we propose a lightweight model that combines a specialized transformer with a traditional convolutional neural network (CNN). Furthermore, we have noticed most researchers only consider three primary colors (RGB) in inpainted images, but we think this is not enough. So we propose a new loss function to intensify color details. Extensive experiments on commonly seen datasets (Places2 and CelebA) validate the efficacy of our proposed model compared with other state-of-the-art methods. The source code and pretrained models are available at https://reurl.cc/RzD11n.},
  keywords={Training;Image color analysis;Computational modeling;Source coding;Computer architecture;Signal processing;Transformers;HSV color space;image inpainting;joint attention;stripe window;transformer},
  doi={10.1109/MLSP55844.2023.10285983},
  ISSN={2161-0371},
  month={Sep.},}@INPROCEEDINGS{9453889,
  author={Tharmaseelan, Janani and Manathunga, Kalpani and Reyal, Shyam and Kasthurirathna, Dharshana and Thurairasa, Tharsika},
  booktitle={2021 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Revisit of Automated Marking Techniques for Programming Assignments}, 
  year={2021},
  volume={},
  number={},
  pages={650-657},
  abstract={Due to the popularity of the Computer science field many students study programming. With large numbers of student enrollments in undergraduate courses, assessing programming submissions is becoming an increasingly tedious task that requires high cognitive load, and considerable amount of time and effort. Programming assignments usually contain algorithmic implementations written in specific programming languages to assess students' logical thinking and problem-solving skills. Evaluators use either a test case-driven or source code analysis approach when evaluating programming assignments. Given that many marking rubrics and evaluation criteria provide partial marks for programs that are not syntactically correct, evaluators are required to analyze the source code during evaluations. This extra step adds additional burden on evaluators that consumes more time and effort. Hence, this research work attempts to study existing automatic source code analysis mechanisms, specifically, use of deep learning approaches in the domain of automatic assessments. Such knowledge may lead to creating novel automated marking models using past student data and apply deep learning techniques to implement automatic assessments of programming assignments irrespective of the computer language or the algorithm implemented.},
  keywords={Deep learning;Training;Computer languages;Automation;Computational modeling;Buildings;Training data;Automatic Assessment;Programming;GCNN;Source Code Analysis;Education;Large Class Teaching},
  doi={10.1109/EDUCON46332.2021.9453889},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{6147827,
  author={Gallo, Mosè and Romano, Elpidio and Santillo, Liberatina C.},
  booktitle={Proceedings of the 2011 Winter Simulation Conference (WSC)}, 
  title={A methodological approach to manage WEEE recovery systems in a push/pull logic}, 
  year={2011},
  volume={},
  number={},
  pages={1035-1047},
  abstract={This work aims at establishing a new management paradigm for Waste Electrical and Electronic Equipment (WEEE) collection and treatment networks, based on Lean Thinking methodological approaches. The objective is to maximize the WEEE recovery rate to effectively support the production of new products, creating on one side the conceptual basis of the Closed Loop Supply Chain, and on the other side minimizing the environmental impact of production processes in exploiting natural resources. The achievement of such results is supported by the application of a System Dynamics simulation approach.},
  keywords={Electronic waste;Reverse logistics;Supply chains;Companies;Computational modeling},
  doi={10.1109/WSC.2011.6147827},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{9917774,
  author={Singh, Pooja and Mishra, Sushil Kumar},
  booktitle={2022 Third International Conference on Intelligent Computing Instrumentation and Control Technologies (ICICICT)}, 
  title={Alzheimer’s Detection And Categorization using a Deep-Learning Approach}, 
  year={2022},
  volume={},
  number={},
  pages={727-734},
  abstract={Alzheimer's disease (AZM) is a deadly neurology syndrome caused by memory loss. It is the most common kind of dementia. It is a syndrome that begins with modest memory loss and gradually deteriorates your thinking abilities, occasions, and ability to execute day-to-day routine tasks. It affects the areas of the brain that govern cognition, memory, and language. It has the potential to have a significant influence on a person's ability to carry out everyday responsibility. Because no drug or cure has yet been discovered, it is critical to forecast it at an early stage. The prediction of Alzheimer's disease is done manually by evaluating MRI scans; nevertheless, the risks of human mistake are quite high with this method. The purpose of this research is to improve prediction accuracy in order to detect AZM at an early stage and prevent the patient from progressing to a severe state of the disease. In this research, a Convolutional Neural Network (CNN) with Softmax classifier (i.e., CNN+Softmax) has been used to identify and categories the AZM MRI into four distinct classes, namely mild demented (MD), moderate demented (MOD), non-demented (ND), very mild demented (VMD). The proposed CNN+Softmax model is then compared by replacing the dense layer of CNN to Support Vector Machine (SVM) classifier, i.e., CNN+SVM and the work is calculated on the various grids which includes accuracy, precision, recall and f1-score. On test data, the presented approach surmounted the CNN+SVM model with a classification accuracy of 98.59 percent.},
  keywords={Training;Magnetic resonance imaging;Computational modeling;Support vector machine classification;Feature extraction;Data models;Convolutional neural networks;Alzheimer;Support Vector Machine;Convolutional Neural Network;Deep Learning;MRI},
  doi={10.1109/ICICICT54557.2022.9917774},
  ISSN={},
  month={Aug},}@ARTICLE{5422840,
  author={Xu, Qingshan and Lai, Loi Lei and Tse, Norman C. F. and Ichiyanagi, Katsuhiro},
  journal={IEEE Transactions on Education}, 
  title={A Multiple-Sessions Interactive Computer-Based Learning Tool for Ability Cultivation in Circuit Simulation}, 
  year={2011},
  volume={54},
  number={1},
  pages={56-62},
  abstract={An interactive computer-based learning tool with multiple sessions is proposed in this paper, which teaches students to think and helps them recognize the merits and limitations of simulation tools so as to improve their practical abilities in electrical circuit simulation based on the case of a power converter with progressive problems. The common problem of fast simulation and differential equation solver convergence are discussed in detail for the simulation of nonlinear power electronic circuits. Another special ratio for ripple restriction is proposed, taking practical work into consideration. Some design and simulation tradeoffs for corresponding problems are also presented. Such a learning tool can improve students' programming skills and inspire their interest in practical work as well. The practical tests-carried out at the Aichi Institute of Technology, Toyota, Japan, and Southeast University, Nanjing, China- validate the effectiveness of the learning tool.},
  keywords={Mathematical model;Computational modeling;Integrated circuit modeling;Inductors;Converters;Load modeling;Capacitors;Education;electrical circuit simulation;power converter;ripple restriction},
  doi={10.1109/TE.2010.2043435},
  ISSN={1557-9638},
  month={Feb},}@ARTICLE{9762837,
  author={Pitti, Alexandre and Quoy, Mathias and Lavandier, Catherine and Boucenna, Sofiane and Swaileh, Wassim and Weidmann, Claudio},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={In Search of a Neural Model for Serial Order: A Brain Theory for Memory Development and Higher Level Cognition}, 
  year={2022},
  volume={14},
  number={2},
  pages={279-291},
  abstract={In order to keep trace of information and grow up, the infant brain has to resolve the problem about where old information is located and how to index new ones. We propose that the immature prefrontal cortex (PFC) uses its primary functionality of detecting hierarchical patterns in temporal signals as a second feature to organize the spatial ordering of the cortical networks in the developing brain itself. Our hypothesis is that the PFC detects the hierarchical structure in temporal sequences in the shape of ordinal patterns and uses them to index information hierarchically in different parts of the brain. Henceforth, we propose that this mechanism for detecting ordinal patterns participates also in the hierarchical organization of the brain during development; i.e., the bootstrapping of the connectome. By doing so, it gives the tools to the language-ready brain for manipulating abstract knowledge and for planning temporally ordered information; i.e., the emergence of causality and symbolic thinking. In this position paper, we will review several neural models from the literature that support serial ordering and propose an original one. We will confront then our ideas with evidence from developmental, behavioral, and brain results.},
  keywords={Neurons;Codes;Task analysis;Reservoirs;Organizations;Computational modeling;Brain modeling;Broca area;cognitive development;compositionality;hierarchical nested trees;mirror neurons System (MNS);ordinal codes;prefrontal cortex (PFC);serial order;symbol grounding},
  doi={10.1109/TCDS.2022.3168046},
  ISSN={2379-8939},
  month={June},}@INPROCEEDINGS{6974218,
  author={Saeidlou, Salman and Saadat, Mozafar and Jules, Guiovanni},
  booktitle={2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Cloud manufacturing analysis based on ontology mapping and multi agent systems}, 
  year={2014},
  volume={},
  number={},
  pages={2019-2024},
  abstract={Manufacturing through the use of cloud computing has been further extended using cloud manufacturing technology. According to the literature, the benefits of this approach include transparency, cost-efficiency, sharing of resources and the scalability of production. A multi-agent system-informed ontology used in manufacturing environments facilitates knowledge storage, inference and retrieval especially for the case of distributed resources. Based on service-oriented thinking, a cloud manufacturing OWL-S ontology model is proposed. Ontology mapping and an inference engine will be used to complete service request, publishing and binding processes. A new cloud-oriented manufacturing service OWL-S ontology would provide an extension to the Web framework, which introduces a semantic description of manufacturing services. This is for the cloud to build upon theoretical foundations and comply with standards. Manufacturing services are built in with a cloud-based negotiation mechanism using agent division, cooperation, competition and negotiation to achieve dynamic cloud manufacturing services' aggregation and running. ANALYSIS is a complex, non-linear, large cloud dynamic system for manufacturing. It is a cloud-based agent model represented in IDEF0 view, and functions on the basis of analysis of the mode of operation. Cloud services are adaptable to clients' needs, and these may include various stages of a product lifestyle, including product design, manufacturing, testing and management.},
  keywords={Manufacturing systems;Ontologies;Computational modeling;Logistics;Software;Monitoring;Agents;Multi Agent Systems (MAS);Ontology;Web Services},
  doi={10.1109/SMC.2014.6974218},
  ISSN={1062-922X},
  month={Oct},}@INPROCEEDINGS{4142841,
  author={Mcmahan, Ryan P. and Bowman, Doug A.},
  booktitle={2007 IEEE Symposium on 3D User Interfaces}, 
  title={An Empirical Comparison of Task Sequences for Immersive Virtual Environments}, 
  year={2007},
  volume={},
  number={},
  pages={},
  abstract={System control - the issuing of commands - is a critical, but largely unexplored task in 3D user interfaces (3DUIs) for immersive virtual environments (IVEs). The task sequence (the order of operations in a system control task) is an important aspect of the design of a system control interface (SCI), because it affects the way the user must think about accomplishing the task. Most command line interfaces are based on the action-object task sequence (e.g. "rm foo.txt"). Most graphical user interfaces (GUIs) are based on the object-action task sequence (e.g. click on an icon then select "delete" from a pop-up menu). An SCI for an IVE should be transparent and induce minimal cognitive load, but it is not clear which task sequences support this goal. We designed an experiment using an interior design application context to determine the cognitive loads induced by various task sequences in IVEs. By subtracting the expected time for a user to complete the task from the total time, we have estimated the cognitive time, dependent only on task sequence. Our experiment showed that task sequence has a significant effect on the cognitive loads induced in IVEs. The object-action sequence and similar task sequences induce smaller cognitive loads than those induced by the action-object sequence. These results can be used to create guidelines for creating 3DUIs for IVEs},
  keywords={Virtual environment;Control systems;Productivity;Graphical user interfaces;User interfaces;Computer science;Computational modeling;Analytical models;Computer simulation;Application software},
  doi={10.1109/3DUI.2007.340770},
  ISSN={},
  month={March},}@INPROCEEDINGS{7822195,
  author={Kreuger, L. Kurt and Weichen Qian and Osgood, Nathaniel and Choi, Kelvin},
  booktitle={2016 Winter Simulation Conference (WSC)}, 
  title={Agile design meets hybrid models: Using modularity to enhance hybrid model design and use}, 
  year={2016},
  volume={},
  number={},
  pages={1428-1438},
  abstract={Dynamic modeling offers many benefits to understand the dynamics of complex systems. Hybrid modeling attempts to bring together the complementary benefits of differing dynamic modeling approaches, such as System Dynamics and Agent-based modeling, to bear on a single research question. We present here, by means of an example, a hybrid modeling technique that allows different modules to be specified separately from their implementation. This enables each module to be designed and constructed on an ad-hoc basis. This approach results in 3 benefits: it facilitates incremental development, a key focus in agile software design; it enhances the ability to test and learn from the behavior of a dynamic model; and it can help with clearer thinking about model structure, especially for those of a hybrid nature.},
  keywords={Adaptation models;Java;System dynamics;Computational modeling;Buildings;Social network services;Contracts},
  doi={10.1109/WSC.2016.7822195},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{7520108,
  author={Barroso, Anderson S. and Madureira, Jamille S. and Melo, Fabrício S. and Souza, Thiago D. S. and Soares, Michel S. and do Nascimento, Rogerio P. C.},
  booktitle={2016 8th Euro American Conference on Telematics and Information Systems (EATIS)}, 
  title={An evaluation of influence of human personality in software development: An experience report}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={Personality of software developers professionals has been a continuous element of interest in academic research. Researchers have applied different models of personality analysis in various software engineering areas to identify improvement points, to promote job satisfaction and to better organize teams. This paper aims to conduct a study, by means of an experience report, to evaluate the MBTI personality model (Myers-Briggs Type Indication) applied to software developers and to understand how human personality influences professionals' work. The experience was applied in one private university to 6 developers to measure quality of developed software by means of Object Oriented Software Metrics. Each software analyzed was developed by a single developer. Evidence was found that developers with MBTI type “INTJ” (Introvert, iNtuitive, Thinking, Judging), presented lower levels of depth of inheritance tree (DIT) and “slightly” smaller methods (LOC). As a result, it is clear that further research on the relationship between personality and object-oriented software metrics is needed.},
  keywords={Software;Visualization;Object oriented modeling;Software metrics;Servers;Computational modeling;Analytical models;Personality;object-oriented software metrics;software development;MBTI},
  doi={10.1109/EATIS.2016.7520108},
  ISSN={},
  month={April},}@INPROCEEDINGS{4421896,
  author={Li-qing, Xing and Shao-rong, Sun},
  booktitle={2007 International Conference on Management Science and Engineering}, 
  title={A New Landmark of Study on System Complexity -On the Development and Inspiration of the Complex Adaptive System Theory}, 
  year={2007},
  volume={},
  number={},
  pages={495-501},
  abstract={CAS (short for "complex adaptive system") theory advanced by Holland broke through the limitation of previous study on the complex systems from a new visual angle. This paper introduces in detail the origin and development, traits, applications and the meaning on methodologies of the theory. The study of the system complexity is very important in the contemporary scientific study. CAS theory has provided new thinking methods to know, understand, control and manage the complex systems for the researchers. Holland defines the complex adaptive system as such systems that consist of large number of individuals that interact by sending and receiving signals and adapt or learn as they interact. These individuals are called as "adaptive agents" enjoying very large initiative and positivity and the internal mechanism of these agents are defined as the classifier systems. The basic frame of CAS theory includes four characteristics- aggregation, nonlinearity, flow, diversity and three mechanisms- tagging, internal model, building blocks of the adaptive agent, and the stimulus-response model of the agents and Echo Model of the macrosystem. Holland describes them by means of metaphorical method and suggests the computer-based modeling and simulating method should be adopted mainly to study the complex adaptive system.},
  keywords={Adaptive systems;Content addressable storage;Conference management;Technology management;Engineering management;Control systems;Chaos;Iron;Sun;Computational modeling;adaptive agents;agent-based computer modeling;CAS theory;classifier systems;echo model;interaction},
  doi={10.1109/ICMSE.2007.4421896},
  ISSN={2155-1855},
  month={Aug},}@INPROCEEDINGS{7044469,
  author={Uludag, Suleyman and Sauer, Pete and Nahrstedt, Klara and Yardley, Tim},
  booktitle={2014 IEEE Frontiers in Education Conference (FIE) Proceedings}, 
  title={Towards designing and developing curriculum for the challenges of the smart grid education}, 
  year={2014},
  volume={},
  number={},
  pages={1-8},
  abstract={At the tipping of a paradigm shift in the way energy is produced, transmitted and delivered, the research efforts have not been paralleled by the curricular development. With rapid pace of changes in the field of Smart Grid (SG), the traditional research and educational efforts have been a major domain for electrical engineers. As a mode of discovery and education, interdisciplinarity facilitates broadened perspectives, ability to synthesize, analyze, integrate, and apply knowledge, and out-of-the-box thinking. The major contributions of this paper are discussion of requirements of the educational efforts in SG with special emphasis on multidisciplinarity, survey of the related work, which is the first in the literature to the best of our knowledge, and a discussion of the content for such an effort. A mixed team of power engineers and computer scientists are developing a layered curriculum starting from the introductory material from a variety of SG topics. A distinguishing advantage is the availability of many software tools and the state-of-the-art testbed as a result of years of research.},
  keywords={Smart grids;Educational institutions;Computer security;Computational modeling},
  doi={10.1109/FIE.2014.7044469},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{6481067,
  author={Farcasescu, Marcela Roxana},
  booktitle={2012 14th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing}, 
  title={Trust Model Engines in Cloud Computing}, 
  year={2012},
  volume={},
  number={},
  pages={465-470},
  abstract={The first concern when we think about adopting cloud computing is security. Even if, cloud computing seems to be remarkably cheap, the security part might transform the "buzz world" in a terribly expensive technology. The goal of this paper is to present a different perspective of delivering security as a service thru a new defined concept, trust engines. This concept, introduced in this paper, relies on trust management. A trust management system can be achieved in cloud computing by implementing multiple trust models that define what a user can do and what type of protection he has. By identifying the static and dynamic trust models, the cloud provider and the cloud user can have a proper control of the cloud security. A trust model engine could create both static and dynamic rules that will establish a classified profile for all the cloud users.},
  keywords={Engines;Business;Cloud computing;Computational modeling;Authorization;Syntactics;trust;trust model;trust management;rule-based engine;evolutionary data engine;Drools;WSO2;KEEL},
  doi={10.1109/SYNASC.2012.57},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{7803116,
  author={Khalid, Mohd Nor Akmal and Yusof, Umi Kalsom and Xiang, Looi Guo},
  booktitle={2016 International Conference On Advanced Informatics: Concepts, Theory And Application (ICAICTA)}, 
  title={Model student selection using fuzzy logic reasoning approach}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={In an educational institution, various students criteria contributed to the main reason the student is nominated as a model student. This includes cumulative grade point average (CGPA) of academic courses taken, co-curriculum involvement, soft skills, hard work, leadership, attitude, time management, attendance, attire, and technical skill in order to make the selection decision. The distinctive student is identified firstly based on their overall score. The problem arises when one needs to evaluate all these different criteria in order to select or nominated a model student. It is a tedious task and time consuming for examiner or reviewer to analyze students individually in order to select a student that showed desirable performance. In addition, as a human has its limitation, there is a high degree of error in judgment in decision making. With the aim of bridging this gap, fuzzy logic is applied to imitate human analytic thinking or the ability to make a decision in the model student selection process. Thus, the system is able to assist examiner or evaluator in the decision-making process of determining the model student with minimal time and error. Furthermore, the user could dynamically change the criteria based on the traits that have been set by the system. Fuzzy logic is chosen as it is a powerful mathematical tool involving ambiguous and incomplete information supported by the experience and judgment of examiner or reviewer while combining this cognitive ability in order to reach a verdict. Therefore, the outputs from the experiment conducted shows that the system provides robust output and information to the user regarding student's aptitude and ultimately aim to effectively predict human judgment.},
  keywords={Fuzzy logic;Pragmatics;Decision making;Analytical models;Computational modeling;Cognition;Mathematical model},
  doi={10.1109/ICAICTA.2016.7803116},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{709778,
  author={Balkir, N.H. and Ozsoyoglu, G.},
  booktitle={Proceedings International Workshop on Multi-Media Database Management Systems (Cat. No.98TB100249)}, 
  title={Multimedia presentation servers: buffer management and admission control}, 
  year={1998},
  volume={},
  number={},
  pages={154-161},
  abstract={Most multimedia servers reported in the literature are designed to serve multiple and independent video/audio streams. We think that, in the future, multimedia servers will also serve complete presentations. A multimedia presentation contains explicitly specified synchronization information describing when each multimedia data needs to be delivered in the playout of the presentation. Multimedia presentations provide unique opportunities to develop algorithms for buffer management and admission control, as execution-time consumption requirements of presentations are known a priori. In this paper, we examine presentations in three different domains (heavyweight, middleweight and lightweight presentations) and provide buffer management and admission control algorithms for the three domains. We propose two improvements (flattening and dynamic adjustments) on the schedules created for the heavyweight presentations. Results from a simulation environment for the proposed algorithms are also presented.},
  keywords={Admission control;Streaming media;Prefetching;Engineering management;Design engineering;Lighting control;Processor scheduling;Computational modeling;Electrical capacitance tomography;Multimedia systems},
  doi={10.1109/MMDBMS.1998.709778},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{4553826,
  author={Junuzovic, Sasa and Dewan, Prasun},
  booktitle={2007 International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom 2007)}, 
  title={Multicasting in groupware?}, 
  year={2007},
  volume={},
  number={},
  pages={168-177},
  abstract={While multicast has been studied extensively in many domains such as content streaming and file sharing, there is little research applying it to synchronous collaborations involving shared access to a distributed object. Based on several cases of real-world collaborations involving instant messaging, distributed lectures, and computationally-intensive collaborative game playing, we show that compared to traditional centralized and replicated collaboration architectures, a new bi-architecture collaboration system model with multicasting support can improve response, feedthrough, and task completion times. In addition, we show that to optimize performance, the set of traditionally considered factors, consisting of network delays and transmission costs, must be expanded to include several new factors, such as processing costs, scheduling policies, and think times. In one or more of the real-world collaborations we consider, we show that multicast (a) can increase feedthrough times if processing costs and scheduling policies are not considered and (b) may degrade or improve task completion times depending on the cost of computing the multicast overlay.},
  keywords={Collaborative software;Collaborative work;Collaboration;Computer architecture;Processor scheduling;Degradation;Computational modeling;Distributed computing;Cost function;Unicast;Multicast;Response;Feedthrough;Task Completion Times},
  doi={10.1109/COLCOM.2007.4553826},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8596588,
  author={Ouadoud, Mohammed and Rida, Nouha and Chkouri, Mohamed Yassin},
  booktitle={2018 IEEE 5th International Congress on Information Science and Technology (CiSt)}, 
  title={Designing an IMS-LD Model for Collaboration Space of Learning Management System}, 
  year={2018},
  volume={},
  number={},
  pages={380-385},
  abstract={The context of this work is that of designing an IMS-LD model for collaboration space of a Learning Management System (LMS). Our work is specifically in the field or seeking to promote, by means of information technology from a distance. Our approach is to first think about the conditions for creating a real LMS between learners, and designing the IT environment that supports this LMS. In this paper, we try to adapt the IMS-LD model with a collaboration model for Learning Management System based on the social constructivism. This adaptation will go through three stages. Firstly, the development of an LMS model. Secondly, the study of correspondence between the developed model and IMS-LD model and their transformation to IMS-LD model.},
  keywords={Adaptation models;Collaboration;Electronic learning;Learning management systems;Computational modeling;Production;LMS;collaboration space;IMS-LD;eLearning platform;designing an IMS-LD model},
  doi={10.1109/CIST.2018.8596588},
  ISSN={2327-1884},
  month={Oct},}@ARTICLE{10291034,
  author={Kale, Alex and Guo, Ziyang and Qiao, Xiao Li and Heer, Jeffrey and Hullman, Jessica},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={EVM: Incorporating Model Checking into Exploratory Visual Analysis}, 
  year={2024},
  volume={30},
  number={1},
  pages={208-218},
  abstract={Visual analytics (VA) tools support data exploration by helping analysts quickly and iteratively generate views of data which reveal interesting patterns. However, these tools seldom enable explicit checks of the resulting interpretations of data—e.g., whether patterns can be accounted for by a model that implies a particular structure in the relationships between variables. We present EVM, a data exploration tool that enables users to express and check provisional interpretations of data in the form of statistical models. EVM integrates support for visualization-based model checks by rendering distributions of model predictions alongside user-generated views of data. In a user study with data scientists practicing in the private and public sector, we evaluate how model checks influence analysts' thinking during data exploration. Our analysis characterizes how participants use model checks to scrutinize expectations about data generating process and surfaces further opportunities to scaffold model exploration in VA tools.},
  keywords={Data models;Analytical models;Visualization;Data visualization;Predictive models;Model checking;Computational modeling;Visualization;model checks;exploratory analysis},
  doi={10.1109/TVCG.2023.3326516},
  ISSN={1941-0506},
  month={Jan},}@INPROCEEDINGS{8102308,
  author={Ireri, Bonface and Wario, Ruth},
  booktitle={2017 IST-Africa Week Conference (IST-Africa)}, 
  title={An assessment of predictors of learner's attention and their influence to learner's engagement and learning outcomes in a mobile learning classroom}, 
  year={2017},
  volume={},
  number={},
  pages={1-10},
  abstract={Mobile devices are commonly found with learners in class, lecturers find it difficult to keep learners focused on the assigned learning activity as learners pretend to be attentive while multitasking. Some educators perceive the mobile devices as learning obstructers and think they should be abolished, however, research has revealed that if the devices are managed well, they can arouse the learner's curiosity to continue learning. The challenge is left to educators to figure out how to manage the learner's attention while using the mobile devices in class without compromising the quality of learning. With online learning tasks, observations and system login statistics as research instruments, this study investigated some of the factors that affected learners' attention and how they influence learner's engagement and learning outcomes in a mobile learning classroom. Using second year undergraduate learners as participants, each learner was allowed to connect and retrieve information from a content management system in order to access instructions and learning content. The learners interacted via chats, discussion forums and submit assignments online. Login data was captured and the lecturer observed learner behaviour. The results revealed that assignment feedback deadlines, instructions and content format, Learner Response time; and Learners' Self-Initiative, or drive played significant role in influencing learner's attention.},
  keywords={Mobile communication;Mobile handsets;Education;Discussion forums;Computational modeling;Androids;Learner;Attention;Mobile Learning;pedagogy},
  doi={10.23919/ISTAFRICA.2017.8102308},
  ISSN={},
  month={May},}@INPROCEEDINGS{9798061,
  author={Mushi, Magreth and Joshi, Harshvardhan P. and Dutta, Rudra and Guvenc, Ismail and Sichitiu, Mihail L. and Floyd, Brian and Zajkowski, Thomas},
  booktitle={IEEE INFOCOM 2022 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={The AERPAW Experiment Workflow - Considerations for Designing Usage Models for a Computing-supported Physical Research Platform}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={The AERPAW project is an ambitious project, funded by the PAWR program of the US NSF, to create a remote accessible research platform for a research facility with some distinct features that makes its usage model unique, and non-obvious to many researchers desirous of making use of this platform. AERPAW is primarily a physical resource (not a computing or cyber-resource) - the RF enviroment, and the airspace. Experimenters can explore them through radio transceivers and Unmanned Aerial Vehicles, both under the Experimenter’s programmatic control. Since the entire workflow of the user is through the mediation of virtual computing environments, users often tend to think of AERPAW as a computing resource, and find some of the experiment workflow counter-intuitive. In this paper, we articulate the challenges and considerations of designing an experiment workflow that balances the need for guaranteeing safe testbed operation, and providing flexible programmatic access to this unique resource.},
  keywords={Radio frequency;Radio transceivers;Computational modeling;Conferences;Atmospheric modeling;Computer architecture;Autonomous aerial vehicles;Wireless;testbed;5G;NextG;UAV;UAS;drone},
  doi={10.1109/INFOCOMWKSHPS54753.2022.9798061},
  ISSN={},
  month={May},}@INPROCEEDINGS{9579625,
  author={Sharma, Chetna and Ramakrishnan, Rahul and Pendse, Ayusha and Chimurkar, Priya and Talele, Kiran T.},
  booktitle={2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Cyber-Bullying Detection Via Text Mining and Machine Learning}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Cyber Bullying is one of the most recent evils of social media. With a boom in the usage of social media, the freedom of expression is being exploited. Statistics show that overall 36.5 percent people think they have been cyberbullied in their lifetime. These numbers are more than double of what they were in 2007, and there is an increase from 2018–19, suggesting we are heading in the wrong direction. Solutions to curtail this issue to a certain extent have already been deployed in the market. However, they possess limitations of usage, or simply do not use efficient algorithms. This paper aims at identifying cyberbullying at is origin, meaning when it is being drafted in real-time. Identifying traces of cyberbullying before the content is uploaded on the internet can help reduce circulation of hurtful messages. Using Machine Learning with the support of Natural Language Processing(NLP, results in better performance of cyberbullying detection.},
  keywords={Support vector machines;Deep learning;Text mining;Social networking (online);Computational modeling;Semantics;Syntactics;Cyberbullying;Machine Learning;Natural Language Processing;Text Mining;Twitter},
  doi={10.1109/ICCCNT51525.2021.9579625},
  ISSN={},
  month={July},}@INPROCEEDINGS{10427215,
  author={Chechulin, Andrey and Gorda, Maxim},
  booktitle={2024 16th International Conference on COMmunication Systems & NETworkS (COMSNETS)}, 
  title={Cybercrime Investigation Model}, 
  year={2024},
  volume={},
  number={},
  pages={37-42},
  abstract={The rise of cybercrime is a daily challenge for individuals, organizations, and governments, especially when resources are scarce and cyberattacks are becoming more complex. These organizations often find it difficult to identify and stop such attacks, but they must investigate them to reduce the damage. This study aims to create a detailed model to help with the investigations of cybercrimes. To build this model, we reviewed existing research on cybercrime and investigative methods, and we used analytical techniques, studies, and logical reasoning. After examining different stages of investigations and the information needed, we created a model and put it to the test by investigating an insider attack. We think that this model could be the foundation for practical guidelines to investigate security breaches in organizations with either limited or ample resources.},
  keywords={Costs;Computational modeling;Government;Information security;Cognition;Computer crime;Guidelines;forensics;digital forensics;cybercrime investigation;cyberattacks;investigation model},
  doi={10.1109/COMSNETS59351.2024.10427215},
  ISSN={2155-2509},
  month={Jan},}@INPROCEEDINGS{129520,
  author={Hughes, R.G.},
  booktitle={1990 Winter Simulation Conference Proceedings}, 
  title={Simulation for design, test and evaluation, and training: reconciling the differences}, 
  year={1990},
  volume={},
  number={},
  pages={231-236},
  abstract={The role of real-time man-in-the-loop simulation across the entire life cycle of a weapon system is examined. Novel aspects of the concept include the potential for the selective use of the developer's engineering simulator during operational test and evaluation as well as the merits of a tightly coupled approach to the design of the engineering simulator and that of related training devices/simulators. Attention is given to the model which is emerging at the helicopter component of McDonnell Douglas and its relationship to some advanced thinking about a US Army preliminary master plan for simulation. The author draws some parallels between the approach as implemented by the 'prime' and the approach as it might be implemented between different Government laboratories in the context of the draft master plan. The author examines a particular aspect of this application, the simulation of the operational mission environment and where that responsibility might best lie. The issue of 'fidelity' is discussed with respect to current simulation technology limitations and their known effects upon performance.<>},
  keywords={Computational modeling;Computer simulation;Real time systems;Weapons;Helicopters;Analytical models;Design engineering;Laboratories;System testing;Computer networks},
  doi={10.1109/WSC.1990.129520},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{717493,
  author={Lorenz, P. and Schulze, T. and Schriber, T.J.},
  booktitle={Proceedings of Winter Simulation Conference}, 
  title={The design, implementation, application and comparison of two highly automated traffic simulators}, 
  year={1994},
  volume={},
  number={},
  pages={1084-1092},
  abstract={The combination of new developments in computing and new problems in practice stimulates new thinking about methods for producing models with which traffic systems can be simulated. This paper describes and compares two approaches aimed at largely automating the process of building rapidly executing micro-level simulation models for complex traffic networks. Two traffic simulators have been designed and implemented, one based on GPSS/H, the other based on a model-specific simulation engine written in Pascal. The alternative-language approaches are discussed in general terms and their use is illustrated in a specific application. Data file interfaces promote the integrated use of these simulation tools with other engineering tools commonly used for traffic system planning.},
  keywords={Traffic control;Computational modeling;Computer simulation;Vehicles;Telecommunication traffic;Mathematical model;Application software;Solid modeling;Computer graphics;Data engineering},
  doi={10.1109/WSC.1994.717493},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{7821737,
  author={Kenwright, Ben},
  booktitle={2016 Future Technologies Conference (FTC)}, 
  title={Bio-inspired animated characters: A mechanistic & cognitive view}, 
  year={2016},
  volume={},
  number={},
  pages={1079-1087},
  abstract={Unlike traditional animation techniques, which attempt to copy human movement, ‘cognitive’ animation solutions mimic the brain's approach to problem solving, i.e., a logical (intelligent) thinking structure. This procedural animation solution uses bio-inspired insights (modelling nature and the workings of the brain) to unveil a new generation of intelligent agents. As with any promising new approach, it raises hopes and questions; an extremely challenging task that offers a revolutionary solution, not just in animation but to a variety of fields, from intelligent robotics and physics to nanotechnology and electrical engineering. Questions, such as, how does the brain coordinate muscle signals? How does the brain know which body parts to move? With all these activities happening in our brain, we examine how our brain ‘sees’ our body and how it can affect our movements. Through this understanding of the human brain and the cognitive process, models can be created to mimic our abilities, such as, synthesizing actions that solve and react to unforeseen problems in a humanistic manner. We present an introduction to the concept of cognitive skills, as an aid in finding and designing a viable solution. This helps us address principal challenges, such as: How do characters perceive the outside world (input) and how does this input influence their motions? What is required to emulate adaptive learning skills as seen in higher life-forms (e.g., a child's cognitive learning process)? How can we control and ‘direct’ these autonomous procedural character motions? Finally, drawing from experimentation and literature, we suggest hypotheses for solving these questions and more. In summary, this article analyses the biological and cognitive workings of the human mind, specifically motor skills. Reviewing cognitive psychology research related to movement in an attempt to produce more attentive behavioural characteristics. We conclude with a discussion on the significance of cognitive methods for creating virtual character animations, limitations and future applications.},
  keywords={Animation;Adaptation models;Computational modeling;Biological system modeling;Kinematics;Brain modeling;animation;life-like;movement;cognitive;biomechanics;human;reactive;responsive;instinctual;learning;adapting;biological;optimisation;modular;scalable},
  doi={10.1109/FTC.2016.7821737},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8631237,
  author={Seda, Pavel and Masek, Pavel and Sedova, Jindriska and Seda, Milos and Krejci, Jan and Hosek, Jiri},
  booktitle={2018 10th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT)}, 
  title={Efficient Architecture Design for Software as a Service in Cloud Environments}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={With the increasing popularity of Software as a Service (SaaS) clouds, software architects face new challenges in software architecture design, e.g. efficiently integrating those chosen web services into clouds. In this respect, early quality evaluation of the designed SaaS cloud application is crucial to mitigate the risk of later architectural changes due to a violation of quality requirements (such as response time, network throughput and scalability). Architects need to navigate in a rich set of offered services, a variability of the SaaS cloud environments, which makes it difficult to predict the general approach without time-consuming implementation of application prototypes (using GraphQL, Representational State Transfer (REST), Simple Object Access Protocol (SOAP), and Application Programming Interfaces (APIs) approaches). In this paper, we present an abstract application model designed to select the details with a high level of scalability and efficient interactions between service components. This model is reusable and provides new way of thinking about cloud architecture.},
  keywords={Cloud computing;Computer architecture;Servers;Service-oriented architecture;Computational modeling;Software as a service;cloud computing;GraphQL;SaaS;sofware architecture;REST;web services},
  doi={10.1109/ICUMT.2018.8631237},
  ISSN={2157-023X},
  month={Nov},}@INPROCEEDINGS{521049,
  author={Heol, E.G. and Samet, H.},
  booktitle={Proceedings of Conference on Computer Architectures for Machine Perception}, 
  title={Data-parallel primitives for spatial operations using PM quadtrees}, 
  year={1995},
  volume={},
  number={},
  pages={266-273},
  abstract={Data-parallel primitives for performing operations on the PM/sub 1/ quadtree and the bucket PMR quadtree are presented using the scan model. Algorithms are described for building these two data structures that make use of these primitives. The data-parallel algorithms are assumed to be main-memory resident. They were implemented on a Thinking Machines CM-5 with 32 processors containing 1 GB of main memory.},
  keywords={Data structures;Computer science;Automation;Educational institutions;Application software;Computer vision;Computational modeling;Concurrent computing;Buildings;Image processing},
  doi={10.1109/CAMP.1995.521049},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{541167,
  author={Peschon, J. and Isaksen, L. and Tyler, B.},
  booktitle={1996 International Symposium on Technology and Society Technical Expertise and Public Decisions. Proceedings}, 
  title={The growth, accretion, and decay of cities}, 
  year={1996},
  volume={},
  number={},
  pages={301-310},
  abstract={The decision analysis way of thinking, including the notions of state and motion in state-space, is used to analyze the evolution of a city over decades of time and in response to a stream of decisions made by local government and others. Due to the numerous and complex interactions between the variables that characterize a city, we focus on a subsystem, or bipole, consisting of land use and transportation. We postulate five city structures with greatly differing population densities and transportation solutions, ranging from traditional pedestrian-friendly to auto-dependent sprawl. The dependent variables (including cost to the city, residents' livability, pollution, and others) are simulated with the help of the popular computer game SimCity 2000.},
  keywords={Cities and towns;Transportation;Motion analysis;State-space methods;Time factors;Local government;Costs;Pollution;Computational modeling;Computer simulation},
  doi={10.1109/ISTAS.1996.541167},
  ISSN={},
  month={June},}@INPROCEEDINGS{9194489,
  author={Song, Dandan and Gao, Jingwen and Pang, Jinhui and Liao, Lejian and Qin, Lifei},
  booktitle={2020 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={Knowledge Base Enhanced Topic Modeling}, 
  year={2020},
  volume={},
  number={},
  pages={380-387},
  abstract={Topic models, such as Latent Dirichlet Allocation (LDA), are successful in learning hidden topics and has been widely applied in text mining. There are many recently developed augmented topic modeling methods to utilize metadata information. However, the effect of topic models is still not comparable to humans. We think one key point is that humans have background knowledge, which is essential for topic understanding. Inspired by this, we propose a knowledge base enhanced topic model in this paper. We take knowledge bases as good presentations of human knowledge, with huge collections of entities and their relations. We assume that documents with related entities tend to have similar topic distributions. Based on this assumption, we compute document similarity information via the linked entities and then use it as a constraint for LDA. More specifically, we embed entities in a low-dimensional space via DeepWalk and use Entity Movers Distance to efficiently and effectively measure the similarities between documents. The results of experiments over two real-world datasets show that our method boosts the LDA model on the document classification while no supervision information is needed.},
  keywords={Knowledge based systems;Task analysis;Computational modeling;Semantics;Optimization;Resource management;Transforms;Topic Model;LDA;Knowledge Base},
  doi={10.1109/ICBK50248.2020.00061},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10009551,
  author={Choudhary, Anurag and Verma, Pradeep Kumar and Rai, Piyush},
  booktitle={2022 6th International Conference on Electronics, Communication and Aerospace Technology}, 
  title={The Proposed Pre-Configured Deployment Model for Amazon EC2 Cloud Services}, 
  year={2022},
  volume={},
  number={},
  pages={794-799},
  abstract={Small, medium, and big organizations get several advantages from cloud computing, but it also presents obstacles. Whether a firm is in the financial, technology, or engineering sector, a cloud component might be beneficial. Though there are numerous obstacles associated with cloud computing, experts think that the benefits outweigh the drawbacks. The issues will be addressed when more research in the field of cloud computing is conducted. Cloud services are provided by a number of significant companies, including Amazon Web Services, Microsoft Azure, and Google Cloud Platform, among others. Among them, AWS (Amazon Web Services) is one of the fine cloud service providers that comprises several features, including the AWS EC2 (Elastic Compute Cloud) which is one of the widely used by many organizations. Amazon's Elastic Compute Cloud Web service delivers highly adjustable processing capacity throughout the cloud, allowing developers to construct applications with incredible scalability. Using EC2 (Elastic Compute Cloud) by using the proposed deployment method can be more effort saver for any IT development and deployment team for any organization. There should be an easy deployment method that auto-configures EC2 Instance. The aim of this research paper is to showcase the current deployment and service models provided by Amazon Web Services EC2 and present the proposed solution in order to the existing scenario. Furthermore, its advantages are also present so that it becomes easier to select the most appropriate one for deployment and research development.},
  keywords={Cloud computing;Databases;Scalability;Computational modeling;Companies;Aerospace electronics;Web servers;Cloud Computing;Cloud Service Provider;Amazon Web Services;Elastic Compute Cloud},
  doi={10.1109/ICECA55336.2022.10009551},
  ISSN={},
  month={Dec},}@ARTICLE{9478208,
  author={Nakashika, Toru and Yatabe, Kohei},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Gamma Boltzmann Machine for Audio Modeling}, 
  year={2021},
  volume={29},
  number={},
  pages={2591-2605},
  abstract={This paper presents an energy-based probabilistic model that handles nonnegative data in consideration of both linear and logarithmic scales. In audio applications, magnitude of time-frequency representation, including spectrogram, is regarded as one of the most important features. Such magnitude-based features have been extensively utilized in learning-based audio processing. Since a logarithmic scale is important in terms of auditory perception, the features are usually computed with a logarithmic function. That is, a logarithmic function is applied within the computation of features so that a learning machine does not have to explicitly model the logarithmic scale. We think in a different way and propose a restricted Boltzmann machine (RBM) that simultaneously models linear- and log-magnitude spectra. RBM is a stochastic neural network that can discover data representations without supervision. To manage both linear and logarithmic scales, we define an energy function based on both scales. This energy function results in a conditional distribution (of the observable data, given hidden units) that is written as the gamma distribution, and hence the proposed RBM is termed gamma-Bernoulli RBM. The proposed gamma-Bernoulli RBM was compared to the ordinary Gaussian-Bernoulli RBM by speech representation experiments. Both objective and subjective evaluations illustrated the advantage of the proposed model.},
  keywords={Gamma distribution;Training;Time-frequency analysis;Computational modeling;Stacking;Stochastic processes;Probabilistic logic;Boltzmann machine;nonnegative data modeling;gamma distribution;speech parameterization;speech synthesis},
  doi={10.1109/TASLP.2021.3095656},
  ISSN={2329-9304},
  month={},}@INPROCEEDINGS{10346668,
  author={AL-Fallooji, Ali and AL-Azawei, Ahmed},
  booktitle={2023 Second International Conference on Advanced Computer Applications (ACA)}, 
  title={Recurrent Deep Learning to Predict Personality Types from Social Media Posts}, 
  year={2023},
  volume={},
  number={},
  pages={63-69},
  abstract={The analysis of personality behavior has become important in many applications such as educational hypermedia systems, psychotherapy, and business recommendation systems. With the development of social media platforms (SMPs), people can express their feelings and opinions through their personal posts, comments and/or tweets. This study aims to analyze texts on SMPs to identify users' personalities according to the Myers-Briggs Type Indicator (MBTI) model. It also sought to enhance prediction accuracy and compare the findings with various deep learning techniques and previous literature. This study analyzes personality through a dataset that includes 8667 participants. Two deep learning techniques are implemented namely, long short-term memory (LSTM) and convolutional neural network (CNN). Unlike earlier literature, this research helps improve the prediction accuracy of users' personalities by building a multi-layer deep learning network and integrating the random search optimization approach. The results suggest that LSTM with the application of random search optimization outperformed previous findings. The average prediction accuracy of the four dimensions namely, Introversion-Extroversion (IE), Feeling-Thinking (FT), Intuition-Sensing (NS), and Judging-Perceiving (JP) is 85.02%.},
  keywords={Deep learning;Social networking (online);Computational modeling;Predictive models;Prediction algorithms;Natural language processing;Convolutional neural networks;Social media platforms (SMPs);Myers-Briggs Type Indicator (MBTI);Users' personality;Deep learning},
  doi={10.1109/ACA57612.2023.10346668},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{8491156,
  author={Giachetti, Ronald and Holness, Karen and McGuire, Mollie},
  booktitle={2018 IEEE 26th International Requirements Engineering Conference (RE)}, 
  title={The Ability of Engineers to Extract Requirements from Models}, 
  year={2018},
  volume={},
  number={},
  pages={394-399},
  abstract={The Department of Defense is adopting model-based systems engineering in which models will replace the extensive amounts of documentation generated in developing a new system. This research examines how this shift from textual description of requirements to a model-based description will effect the requirements engineering process. Specifically, we ask whether engineers will be able to extract the same understanding of the system requirements from the models as they can from the traditional textual requirements specifications. This paper describes the theory and related work on the understandability of models and the performance of cognitive tasks such as requirements engineering. Our research into model representation is part of a larger effort on a theory of model relativity postulating that models affect how we think about the system of interest. In this paper, we present our exploratory research studies, discuss our research protocol, describe the research plan, and present the current status of our study.},
  keywords={Unified modeling language;Cognition;Object oriented modeling;Computational modeling;Visualization;model based systems engineering;requirements engineering;empirical research;cognitive processes},
  doi={10.1109/RE.2018.00-19},
  ISSN={2332-6441},
  month={Aug},}@INPROCEEDINGS{8639371,
  author={Wharton, Zachary and Thomas, Erik and Debnath, Bappaditya and Behera, Ardhendu},
  booktitle={2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)}, 
  title={A Vision-based Transfer Learning Approach for Recognizing Behavioral Symptoms in People with Dementia}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={With an aging population that continues to grow, dementia is a major global health concern. It is a syndrome in which there is a deterioration in memory, thinking, be-havior and the ability to perform activities of daily living. Depression and aggressive behavior are the most upsetting and challenging symptoms of dementia. Automatic recognition of these behaviors would not only be useful to alert family members and caregivers, but also helpful in planning and managing daily activities of people with dementia (PwD). In this work, we propose a vision-based approach that unifies transfer learning and deep convolutional neural network (CNN) for the effective recognition of behavioral symptoms. We also compare the performance of state-of-the-art CNN features with the hand-crafted HOG-feature, as well as their combination using a basic linear SVM. The proposed method is evaluated on a newly created dataset, which is based on the dementia storyline in ITVs Emmerdale episodes. The Alzheimer's Society has described it as a "realistic portrayal"1 of the condition to raise awareness of the issues surrounding dementia.},
  keywords={Feature extraction;Dementia;Monitoring;Support vector machines;Computational modeling;Task analysis;Image recognition},
  doi={10.1109/AVSS.2018.8639371},
  ISSN={},
  month={Nov},}@ARTICLE{10506064,
  author={Li, Xiang and Wen, Congcong and Hu, Yuan and Yuan, Zhenghang and Zhu, Xiao Xiang},
  journal={IEEE Geoscience and Remote Sensing Magazine}, 
  title={Vision-Language Models in Remote Sensing: Current progress and future trends}, 
  year={2024},
  volume={12},
  number={2},
  pages={32-66},
  abstract={The remarkable achievements of ChatGPT and Generative Pre-trained Transformer 4 (GPT-4) have sparked a wave of interest and research in the field of large language models (LLMs) for artificial general intelligence (AGI). These models provide intelligent solutions that are closer to human thinking, enabling us to use general artificial intelligence (AI) to solve problems in various applications. However, in the field of remote sensing (RS), the scientific literature on the implementation of AGI remains relatively scant. Existing AI-related research in RS focuses primarily on visual-understanding tasks while neglecting the semantic understanding of the objects and their relationships. This is where vision-LMs (VLMs) excel as they enable reasoning about images and their associated textual descriptions, allowing for a deeper understanding of the underlying semantics. VLMs can go beyond visual recognition of RS images and can model semantic relationships as well as generate natural language descriptions of the image. This makes them better suited for tasks that require both visual and textual understanding, such as image captioning and visual question answering (VQA). This article provides a comprehensive review of the research on VLMs in RS, summarizing the latest progress, highlighting current challenges, and identifying potential research opportunities. Specifically, we review the application of VLMs in mainstream RS tasks, including image captioning, text-based image generation, text-based image retrieval (TBIR), VQA, scene classification, semantic segmentation, and object detection. For each task, we analyze representative works and discuss research progress. Finally, we summarize the limitations of existing works and provide possible directions for future development. This review aims to provide a comprehensive overview of the current research progress of VLMs in RS (see Figure 1), and to inspire further research in this exciting and promising field.},
  keywords={Task analysis;Visualization;Transformers;Computational modeling;Feature extraction;Chatbots;Semantics;Visual analytics;Communication systems},
  doi={10.1109/MGRS.2024.3383473},
  ISSN={2168-6831},
  month={June},}@INPROCEEDINGS{7816916,
  author={Marchiori, Massimo},
  booktitle={2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)}, 
  title={Little Big Data: Shaping Minds for the Cloud}, 
  year={2016},
  volume={},
  number={},
  pages={745-752},
  abstract={Big Data, Cloud Computing are, beyond a technical revolution, a mental revolution: they change the basic assumptions of computing, as such the mental habits that are proper of classical computing teaching. For this reason, we think it is essential to help students to change their mental habits as early as possible, become familiar with at least the basic notions of distributed storage, cloud computing. In this paper we introduce the Little Big Data system, that has been developed with an ambitious task in mind: teach cloud computing basics to K-12 kids, helping them to be part of this revolution. We report on the creation of the system, the challenges, also the impact on higher K-18 education. The results, tested in the field with a wide variety of kids, children, have been extremely successful, thanks also to advanced educational techniques like gamification, have also provided valuable insights for the general problem of education of big data computing.},
  keywords={Cloud computing;Big data;Education;Visualization;Computational modeling;Smart phones;Programming;Big Data;Cloud Computing;Gamification;Education;m-learning;K-12;K-18},
  doi={10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0120},
  ISSN={},
  month={July},}@INPROCEEDINGS{7796709,
  author={Abdelgawad, Ahmed A. and Radianti, Jaziar and Snaprud, Mikael H. and Krogstie, John},
  booktitle={2016 UKSim-AMSS 18th International Conference on Computer Modelling and Simulation (UKSim)}, 
  title={Accessibility of Norwegian Municipalities Websites: An Interactive Learning Environment Experimental Investigation}, 
  year={2016},
  volume={},
  number={},
  pages={209-214},
  abstract={Accessibility is an important aspect of websites generally and public websites particularly. Many ways could be proposed to enhance accessibility, however the impact of selected actions is hard to predict due to diversification and contradiction, in addition to the existence of the time factor. A System Dynamics simulation model including factors affecting the accessibility of Norwegian municipal websites was encapsulated in an Interactive Learning Environment (ILE). As the model promised to be able to change how users think and take decisions, this ILE was tested by users in an experiment. We have conducted α, β, and γ change analysis on the results of this experiment. Results showed that the ILE was successful in changing 50% of its users' understanding and perceptions about the system's causal relationships and policy options, and helping 30% redefining the standards they use to assess or evaluate these relationships and policy options.},
  keywords={Analytical models;Servers;Databases;Graphical user interfaces;System dynamics;Computers;Computational modeling;Experimental Design;Alpha Beta Gamma Analysis;Accessibility;System Dynamics;Municipal Websites;Interactive Learning Environment},
  doi={10.1109/UKSim.2016.16},
  ISSN={},
  month={April},}@INPROCEEDINGS{8606875,
  author={Huynh, Thi-Thanh-Thuy and Le, Anh-Cuong},
  booktitle={2018 5th NAFOSTED Conference on Information and Computer Science (NICS)}, 
  title={Integrating Grammatical Features into CNN Model for Emotion Classification}, 
  year={2018},
  volume={},
  number={},
  pages={243-249},
  abstract={Emotion analysis is currently an attractive research topic in data mining and natural language processing. Along with the development of technology, people are also gradually evolving to post their emotional thinking on social media. Emotional information is useful for various aspects of business such as advertisement. Automatically classifying user emotions therefore becomes very important. In this paper we firstly formulate this problem under Convolutional Neural Network (CNN) framework. Actually language to express emotions is very diverse that make deep learning techniques such as CNN are ineffective in feature learning when the training data is not large enough. To solve this problem, we propose to use predefined grammatical patterns, which contain potential emotional information, to extract external features and integrate them into the CNN model. Our experiment are performed on two datasets, the ISEAR11http://affective-sciences.org/home/research/materials-and-onlineresearch/research-material/ (International Survey On Emotion Antecedents And Reactions) dataset and the Vietnamese emotion dataset. The experimental results show that the proposed model is very effective in comparison with previous studies.},
  keywords={Semantics;Feature extraction;Computational modeling;Convolution;Deep learning;Neural networks;Matrix converters;Convolutional neural networks (CNN);emotion classification;grammatical features;ISEAR dataset},
  doi={10.1109/NICS.2018.8606875},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8852304,
  author={Schaetti, Nils},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Behaviors of Reservoir Computing Models for Textual Documents Classification}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={Reservoir Computing is a paradigm of recurrent neural network (RNN) models, attractive because of its ease of training and new neuromorphic optoelectronic implementations. Applied with success to time series prediction and speech recognition, few works have so far studied the behavior of these networks on natural language processing (NLP) tasks. Therefore, we decided to explore the ability of Echo State Network-based Reservoir Computing (ESN) models with additional embedding layers to classify text documents of the Reuters C50 data set based on authorship. We explored various learned representations such as word and character embedding and deep feature extractors. Our experiments demonstrate that ESN models can achieve state-of-the-art results on this task and are competitive with common models such as Support Vector Machines (SVM). Moreover, we show that these models compute documents as data streams and could then be able to handle other tasks such as event detection and text segmentation. The best performance is obtained by an ESN with a large reservoir of 1,500 neurons based on word vectors. We think that these results demonstrate the possibility of processing massive quantities of textual data in the future using Reservoir Computing-based systems.},
  keywords={Reservoirs;Computational modeling;Feature extraction;Recurrent neural networks;Task analysis;Natural language processing;Training;Reservoir Computing;Natural Language Processing;Auhorship Attribution;Recurrent Neural Network},
  doi={10.1109/IJCNN.2019.8852304},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{7588817,
  author={Zhou, Xiaokang and Wu, Bo and Jin, Qun and Jianhua and Ma and Li, Weimin and Yen, Neil Y.},
  booktitle={2016 IEEE 14th Intl Conf on Dependable, Autonomic and Secure Computing, 14th Intl Conf on Pervasive Intelligence and Computing, 2nd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)}, 
  title={Personal Data Analytics to Facilitate Cyber Individual Modeling}, 
  year={2016},
  volume={},
  number={},
  pages={39-46},
  abstract={The high development of emerging computing paradigms, such as Ubiquitous Computing, Mobile Computing, and Social Computing, has brought us a big change from all walks of our work, life, learning and entertainment. Especially, with the high accessibility of social networking services along with the increasingly pervasive use of portable wireless mobile computing devices, more and more populations have been engaged into this kind of integration of real physical world and cyber digital space, which can be called the hyper world. To help people live better in the highly developed information society, the so-called cyber-individual (Cyber-I), which is far beyond a user model or a software agent to assist a user, has been proposed to provide the most comprehensive digital entities for its corresponding Real-I in terms of the individual's experience, behavior, and thinking as well as his or her birth, growth, and death. In this study, we concentrate on the personal data analytics to facilitate the cyber individual modeling. Organic Stream is introduced to systematically organize and refine the personal stream data, which can help improve the data processing and management in the CI-Spine tier and CI-Pivot tier of Cyber-I. The DSUN (Dynamically Socialized User Networking) model is employed to better utilize the collective intelligence from a group of users, which can help improve the CI-Mind tier to make Cyber-I to become more robust. Based on these, we discuss the functional modules for the facilitation of cyber individual modeling. Finally, a scenario is given, and the experimental results are presented to demonstrate that the valuable outcomes from the personal analysis can be utilized to enrich the Cyber-I, and provide users with more suitable services.},
  keywords={Analytical models;Data models;Data analysis;Solid modeling;Computational modeling;Social network services;Adaptation models;Cyber-I;Data Analysis;User Modeling;Web Mining;Social Networking Service},
  doi={10.1109/DASC-PICom-DataCom-CyberSciTec.2016.22},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10005436,
  author={Falcão, Eduardo and Silva, Matteus and Luz, Ariel and Brito, Andrey},
  booktitle={2022 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)}, 
  title={Supporting Confidential Workloads in SPIRE}, 
  year={2022},
  volume={},
  number={},
  pages={186-193},
  abstract={The migration of traditional deployment to clouds has driven the need for a more robust security model, the Zero-Trust model. The application of zero-trust principles addresses known security issues such as lateral movement attacks but adds extra identity management complexity. In addition, to cover a broader range of attacks, one must think of strategies to protect data, code, and credentials in such applications. Confidential computing aims to fulfill this goal. Nevertheless, confidential computing is even more complex to implement than Zero-Trust. In this work, we combine the Zero-Trust model with confidential computing by leveraging the SPIFFE standard through its reference implementation (SPIRE), and Intel SGX through the SCONE framework, to seamlessly supply software identities to confidential microservices. Furthermore, we also protected the whole identity-provisioning stack with Intel SGX and assessed the performance overhead. We believe this combination not only improves the security of SPIFFE deployments but also leverages SPIFFE to facilitate the integration between confidential computing components and native applications.},
  keywords={Computers;Cloud computing;Codes;Computational modeling;Microservice architectures;Software;Complexity theory;confidential computing;Zero-Trust;Intel SGX;SPIRE},
  doi={10.1109/CloudCom55334.2022.00035},
  ISSN={2330-2186},
  month={Dec},}@INPROCEEDINGS{9823665,
  author={Yadav, Vikas and Kumar, Rahul and Azad, Chandrashekhar},
  booktitle={2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={A filter-based feature selection approach for the prediction of Alzheimer's diseases through audio classification}, 
  year={2022},
  volume={},
  number={},
  pages={1890-1894},
  abstract={Alzheimer's disease (AD) is a accelerating brain disease that wreaks havoc on memory and cognition, as well as the ability to perform even the most basic tasks. Dementia, which gradually damages brain cells, is the primary cause of AD. People with this disease lose their ability to think, read, and do a variety of other things. A machine learning system can help to alleviate this problem by predicting the disease. The primary goal is to detect dementia in a wide range of patients. The classification of speech signal into various categories such as audio, non- audio is an very significant front-end problem in AD prediction. There are many features have been presented for AD prediction. Unfortunately, these characteristics are not mutually exclusive, and combining them has no effect on AD prediction performance. By removing these redundant and irrelevant features, Feature Selection (FS) provides a simple yet effective solution to this problem. Removing irrelevant data improves learning accuracy, decreases computation time, and allows for a more thorough understanding of the learning model or data. The proposed model in this paper is a hybrid machine learning model in which we used an FS approach based on Mutual Information (MI). MLP is used for classification and MFCC is used to extract all of the features from the ADReSSo dataset. In terms of accuracy, our experimental results show that the proposed classifier outperforms existing classifiers.},
  keywords={Computational modeling;Semantics;Machine learning;Predictive models;Feature extraction;Prediction algorithms;Data models;Cognitive impairment Detection;perceptual Computing;Alzheimer's dementia;Algorithmic Paralinguistics},
  doi={10.1109/ICACITE53722.2022.9823665},
  ISSN={},
  month={April},}@INPROCEEDINGS{1592083,
  author={Schuster, S. and Gilbert, N.},
  booktitle={First International Conference on Automated Production of Cross Media Content for Multi-Channel Distribution (AXMEDIS'05)}, 
  title={Agent based simulation for modelling the distribution of online music}, 
  year={2005},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={The online content market for music is changing rapidly with the spread of technology and innovative business models. It is difficult for suppliers of online content to anticipate these developments and the effects of their businesses. The paper describes a multi-agent simulation to model possible scenarios in this market and argues that agent-based modeling can be a useful tool in thinking about future developments in these markets. It demonstrates this by applying the model to two simple scenarios of interest in the domain, the disintermediation of the value chain in the Internet and the lock-in of consumers to Apple's iTunes download platform.},
  keywords={Multiple signal classification;Business;Production;Differential equations;Aggregates;Humans;Internet;Consumer behavior;Computational modeling;Contracts},
  doi={10.1109/AXMEDIS.2005.6},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{6685148,
  author={Martinez-Arias, Juan-Carlos and Sarria M., Gerardo M.},
  booktitle={2013 IEEE Frontiers in Education Conference (FIE)}, 
  title={Didactic and interdisciplinary experiences in a Software Engineering course}, 
  year={2013},
  volume={},
  number={},
  pages={1800-1805},
  abstract={Didactic experiences are very important in a Software Engineering course. We think they help to achieve at least six objectives of the course: to identify fundamental concepts of software engineering, to recognize software life cycles, models and methodologies of software development, to perform analysis of software products requirements, to design and develop a software product, to use the methodical processes of a real-world project, and to implement solutions following specific methodologies. In this paper we will show our didactic experiences in the Software Engineering Processes course. We developed a sequence of learning activities and their application (extracted from real requirements of clients and users) in different contexts such as environmental, medical and social, which results in higher levels of learning, interdisciplinary exercises and practices close to what students will face in their professional lives.},
  keywords={Unified modeling language;Computational modeling;Computers;Law;Security;Software Engineering;Didactic Experiences;Learning Activities;Interdisciplinary},
  doi={10.1109/FIE.2013.6685148},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{6633948,
  author={Elhussein, Khalid and Babiker, Mohamed},
  booktitle={2013 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRICAL AND ELECTRONIC ENGINEERING (ICCEEE)}, 
  title={Smart phones as system integration development tools: (Android SCL simulation environment as prototype)}, 
  year={2013},
  volume={},
  number={},
  pages={280-286},
  abstract={Smart phones and cloud computing were introduced to automation industry as components of connected enterprise integration systems. The established protocols and interfacing done in that area, beside the rapid growth of the hardware specification of those devices, was behind the motivation to think of smart phones as programming and simulation devices. This paper proposes a conceptual design of a system integration work structure based on smart phones and cloud computing. The conceptual design is supported by prototype of an Android application for Siemens SCL programming and simulation. The proposal assumes a private cloud with a SAAS/PAAS/IAAS cloud model owned by an Automation solutions vendor (provider) whereas the handheld portable computing devices (e.g. smart phones) performs typical POUs (Project organization units) configuration and/or programming of preconfigured device (controller) and uploading the generated and tested-by means of simulation-code as (.prj files) or .txt files to the cloud. As part of the design, the paper will present a smart phone based automation application which will be capable of parsing the IEC 61131-3 SCL PLC programming language code, interpreting and checking validity by means of a high level simulator (Java based), generating a .txt file, this will assume a private cloud model and a coding (Engineering) management application on the server side.},
  keywords={Cloud computing;Automation;Smart phones;Research and development management;Prototypes;Computational modeling;Performance evaluation;Cloud computing;smartphones;portable engineering station terminal;portable asset management terminal},
  doi={10.1109/ICCEEE.2013.6633948},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8672686,
  author={Hamad, Ruba Mohammad Haj and Al Fayoumi, Mustafa},
  booktitle={2018 International Arab Conference on Information Technology (ACIT)}, 
  title={Modernization of a Classical Data Center (CDC) vs. Adoption in Cloud Computing Calculate Total Cost of Ownership for Both Cloud and CDC - Jordanian Case Study}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={Cloud computing is a vital paradigm which has become a top priority in companies around the world. Small to medium enterprises (SMEs) are thinking about how to adopt Cloud computing with high hopes of improving efficiency, using the latest technologies, increasing agility, avoiding the headache of acquiring hardware and software in CDC and, finally, saving money by minimizing the upfront cost. However, there are currently no accurate feasibility or Total Cost of Ownership (TCO) studies to encourage them to go for the Cloud approach and stop modernizing CDC. Since Cloud cost is one of the key topics nowadays, a one-year project was conducted to modernize and innovate a Classical Data Center (CDC) owned by a Jordanian information technology company and track the associated expenses to determine whether modernization of a CDC or adoption of Cloud computing instances is more cost-effective. To achieve clear insights, this study presented the cost difference between modernization of CDC and Oracle Cloud adoption. The results of this research study revealed that Cloud Computing is highly cost effective when TCO is calculated. Moreover, this study could be useful and applicable for information technology enterprises and banking domains.},
  keywords={Cloud computing;Data centers;Hardware;Computational modeling;Companies;Software;Cloud Total Cost of Ownership;Modernization of Classical Data Center;Oracle Cloud Bare-metal;Innovating CDC;Cost Benefit Analysis;Cloud Adoption vs. CDC},
  doi={10.1109/ACIT.2018.8672686},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{184155,
  author={Ting-peng Liang},
  booktitle={Proceedings of the Twenty-Fourth Annual Hawaii International Conference on System Sciences}, 
  title={Modeling by analogy: a case-based approach to automated linear program formulation}, 
  year={1991},
  volume={iii},
  number={},
  pages={276-283 vol.3},
  abstract={Developing a user-friendly modeling environment has been a focus of recent research. One technique widely used in human modeling processes but virtually unexplored in existing model management literature is the application of analogical thinking to improve the productivity of model formulation. Modeling by analogy is a process by which model builders transform modeling knowledge obtained from previous experience to build models for new problems that share significant features with the previously formulated ones. It overcomes certain human cognitive limitations and reduces the need for repetitive trials. The author examines the process of modeling by analogy, explores how this approach can be applied to the formulation of linear programs, and discusses issues involved in supporting modeling by analogy.<>},
  keywords={Humans;Productivity;Problem-solving;Environmental management;Cybernetics;Computational modeling;Technology management;Logic;Production},
  doi={10.1109/HICSS.1991.184155},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{8545355,
  author={Wang, Fuwei and Gong, Xiaolong and Huang, Linpeng},
  booktitle={2018 24th International Conference on Pattern Recognition (ICPR)}, 
  title={Time-Dependent Pre-attention Model for Image Captioning}, 
  year={2018},
  volume={},
  number={},
  pages={3297-3302},
  abstract={The task of automatically generating image captions draws a lot of attention in the past few years because it shows great potential in a wide range of application scenarios. The encoder-decoder structure with attention mechanism has been extensively applied to solve this task. However, most researches apply attention mechanism only to pay attention to image features but neglect the relations between image features which we think play an important role in scene understanding. To tackle this problem, we propose a novel attention mechanism named “attention to Time-Dependent Pre-Attention” (TDPA-attention) and the TDPA-attention is combined with a hierarchical LSTM decoder to compose our captioning model (TDPA-model). Within our TDPA-attention, at every time step, every image feature pays attention to all image features according to a semantic context and the attended feature is treated as an aggregated feature that contains relations between this image feature and all image features. All these aggregated features form a new feature set that the hierarchical LSTM decoder attends to. We evaluate our model on public image caption dataset Microsoft COCO and achieve state-of-the-art performance on most evaluation metrics.},
  keywords={Decoding;Task analysis;Semantics;Visualization;Feature extraction;Computational modeling;Computer science},
  doi={10.1109/ICPR.2018.8545355},
  ISSN={1051-4651},
  month={Aug},}
