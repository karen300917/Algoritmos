@INPROCEEDINGS{10578677,
  author={Chatzopoulos, Avraam and Xenakis, Apostolos and Papoutsidakis, Michail and Kalovrektis, Konstantinos and Kalogiannakis, Michail and Psycharis, Sarantos},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Proposing and Testing an Open - Source and Low - Cost Drone Under the Engineering Design Process for Higher Education: The Mechatronics Course Use Case}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The Engineering Design Process (EDP) is contemporary teaching method, applicable within STEM framework, and consists of a series of steps that students – as future engineers – follow, in order to design a prototype artifact and find a solution to a complex engineering problem. These steps usually include problem – solving processes, such as defining the problem, background research, specifying requirements, brainstorming, evaluating, choosing the best solution, developing a prototype, testing the prototype and finally communicating the research results. During the process, students engage themselves with all Computational Thinking (CT) dimensions. In this research, we apply EDP, within the STEM and CT Epistemology framework, in order to design and develop an open – hardware, open – source, low – cost, easy and safe to use, drown, for educational activities, in Higher education. The purpose of this work is to highly engage University students, in developing solutions for complex Mechatronic course - related problems, and evaluate how they achieved their learning objectives. We also design a use case scenario, in which students form proper engineering teams to work with the design of the UAV, to program its behavior and to understand avionics. The simple design, safe use, economic cost, and open philosophy of this drone make it suitable not only for university courses, but also for educational robotics applications, and in STEM education in general, regardless of the educational level.},
  keywords={Costs;Philosophical considerations;Mechatronics;Prototypes;Software;Robots;Programming profession;Drones;Open H/W;Open S/W;Engineering Design Process;Educational Robotics;STEM},
  doi={10.1109/EDUCON60312.2024.10578677},
  ISSN={2165-9567},
  month={May},}@INBOOK{8043524,
  author={Setoodeh, Peyman and Haykin, Simon},
  booktitle={Fundamentals of Cognitive Radio}, 
  title={Introduction}, 
  year={2017},
  volume={},
  number={},
  pages={1-24},
  abstract={This chapter begins the study of cognitive radio with the critical issue as a starting point. Cognitive radio offers a new way of thinking on how to promote efficient use of the radio spectrum by exploiting the existence of spectrum holes. In a related context, the spectrum&#x2010;utilization efficiency of cognitive radio is assessed in the context of four practical system issues: accuracy and reliability, computational speed, management of resources and coexistence of the cognitive radio network alongside the legacy radio network. A principled basis for the dynamic allocation and management of resources in a cognitive radio network is developed based on the fusion of ideas from game theory, control theory, and optimization. The chapter reviews the dominant sources of uncertainty in cognitive radio networks. It also presents an overview of the key concepts discussed in the subsequent chapters of this book.},
  keywords={Cognitive radio;Supply chains;Production facilities;Sensors;Decision making},
  doi={10.1002/9781119405818.ch1},
  ISSN={},
  publisher={Wiley},
  isbn={9781119405832},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/8043524},}@INPROCEEDINGS{6625220,
  author={Sklyarov, Valery and Skliarova, Iouliia and Kruus, Margus and Mihhailov, Dmitri and Sudnitson, Alexander},
  booktitle={Eurocon 2013}, 
  title={Address-based data processing over N-ary trees}, 
  year={2013},
  volume={},
  number={},
  pages={1790-1797},
  abstract={The existing trends and growing tendency to high-performance computing strongly require traditional computational algorithms to be revised in such a way that would permit optimal hardware implementations to be found. The latter can be done if algorithms can efficiently be mapped to hardware-specific functional blocks that require different style of thinking and manipulation by different operations and memory models. Besides, concurrency (pipelining and parallelism) can be widely applied. This paper focuses on data processing algorithms that use values of incoming data items as memory addresses with one-bit flags indicating presence or absence of data. The main problem of similar known methods is an appearance of huge number of memory cells with no data items (empty holes), which, nevertheless, have to be processed involving lots of unnecessary time. It is proposed to apply N-ary tree technique that enables data items to be stored and found very fast through executing special traversal procedure. Such trees completely differ from known tree-walk tables because they have pre-established configuration that does not require explicit addresses of subsequent (child) nodes. As a result the size of memory needed to keep data items is decreased in number of times. Finally, significantly more complicated problems can be solved faster and with smaller hardware resources. The presented results of numerous experiments clearly demonstrate advantages of the proposed method compared to known implementations.},
  keywords={Hardware;Field programmable gate arrays;Data processing;Memory management;Sorting;Vectors;Encoding;data processing;N-ary tree;hardware implementation;FPGA;sort;search},
  doi={10.1109/EUROCON.2013.6625220},
  ISSN={},
  month={July},}@INPROCEEDINGS{7380623,
  author={Moses J., Sharon and Babu, L.D. Dhinesh},
  booktitle={2015 International Conference on Green Computing and Internet of Things (ICGCIoT)}, 
  title={Analysis of open source cloud infrastructures over cost incurred by closed source Cloud infrastructures}, 
  year={2015},
  volume={},
  number={},
  pages={1076-1082},
  abstract={In today's world, almost every individual uses computational machines for their day to day activities. Contribution of Cloud Computing in our day to day life is commendable. Even a common man has the privilege to use cloud services in the form of email, games, storage and etc., because of Cloud Computing. Cloud services tend to be cheaper and affordable with pay as you use policy. Scalability and on demand service is an added advantage of cloud computing. With all its benefits and simplicity in usage, clouds have earned a huge number of customers. While the growth of cloud computing looks healthy, several issues like security, cloud outages and expenses compel an user to think and analyze before converting to cloud services. This paper discusses about the hidden costs incurred by using closed source cloud services and the advantages of using open source cloud platforms available in the market.},
  keywords={Cloud computing;Security;Virtual machining;Computer architecture;Companies;Virtualization;OpenStack;OpenNebula;Eucalyptus;CloudStack;Reservoir;Nimbus;Cloud Expense},
  doi={10.1109/ICGCIoT.2015.7380623},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10079832,
  author={S J, Anisha Angel and J B, Mala},
  booktitle={2022 Second International Conference on Next Generation Intelligent Systems (ICNGIS)}, 
  title={A Review on Aspect Based Sentiment Analysis}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Sentiment analysis, otherwise called emotion AI, is the computational analysis of raw data that uses text to detect a person's sentiment. Opinions and feelings are communicated more frequently and extensively than ever before in the age of social media. The number of likes for social media opinions reveals which subjects are receiving the most attention, allowing companies and artists to better understand what their customers think of their products. As a result, the problem of picture or text sentiment categorization is of tremendous interest. Document level, phrase level, and aspect level sentiment analysis are the three ways for doing sentiment analysis. There are three major jobs at the aspect level. The most important and first objective is to recognise and extract question parts. The second goal is to identify the extremes of diverse points of view on various characteristics: positive, negative, and neutral. Next task is determined by compiling a list of terms that are similar to features. The goal of aspect-level sentiment analysis is to predict the sentiment polarity of each individual aspect term in a sentence, which is a notable challenge in natural language processing. Fine-grained sentiment analysis at the aspect level is a research hotspot.},
  keywords={Sentiment analysis;Social networking (online);Bit error rate;Companies;Feature extraction;Task analysis;Intelligent systems;Sentiment Analysis;Deep Learning;Aspect Based Sentiment Analysis;Parsing},
  doi={10.1109/ICNGIS54955.2022.10079832},
  ISSN={},
  month={July},}@ARTICLE{7339414,
  author={Ma, Jianhua and Zheng, Yumei and Ning, Huansheng and Yang, Laurence T. and Huang, Runhe and Liu, Hong and Mu, Qitao and Yau, Stephen S.},
  journal={IEEE Access}, 
  title={Top Challenges for Smart Worlds: A Report on the Top10Cs Forum}, 
  year={2015},
  volume={3},
  number={},
  pages={2475-2480},
  abstract={Smart worlds begin with smart things, such as smart objects, smart cities, smart manufacturing, and smart systems, are overlaid with sensing and actuation, many embedded in things, and eventually encompass all aspects of the cyber, physical, social, and thinking hyperspace. In the future, human beings will live in a smart environment where both life and work are well addressed by technology, whereas humans will be responsible only for providing creativity. For this purpose, we have organized the first 2015 Smart World Congress, including five IEEE International Conferences. Specifically, a variety of challenges are presented in the field of smart world. Therefore, an open forum on the top ten challenges (Top10Cs) for smart worlds was held under the congress to identify the main challenges through collecting the intelligence existing particularly in crowd wisdom. Top10Cs and related works, as a crowdsourcing approach, discuss and analyze the top challenges for smart worlds based on the selective results of the crowd and experts via an online platform. Moreover, we summarize the experiences obtained in organizing the Top10Cs forum.},
  keywords={Crowdsourcing;Electronic mail;Security;Internet of things;Big data;Organizations;smart worlds;top challenges;collective intel-ligence;crowdsourcing;crowd wisdom;Smart worlds;top challenges;collective intelligence;crowdsourcing;crowd wisdom},
  doi={10.1109/ACCESS.2015.2504123},
  ISSN={2169-3536},
  month={},}@ARTICLE{182763,
  author={},
  journal={IEEE Std 610}, 
  title={IEEE Standard Computer Dictionary: A Compilation of IEEE Standard Computer Glossaries}, 
  year={1991},
  volume={},
  number={},
  pages={1-217},
  abstract={Identifies terms currently in use in the computer field. Standard definitions for thoseterms are established. Compilation of IEEE Stds IEEE Std 1084, IEEE Std 610.2, IEEE Std 610.3, IEEE Std 610.4, IEEE Std 610.5 and IEEE Std 610.12},
  keywords={Terminology;terminology;computer;applications;glossary;definitions;dictionary;610},
  doi={10.1109/IEEESTD.1991.106963},
  ISSN={},
  month={Jan},}@ARTICLE{5733835,
  author={},
  journal={ISO/IEC/IEEE 24765:2010(E)}, 
  title={ISO/IEC/IEEE International Standard - Systems and software engineering -- Vocabulary}, 
  year={2010},
  volume={},
  number={},
  pages={1-418},
  abstract={The systems and software engineering disciplines are continuing to mature while information technology advances. This International Standard was prepared to collect and standardize terminology. Its purpose is to identify terms currently in use in the field and standard definitions for these terms. It is intended to serve as a useful reference for those in the Information Technology field, and to encourage the use of systems and software engineering standards prepared by ISO and liaison organizations IEEE Computer Society and Project Management Institute (PMI). This International Standard replaces IEEE Std 610.12-1990, IEEE Standard Glossary of Software Engineering Terminology, which was contributed by the IEEE as a source document. The approach and lexical exactitude of IEEE Std 610.12-1990 served as a model for this International Standard. Nevertheless, approximately two thirds of the definitions in this International Standard are new since IEEE Std 610.12 was last updated in 1990, a reflection of the continued evolution in the field.},
  keywords={IEEE standards;ISO standards;IEC standards;Software engineering;Dictionaries;computer;dictionary;information technology;software engineering;systems engineering;terminology;vocabulary},
  doi={10.1109/IEEESTD.2010.5733835},
  ISSN={},
  month={Dec},}@ARTICLE{7906512,
  author={L’Heureux, Alexandra and Grolinger, Katarina and Elyamany, Hany F. and Capretz, Miriam A. M.},
  journal={IEEE Access}, 
  title={Machine Learning With Big Data: Challenges and Approaches}, 
  year={2017},
  volume={5},
  number={},
  pages={7776-7797},
  abstract={The Big Data revolution promises to transform how we live, work, and think by enabling process optimization, empowering insight discovery and improving decision making. The realization of this grand potential relies on the ability to extract value from such massive data through data analytics; machine learning is at its core because of its ability to learn from data and provide data driven insights, decisions, and predictions. However, traditional machine learning approaches were developed in a different era, and thus are based upon multiple assumptions, such as the data set fitting entirely into memory, what unfortunately no longer holds true in this new context. These broken assumptions, together with the Big Data characteristics, are creating obstacles for the traditional techniques. Consequently, this paper compiles, summarizes, and organizes machine learning challenges with Big Data. In contrast to other research that discusses challenges, this work highlights the cause–effect relationship by organizing challenges according to Big Data Vs or dimensions that instigated the issue: volume, velocity, variety, or veracity. Moreover, emerging machine learning approaches and techniques are discussed in terms of how they are capable of handling the various challenges with the ultimate objective of helping practitioners select appropriate solutions for their use cases. Finally, a matrix relating the challenges and approaches is presented. Through this process, this paper provides a perspective on the domain, identifies research gaps and opportunities, and provides a strong foundation and encouragement for further research in the field of machine learning with Big Data.},
  keywords={Big Data;Machine learning algorithms;Data mining;Algorithm design and analysis;Data analysis;Support vector machines;Classification algorithms;Big Data;Big Data Vs;data analysis;data analytics;deep learning;distributed computing;machine learning;neural networks},
  doi={10.1109/ACCESS.2017.2696365},
  ISSN={2169-3536},
  month={},}@ARTICLE{9006805,
  author={Hussein, Mohamed K. and Mousa, Mohamed H.},
  journal={IEEE Access}, 
  title={Efficient Task Offloading for IoT-Based Applications in Fog Computing Using Ant Colony Optimization}, 
  year={2020},
  volume={8},
  number={},
  pages={37191-37201},
  abstract={The current thinking concerning computations required by Internet of Things (IoT) applications is shifting toward fog computing instead of cloud computing, thereby achieving most of the required computations at the network edge of the IoT devices. Fog computing can thus improve the quality of service of delay-sensitive applications by allowing such applications to take advantage of the low latency provided by fog computing rather than the high latency of the cloud. Therefore, tasks in various IoT applications must be effectively distributed over the fog nodes to improve the quality of service, specifically the task response time. In this paper, two nature-inspired meta-heuristic schedulers, namely ant colony optimization (ACO) and particle swarm optimization (PSO), are used to propose two different scheduling algorithms to effectively load balance IoT tasks over the fog nodes under communication cost and response time considerations. The experimental results of the proposed algorithms are compared with those of the round robin (RR) algorithm. The evaluations show that the proposed ACO-based scheduler achieves an improvement in the response times of IoT applications compared to the proposed PSO-based and RR algorithms and effectively load balances the fog nodes.},
  keywords={Task analysis;Cloud computing;Edge computing;Time factors;Quality of service;Delays;Computer architecture;Fog computing;Internet of Things;quality of service;task offloading and scheduling},
  doi={10.1109/ACCESS.2020.2975741},
  ISSN={2169-3536},
  month={},}@ARTICLE{10105236,
  author={Shoufan, Abdulhadi},
  journal={IEEE Access}, 
  title={Exploring Students’ Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey}, 
  year={2023},
  volume={11},
  number={},
  pages={38805-38818},
  abstract={ChatGPT has sparked both excitement and skepticism in education. To analyze its impact on teaching and learning it is crucial to understand how students perceive ChatGPT and assess its potential and challenges. Toward this, we conducted a two-stage study with senior students in a computer engineering program ( $n=56$ ). In the first stage, we asked the students to evaluate ChatGPT using their own words after they used it to complete one learning activity. The returned responses (3136 words) were analyzed by coding and theme building (36 codes and 15 themes). In the second stage, we used the derived codes and themes to create a 27-item questionnaire. The students responded to this questionnaire three weeks later after completing other activities with the help of ChatGPT. The results show that the students admire the capabilities of ChatGPT and find it interesting, motivating, and helpful for study and work. They find it easy to use and appreciate its human-like interface that provides well-structured responses and good explanations. However, many students feel that ChatGPT’s answers are not always accurate and most of them believe that it requires good background knowledge to work with since it does not replace human intelligence. So, most students think that ChatGPT needs to be improved but are optimistic that this will happen soon. When it comes to the negative impact of ChatGPT on learning, academic integrity, jobs, and life, the students are divided. We conclude that ChatGPT can and should be used for learning. However, students should be aware of its limitations. Educators should try using ChatGPT and guide students on effective prompting techniques and how to assess generated responses. The developers should improve their models to enhance the accuracy of given answers. The study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.},
  keywords={Chatbots;Education;Codes;Encoding;Performance evaluation;Oral communication;ChatGPT;students’ perceptions;education},
  doi={10.1109/ACCESS.2023.3268224},
  ISSN={2169-3536},
  month={},}@ARTICLE{9405644,
  author={Kashevnik, Alexey and Shchedrin, Roman and Kaiser, Christian and Stocker, Alexander},
  journal={IEEE Access}, 
  title={Driver Distraction Detection Methods: A Literature Review and Framework}, 
  year={2021},
  volume={9},
  number={},
  pages={60063-60076},
  abstract={Driver inattention and distraction are the main causes of road accidents, many of which result in fatalities. To reduce road accidents, the development of information systems to detect driver inattention and distraction is essential. Currently, distraction detection systems for road vehicles are not yet widely available or are limited to specific causes of driver inattention such as driver fatigue. Despite the increasing automation of driving due to the availability of increasingly sophisticated assistance systems, the human driver will continue to play a longer role as supervisor of vehicle automation. With this in mind, we review the published scientific literature on driver distraction detection methods and integrate the identified approaches into a holistic framework that is the main contribution of the paper. Based on published scientific work, our driver distraction detection framework contains a structured summary of reviewed approaches for detecting the three main distraction detection approaches: manual distraction, visual distraction, and cognitive distraction. Our framework visualizes the whole detection information chain from used sensors, measured data, computed data, computed events, inferred behavior, and inferred distraction type. Besides providing a sound summary for researchers interested in distracted driving, we discuss several practical implications for the development of driver distraction detection systems that can also combine different approaches for higher detection quality. We think our research can be useful despite - or even because of - the great developments in automated driving.},
  keywords={Vehicles;Automation;Task analysis;Monitoring;Visualization;Taxonomy;Psychology;Automotive applications;automated vehicles;data systems;distraction detection;driver distraction;driver monitoring;driving distraction;intelligent transportation;vehicle driving},
  doi={10.1109/ACCESS.2021.3073599},
  ISSN={2169-3536},
  month={},}@ARTICLE{9812604,
  author={Ahmad, Naqash and Ghadi, Yazeed and Adnan, Muhammad and Ali, Mansoor},
  journal={IEEE Access}, 
  title={Load Forecasting Techniques for Power System: Research Challenges and Survey}, 
  year={2022},
  volume={10},
  number={},
  pages={71054-71090},
  abstract={The main and pivot part of electric companies is the load forecasting. Decision-makers and think tank of power sectors should forecast the future need of electricity with large accuracy and small error to give uninterrupted and free of load shedding power to consumers. The demand of electricity can be forecasted amicably by many Machine Learning (ML), Deep Learning (DL) and Artificial Intelligence (AI) techniques among which hybrid methods are most popular. The present technologies of load forecasting and present work regarding combination of various ML, DL and AI algorithms are reviewed in this paper. The comprehensive review of single and hybrid forecasting models with functions; advantages and disadvantages are discussed in this paper. The comparison between the performance of the models in terms of Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE) values are compared and discussed with literature of different models to support the researchers to select the best model for load prediction. This comparison validates the fact that the hybrid forecasting models will provide a more optimal solution.},
  keywords={Load forecasting;Load modeling;Forecasting;Predictive models;Biological system modeling;Companies;Meteorology;Load forecasting;machine learning;load shedding;root mean squared error;mean absolute percentage error},
  doi={10.1109/ACCESS.2022.3187839},
  ISSN={2169-3536},
  month={},}@ARTICLE{9583245,
  author={Ahmad, Hussain and Asghar, Muhammad Usama and Asghar, Muhammad Zubair and Khan, Aurangzeb and Mosavi, Amir H.},
  journal={IEEE Access}, 
  title={A Hybrid Deep Learning Technique for Personality Trait Classification From Text}, 
  year={2021},
  volume={9},
  number={},
  pages={146214-146232},
  abstract={Recently, Cognitive-based Sentiment Analysis with emphasis on automatic detection of user behaviour, such as personality traits, based on online social media text has gained a lot of attention. However, most of the existing works are based on conventional techniques, which are not sufficient to get promising results. In this research work, we propose a hybrid Deep Learning-based model, namely Convolutional Neural Network concatenated with Long Short-Term Memory, to show the effectiveness of the proposed model for 8 important personality traits (Introversion-Extroversion, Intuition-Sensing, Thinking-Feeling, Judging-Perceiving). We implemented our experimental evaluations on the benchmark dataset to accomplish the personality trait classification task. Evaluations of the datasets have shown better results, which demonstrates that the proposed model can effectively classify the user’s personality traits as compared to the state-of-the-art techniques. Finally, we evaluate the effectiveness of our approach through statistical analysis. With the knowledge obtained from this research, organizations are capable of making their decisions regarding the recruitment of personals in an efficient way. Moreover, they can implement the information obtained from this research as best practices for the selection, management, and optimization of their policies, services, and products.},
  keywords={Social networking (online);Deep learning;Feature extraction;Convolutional neural networks;Machine learning;Blogs;Data mining;Personality trait;deep learning;artificial intelligence;convolutional neural network;long short-term memory;social networks;machine learning},
  doi={10.1109/ACCESS.2021.3121791},
  ISSN={2169-3536},
  month={},}@ARTICLE{10190626,
  author={AlZubi, Ahmad Ali and Galyna, Kalda},
  journal={IEEE Access}, 
  title={Artificial Intelligence and Internet of Things for Sustainable Farming and Smart Agriculture}, 
  year={2023},
  volume={11},
  number={},
  pages={78686-78692},
  abstract={Technologies like AI and IoT have been employed in farming for some time now, along with other forms of cutting-edge computer science. There has been a shift in recent years toward thinking about how to put this new technology to use. Agriculture has provided a large portion of humanity’s sustenance for thousands of years, with its most notable contribution being the widespread use of effective agricultural practices for several crop types. The advent of cutting-edge IoT know-how with the ability to monitor agricultural ecosystems and guarantee high-quality production is underway. Smart Sustainable Agriculture continues to face formidable hurdles due to the widespread dispersion of agricultural procedures, such as the deployment and administration of IoT and AI devices, the sharing of data and administration, interoperability, and the analysis and storage of enormous data quantities. This work initially analyses existing Internet-of-Things technologies used in Smart Sustainable Agriculture (SSA) to discover architectural components that might facilitate the development of SSA platforms. This paper examines the state of research and development in SSA, pays attention to the current form of information, and proposes an Internet of Things (IoT) and artificial intelligence (AI) framework as a starting point for SSA.},
  keywords={Smart agriculture;Crops;Artificial intelligence;Internet of Things;Farming;Monitoring;Soil;Internet of Things;Sustainable development;Smart agriculture;Internet of Things (IoT);artificial intelligence (AI);smart sustainable agriculture (SSA);smart farming},
  doi={10.1109/ACCESS.2023.3298215},
  ISSN={2169-3536},
  month={},}@ARTICLE{8933508,
  author={Tocoglu, Mansur Alp and Ozturkmenoglu, Okan and Alpkocak, Adil},
  journal={IEEE Access}, 
  title={Emotion Analysis From Turkish Tweets Using Deep Neural Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={183061-183069},
  abstract={Text data analysis of social media is becoming more and more important since it includes the most recent information on what people think about. Likewise, emotion is one of the most valuable parts of human communication, emotion analysis is a type of information extraction process which identifies the emotional states of a given text. In this study, we investigated the performance of deep neural networks on emotion analysis from Turkish tweets. For this, we examined three different deep learning architectures including artificial neural network (ANN), convolutional neural network (CNN) and recurrent neural network (RNN) with long short-term memory (LSTM). Besides, we curated a dataset of Turkish tweets and annotated each tweet automatically for six emotion categories using a lexicon-based approach. For the evaluation, we conducted a set of experiments for each architecture. The results showed that the lexicon-based automatic annotation of tweets is valid. Secondly, ANN produced the worst result as expected, and CNN resulted in the highest score of 0.74 in terms of accuracy measure. Experiments also showed that our proposed approach for emotion analysis of tweets in Turkish performs better than state-of-the-art in this topic.},
  keywords={Twitter;Tagging;Deep learning;Recurrent neural networks;Data mining;Emotion analysis; Twitter;deep learning;Turkish text analysis;text mining;machine learning;information extraction},
  doi={10.1109/ACCESS.2019.2960113},
  ISSN={2169-3536},
  month={},}@ARTICLE{8279419,
  author={He, Dazhong and Wang, Zhenhua and Liu, Jun},
  journal={IEEE Access}, 
  title={A Survey to Predict the Trend of AI-able Server Evolution in the Cloud}, 
  year={2018},
  volume={6},
  number={},
  pages={10591-10602},
  abstract={About a decade ago, people concerned about the risks of adopting cloud computing. It was an unproven new thing that raised more questions than it answered. Nowadays, we hear more about the risks of not adopting the cloud. Three of the leading cloud players, Amazon Web Services, Microsoft Azure, and Google Cloud Platform, and other participants have developed complex cloud platforms that are driving the cloud agenda and launching innovative new products to meet the needs of modern businesses. When looking at processors, core components of the cloud, there is a trend for hyperscale data centers is to move beyond the CPUs and turn to dedicated chips, such as graphics processing units, field programmable gating arrays, and application specific integrated circuits. We think it is an artificial intelligence (AI) realization process and provide a detailed survey about hardware server design in this process. After discussing and summarizing various disclosed techniques and platforms, we conceived a hybrid hardware structure for efficient AI applications.},
  keywords={Cloud computing;Hardware;Servers;Graphics processing units;Field programmable gate arrays;Artificial intelligence;Data centers;Clouds;server;artificial intelligence},
  doi={10.1109/ACCESS.2018.2801293},
  ISSN={2169-3536},
  month={},}@ARTICLE{9044856,
  author={Tian, Wei and Huang, Wei and Yi, Lei and Wu, Liguang and Wang, Chao},
  journal={IEEE Access}, 
  title={A CNN-Based Hybrid Model for Tropical Cyclone Intensity Estimation in Meteorological Industry}, 
  year={2020},
  volume={8},
  number={},
  pages={59158-59168},
  abstract={Accurate estimation of tropical cyclone (TC) intensity is the key to understanding and forecasting the behavior of TC and is crucial for initialization in forecast models and disaster management in the meteorological industry. TC intensity estimation is a challenge because it requires domain knowledge to manually extract TC cloud structure features and form various sets of parameters obtained from satellites. In this paper, a novel hybrid model is proposed based on convolutional neural networks (CNNs) for TC intensity estimation with satellite remote sensing. According to the intensity of TCs, we divide them into three types and use three different models for intensity regression, respectively. The results show that the use of piecewise thinking can improve the model's fitting speed on small samples. A classification network is provided to classify unlabeled TC samples before TC regression, whose results would determine which regression network to estimate these samples. Finally, the estimation values are sent to the backpropagation (BP) neural network to fit the suitable intensity values. Experimental results demonstrate that our model achieves high accuracy and low root-mean-square error (RMSE up to 8.91 kts) by just using inferred images.},
  keywords={Estimation;Satellites;Convolutional neural networks;Convolution;Tropical cyclones;Industries;Meteorology;Convolutional neural networks;hybrid model;tropical cyclone intensity estimation;infrared imagery},
  doi={10.1109/ACCESS.2020.2982772},
  ISSN={2169-3536},
  month={},}@ARTICLE{9388662,
  author={Yang, Rui and Ke, Fengkai and Liu, Huanping and Zhou, Mingcheng and Cao, Hui-Min},
  journal={IEEE Access}, 
  title={Exploring sMRI Biomarkers for Diagnosis of Autism Spectrum Disorders Based on Multi Class Activation Mapping Models}, 
  year={2021},
  volume={9},
  number={},
  pages={124122-124131},
  abstract={Due to the complexity of the etiology of autism spectrum disorders, the existing autism diagnosis method is still based on scales. With the continuous development of artificial intelligence, image-aided diagnosis of brain diseases has been widely studied and concerned. However, many doctors and researchers still doubt the diagnosis basis of the neural network and think that the neural network belongs to a limited interpretable black-box function approximator. They are not sure whether the neural network has learned some interpretive image features like humans. In order to solve this problem, three new models (2D CAM, 3D CAM and 3D Grad-CAM) are proposed for structural Magnetic Resonance Imaging (sMRI) data. The Regions Of Interest (ROI) of subcortical tissues among models and between groups are analyzed based on the heat maps of the three models. The experimental results show that these models mainly distinguish the autism group and the control group according to the voxel value of these ROIs. There are significant differences in mean voxel value and standard deviation of voxel value between the autism group and the control group, such as in the left amygdala, optic chiasm and right hippocampus. According to medical references, these ROIs are closely related to people's speech, cognition and behavior. This can partly explain why autistic patients have unusual symptoms such as speech communication disorder, stereotyped repetitive behavior and so on. The proposed visualization models can provide a good bridge for doctors to understand the brain features learned by the neural network. The research method of this paper may provide a new way for doctors and researchers to find the diagnostic biomarkers of autism, which can greatly speed up the process of modern medical diagnosis and treatment strategies, and liberate doctors from the traditional trial and error.},
  keywords={Brain modeling;Autism;Convolution;Biological neural networks;Biomedical imaging;Medical services;Feature extraction;Autism spectrum disorders;class activation mapping;sMRI;biomarker},
  doi={10.1109/ACCESS.2021.3069211},
  ISSN={2169-3536},
  month={},}@ARTICLE{8701498,
  author={Wu, Huaiguang and Yang, Yang},
  journal={IEEE Access}, 
  title={Code Search Based on Alteration Intent}, 
  year={2019},
  volume={7},
  number={},
  pages={56796-56802},
  abstract={Code search is to retrieve the method according to the user needs. Many people think of the query as the only one to reflect the user needs. So they start with the query and find the synonyms, semantically similar to the query terms, for query expansion. However, they overlook a fact: the retrieved methods still need to be altered because it does not meet the user needs directly. This implies that the alteration made in the retrieved methods also reflects the user needs. In this paper, we start with the alteration intent (the possible alterations after retrieving methods) and propose to predict the alteration intent and use it for query expansion. The experiment results show that our approach outperforms CodeHow, the approach to use APIs for query expansion, by 59.8% with a precision score of 0.815.},
  keywords={Search engines;Data mining;Mathematical model;Search problems;Computer security;Industries;Code search;query expansion;alteration intent;program context},
  doi={10.1109/ACCESS.2019.2913560},
  ISSN={2169-3536},
  month={},}@ARTICLE{8653296,
  author={Wang, Xin and Qian, Zhihong and Wang, Xue and Huang, Lan},
  journal={IEEE Access}, 
  title={Robust Localization for Cognitive IoT via the Mobile Anchor Node Based on the Diameter-Varying Spiral Line}, 
  year={2019},
  volume={7},
  number={},
  pages={28487-28497},
  abstract={Research on IoT that merely aims at connecting and communicating is about to past. Thereafter, general objects should have the capability to learn, think, and understand both physical and social areas by themselves. Cognitive Internet of Things (CIoT) attempts to empower the current IoT with a “brain” for high-level intelligence, requiring networks to have the ability to bridge the physical and social worlds. This attempt means matching equipment and resources with people and their behavior. Therefore, accurate location information is crucial for equipment connecting to CIoT. This endeavor sets a higher requirement for the localization technology of wireless sensor networks in terms of accuracy, energy, and efficiency compared with that in the past. In this paper, we propose an efficient and accurate mobile anchor node assisted localization algorithm for WSNs based on diameter-varying spiral line (LDVSL), which broadcasts coordinates of the anchor node to assist localizing unknown sensor nodes. The proposed algorithm has two main innovations. First, we obtain the mobile anchor node position through a time and angle mechanism instead of GPS, given the unique characteristics of the diameter-varying spiral line. Second, the linear fitting method is adapted to select the key virtual node, which has the real maximum received signal strength indicator. Simulations indicate that the proposed LDVSL algorithm outperforms other similar algorithms in terms of average localization error and positionable node ratio. The simulations also show that the LDVSL is not affected by obstacles seriously and has good robustness. The LDVSL has a wide prospect of application in CIoT.},
  keywords={Spirals;Path planning;Directional antennas;Wireless sensor networks;Global Positioning System;Internet of Things;Received signal strength indicator;CIoT;localization;mobile anchor node;diameter-varying spiral line;linear fitting},
  doi={10.1109/ACCESS.2019.2901745},
  ISSN={2169-3536},
  month={},}@ARTICLE{8960343,
  author={Wang, Zhu and Yu, Zhiwen and Fan, Renjie and Guo, Bin},
  journal={IEEE Access}, 
  title={Correcting Biases in Online Social Media Data Based on Target Distributions in the Physical World}, 
  year={2020},
  volume={8},
  number={},
  pages={15256-15264},
  abstract={Social media is an important data source. Billions of posts, likes, and connections are created by people all around the world every day. The promises of such social media data are plentiful, including understanding “what the world thinks” about a social issue, brand, product, celebrity, or other entity, as well as enabling better decision-making in a variety of fields including public policy, transportation, healthcare, and economics. However, while the validity of these data-driven researches are largely dependent on the accuracy and representativeness of the used data, online social media data collected with common mechanisms are usually biased compared with the distribution of related features in the physical world. For example, sampling issues, especially selection bias, associated with such data sources can have far reaching implications for data analysis and interpretation. Therefore, how to calibrate biases in the online social media data set to achieve unbiased results becomes a significant and urgent problem. In this paper, we propose to address the bias calibration issue by adopting a data resampling approach. Specifically, we develop a data resampling algorithm based on the stochastic stability theory of Markov Chains to collect data samples from the given biased data set to calibrate possible biases. By regarding the data resampling process as status transitions of a stochastic variable, the algorithm leverages the stationary distribution of Markov Chains to build an acceptance matrix to control the resampling process, and thus optimize the original dataset towards target distributions in the physical world. Experimental results demonstrate that the proposed algorithm can effectively output data sets with similar distributions to the target ones.},
  keywords={Twitter;Sociology;Statistics;Markov processes;Data collection;Bias correction;data bias;data resampling;social media},
  doi={10.1109/ACCESS.2020.2966790},
  ISSN={2169-3536},
  month={},}@ARTICLE{9878097,
  author={Boutros, Andrew and Nurvitadhi, Eriko and Betz, Vaughn},
  journal={IEEE Access}, 
  title={Architecture and Application Co-Design for Beyond-FPGA Reconfigurable Acceleration Devices}, 
  year={2022},
  volume={10},
  number={},
  pages={95067-95082},
  abstract={In recent years, field-programmable gate arrays (FPGAs) have been increasingly deployed in datacenters as programmable accelerators that can offer software-like flexibility and custom-hardware-like efficiency for key datacenter workloads. To improve the efficiency of FPGAs for these new datacenter use cases and data-intensive applications, a new class of reconfigurable acceleration devices (RADs) is emerging. In these devices, the FPGA fine-grained reconfigurable fabric is a component of a bigger monolithic or multi-die system-in-package that can incorporate general-purpose software-programmable cores, domain-specialized accelerator blocks, and high-performance networks-on-chip (NoCs) for efficient communication between these system components. The integration of all these components in a RAD results in a huge design space and requires re-thinking the implementation of applications that need to be migrated from conventional FPGAs to these novel devices. In this work, we introduce RAD-Sim, an architecture simulator that allows rapid design space exploration for RADs and facilitates the study of complex interactions between their various components. We also present a case study that highlights the utility of RAD-Sim in re-designing applications for these novel RADs by mapping a state-of-the-art deep learning (DL) inference FPGA overlay to different RAD instances. Our case study illustrates how RAD-Sim can capture a wide variety of reconfigurable architectures, from conventional FPGAs to devices augmented with hard NoCs, specialized matrix-vector blocks, and 3D-stacked multi-die devices. In addition, we show that our tool can help architects evaluate the effect of specific RAD architecture parameters on end-to-end workload performance. Through RAD-Sim, we also show that novel RADs can potentially achieve  $2.6\times $  better performance on average compared to conventional FPGAs in the key DL application domain.},
  keywords={Field programmable gate arrays;Computer architecture;Fabrics;Hardware acceleration;Performance evaluation;Benchmark testing;Memory management;Deep learning;Reconfigurable logic;Deep learning;field-programmable gate arrays;hardware acceleration;network-on-chip;reconfigurable computing},
  doi={10.1109/ACCESS.2022.3204664},
  ISSN={2169-3536},
  month={},}@ARTICLE{7577724,
  author={Gao, Kun and Zhu, Yiwei},
  journal={IEEE Access}, 
  title={Deep Data Stream Analysis Model and Algorithm With Memory Mechanism}, 
  year={2017},
  volume={5},
  number={},
  pages={84-93},
  abstract={Integrated analysis is an important method for data analysis. Aimed at improving the deficiencies of traditional integrated data stream analysis, a human-like remembering and forgetting mechanism is introduced into data stream analysis, and a deep data stream analysis model based on remembering (DSAR) is proposed. Through this remembering and forgetting mechanism, the model regards basic classifiers as system-obtained knowledge and not only stores useful basic classifiers in a “remembering library” to improve prediction stability but also selects good basic classifiers to participate in integrated prediction, thus improving its ability to accommodate conceptual variations. Based on the DSAR model, an integrated deep data stream analysis (DDSA) algorithm is proposed. The algorithm uses the forgetting curve and a selective ensemble classifier to simulate human thinking. Compared with four typical data stream analysis algorithms, the DDSA algorithm has a high classification accuracy and a strong capacity for accommodating concept drift features (CDFs) within data stream analysis. The DDSA is particularly adaptable to complex CDFs in practical applications. Experiments show that the proposed algorithm can not only adapt to new concept changes quickly but also effectively resist the impact of random fluctuations on system performance.},
  keywords={Classification algorithms;Algorithm design and analysis;Prediction algorithms;Data analysis;Analytical models;Data models;Predictive models;Data stream analysis;remembering and ignoring;ignoring curve;selective ensemble},
  doi={10.1109/ACCESS.2016.2613922},
  ISSN={2169-3536},
  month={},}@ARTICLE{8906122,
  author={Youssef, Ahmed E. and Mostafa, Almetwally M.},
  journal={IEEE Access}, 
  title={Critical Decision-Making on Cloud Computing Adoption in Organizations Based on Augmented Force Field Analysis}, 
  year={2019},
  volume={7},
  number={},
  pages={167229-167239},
  abstract={Cloud Computing (CC) has become an important milestone information technology that attracts many organizations. With the potential to transform business processes, lower IT expenses, and offer access to unlimited computing resources with minimal management effort, organizations look to cloud-based solutions to achieve business efficiencies. Thus, it would seem that these organizations could easily migrate to CC. However, enterprises are still concerned about moving their business-critical applications to the cloud. Among the reasons are that it is an emerging technology that has not reached a level of maturity; the lack of industry-specific conformity to standards; and a high level of security risks. As a result, there is a big dispute among organizations on the decision of whether it is more business-efficient to embark on the cloud or remain with their interior IT infrastructures. In this paper, we aim to solve this debate by proposing a novel approach that supports decision-making on CC adoption in organizations. Unlike traditional decision-making approaches that pay little or no consideration to organizational high-level business objectives, our proposed approach is driven by the business objectives of the organization. First, we identify driving and restraining forces that influence CC adoption in organizations. Second, a formal decision-making model is proposed based on Force Field Analysis (FFA) augmented by pairwise comparison and Delphi methods, this model estimates the values of the driving and restraining forces based on their impacts on the organization's objectives. By analyzing the forces for and against CC adoption, organizations can decide whether or not to move forward with the adoption. Alternatively, organizations can use the analysis to think about how they can strengthen the forces that support the adoption and weaken the forces opposing it, so that the adoption is more successful. The proposed model is validated for usability and applicability through a use case scenario.},
  keywords={Organizations;Cloud computing;Standards organizations;Decision making;Force;Software;Cloud computing;decision making;force field analysis (FFA);pairwise comparison;Delphi method},
  doi={10.1109/ACCESS.2019.2954415},
  ISSN={2169-3536},
  month={},}@ARTICLE{8830475,
  author={Shen, Gang and Han, Dan and Liu, Peiwen},
  journal={IEEE Access}, 
  title={A Sparse Manifold Learning Approach to Robust Indoor Positioning Based on Wi-Fi RSS Fingerprinting}, 
  year={2019},
  volume={7},
  number={},
  pages={130791-130803},
  abstract={The emerging location-based applications depend on the fast and accurate positioning of mobile targets. Wi-Fi received signal strength (RSS) fingerprinting provides a promising solution to localize an object in indoor environments. Among the factors challenging the RSS fingerprinting based algorithms are the site survey cost and the time-varying environment, given the unreliable signal qualities. Here we present a novel approach to indoor object positioning using the manifold assumption on the radio map in RSS-location space. Thinking the measured RSS from one access point (AP) in different locations are randomly drawn from a nonlinear manifold (ground truth), we propose an expectation-maximization (EM) style algorithm to reconstruct the sparse representation of this manifold from the noisy RSS observations. Motivated by the observation that the radio map has a strong local correlation in the RSS-location space, we introduce a multi-scale constrained quadratic programming to approximate the manifold. Within limited iterations, we can estimate the ground truth RSS values and parameters simultaneously. As a result, the learned manifold is exploited to predict the object's position: we develop a positioning algorithm by minimizing the manifold distortion effort which integrates both measurement error and manifold shape preservation. We conducted extensive simulations and experiments in different settings, testing the datasets collected in a building in the last 8 months. The results showed that the proposed approach was adaptive to the varying environmental noise levels, presenting robust positioning performance.},
  keywords={Manifolds;Wireless fidelity;IP networks;Noise measurement;Robustness;Antenna measurements;Position measurement;Expectation-maximization;indoor positioning;manifold learning;received signal strength},
  doi={10.1109/ACCESS.2019.2940629},
  ISSN={2169-3536},
  month={},}@ARTICLE{9171234,
  author={Belwafi, Kais and Gannouni, Sofien and Aboalsamh, Hatim},
  journal={IEEE Access}, 
  title={An Effective Zeros-Time Windowing Strategy to Detect Sensorimotor Rhythms Related to Motor Imagery EEG Signals}, 
  year={2020},
  volume={8},
  number={},
  pages={152669-152679},
  abstract={Brain-computer interface (BCI) acquires, analyzes and transforms human brain activity to control commands allowing as such disabled people to communicate or control external devices. A motor imagery-based BCI enables patients to control artificial peripherals and communicate with the outside world by merely thinking of the task such as, e.g., the imagination of left-hand, right-hand, or foot movement. The mere intention of moving one of the limbs triggers neural activity, which is induced in the primary sensorimotor areas like that observed with real executed movements. Tracking generated sensorimotor rhythms (SMRs) and extracting robust and informative features from electroencephalogram (EEG) signals are challenging due to the time-varying nature of EEG signals and the inter-human variability. In this paper, we proposed an EEG-zeros-time windowing (E2ZTW) approach based on a highly decaying window function to track SMRs and identify the temporal epochs containing useful information without any prior information on the trigger. The proposed approach involves the application of the group-delay function, allowing the improvement of the spectral resolution due to the additive property of the function on individual resonances. Some algorithms were integrated into the proposed approach, such as the common spatial pattern algorithm, which is used to extract features and linear discriminant analysis and a convolutional neural network, which are used for the classification of the features. The effectiveness of the proposed approach in tracking the SMRs rhythms is evaluated in terms of accuracy. Experiments were performed on three public datasets provided by BCI competition for 17 subjects. Following experimental results, it is shown that discrimination between the left- and right-hand movements can be achieved within a few seconds with high classification accuracy. As compared to other state-of-art techniques, the proposed approach achieves an average classification accuracy and standard error values of 82% and 13, respectively, thereby outperforming existing algorithm by an accuracy mean of 2%.},
  keywords={Electroencephalography;Microsoft Windows;Feature extraction;Brain;Training;Task analysis;Tracking;Brain-computer interface (BCI);electroencephalography (EEG);motor imagery;EEG-zero-time windowing;group-delay function},
  doi={10.1109/ACCESS.2020.3017888},
  ISSN={2169-3536},
  month={},}@ARTICLE{9893785,
  author={Din, Nizam Ud and Bae, Seho and Javed, Kamran and Park, Hyunkyu and Yi, Juneho},
  journal={IEEE Access}, 
  title={Cross Modal Facial Image Synthesis Using a Collaborative Bidirectional Style Transfer Network}, 
  year={2022},
  volume={10},
  number={},
  pages={99077-99087},
  abstract={In this paper, we present a novel collaborative bidirectional style transfer network based on generative adversarial network (GAN) for cross modal facial image synthesis, possibly with large modality gap. We think that representation decomposed into content and style can be effectively exploited for cross modal facial image synthesis. However, we have observed that unidirectional application of decomposed representation based style transfer in case of large modality gap does not work well for this purpose. Unlike existing image synthesis methods that typically formulate image synthesis as an unidirectional feed forward mapping, our network utilizes mutual interaction between two opposite mappings in a collaborative way to address complex image synthesis problem with large modality gap. The proposed bidirectional network aligns shape content from two modalities and exchanges their appearance styles using feature maps of the layers in the encoder space. This allows us to effectively retain the shape content and transfer style details for synthesizing each modality. Focusing on facial images, we consider facial photo, sketch, and color-coded semantic segmentation as different modalities. The bidirectional synthesis results for the pairs of these modalities show the effectiveness of the proposed approach. We further apply our network to style-content manipulation to generate multiple photo images with various appearance styles for a same content shape. The proposed method can be adopted for solving other cross modal image synthesis tasks. The dataset and source code are available at https://github.com/kamranjaved/Bidirectional-style-transfer-network.},
  keywords={Image synthesis;Image segmentation;Face recognition;Generative adversarial networks;Bidirectional control;Collaborative work;Generative adversarial network;image synthesis;unidirectional style transfer network;bidirectional style transfer network;collaborative learning},
  doi={10.1109/ACCESS.2022.3207288},
  ISSN={2169-3536},
  month={},}@ARTICLE{8933378,
  author={Wang, Juan and Tannaz, Sirous and Cai, Changxin and Aliabadi, Amin and Mostafapour, Ehsan and Zhang, Wei},
  journal={IEEE Access}, 
  title={Performance Analysis of Wireless Adaptive Incremental Networks Under Strong FSO Link Turbulence Conditions}, 
  year={2020},
  volume={8},
  number={},
  pages={12290-12299},
  abstract={The aim of this paper is to show the problems of implementing the wireless adaptive networks with the free space optical (FSO) technology. Implementing adaptive networks with the wireless optical communication technology has several benefits and also some hindering problems. The thermal optical noise modeled with Gaussian distribution and link turbulence is two of the major problems of this implementation. In this paper, the theoretical analysis of the FSO link effects that are modeled with K-distribution and Negative exponential distributions are considered on the estimation performance of the adaptive incremental networks. These distributions arise when the FSO link is contaminated with strong optical turbulence. Experiments are designed to cover these conditions and the analysis is based on the steady state mean square deviation (MSD) and excess mean square error (EMSE) values for the incremental LMS (ILMS) algorithm and these are the metrics that show how well the adaptive network performs. Simulation results are presented for different parameters of K -distribution and negative exponential distribution and the results show perfect match with the theoretical outcomes. Based on these results, we show that implementing the incremental adaptive networks in the strong turbulence conditions is not feasible and we must think of some countermeasures for these cases.},
  keywords={Adaptive systems;Wireless communication;Optical fiber communication;Estimation;Optical transmitters;Optical receivers;Optical refraction;Free space optical communications;distributed processing;negative exponential distribution;adaptive networks;strong turbulence;estimation},
  doi={10.1109/ACCESS.2019.2960128},
  ISSN={2169-3536},
  month={},}@ARTICLE{10024282,
  author={Lee, Won Jun and Kim, Chang Hyun and Paik, Yoonah and Kim, Seon Wook},
  journal={IEEE Access}, 
  title={PISA-DMA: Processing-in-Memory Instruction Set Architecture Using DMA}, 
  year={2023},
  volume={11},
  number={},
  pages={8622-8632},
  abstract={Processing-in-memory (PIM) has attracted attention to overcome the memory bandwidth limitation, especially for computing memory-intensive DNN applications. Most PIM approaches use the CPU’s memory requests to deliver instructions and operands to the PIM engines, making a core busy and incurring unnecessary data transfer, thus, resulting in significant offloading overhead. DMA can resolve the issue by transferring a high volume of successive data without intervening CPU and polluting the memory hierarchy, thus perfectly fitting the PIM concept. However, the small computing resources of DRAM-based PIM devices allow us to transfer only small amounts of data at one DMA transaction and require a large number of descriptors, thus still incurring significant offloading overhead. This paper introduces PIM Instruction Set Architecture (ISA) using a DMA descriptor called PISA-DMA to express a PIM opcode and operand in a single descriptor. Our ISA makes PIM programming intuitive by thinking of committing one PIM instruction as completing one DMA transaction and representing a sequence of PIM instructions using the DMA descriptor list. Also, PISA-DMA minimizes the offloading overhead while guaranteeing compatibility with commercial platforms. Our PISA-DMA eliminates the opcode offloading overhead and achieves 1.25x, 1.31x, and 1.29x speedup over the baseline PIM at the sequence length of 128 with the BERT, RoBERTa, and GPT-2 models, respectively, in ONNX runtime with real machines. Also, we study how our proposed PISA affects performance in compiler optimization and show that the operator fusion of matrix-matrix multiplication and element-wise addition achieved 1.04x speedup, a similar performance gain using conventional ISAs.},
  keywords={Engines;Computer architecture;Registers;Switches;DRAM chips;Random access memory;Programming;Processing-in-DRAM;direct memory access;instruction set architecture;PIM offloading},
  doi={10.1109/ACCESS.2023.3238812},
  ISSN={2169-3536},
  month={},}@ARTICLE{9425535,
  author={Qi, Hui and Shi, Ying and Mu, Xiaofang and Hou, Mingxing},
  journal={IEEE Access}, 
  title={Knowledge Granularity for Continuous Parameters}, 
  year={2021},
  volume={9},
  number={},
  pages={89432-89438},
  abstract={In the community of Granular Computing, knowledge is interpreted as one classification ability of realistic or abstract objects. Generally, the concept of granularity is used for characterizing such an ability, which has been widely explored in literatures. To calculate the parameterized granularity, a naive approach is to find the granularity in terms of the parameter one by one. Nevertheless, such approach can only generate the single parameter based knowledge granularity, and the difference of knowledge granularities among different parameters may be slight. It follows that the knowledge granularity derived from single parameter may be lack of representativeness. In this paper, the continuous parameters based knowledge granularity is proposed, and the corresponding calculation approach is presented. Inspired by the thinking of definite integral in mathematical problems, the calculation approach is mainly implemented by following steps: firstly, the graph formed by granularity and parameter interval is divided into several small rectangles whose length of interval tends to be 0; secondly, the sum of area values of all the small rectangles is calculated; finally, the obtained area value divided by the whole length of parameter interval can be considered as the continuous parameters based knowledge granularity. This study suggests a new trend of handling problems related to knowledge from the viewpoint of continuity.},
  keywords={Knowledge representation;Data mining;Voting;Tools;Semantics;Rough sets;Continuous parameters;granular computing;granularity;knowledge},
  doi={10.1109/ACCESS.2021.3078269},
  ISSN={2169-3536},
  month={},}@ARTICLE{9032212,
  author={Hong, Xin and Lin, Rongjie and Yang, Chenhui and Cai, Chunting and Clawson, Kathy},
  journal={IEEE Access}, 
  title={ADPM: An Alzheimer’s Disease Prediction Model for Time Series Neuroimage Analysis}, 
  year={2020},
  volume={8},
  number={},
  pages={62601-62609},
  abstract={Alzheimer's Disease (AD) is a form of dementia which causes memory, thinking, and behavior disorders in humans. Effective early diagnosis and treatment of AD is of fundamental importance as it can reduce disease progression, allow more effective management of symptoms, facilitate timely patient access to advice and support, and lower associated costs of health care. Given that Alzheimer's typically progresses in stages over an extended period of time, we propose that automated analysis of time sequential data may enhance disease prediction. We present a novel time-series Alzheimer's Disease Prediction Model (ADPM) comprising Random Forest (RF) region of interest (ROI) selection and Gated Recurrent Units (GRU) prediction. Experiments show that our methodology achieves higher classification accuracy in comparison to existing algorithms, and can facilitate prediction of early onset AD. Furthermore, testing demonstrates that random forest ROI selection can identify disease-relative brain regions across different image modalities (MRI, PET, DTI).},
  keywords={Dementia;Feature extraction;Forestry;Predictive models;Diffusion tensor imaging;Alzheimer’s disease prediction;time series;random forest;GRU},
  doi={10.1109/ACCESS.2020.2979969},
  ISSN={2169-3536},
  month={},}@ARTICLE{10399808,
  author={Koru, Gülsüm Kayabaşi and Uluyol, Çelebı},
  journal={IEEE Access}, 
  title={Detection of Turkish Fake News From Tweets With BERT Models}, 
  year={2024},
  volume={12},
  number={},
  pages={14918-14931},
  abstract={As the number of people using social networks increases, more people are using social media platforms to meet their news needs. Users think that it is easier to follow the agenda by accessing news, especially on Twitter, rather than newspaper news pages. However, fake news is increasingly appearing on social media, and it is not always possible for people to obtain correct news from partial news pages or short Twitter posts. Understanding whether the news shared on Twitter is true or not is an important problem. Detecting fake tweets is of great importance in Turkish as well as in any language. In this study, fake news obtained from verification platforms on Twitter and real news obtained from the Twitter accounts of mainstream newspapers were labeled and, preprocessed using the Zemberek natural language processing tool developed for the Turkish language, and a dataset named TR_FaRe_News was created. Then, the TR_FaRe_News dataset was explored using ensemble methods and BoW, TF-IDF, and Word2Vec vectorization methods for fake news detection. Then a pre-trained BERT deep learning model was fine-tuned, and variations of the model extended with Bi-LSTM and Convolutional Neural Network (CNN) layers with the frozen and unfrozen parameters methods were explored. The performance evaluation was conducted using seven comparable datasets, namely BuzzFeedNews, GossipCop, ISOT, LIAR, Twitter15, and Twitter16, including an LLM-generated fake news dataset. Analyzing Turkish tweets and using fake news datasets generated by LLM is considered an important contribution. Accuracy values between 90 and 94% were obtained with the BERT and BERTurk + CNN models with 94% accuracy.},
  keywords={Fake news;Social networking (online);Blogs;Deep learning;Ensemble learning;Convolutional neural networks;Machine learning algorithms;Fake news;generated news;ensemble learning;deep learning;BERT},
  doi={10.1109/ACCESS.2024.3354165},
  ISSN={2169-3536},
  month={},}@ARTICLE{8700182,
  author={Ko, Chihhsiang and Liu, Yuchun},
  journal={IEEE Access}, 
  title={Old and Young Users’ White Space Preferences for Online News Web Pages}, 
  year={2019},
  volume={7},
  number={},
  pages={57284-57297},
  abstract={In the future, the importance and usage rate of the Internet will increase gradually year by year. However, in the case of frequently browsed news web pages, mass news information derived from visual design elements or different layout designs may affect the preferences of users from different demographics and socio-economic backgrounds. This is due to the dissimilarities between their physical and psychological limitations. The purpose of this study is to investigate users' white-space ratio preferences for news web pages. We tested the top ten online Chinese and English websites, 20 news web pages in total. Two statements were picked from the system usability scale (SUS) and the visual aesthetics of website inventory (VisAWI) to evaluate these samples. We took these two statements as questionnaire questions. They are the following: Q1 “I think that I would like to use this system frequently” and Q2 “Everything goes together on these web pages.” The design of the questionnaire was based on a five-point Likert scale. The research variables include age, gender, education, occupation, white-space ratio, along with the other demographic properties. Our results indicated that there are significant differences between age, white-space ratio, education, occupation, news sources, computer usage time, and computer usage history. The group aged between 31-45 years old scored all samples higher than other groups. None prefer too high (90%) or too low (50%) white-space ratio. It is necessary to accumulate more preferences from different groups prior to the coming age of AI and machine learning.},
  keywords={Web pages;Usability;White spaces;Visualization;Layout;Complexity theory;Image color analysis;White space;news web pages;user preference;user interface;usability;aesthetics},
  doi={10.1109/ACCESS.2019.2913407},
  ISSN={2169-3536},
  month={},}@ARTICLE{9751071,
  author={Zhong, Shiyu and Fu, Xinsha and Lu, Wei and Tang, Feng and Lu, Yue},
  journal={IEEE Access}, 
  title={An Expressway Driving Stress Prediction Model Based on Vehicle, Road and Environment Features}, 
  year={2022},
  volume={10},
  number={},
  pages={57212-57226},
  abstract={Driving stress is the demand for reserved cognitive space after a driver perceives changes in vehicle, road and environmental factors during driving, which has been proven to affect driving behaviour, interfering with driving safety. Traditional stress prediction relies extensively on psychological data and is limited by the unpopularity of psychological data collection technology, which cannot be applied in daily life on a large scale. In recent years, advances in high-precision visual analysis technology represented by deep learning have laid the foundation for automated and large-scale visual environment analysis. This study proposes a framework for the quantitative analysis of highway driving stress based on multiple vehicle, road, and environmental factors. A dilated residual network model and other methods were used to extract visual environmental indexes. Combined with multisource data such as traffic volume and road design parameters, the LightGBM method was used to construct an expressway driving stress prediction model with high accuracy. The MAE, RMSE and  $R^{2}$  values of the proposed model are 0.042, 0.004 and 0.881, respectively, demonstrating the usefulness for scaled and efficient assessment of expressway stress loads. The SHAP method was used to explore the relationship between different influencing factors and driving stress to quantify the mechanism of vehicle, road and environment influences on stress load, and to propose recommendations for highway design and planning from the perspective of reducing stress load. This study provides a new way of thinking to quantitatively investigate the link between multiple road traffic factors and driving stress, providing efficient and large-scale assessment of expressway driving stress, as well as proposing some suggestions for highway design and planning to enhance stress reduction.},
  keywords={Stress;Vehicles;Psychology;Roads;Task analysis;Predictive models;Load modeling;Expressway;prediction model;driving stress;LightGBM method;SHAP method},
  doi={10.1109/ACCESS.2022.3165570},
  ISSN={2169-3536},
  month={},}@ARTICLE{10403882,
  author={Nallakaruppan, M. K. and Somayaji, Siva Rama Krishnan and Fuladi, Siddhesh and Benedetto, Francesco and Ulaganathan, Senthil Kumaran and Yenduri, Gokul},
  journal={IEEE Access}, 
  title={Enhancing Security of Host-Based Intrusion Detection Systems for the Internet of Things}, 
  year={2024},
  volume={12},
  number={},
  pages={31788-31797},
  abstract={The Internet of Things (IoT) infrastructure enables smart devices to learn, think, speak and perform. The facilities of the IoT devices can be enhanced to support an intelligent application through technologies like fog computing, smart networks, federated learning or explainable artificial intelligence infrastructures. In all these cases networking of IoT devices becomes inevitable. Whereever there exists a network, a threat to the network infrastructure is also possible. The proposed work classifies various attacks on the hosts with the support of proven machine learning (ML) algorithms. This work performs the comparative analysis of all these classification parameters of the machine learning algorithms with the use of fuzzy-based recommendation systems. This work also lists out various incidents of intrusions on the IoT hosts in appropriate layers of the interface and proposes an efficient algorithm and framework to overcome the occurrences of intrusions on the host side. In particular, we propose an effective security framework to deal with the intrusions that can deteriorate the host-based systems. The ranking of the algorithms is evaluated using fuzzy-based recommendation systems such as TOPSIS, VIKOR, MORA, WASPAS. The ensemble of machine learning algorithms such as Decision Tree, Lite Gradient Boost, Xtra Gradient Boost and Random Forest provide better values of accuracy (around 99%) with higher precision, re-call and F1-scores, thus proving their efficacy for intrusion detection in IoT networks.},
  keywords={Internet of Things;Security;Intrusion detection;Machine learning algorithms;Machine learning;Deep learning;Classification algorithms;Artificial intelligence;Artificial intelligence;Internet of Things;intrusion detection systems;network security;privacy},
  doi={10.1109/ACCESS.2024.3355794},
  ISSN={2169-3536},
  month={},}@ARTICLE{8502036,
  author={Mu, Dan and Liang, Yinghui and Zhang, Wenhui and Wang, Yucheng},
  journal={IEEE Access}, 
  title={Investigation on Tree Molecular Genome of Arabidopsis Thaliana for Internet of Things}, 
  year={2018},
  volume={6},
  number={},
  pages={67688-67698},
  abstract={Research and regulation of tree growth at molecular level is a new trend in the development of forest biotechnology. However, as the limitations of wood as a research material, it is difficult to operate and compare the growth cycle in the laboratory, which greatly hinders study of the molecular biology of forest trees. Arabidopsis thaliana is the most important model plant in botanical research and is an excellent material for plant molecular biology research. Recent studies have shown that herbaceous Arabidopsis can not only provide genetic resources for tree molecular breeding but also can be used as an auxiliary means of wood molecular biology research and even can be directly used as an experimental model for the study of the molecular mechanism of tree development. This paper mainly discusses the establishment process of the tree molecular gene system platform under the background of the Internet of Things and studies the molecular genome of Arabidopsis, combining the characteristics of the tree itself and using the diversity of the frequency of different bases in the gene fragment to cluster the tree molecular genome, which is a molecular biology research and provides an important way of thinking.},
  keywords={Genomics;Bioinformatics;Vegetation;Forestry;Internet of Things;Molecular biology;Arabidopsis thaliana;forest molecular genome;cluster research;Internet of Things},
  doi={10.1109/ACCESS.2018.2877411},
  ISSN={2169-3536},
  month={},}@ARTICLE{10271339,
  author={Huang, Qian and Xia, Haibin and Zhang, Zhancheng},
  journal={IEEE Access}, 
  title={Clustering Analysis of Integrated Rural Land for Three Industries Using Deep Learning and Artificial Intelligence}, 
  year={2023},
  volume={11},
  number={},
  pages={110530-110543},
  abstract={This study employs deep learning and artificial intelligence (AI) clustering analysis techniques to evaluate the suitability of integrated rural land for three industries. Diverse datasets pertaining to rural development, encompassing land use, agricultural production, and rural tourism, are gathered and harmoniously amalgamated. An innovative land suitability assessment model, merging ResNet-50 with the k-means algorithm, is devised. Specifically, ResNet-50 is harnessed for the classification and recognition of rural land-use images, thus deriving feature vectors for each sample. These feature vectors are subsequently fed into the k-means algorithm to cluster samples with akin land-use patterns. The ensuing examination of land use composition within each cluster facilitates the evaluation of rural land’s suitability for three-industry integration. Experimental scrutiny discloses that this study achieves an accuracy rate of 88.3% in rural land-use classification and recognition, outperforming alternative algorithms by at least 3.1%. Furthermore, it yields an average intersection over union (IoU) of 67.29%. Remarkably, the k-means algorithm exhibits superior clustering outcomes. Consequently, the model introduces herein demonstrated substantial enhancements in rural land-use classification and recognition accuracy, average IoU, and clustering performance. It offers an innovative tool for policymakers to advance rural industry integration, fostering economic diversification. Additionally, this model aids decision-makers in identifying prospective opportunities and challenges, thus facilitating the formulation of forward-thinking and viable rural development strategies.},
  keywords={Deep learning;Artificial intelligence;Clustering algorithms;Classification algorithms;Agriculture;Sustainable development;Economics;Deep learning;Artificial intelligence;deep learning;integrated rural land for three industries;cluster;suitability evaluation},
  doi={10.1109/ACCESS.2023.3321894},
  ISSN={2169-3536},
  month={},}@ARTICLE{10076418,
  author={Soysal, Omurhan Avni and Guzel, Mehmet Serdar and Dikmen, Mehmet and Bostanci, Gazi Erkan},
  journal={IEEE Access}, 
  title={Common Thorax Diseases Recognition Using Zero-Shot Learning With Ontology in the Multi-Labeled ChestX-ray14 Data Set}, 
  year={2023},
  volume={11},
  number={},
  pages={27883-27892},
  abstract={Disease detection/recognition with limited data sets and labels in the medical image domain is a very costly and greatest challenge. Although open image data sets have increased recently, researches on this problem still need to be developed. Researches to diversify data sets are both costly and face the problem of subjectivity. Unseen classes can be trained with the Zero-Shot Learning (ZSL) in order to overcome this problem. In this paper, we aimed to strengthen ZSL by using ontology as an auxiliary information for class embeddings. In our approach, ZSL is supported by the image embeddings and class embeddings of the multi-labelled ChestX-ray14 data set, as well as the semantic data from DBpedia. In this paper, which we believe will be pioneering in the medical image domain, the Cosine, Hamming and Euclidean distances were taken into account in order to maximize the similarities. We trained ResNet50 neural network with different parameters on the multi-labelled ChestX-ray14 data set. 23.25% precision value in one-to-one matching and 29.59% precision value in at least one matching were obtained. We think that this paper will make a significant contribution to the medical image domain by detecting/recognizing unseen disease images.},
  keywords={Thorax;Semantics;Ontologies;Visualization;Deep learning;Biomedical imaging;Task analysis;X-ray imaging;Zero-shot learning;ResNet50;ontology;ChestX-ray14},
  doi={10.1109/ACCESS.2023.3259062},
  ISSN={2169-3536},
  month={},}@ARTICLE{10188391,
  author={Han, Lei and Zheng, Shengnan and Shi, Zhan and Xia, Mingliang},
  journal={IEEE Access}, 
  title={Exploiting Sequence Analysis for Accurate Light-Field Depth Estimation}, 
  year={2023},
  volume={11},
  number={},
  pages={74657-74670},
  abstract={Depth estimation for light field (LF) images is the cornerstone of many applications of light field cameras, such as 3D reconstruction, defects inspection, face liveness detection, and so forth. In recent years, convolutional neural network (CNN) has dominated the primary workhorse for depth estimation. However, the interpretability of the network and the accuracy of the depth estimation results still need to be improved. This paper uses the conditional random field (CRF) theory to explain and model the LF depth estimation. Further, from the perspective of sequence analysis, we extract the sequence features of epipolar plane image (EPI) patches with recurrent neural network (RNN) and serve as the unary term of the energy function in the CRF. Then, a unified neural network (called as LFRNN) is designed to solve the CRF and get the disparity map. Our LFRNN builds upon two-stage architecture, involving a local depth estimation and a depth refinement. In the first part, we design an RNN to analyze the vector sequences in EPI patches and obtain local disparity values. There are two thinking behind the design of this part. The first is the general principle that the slope of the straight line in the EPI is inversely proportional to the depth; the second is our unique observation that those straight lines are distributed in vector sequences. In the second part, continuous CRF is used to optimize the output of the first part. We train LFRNN on a synthetic LF dataset and test it on both synthetic and real-world LF datasets. Quantitative and qualitative results validate the superior performance of our LFRNN over the state-of-the-art methods.},
  keywords={Estimation;Light fields;Conditional random fields;Cameras;Lenses;Deep learning;Sequences;Computer vision;Sequential analysis;Image processing;Computer vision;depth estimation;light field imaging;deep learning;sequence analysis},
  doi={10.1109/ACCESS.2023.3296800},
  ISSN={2169-3536},
  month={},}@ARTICLE{9878123,
  author={Verma, Shanu and Pandey, Vivekanand and Pant, Millie and Snasel, Vaclav},
  journal={IEEE Access}, 
  title={A Balanced Squad for Indian Premier League Using Modified NSGA-II}, 
  year={2022},
  volume={10},
  number={},
  pages={100463-100477},
  abstract={Selecting team players is a crucial and challenging task demanding a considerable amount of thinking and hard work by the selectors. The present study formulated the selection of an IPL squad as a multi-objective optimization problem with the objectives of maximizing the batting and bowling performance of the squad, in which a player’s performance is estimated using an efficient Batting Performance Factor and Combined Bowling Rate. Also, the proposed model tries to formulate a balanced squad by constraining the number of pure batters, pure bowlers, and all-rounders. Bounds are also considered on star players to enhance the performance of the squad and also from the income prospects of IPL. The problem in itself is treated as a 0/1 knapsack problem for which two combinatorial optimization algorithms, namely, BNSGA-II and INSGA-II, are developed. These algorithms were compared with existing modified NSGA-II for IPL team selection and three other popular multi-objective optimization algorithms, NSGA-II, NSDE, and MOPSO-CD, on the basis of standard performance metrics: hypervolume, inverted generational distance, and number of Pareto optimal solutions. Both algorithms performed well, with BNSGA-II performing better than all the other algorithms considered in this study. The IPL 2020 players’ data validated the applicability of the proposed model and algorithms. The trade-off squads contained players of each expertise in appropriate proportions. Further analysis of the trade-off squads demonstrated that many theoretically selected players performed well in IPL 2020 matches.},
  keywords={Optimization;Sorting;Franchising;Optimization methods;Genetic algorithms;Costs;Data models;Sports;Cricket;twenty20;knapsack problem;combinatorial;Indian premier league;multi-objective;optimization;squad selection},
  doi={10.1109/ACCESS.2022.3204649},
  ISSN={2169-3536},
  month={},}@ARTICLE{9623457,
  author={Liu, Wenxuan and Wu, Huayi and Hu, Kai and Luo, Qing and Cheng, Xiaoqiang},
  journal={IEEE Access}, 
  title={A Scientometric Visualization Analysis of Image Captioning Research From 2010 to 2020}, 
  year={2021},
  volume={9},
  number={},
  pages={156799-156817},
  abstract={Image captioning has gradually gained attention in the field of artificial intelligence and become an interesting and challenging task for image understanding. It needs to identify important objects in images, extract attributes, tell relationships, and help the machine generate human-like descriptions. Recent works in deep neural networks have greatly improved the performance of image caption models. However, machines are still unable to imitate the way humans think, talk and communicate, so image captioning remains an ongoing task. It is thus very important to keep up with the latest research and results in the field of image captioning whereas publications on this topic are numerous. Our work aims to help researchers to have a macro-level understanding of image captioning from four aspects: spatial-temporal distribution characteristics, collaborative networks, trends in subject research, and historical evolutionary path. We employ scientometric visualization methods to achieve this goal. The results show that China has published the largest amount of publications in image captioning, but the United States has the greatest impact on research in this area. Besides, thirteen academic groups are identified in the field of image description, with institutions such as Microsoft, Google, Australian National University, and Georgia Institute of Technology being the most prominent research institutions. Meanwhile, we find that evaluation methods, datasets, novel image captioning models based on generative adversarial networks, reinforcement learning, and Transformer, as well as remote sensing image captioning, are the new research trends. Lastly, we conclude that image captioning research has gone through three major development stages from 2010 to 2020, and on this basis, we propose a more comprehensive taxonomy of image captioning.},
  keywords={Bibliometrics;Visualization;Indexes;Conferences;Remote sensing;Market research;Image recognition;Image captioning;image description generation;scientometric analysis;visualization},
  doi={10.1109/ACCESS.2021.3129782},
  ISSN={2169-3536},
  month={},}@ARTICLE{9857902,
  author={Cao, Jinxin and Xu, Weizhong and Jin, Di and Zhang, Xiaofeng and Miller, Anthony and Liu, Lu and Ding, Weiping},
  journal={IEEE Access}, 
  title={A Network Embedding-Enhanced NMF Method for Finding Communities in Attributed Networks}, 
  year={2022},
  volume={10},
  number={},
  pages={118141-118155},
  abstract={Community detection is an extremely important task for complex network analysis. There still remains a challenge of how to improve the performance of community detection in real-world scenario. Some researchers think that the content in networks is helpful to identify communities, and also focus on combining network topology with node contents, alongside the eradication of inauspicious performance. Furthermore, network topology is often sparse, which is reflected in the lack of capability to represent communities. To address the above problems, this study identifies a novel non-negative matrix factorization method which both employs network embedding to enhance the representation power of network topology for communities and also integrates network topology and node contents for further raising the quality of community detection. Furthermore, we then obtain the parameters of the model for finding communities which is based on model inference. Alongside both synthetic and real-world networks with ground-truths, we compare the new method with the state-of-the-art methods. Experimental results show that the new method obtains significant improvement for community detection both by incorporating node contents and by enhancing network topology.},
  keywords={Network topology;Stochastic processes;Probabilistic logic;Complex networks;Topology;Social networking (online);Behavioral sciences;Community detection;network embedding;node contents;non-negative matrix factorization},
  doi={10.1109/ACCESS.2022.3198979},
  ISSN={2169-3536},
  month={},}@ARTICLE{10595088,
  author={Ito, Koya and Ishii, Yoko and Ishii, Ryo and Eitoku, Shin-Ichiro and Otsuka, Kazuhiro},
  journal={IEEE Access}, 
  title={Exploring Multimodal Nonverbal Functional Features for Predicting the Subjective Impressions of Interlocutors}, 
  year={2024},
  volume={12},
  number={},
  pages={96769-96782},
  abstract={This paper proposes models for predicting the subjective impressions of interlocutors in discussions according to multimodal nonverbal behaviors. To that end, we focus mainly on the functional aspects of head movement and facial expressions as insightful cues. For example, head movement functions include the speaker’s rhythm and the listener’s back channel and thinking processes, as well as their positive emotions. Facial expression functions include emotional expressions and communicative functions such as the speaker addressing the listener and the listener’s affirmation. In addition, our model employs synergetic functions, which are jointly performed with head movements and facial expressions, assuming that the simultaneous appearance of head and face functions could strengthen the results or lead to multiplexing. On the basis of these nonverbal functions, we define a set of functional features, including the rate of occurrence and composition balance among different functions that emerge during conversation. Then, a feature selection scheme is used to identify the best combinations of intermodal and intramodal features. In the experiments, an SA-Off corpus of 17 groups of discussions involving 4 female participants was used, including interlocutors’ self-reported scores for 16 impression items felt during the discussion, such as helpfulness and interest. The experiments confirmed that our models’ predictions were significantly correlated with the self-reported scores for more than 70% of the impression items. These results indicate the effectiveness of multimodal nonverbal functional features for predicting subjective impressions.},
  keywords={Indium tin oxide;Face recognition;Task analysis;Feature extraction;Eyebrows;Facial animation;Facial animation;Facial expression;feature selection;group meeting;head movement;multimodal recognition;nonverbal communication;social signal;subjective impression},
  doi={10.1109/ACCESS.2024.3426537},
  ISSN={2169-3536},
  month={},}@ARTICLE{10143650,
  author={Ketsbaia, Lida and Issac, Biju and Chen, Xiaomin and Jacob, Seibu Mary},
  journal={IEEE Access}, 
  title={A Multi-Stage Machine Learning and Fuzzy Approach to Cyber-Hate Detection}, 
  year={2023},
  volume={11},
  number={},
  pages={56046-56065},
  abstract={Social media has revolutionized the way individuals connect and share information globally. However, the rise of these platforms has led to the proliferation of cyber-hate, which is a significant concern that has garnered attention from researchers. To combat this issue, various solutions have been proposed, utilizing Machine learning and Deep learning techniques such as Naive Bayes, Logistic Regression, Convolutional Neural Networks, and Recurrent Neural Networks. These methods rely on a mathematical approach to distinguish one class from another. However, when dealing with sentiment-oriented data, a more “critical thinking” perspective is needed for accurate classification, as it provides a more realistic representation of how people interpret online messages. Based on a literature review conducted to explore efficient classification techniques, this study applied two machine learning classifiers, Multinomial Naive Bayes and Logistic Regression, to four online hate datasets. The results of the classifiers were optimized using bio-inspired optimization techniques such as Particle Swarm Optimization and Genetic Algorithms, in conjunction with Fuzzy Logic, to gain a deeper understanding of the text in the datasets.},
  keywords={Cyberbullying;Machine learning;Genetic algorithms;Feature extraction;Multimedia Web sites;Fuzzy logic;Random forests;Bayes methods;Cyberbullying;fuzzy logic;logistic regression;multinomial Naive Bayes;PSO;VADER},
  doi={10.1109/ACCESS.2023.3282834},
  ISSN={2169-3536},
  month={},}@ARTICLE{9295320,
  author={Zhang, Xin and Cheng, Zhi},
  journal={IEEE Access}, 
  title={Improving Query Quality for Transductive Learning in Learning to Rank}, 
  year={2020},
  volume={8},
  number={},
  pages={226188-226198},
  abstract={In traditional transductive learning, all queries are used in learning to rank in order to generate pseudo-labels when sufficient training data are not available. However, low quality queries may affect retrieval performance in transductive learning. We thus think that it is important to improve the quality of queries in transductive learning to train an effective ranking model. By using a small number of reliable samples and data close to the boundaries of classification, we propose building a query quality estimator by establishing a relationship between the benefits of good retrieval performance and features of the normalized query commitment that influence query quality. In our proposed transduction model, all queries available are filtered by the proposed query quality estimator and only high quality queries that enhance the effectiveness of retrieval such that they yield performance-related benefits, are used to generate pseudo-labels for learning to rank. Queries that can degrade performance benefits are discarded while creating the pseudo-labels. Pseudo-labels aggregated by high quality queries in transductive learning are then leveraged in learning to rank scenarios without sufficient training data. The results of extensive experiments on the standard LETOR 4.0 dataset showed that our proposed method can outperform strong baselines and the average normalized discounted cumulative gain is enhanced up to 7.77% in some case.},
  keywords={Training data;Reliability;Semisupervised learning;Feature extraction;Information retrieval;Training;Supervised learning;Transductive learning;query quality;retrieval performance;learning to rank},
  doi={10.1109/ACCESS.2020.3043459},
  ISSN={2169-3536},
  month={},}@ARTICLE{10666721,
  author={Ozkan, Dilek and Katar, Oguzhan and Ak, Murat and Al-Antari, Mugahed A. and Yasan Ak, Nehir and Yildirim, Ozal and Mir, Hasan S. and Tan, Ru-San and Rajendra Acharya, U.},
  journal={IEEE Access}, 
  title={Deep Learning Techniques for Automated Dementia Diagnosis Using Neuroimaging Modalities: A Systematic Review}, 
  year={2024},
  volume={12},
  number={},
  pages={127879-127902},
  abstract={Dementia is a condition that often comes with aging and affects how people think, remember, and behave. Diagnosing dementia early is important because it can greatly improve patients’ lives. This systematic review looks at how deep learning (DL) techniques have been used to diagnose dementia automatically from 2012 to 2023. We explore how different DL methods like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Deep Neural Networks (DNN) are used to diagnose types of dementia such as Alzheimer’s, vascular dementia, and Lewy body dementia. We also discuss the difficulties of using DL for diagnosing dementia, like the lack of large and varied datasets and the challenge of applying models to different groups of people. These issues indicate the need for more dependable and understandable models that consider a wide range of patient characteristics and biomarkers. Longitudinal studies are also needed to understand how the disease progresses and how treatments work. Collaboration among researchers, doctors, and data scientists is crucial to ensure DL models are scientifically sound and effective in clinical settings. In summary, DL techniques show promise for automated dementia diagnosis and could improve how accurately and efficiently it is diagnosed in practice. However, further research is needed to address the challenges highlighted in this review.},
  keywords={Dementia;Neuroimaging;Deep learning;Positron emission tomography;Single photon emission computed tomography;Medical diagnostic imaging;Functional magnetic resonance imaging;Alzheimer's disease;Artificial neural networks;Alzheimer’s;deep learning;deep neural networks;disease classification;neuroimaging},
  doi={10.1109/ACCESS.2024.3454709},
  ISSN={2169-3536},
  month={},}@ARTICLE{10488363,
  author={Kim, Seong-Kyu and Huh, Jun-Ho and Kim, Byung-Gyu},
  journal={IEEE Access}, 
  title={Artificial Intelligence Blockchain Based Fake News Discrimination}, 
  year={2024},
  volume={12},
  number={},
  pages={53838-53854},
  abstract={This paper minimizes fake news, which has been a hot topic recently, using blockchain and artificial intelligence technology, and verifies it with blockchain. Also, using Artificial Intelligence technology, we want to create an algorithm that predicts how fake news will spread in the future. You can see various attempts at a news media platform based on Blockchain technology. However, the Blockchain news media platform is still not getting the market response we expected. It is questionable whether the reason is simply because it is a new technology, so it takes a long time to gain trust from consumers, whether consumers are not yet expecting an innovative news media platform, or whether the explosive growth of the Blockchain news media platform is difficult for other reasons. Research to answer this or direct research between Blockchain and media platforms is still lacking. In addition, the method of verifying fake news using artificial intelligence was verified, ANN, CBR, and MDA were changed, and the experiment was verified for progress. In addition, the use of 5-fold cross-validation as a comparative method was added as described above to more closely examine the possibility of its usefulness even in general situations. Also, through various fields of artificial intelligence and blockchain, verification work was done with blockchain, and fake news prediction was made using artificial intelligence. Various experiments were conducted and performance tests were performed, while the performance of about 5,000 TTPS was recorded through the third experiment. In the future, we think it is necessary to combine Artificial Intelligence and blockchain technology.},
  keywords={Fake news;Blockchains;Artificial intelligence;Internet;Computers;Web sites;Video on demand;Parallel processing;Blockchain;super node;artificial intelligence;fake news;multi-channel;parallel processing},
  doi={10.1109/ACCESS.2024.3384338},
  ISSN={2169-3536},
  month={},}@ARTICLE{9761240,
  author={León, A. and Simon, A. García and Pastor, O.},
  journal={IEEE Access}, 
  title={An Advanced Search System to Manage SARS-CoV-2 and COVID-19 Data Using a Model-Driven Development Approach}, 
  year={2022},
  volume={10},
  number={},
  pages={43528-43534},
  abstract={The pandemic outbreak of COVID-19 has allowed the proliferation of an unprecedented amount of data that must be organized and connected in a way that allows its efficient management. Nevertheless, the speed at which all of this knowledge is being generated has highlighted the shortcomings of the research community in creating well-organized, standardized, and structured databases. Despite the efforts of the community to develop advanced integrative platforms such as CovidGraph, we have identified some limitations when using these solutions that we think are derived from the lack of a sound ontological schema to guide the collection, standardization, and integration of data. This work explores the advantages and disadvantages for the final user of building advanced information systems using a Model Driven Development approach to integrate heterogeneous and complex data using an ontological background as a basis. As a proof of concept, we built a database (CovProt) to integrate data about different aspects of SARS-CoV-2 using this approach, we analyzed the advantages and disadvantages of using this approach compared to CovidGraph by performing a set of queries in CovProt and CovidGraph, and finally, we compared the structure and redundancy of the retrieved data.},
  keywords={Databases;COVID-19;Data models;Proteins;Coronaviruses;Unified modeling language;Soft sensors;Conceptual model;graph data model;MDD;COVID-19;design methods},
  doi={10.1109/ACCESS.2022.3169268},
  ISSN={2169-3536},
  month={},}@ARTICLE{9200995,
  author={Sophatsathit, Peraphon},
  journal={IEEE Access}, 
  title={The N-Dimension Computing Machine Postulate}, 
  year={2020},
  volume={8},
  number={},
  pages={173044-173055},
  abstract={This paper postulates a novel N-dimension computing machine that operates in an unconventional manner. This postulate aims at solving existing problems in higher dimensions, where one must re-think the scope of a given problem domain beyond the one-dimension Turing machine to dictate all subsequent problem representation, problem transformation, and algorithmic derivation. Two over-simplified well-known problems, namely, the Traveling Salesman Problem and the Tower of Hanoi problem are presented to demonstrate the point. Both synthetic problems are effectively adapted to solve a real world project. To realize the postulate in a viable architectural construct, data flow and molecular computers are investigated since they show potential computation power. Unfortunately, they are still confined to working in one-dimension domain. A biological-like architecture for software systems is proposed in three design aspects: structure, function, and behavior. Contributions of this work are to revamp traditional Turing computation paradigm to N-dimension computing machine, yet it is simple, straightforward, and implementable by state-of-the-practice hardware and software technologies. Thus, the burden of solving difficult problems can be lessened.},
  keywords={Computers;Complexity theory;Turing machines;Computer architecture;Parallel processing;Classification algorithms;Turing machine;N-dimension computing;data flow computers;molecular computers;biological-like architecture},
  doi={10.1109/ACCESS.2020.3025149},
  ISSN={2169-3536},
  month={},}@ARTICLE{10443471,
  author={Li, Lanqi and Dong, Weiming},
  journal={IEEE Access}, 
  title={Graph Information Bottleneck-Based Dual Subgraph Prediction for Molecular Interactions}, 
  year={2024},
  volume={12},
  number={},
  pages={30113-30122},
  abstract={Recently, graph neural networks have achieved remarkable success in predicting molecular interactions. However, existing methodologies often fall short of comprehensively considering a pivotal factor influencing these interactions: the core subgraph within molecules, commonly represented by functional groups or atoms capable of engaging in interactions with other molecules. In this work, we propose a novel interaction prediction framework, called GIB-DS, which centers on the identification of the core subgraph in pairs of molecules to anticipate their interaction behavior. Guided by the principles of the Graph Information Bottleneck, our approach adeptly identifies two subgraphs within this pair of graphs that capture the essential information pertinent to the task at hand. We think that the dual-subgraph formulation could more faithfully capture the underlying nature of chemical reactions, where interactions between molecules and the interactions among specific atoms are inherently intertwined. Extensive experimentation across diverse datasets underscores the superiority of GIB-DS over state-of-the-art baselines, achieving an approximate 5% improvement. The GIB-DS code proposed can be found at https://github.com/LiLanQi/GIB_DS.},
  keywords={Task analysis;Hydrogen;Solvents;Predictive models;Optimization;Mutual information;Feature extraction;Graph neural networks;Molecular computing;Graph information bottleneck;graph neural networks;molecular interactions},
  doi={10.1109/ACCESS.2024.3368926},
  ISSN={2169-3536},
  month={},}@ARTICLE{10540133,
  author={Abdullah, Mohammed and Negied, Nermin},
  journal={IEEE Access}, 
  title={Detection and Prediction of Future Mental Disorder From Social Media Data Using Machine Learning, Ensemble Learning, and Large Language Models}, 
  year={2024},
  volume={12},
  number={},
  pages={120553-120569},
  abstract={Social media platforms are used widely by all people to express their feelings, opinions, and emotional states. Billions of people worldwide use them daily to share what they think and feel in their posts. Amongst all social media available platforms, Facebook only contains around three billion personal accounts. In this work Reddit dataset is used to automatically detect mental illness from social media posts. This study is not only limited to early detection of already existing mental illness or disorder like depression and anxiety from social posts, but also and most importantly the study is extended to predict successfully potential mental illness that would happen in future. This study deploys Nineteen different models to study the capability of them in detecting and predicting mental disorders from social media posts. Some of the deployed models are classical machine learning classifiers, some are ensemble learning models, and the rest are large language models (LLMs). Six machine learning classifiers were used in this work for the automatic detection and prediction of mental illness and logistic regression proved to be the best amongst other classifiers in this task. Nine Ensemble methods were also used and examined. Amongst the Nine ensemble learning models VC2, Light GBM, Bagging estimator, and XGBoost proved to be superior in this task. Four large language models were also used and examined for the same task. RoBERTa and OpenAI GPT proved to outperform the rest of models in this task. All those models were built, trained, tested, and compared with previous work in literature to get the best possible results. The study covers the main four mental disorders which are ADHD, Anxiety, Bipolar, and Depression. The work proposed in this paper succeeded in outperforming the results in literature in terms of number of addressed mental disorders, number of models used and tested, and dataset size used to validate results. The proposed work also outperformed the only attempt in literature that addressed all mental disorders in results of detection and prediction noticeably. This work achieved the detection of already existing mental disorders F1-score of 0.80 from clinical data and of 0.52 from non-clinical data, and it achieved a prediction of future mental disorder F1-score of 0.43 from non-clinical data.},
  keywords={Social networking (online);Depression;Anxiety disorders;Support vector machines;Mental health;Ensemble learning;Predictive models;ADHD;anxiety;bipolar;mental illness classification;depression detection;depression prediction;Reddit},
  doi={10.1109/ACCESS.2024.3406469},
  ISSN={2169-3536},
  month={},}@ARTICLE{10506479,
  author={Zabeehullah and Arif, Fahim and Ali Khan, Nauman and Iqbal, Javed and Khalid Karim, Faten and Innab, Nisreen and Mostafa, Samih M.},
  journal={IEEE Access}, 
  title={DQQS: Deep Reinforcement Learning-Based Technique for Enhancing Security and Performance in SDN-IoT Environments}, 
  year={2024},
  volume={12},
  number={},
  pages={60568-60587},
  abstract={The Internet of Things (IoT) is an emerging technology that allow smart devices to communicate through various heterogeneous channels (wired or wireless). However, for conventional networks, it has become a challenging task to efficiently control and manage the data flows of a huge number of devices. Software-defined networking (SDN) is a new way of thinking about networking. Because it is programmable, flexible, agile, and gives you a big picture of the network, it has tried to solve some IoT problems, like scalability, heterogeneity, and complexity. In large-scale SDN-IoT networks, there is a requirement for routing protocols that are both efficient and secure in order to ensure a superior level of quality of service (QoS) and quality of experience (QoE). To address the above stated challenges, a novel deep reinforcement learning (DRL) known as DQQS model is proposed. The aim is to achieve QoS and QoE while also ensuring the security of the SDN-IoT network. The proposed DQQS model dynamically extracts patterns from the past network history by interacting with the underlying network and generating optimized routing policies. This article employs three network metrics—throughput, latency, and the probability of avoiding malicious nodes—to measure the performance of DQQS. Simulations reveal that the proposed framework outperforms four state-of-the-art routing algorithms: OSPF, L-L Routing, Sailfish Routing, and RL-Routing in terms of both throughput and latency. For instance, in an attacked environment, the proposed DQQS model achieved the highest throughput value of 14.5 Mbps, surpassing OSPF at 8 Mbps, L-L at 8.2 Mbps, Sailfish at 9 Mbps, and RL at 9.5 Mbps. Similarly, this model exhibited superior performance in latency, recording the lowest latency value of 52 ms, compared to OSPF 88 ms, L-L 85 ms, Sailfish 72 ms, and RL 75 ms routing algorithms. The experimental results demonstrate that this new DQQS model is a pioneering deep reinforcement learning-based technique that optimally addresses secure routing in the SDN-IoT environment, ensuring enhanced quality of service and experience, and outperforming state-of-the art DL methodologies in both security and network performance metrics.},
  keywords={Routing;Quality of service;Internet of Things;Quality of experience;Security;Sensors;Optimization;Deep reinforcement learning;Malware;Telecommunication network management;Software defined networking;Deep reinforcement learning;Internet of Things;malicious node detection;optimal network management;routing optimization;software defined network;security},
  doi={10.1109/ACCESS.2024.3392279},
  ISSN={2169-3536},
  month={},}@ARTICLE{6733220,
  author={Zeng, Daniel},
  journal={IEEE Intelligent Systems}, 
  title={From Computational Thinking to AI Thinking [A letter from the editor]}, 
  year={2013},
  volume={28},
  number={6},
  pages={2-4},
  abstract={How can the AI community set about promoting a better understanding of AI's accomplishments and greater awareness of its potential across multiple disciplines?},
  keywords={AI;foundation of learning;intelligent systems;AI thinking;computational thinking;artificial intelligence},
  doi={10.1109/MIS.2013.141},
  ISSN={1941-1294},
  month={Nov},}@INPROCEEDINGS{4536091,
  author={Wing, Jeannette},
  booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing}, 
  title={Computational thinking and thinking about computing}, 
  year={2008},
  volume={},
  number={},
  pages={1-1},
  abstract={Summary form only given. My vision for the 21st Century: computational thinking will be a fundamental skill used by everyone in the world. To reading, writing, and arithmetic, let's add computational thinking to every child's analytical ability. Computational thinking has already influenced other disciplines, from the sciences to the arts. The new NSF cyber-enabled discovery and innovation initiative in a nutshell is computational thinking for science and engineering. Realizing this vision gives the field of computing both exciting research opportunities and novel educational challenges. The field of computing is driven by technology innovation, societal demands, and scientific questions. We are often too easily swept up with the rapid progress in technology and the surprising uses by society of our technology, that we forget about the science that underlies our field. In thinking about computing, I have started a list of "Deep Questions in Computing," with the hope of encouraging the community to think about the scientific drivers of our field.},
  keywords={Computer science;Computer vision;Information science;Technological innovation;Councils;Writing;Arithmetic;Art;Computer languages;Information technology},
  doi={10.1109/IPDPS.2008.4536091},
  ISSN={1530-2075},
  month={April},}@ARTICLE{8322432,
  author={García-Peñalvo, Francisco José},
  journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, 
  title={Editorial Computational Thinking}, 
  year={2018},
  volume={13},
  number={1},
  pages={17-19},
  abstract={Information technologies are the base of the world infrastructure. In this social context, education, like any productive or service sector, is affected by technology. Faced with this reality, educational systems must prepare our young people to live in the digital world, for which they must be proficient in a new language without which they will become digital illiterates. Therefore, in school we should not only train in linguistic and numerical literacy, but also in digital literacy. So far, the effort has been oriented mainly to convert our young people into users of computer tools. This has gone from being necessary to being insufficient, because the use of software applications means to manage a digital language that is obsolete in a time that is not proportional, in effort, to the time that has been invested in acquiring these skills. Therefore, the challenge is to prepare our young people to face the world in which they live, giving them the necessary cognitive tools to succeed in the digital world. That is, instead of teaching students only the syntax of a changing language, they should be instructed in the rules that allow them to know how the digital language is constructed. Thus, computational thinking emerges as a paradigm of work, and the programming is stablished as the tool to solve problems.},
  keywords={Computational thinking;pre-university studies;programming;teaching of computer science;university studies},
  doi={10.1109/RITA.2018.2809939},
  ISSN={1932-8540},
  month={Feb},}@INPROCEEDINGS{6070404,
  author={Wing, Jeannette M.},
  booktitle={2011 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Computational thinking}, 
  year={2011},
  volume={},
  number={},
  pages={3-3},
  abstract={Summary form only given. My vision for the 21st century, Computational Thinking, will be a fundamental skill used by everyone in the world. To reading, writing, and arithmetic, we should add computational thinking to every child's analytical ability. Computational thinking involves solving problems, designing systems, and understanding human behavior by drawing on the concepts fundamental to computer science. Thinking like a computer scientist means more than being able to program a computer. It requires the ability to abstract and thus to think at multiple levels of abstraction. In this talk I will give many examples of computational thinking, argue that it has already influenced other disciplines, and promote the idea that teaching computational thinking can not only inspire future generations to enter the field of computer science but benefit people in all fields.},
  keywords={},
  doi={10.1109/VLHCC.2011.6070404},
  ISSN={1943-6106},
  month={Sep.},}@INPROCEEDINGS{7836158,
  author={Cahill, Clara},
  booktitle={2016 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT)}, 
  title={Designing for differentiation: Learning objectives and design strategies for computational thinking}, 
  year={2016},
  volume={},
  number={},
  pages={1-1},
  abstract={In order to meet broadening participation goals for computer science, it is important to consider how pedagogy and design may impact different learners in different ways. Individual characteristics related to prior experience, social context, ethnic/racial identity, and gender identity may each play a part in how the design of a learning experience influences student engagement, attitudes, interests, skills, and knowledge. To examine these relationships, this talk will present findings and implications of research conducted in conjunction with the design and development of The Science Behind Pixar, a large traveling exhibition created collaboratively by the Museum of Science, Boston and Pixar Animation Studios. This exhibition, which features experiences that demonstrate how Pixar filmmakers use computational thinking and creativity to approach complex artistic and technical challenges, used several distinct engagement strategies and pedagogical approaches to guide exhibit design. This presentation will examine how these design approaches related to learning, engagement, and broadening participation goals.},
  keywords={},
  doi={10.1109/RESPECT.2016.7836158},
  ISSN={},
  month={Aug},}@ARTICLE{5678572,
  author={Day, Charles},
  journal={Computing in Science & Engineering}, 
  title={Computational Thinking Is Becoming One of the Three Rs}, 
  year={2011},
  volume={13},
  number={1},
  pages={88-88},
  abstract={Computational thinking, or something like it, has always been, and always should be, essential to education.},
  keywords={Computational modeling},
  doi={10.1109/MCSE.2011.5},
  ISSN={1558-366X},
  month={Jan},}@ARTICLE{7420499,
  author={Booch, Grady},
  journal={IEEE Software}, 
  title={The Computational Human}, 
  year={2016},
  volume={33},
  number={2},
  pages={8-10},
  abstract={Different ages of humanity have required different modes of thinking. These modes aren't only reflections of the particular circumstances of life in each age; they're also projections of the forces that propel us to the next. The Web extra at https://youtu.be/0_kwid5kUAU is an audio podcast of Grady Booch's On Computing column, in which he discusses how we have progressed from the Cognitive Revolution to the Agricultural Revolution to the Industrial Revolution and now find ourselves in the Computational Revolution.},
  keywords={computational thinking;history;science;software engineering},
  doi={10.1109/MS.2016.59},
  ISSN={1937-4194},
  month={Mar},}@ARTICLE{5337638,
  author={Thiruvathukal, George K.},
  journal={Computing in Science & Engineering}, 
  title={Computational Thinking … and Doing}, 
  year={2009},
  volume={11},
  number={6},
  pages={4-4},
  abstract={Computing in Science and Engineering From the Editors},
  keywords={Computer science;Computer networks;Software algorithms;Application software;Medical services;Social network services;Computational modeling;Computer simulation;Collaborative tools;Collaborative software;Computing in Science and Engineering From the Editors},
  doi={10.1109/MCSE.2009.190},
  ISSN={1558-366X},
  month={Nov},}@ARTICLE{4804815,
  author={Wang, Fei-Yue},
  journal={IEEE Intelligent Systems}, 
  title={Is Culture Computable?}, 
  year={2009},
  volume={24},
  number={2},
  pages={2-3},
  abstract={EIC Fei-Yue Wang discusses the emerging field of social and cultural computing and how the digital era could make computational thinking a basic skill set.},
  keywords={Cultural differences;Machine learning;Computer vision;Social network services;Statistics;Computational cultural modeling;Computational intelligence;Writing;Digital arithmetic;Solids;AI;cultural heritage;computational thinking;cultural learning;social learning},
  doi={10.1109/MIS.2009.31},
  ISSN={1941-1294},
  month={March},}@INPROCEEDINGS{6344467,
  author={Blackwell, Alan},
  booktitle={2012 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Computational thinking and creative practice}, 
  year={2012},
  volume={},
  number={},
  pages={3-3},
  abstract={End-user programmers have experiences of computation that are different from those of professional software engineers or people trained in computer science. We now understand that these different experiences arise from different motivations, different approaches to the task of programming, and different expectations about the outcomes. This talk reports results from a 10 year programme of research, engaging with collaborators who have been sought out precisely because their motivations, work methods and intentions are as different as possible from typical engineering programmers. These investigations have involved the development of a wide range of novel programmable systems and notations designed for use by choreographers, composers, musicians, and visual artists. The findings extend previous analyses of computational experience such as the attention investment model of abstraction use, and the cognitive dimensions of notations, drawing attention to ways of programming that are not only utilitarian, but playful and engaging. Research of this kind also helps us to understand that there are not necessarily different kinds of people in the world - those who are creative or not - but rather different ways of engaging with technology, available to all designers painting from the palette of human-centric computing systems.},
  keywords={},
  doi={10.1109/VLHCC.2012.6344467},
  ISSN={1943-6106},
  month={Sep.},}@INPROCEEDINGS{5109215,
  author={Gallant, Jack},
  booktitle={2009 4th International IEEE/EMBS Conference on Neural Engineering}, 
  title={“Lets see what you think! Bayesian reconstruction of perceptual experiences from human brain activity”}, 
  year={2009},
  volume={},
  number={},
  pages={vi-vi},
  abstract={Summary form only given. Recent interest in brain-computer interfaces has pushed development of decoding models that aim to classify, identify or reconstruct visual stimuli directly from measured brain activity. Most decoding models are based on non-parametric algorithms such as SVM and do not exploit current computational models of visual processing. We have pioneered an alternative approach in which the decoding algorithm is inferred from one or more explicit visual processing (nonlinear filtering) models. In previous work we showed that our approach extracts far more information from functional MRI measurements than was generally believed possible. In this task I will describe a new Bayesian decoding model that can actually reconstruct natural images that were seen by an observer from brain activity measured using fMRI. The decoder combines three elements: (1) a structural encoding model that characterizes signals from early visual areas; (2) a semantic encoding model that characterizes signals from higher visual areas; and (3) appropriate priors that incorporate statistical information about the structure and semantics of natural scenes. By combining all these elements the decoder produces reconstructions that accurately reflect the distribution, structure and semantic category of the objects contained in the original image. These results help clarify how distinct representations in different parts of the brain can be combined to provided a coherent reconstruction of the visual world; they also highlight a potentially important role for prior knowledge in visual perception. Our Bayesian decoding framework can be generalized directly to permit reconstruction of other perceptual dimensions, and might facilitate reconstruction of subjective perceptual processes such as visual imagery and dreaming. In the future Bayesian decoding algorithms might form the basis of powerful new brain-reading technologies and brain-computer interfaces.},
  keywords={Bayesian methods;Humans;Decoding;Image reconstruction;Brain computer interfaces;Brain modeling;Encoding;Support vector machines;Support vector machine classification;Computational modeling},
  doi={10.1109/NER.2009.5109215},
  ISSN={1948-3554},
  month={April},}@ARTICLE{10584380,
  author={Sengupta, Kaushik},
  journal={IEEE Solid-State Circuits Magazine}, 
  title={Solid-State Circuits Directions Technical Committee Launches “Think Impact with ICs” Workshop Series and “Impact Community Projects” in Partnership With EPICS in IEEE [Society News]}, 
  year={2024},
  volume={16},
  number={2},
  pages={89-91},
  abstract={Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  keywords={},
  doi={10.1109/MSSC.2024.3378188},
  ISSN={1943-0590},
  month={Spring},}@ARTICLE{4293737,
  author={Kusnezov, Dimitri},
  journal={Computing in Science & Engineering}, 
  title={How Big Can You Think? Challenges at the Frontier}, 
  year={2007},
  volume={9},
  number={5},
  pages={62-67},
  abstract={The world is on the threshold of a remarkable era of computing, in which raw computational power is no longer the limiting factor. The author argues that today's approach to computational science requires revision. This is becoming critical as simulation exerts greater influence on high-consequence decisions with societal impact.},
  keywords={Computational modeling;Computer simulation;National security;Stability analysis;Leg;Investments;Technological innovation;Computer vision;Engineering profession;Face recognition;nuclear simulation;supercomputing;grid computing;computational science;At Issue},
  doi={10.1109/MCSE.2007.98},
  ISSN={1558-366X},
  month={Sep.},}@ARTICLE{5508720,
  author={Tan, Kay Chen},
  journal={IEEE Computational Intelligence Magazine}, 
  title={The Nuts and “Bots” of Our Future [Editor's Remarks]}, 
  year={2010},
  volume={5},
  number={3},
  pages={2-6},
  abstract={I have recently returned from the US after attending the 2010 IEEE Panel of Editors (PoE) meeting at New Brunswick. On the 18-hour flight back home, I was thinking if the courteous stewardesses could one day be replaced by intelligent robots serving my favorite meal. Imagine asking a robot to prepare a cup of cappuccino and bringing it to you.},
  keywords={USA Councils;Intelligent robots;Computational intelligence;Computer integrated manufacturing;Production;Machine learning;Humans;Biological systems;Power engineering and energy;Computational Intelligence Society},
  doi={10.1109/MCI.2010.937325},
  ISSN={1556-6048},
  month={Aug},}@ARTICLE{6798648,
  author={Thiruvathukal, George K.},
  journal={Computing in Science & Engineering}, 
  title={What We Publish in CiSE}, 
  year={2014},
  volume={16},
  number={2},
  pages={4-6},
  abstract={Here, the Editor-in-Chief discusses what we publish in CiSE, and the best way to present work for publication in the magazine.},
  keywords={computational science;scientific computing;peer review;scientific publishing;interdisciplinary thinking},
  doi={10.1109/MCSE.2014.46},
  ISSN={1558-366X},
  month={Mar},}@ARTICLE{6898799,
  author={Booch, Grady},
  journal={IEEE Software}, 
  title={To Code or Not to Code, That Is the Question}, 
  year={2014},
  volume={31},
  number={5},
  pages={9-11},
  abstract={There have been many periods in the unfolding of human history when we have asserted that it was possible to catalog all that was known or that could be known. Ignoring the pragmatic reality of trying to catalog an ever-expanding corpus, one must understand that such a task is further complicated by cultural and situational bias: what is important to know at one place and time is not necessary important in another. So it is with our present day; this raises the question, what must a functioning member of society know about computing? The Web extra at http://youtu.be/PjR6GqobTBo is an audio podcast of author Grady Booch reading his On Computing column, in which he discusses how much a functioning member of society today should know about computing.},
  keywords={computational thinking;programming;knowledge;information;history;software engineering},
  doi={10.1109/MS.2014.128},
  ISSN={1937-4194},
  month={Sep.},}@INPROCEEDINGS{7407051,
  author={Poupart, Pascal},
  booktitle={2015 Conference on Technologies and Applications of Artificial Intelligence (TAAI)}, 
  title={Keynote speech VI think fast — resource constrained reasoning and planning under uncertainty}, 
  year={2015},
  volume={},
  number={},
  pages={30-30},
  abstract={Recent advances in planning techniques have focused on online search techniques. While these techniques allow practitioners to obtain policies for fairly large problems, they assume that a non-negligible amount of computation can be done between each decision point. In contrast, the recent proliferation of mobile and embedded devices has lead to a surge of applications that could benefit from state of the art planning techniques if they can operate under severe constraints on computational resources. For instance, consider the emerging class of monitoring and assistive applications that run on smart-phones, wearable systems or other mobile devices. While computational resources are rapidly increasing, energy consumption remains an important bottleneck due to limited battery life. In this talk, I will present some experiments about battery consumption for various types of planning policies on smart-phones. I will then present recent results for the optimization and compilation of policies into controllers with negligible energy consumption during their execution. I will also present recent advances in multi-objective optimization to tradeoff the utility and energy costs resulting from different actions.},
  keywords={},
  doi={10.1109/TAAI.2015.7407051},
  ISSN={2376-6824},
  month={Nov},}@ARTICLE{7360255,
  author={Swan, Melanie},
  journal={IEEE Technology and Society Magazine}, 
  title={Blockchain Thinking : The Brain as a Decentralized Autonomous Corporation [Commentary]}, 
  year={2015},
  volume={34},
  number={4},
  pages={41-52},
  abstract={Reports on the concept of blockchains, a new form of information technology that could have several important future applications. One is blockchain thinking, formulating thinking as a blockchain process. This could have benefits for both artificial intelligence and human enhancement, and their potential integration. Blockchain thinking is outlined here as an input-processing-output computational system.},
  keywords={Brain models;Information processing},
  doi={10.1109/MTS.2015.2494358},
  ISSN={1937-416X},
  month={Dec},}@ARTICLE{9245895,
  author={},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Guest Editorial: Smart Fuzzy Optimization in Operational Research and Renewable Energy: Modeling, Simulation, and Application}, 
  year={2020},
  volume={28},
  number={11},
  pages={2675-2676},
  abstract={The papers in this special section focus on smart fuzzy optimization in operational research and renewable energy. Over the last five decades, fuzzy optimization has found numerous successful applications in diverse fields, including operational research (OR), manufacturing, information technology, energy optimization, data science, smart cities, and big data analytics. Fuzzy optimization has strongly influenced research and development into other areas of intelligent computing leading to many hybrid and deep learning systems. It has opened new horizons in thinking, research and development and it will guide us into another half century of progress. In actually, fuzzy optimization is an approximation of nonlinear optimization, which has formed a systematic but not yet unified theory of fuzzy systems and other fuzzy-set based methodologies. Fuzzy optimization along with decision making is an interdisciplinary area, which focuses on extracting useful knowledge with data technology and employing it. Specific topics include fuzzy sets, rough sets, statistical methods, parallel/distributed data mining, hybrid fuzzy optimization, hybrid evolutionary and swarm intelligence methods, big data optimization, IoTs, flexibility, reliability and robustness, smart systems, high-dimensional and big-data analytics, energy optimization, and software engineering. },
  keywords={Special issues and sections;Fuzzy methods;Optimization methods;Renewable energy sources;Mathematical models;Computational modeling;Job shop scheduling;Big Data;Modeling;Simulation;Internet of Things},
  doi={10.1109/TFUZZ.2020.3023572},
  ISSN={1941-0034},
  month={Nov},}@ARTICLE{6188559,
  author={Beichl, Isabel},
  journal={Computing in Science & Engineering}, 
  title={Is My Car Smarter than My Cat?}, 
  year={2012},
  volume={14},
  number={3},
  pages={4-5},
  abstract={Measuring a creature's intelligence is intertwined with our ability to understand the creature's cognition. Will computational science offer more solutions to this puzzle than we think?},
  keywords={computational science;scientific computing;telematics;intelligence;cognition},
  doi={10.1109/MCSE.2012.53},
  ISSN={1558-366X},
  month={May},}@ARTICLE{10466457,
  author={Grassi, Flavia},
  journal={IEEE Electromagnetic Compatibility Magazine}, 
  title={Technical Theme Topics}, 
  year={2023},
  volume={12},
  number={4},
  pages={65-65},
  abstract={I found a book under the Christmas tree with a curious title “The Shortcut”, by Nello Cristianini. The subtitle “Why Intelligent Machines Do Not Think Like Us” unveils that the book is about Artificial Intelligence (AI). What is the shortcut, then? As the author explains, there has been a change of paradigm associated with AI: From the original idea to create machines able to think as we do, to machines able to get trained by data-driven approaches based on statistics, and to make it so effectively as to give us the idea they are really thinking as we do. In a nutshell, machine learning (ML) has been our shortcut towards AI.},
  keywords={},
  doi={10.1109/MEMC.2023.10466457},
  ISSN={2162-2272},
  month={th},}@ARTICLE{10574406,
  author={Zyda, Michael},
  journal={Computer}, 
  title={Can OpenAI’s Sora Generate Pixar’s Toy Story?}, 
  year={2024},
  volume={57},
  number={7},
  pages={136-140},
  abstract={In a previous “Games” column, I raised the question of whether OpenAI’s Sora could generate the complete Pixar animated film Toy Story. We discuss how to think about the computational requirements of such an endeavor.},
  keywords={Games;Open Access;Artificial intelligence;Animation;Performance analysis},
  doi={10.1109/MC.2024.3393249},
  ISSN={1558-0814},
  month={July},}@INPROCEEDINGS{10703452,
  author={Pandey, Ayushi and Saini, Aradhna and Shukla, Amita and Kasana, Hemant and Goel, Rati},
  booktitle={2022 International Conference on Computational Intelligence and Sustainable Engineering Solutions (CISES)}, 
  title={Expression of Concern for: Brain Tumor Detection Using Segmentation with Wavelet Features}, 
  year={2022},
  volume={},
  number={},
  pages={1-1},
  abstract={Attractive reverberation imaging is a clinical thinking system that utilizations radio waves and a solid visual field to make explicit transmissions of tissues and organs. Examining mental development is frequently utilized. Cancer in the cerebrum is a group of cells that replicate and grow strangely. Growth is made up of unwanted cells, which may be found in different parts of the brain, for example, the skull, arteries, glial cells, neurons, lymphatic tissue or metastasize from cancers found in different organs. When in doubt, development can be characterized into two classes, for instance, undermining (cancer-causing) and innocuous (non- destructive). The disruptive proof and ID of cerebrum development is incredible for MRI to imagine, nonetheless, the drawn-out and frightening work performed by clinical experts. This paper introduces systematic brain collection of MRI and recognition using differentiation (k-implies). The recommended strategy covers several stages. The recommended technique comprises a few phases, for example, preprocessing, filtration, and wavelet changes highlight extraction division and grouping. Here, the Median sifting strategy is used to preprocess the given picture for eliminating the commotion and afterward apply DWT to remove the GLCM highlights and grouping division to track down the growth region restriction. At last, the trial result examines the capacity of the proposed calculation concerning exactness.},
  keywords={},
  doi={10.1109/CISES54857.2022.10703452},
  ISSN={},
  month={May},}@INPROCEEDINGS{10702777,
  author={Velliangiri, S. and Karthikeyan, P. and Joseph, Iwin Thanakumar and Kumar, Satish A. P.},
  booktitle={2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)}, 
  title={Expression of Concern for: Investigation of Deep Learning Schemes in Medical Application}, 
  year={2019},
  volume={},
  number={},
  pages={1-1},
  abstract={Deep learning models are equipped for thinking out how to concentrate on the correct features without anyone else's input, requiring a little direction from the software engineer. Essentially, deep learning mirrors how our brain is functioning to take decisions. Deep learning techniques are highly applied in medical imaging diagnosis. Deep learning techniques are used in medical applications in four different areas i. Detections ii. Classifications iii. Segmentations iv. Registrations. In this paper we have discussed deep learn scheme advantage, dataset, software and hardware used in medical applications. Further, we discussed the comparative analysis of medical application using deep learning techniques.},
  keywords={},
  doi={10.1109/ICCIKE47802.2019.10702777},
  ISSN={},
  month={Dec},}@ARTICLE{9399937,
  author={Grier, David Alan},
  journal={Computer}, 
  title={Linking the Elements Together: Will NoSQL Databases Live up to Their Promise?}, 
  year={2021},
  volume={54},
  number={4},
  pages={46-48},
  abstract={The field of computing is not as unified as we like to think. The commercial and academic cohorts can have different goals and pursue different kinds of priorities. Some of Computer’s most influential articles are those that bring these two groups together.},
  keywords={NoSQL databases;Data models;Computational modeling;Relational databases;Structured Query Language;Distributed computing},
  doi={10.1109/MC.2021.3057443},
  ISSN={1558-0814},
  month={April},}@ARTICLE{10254729,
  author={Maleh, Yassine and Tawalbeh, Lo'ai},
  journal={Journal of ICT Standardization}, 
  title={Editorial}, 
  year={2022},
  volume={10},
  number={2},
  pages={1-2},
  abstract={There are many challenges to creating artificial intelligence systems. There are limited resources, insufficient knowledge in the field, feasibility, and many other technical problems on the way to creating AI. Artificial Intelligence currently remains a scientific field related to computer modeling of human intellectual functions. Artificial intelligence systems are generally used to refer to a computer system's ability to perform tasks that are intrinsic to human intelligence, such as logical inference and learning tasks. Any task whose solution algorithm is not known in advance or whose data are incomplete can be classified as an AI task. Systems, programs performing actions to solve a task can be classified as AI if their activity is similar to the result of a human in solving the same task. Therefore, a number of software means can be referred to as AI: text recognition systems, automated design, self-training programs, etc. But not only for this reason, but also because they operate on similar principles to humans. There are two main promising directions in AI research. The first is to bring AI systems closer to the principles of human thinking. The second is to create AI representing the integration of already developed AI systems into a single system capable of solving human problems.},
  keywords={Text recognition;Human intelligence;Computational modeling;Standardization;Learning (artificial intelligence);Software;Inference algorithms},
  doi={},
  ISSN={2246-0853},
  month={},}@ARTICLE{6882973,
  author={Chong, Theresa},
  journal={IEEE Spectrum}, 
  title={How social media teaches skype to speak [News]}, 
  year={2014},
  volume={51},
  number={9},
  pages={15-16},
  abstract={Think you have trouble deciphering social media slang? Try translating it. Microsoft researchers have been studying how to translate social media, and in their efforts they came across a way to teach the company's upcoming Skype Translator how to speak more like us. Some researchers think social media could be key to getting computers to better understand humans. Social media experiments are "important examples of a new line of research in computational social science, showing that subtle social meaning can be automatically extracted from speech and text in a complex natural task," says Dan Jurafsky, an expert in computational linguistics at Stanford, who recently led work on teaching computers about human interactions by listening to speed dating.},
  keywords={},
  doi={10.1109/MSPEC.2014.6882973},
  ISSN={1939-9340},
  month={Sep.},}@ARTICLE{8179980,
  author={Miensopust, Marion P. and Queralt, Pilar and Jones, Alan G.},
  journal={Geophysical Journal International}, 
  title={Magnetotelluric 3-D inversion—a review of two successful workshops on forward and inversion code testing and comparison}, 
  year={2013},
  volume={193},
  number={3},
  pages={1216-1238},
  abstract={Over the last half decade the need for, and importance of, three-dimensional (3-D) modelling of magnetotelluric (MT) data have increased dramatically and various 3-D forward and inversion codes are in use and some have become commonly available. Comparison of forward responses and inversion results is an important step for code testing and validation prior to ‘production’ use. The various codes use different mathematical approximations to the problem (finite differences, finite elements or integral equations), various orientations of the coordinate system, different sign conventions for the time dependence and various inversion strategies. Additionally, the obtained results are dependent on data analysis, selection and correction as well as on the chosen mesh, inversion parameters and regularization adopted, and therefore, a careful and knowledge-based use of the codes is essential. In 2008 and 2011, during two workshops at the Dublin Institute for Advanced Studies over 40 people from academia (scientists and students) and industry from around the world met to discuss 3-D MT inversion. These workshops brought together a mix of code writers as well as code users to assess the current status of 3-D modelling, to compare the results of different codes, and to discuss and think about future improvements and new aims in 3-D modelling. To test the numerical forward solutions, two 3-D models were designed to compare the responses obtained by different codes and/or users. Furthermore, inversion results of these two data sets and two additional data sets obtained from unknown models (secret models) were also compared. In this manuscript the test models and data sets are described (supplementary files are available) and comparisons of the results are shown. Details regarding the used data, forward and inversion parameters as well as computational power are summarized for each case, and the main discussion points of the workshops are reviewed. In general, the responses obtained from the various forward models are comfortingly very similar, and discrepancies are mainly related to the adopted mesh. For the inversions, the results show how the inversion outcome is affected by distortion and the choice of errors, as well as by the completeness of the data set. We hope that these compilations will become useful not only for those that were involved in the workshops, but for the entire MT community and also the broader geoscience community who may be interested in the resolution offered by MT.},
  keywords={Numerical solutions;Inverse theory;Magnetotelluric;Geomagnetic induction},
  doi={10.1093/gji/ggt066},
  ISSN={1365-246X},
  month={June},}@ARTICLE{8453986,
  author={Escalera, Sergio and Baró, Xavier and Guyon, Isabelle and Escalante, Hugo Jair},
  journal={IEEE Transactions on Affective Computing}, 
  title={Guest Editorial: Apparent Personality Analysis}, 
  year={2018},
  volume={9},
  number={3},
  pages={299-302},
  abstract={The papers in this special section focus on personality analysis. Automatic analysis of videos to characterize human behavior has become an active area of research with applications in affective computing, human-machine interfaces, gaming, security, marketing, and health, just to mention a few. Research advances in multimedia information processing, computer vision and pattern recognition have lead to established methodologies that are able to successfully recognize consciously executed actions, or intended movements (e.g., gestures, actions, interactions with objects and other people). However, recently there has been much progress in terms of computational approaches to characterize sub-conscious behaviors, which may be revealing aptitudes or competence, hidden intentions, and personality traits. Much remains to be done still, but it is essential nowadays to have a compilation of cutting edge work in this direction to identify potential opportunities and challenges involved. In this line, we edited a special issue on automatic methods for apparent personality analysis. Personality refers to individual differences in characteristic patterns of thinking, feeling and behaving.},
  keywords={Special issues and sections;Human factors;Behavioral sciences;Computer vision;Emotion recognition;Machine learning;Psychology},
  doi={10.1109/TAFFC.2018.2864230},
  ISSN={1949-3045},
  month={July},}@ARTICLE{1423965,
  author={Smith, S.W.},
  journal={IEEE Security & Privacy}, 
  title={Turing is from Mars, Shannon is from Venus: computer science and computer engineering}, 
  year={2005},
  volume={3},
  number={2},
  pages={66-69},
  abstract={When thinking about systems, it's tempting to only envision computational elements such as machines, operating systems, and programming languages, or human elements such as user interfaces, business practices, and public policy. However, to mangle an analogy from physics, the observer is also part of the system. When reasoning about or designing (or breaking into) secure systems, it's important to remember the tools, mindset, and background we bring to the table. Computer security's primary background fields are computer science and computer engineering (although some might make a case for mathematical logic). These fields sometimes bring very different approaches to the same basic security problems. We take a light-hearted look at these differences.},
  keywords={Mars;Venus;Computer science;Computer interfaces;Operating systems;Computer languages;Humans;User interfaces;Public policy;Physics;computer science;computer engineering;Shannon;Turing},
  doi={10.1109/MSP.2005.54},
  ISSN={1558-4046},
  month={March},}@INPROCEEDINGS{10703479,
  author={Joseph, Ushus Maria and Jacob, Mendus},
  booktitle={2022 International Conference on Computing, Communication, Security and Intelligent Systems (IC3SIS)}, 
  title={Expression of Concern for: Developing a Real time model to Detect SMS Phishing Attacks in Edges using BERT}, 
  year={2022},
  volume={},
  number={},
  pages={1-1},
  abstract={Phishing is the enchanting utilization of automated trades to cheat and exploit clients. Phishing attacks exertion to get intriguing, private information, for instance, usernames, passwords, charge card information, and affiliation confirmations, absolutely. By acting like a real individual or foundation through telephone or email, electronic aggressors utilize social expecting to push occurrences toward performing unequivocal activities like tapping on a perilous collusion or affiliation or wilfully uncovering private data. Nowadays, aggressors use different correspondence mediums to talk with the adversities, for instance, email, message (SMS), telephone, and others. No matter what the quick movement of Internet show based illuminating affiliations, SMS genuinely remains an obvious correspondence relationship in our lives as of in the relatively recent past. For example, a few affiliations consider that messages are more convincing than messages. This is thinking about the way that 82% of SMSs are explored inside 5 min., yet clients simply open one of each four messages they get. The significance of generally suggests irritating or unconstrained messages got by phone clients through Short Messaging Service (SMS). The SMS phishing is another strategy where the phisher works the SMS as a medium to visit with individuals being suggested and this system is seen as smishing (SMS+phishing). In any case, SMS is one of the potential instruments to really chat with others through phones without the web. As Transfer Learning from colossal degree set up models ends up being more inevitable in Natural Language Processing (NLP), working these huge models in on-the-edge as well as under obliged computational arrangement or confirmation monetary plans stays testing. Phones are famous with engineers since they're expe},
  keywords={},
  doi={10.1109/IC3SIS54991.2022.10703479},
  ISSN={},
  month={June},}@INPROCEEDINGS{10703016,
  author={Jain, Mayank and Kaur, Gagandeep and Quamar, Muhammad Parvez and Gupta, Harshit},
  booktitle={2021 International Conference on Innovative Practices in Technology and Management (ICIPTM)}, 
  title={Expression of Concern for: Handwritten Digit Recognition Using CNN}, 
  year={2021},
  volume={},
  number={},
  pages={1-1},
  abstract={The issue of transcribed digit acknowledgment has for some time been an open issue in the field of example order. A few examined have demonstrated that Neural Network has an incredible execution in information arrangement. The fundamental target of this paper is to give effective and solid procedures to acknowledgment of transcribed numerical by looking at different existing arrangement models. This paper thinks about the exhibition of Convolutional Neural Network (CCN). Results demonstrate that CNN classifier beat over Neural Network with critical improved computational effectiveness without relinquishing execution. Handwritten digit recognition can be performed using the Convolutional neural network from Machine Learning. Using the MNIST (Modified National Institute of Standards and Technologies) database and compiling with the CNN gives the basic structure of my project development. So, basically to perform the model we need some libraries such as NumPy, ‘Pandas’, TensorFlow, Keras. These are the main structure on which my main project stands. MNIST data contains about 70,000 images of handwritten digits from 0–9. So, it is a class 10 classification model. This dataset is divided into 2 parts i.e. Training and Test dataset. Image representation as 28*28 matrix where each cell contains grayscale pixel value.},
  keywords={},
  doi={10.1109/ICIPTM52218.2021.10703016},
  ISSN={},
  month={Feb},}@ARTICLE{6129963,
  author={Day, Charless},
  journal={Computing in Science & Engineering}, 
  title={"Supercomputers are awesome and why I love what I DO!!!"}, 
  year={2012},
  volume={14},
  number={1},
  pages={88-88},
  abstract={Supercomputers are not just useful, they're glamorous, too. What's more, their awesome power could be used to encourage children to think about careers in computational science.},
  keywords={scientific computing;supercomputing;education},
  doi={10.1109/MCSE.2012.3},
  ISSN={1558-366X},
  month={Jan},}@INPROCEEDINGS{7356971,
  author={Turbak, Franklyn},
  booktitle={2015 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Taking stock of blocks: Promises and challenges of blocks programming languages}, 
  year={2015},
  volume={},
  number={},
  pages={2-2},
  abstract={Blocks programming environments (e.g., Scratch, Blockly, App Inventor, Snap!, Pencil Code, Alice/Looking Glass, AgentSheets/AgentCubes) represent program syntax trees as compositions of visual blocks. Through activities like Code.org's Hour of Code, these languages have become extremely popular ways to introduce programming and computational thinking to tens of millions of people of all ages and backgrounds, from grade-schoolers to President Obama. Proponents of blocks languages claim that blocks languages lower barriers to programming and enhance learning, while detractors complain that they are not particularly visual and are just toy languages from which it is difficult to transition to “real” text-based programming.},
  keywords={},
  doi={10.1109/VLHCC.2015.7356971},
  ISSN={},
  month={Oct},}@ARTICLE{10035809,
  author={},
  journal={IEEE Transactions on Education}, 
  title={Call for Papers: Special Issue on Coding, Computational, Algorithmic, Design, Creative, and Critical Thinking in K-16 Education}, 
  year={2023},
  volume={66},
  number={1},
  pages={99-103},
  abstract={},
  keywords={},
  doi={10.1109/TE.2023.3235515},
  ISSN={1557-9638},
  month={Feb},}@INPROCEEDINGS{7328048,
  author={Hiura, Shinsaku and Nagahara, Hajime and Iwai, Daisuke and Amano, Toshiyuki},
  booktitle={2015 IEEE International Symposium on Mixed and Augmented Reality}, 
  title={Tutorial 2: Computational Imaging and Projection}, 
  year={2015},
  volume={},
  number={},
  pages={xxxi-xxxi},
  abstract={In this tutorial, we will introduce emerging technologies on computational imaging and light field projection to AR/MR researchers.Light is the most important medium in AR/VR technologies to not only obtain information but also show and modify visual cue in the real scenes. Therefore in this area, latest techniques on optics, imaging and lighting have played an important role to make a next step toward the sophisticated experiences. Computational photography is one of the most influential technology in computer vision and optical engineering areas, and we think most techniques in computational imaging and projection can be applied to common problems in mixed reality, such as scene modeling, modification of the appearances of actual objects and user interactions.},
  keywords={Photography;Cities and towns;Computer vision;Cameras;Virtual reality;Tutorials},
  doi={10.1109/ISMAR.2015.71},
  ISSN={},
  month={Sep.},}@ARTICLE{7419791,
  author={Perrault, Paul and Teachman, Mike},
  journal={IEEE Spectrum}, 
  title={Bee Counters: Measuring a nest's occupation by its capacitance [Resources_Hands On]}, 
  year={2016},
  volume={53},
  number={2},
  pages={20-21},
  abstract={Bees are important: they pollinate dozens of crops, including almonds, cacao, and coffee. While there has been a lot of attention paid to Western honeybees owing to colony collapse disorder, this specific disease and others like it are really measurable only once a colony collapses. And in any case, honeybees are not the only important bee pollinators. What we need is the ability to measure and monitor bee activity as it happens. - Historically, such monitoring was the purview of undergraduates armed with clipboards. More recently, optical sensors have allowed for the automatic detection of bees entering and exiting the hive. But placing optical sensors in a habitat of pollen, mud, and other hive debris drastically degrades their effectiveness. What if there was a better way? - A solution suggested itself when the two of us--a field applications engineer for Analog Devices and an amateur bee enthusiast--were working together on a previous project that involved capacitive sensing. Teachman (the bee enthusiast) commented to Perrault (the applications engineer) that the sensitivity of the AD7746 capacitance-to-digital conversion chip was better than he had expected, and wondered, "Do you think we could measure bees with this?" All else being equal, the capacitance between two electrodes depends on the dielectric constant of the substance between them. Air has a dielectric constant of roughly 1, while water comes in at around 80. As living cells are mostly water, a bee should have a detectable dielectric signature. Intrigued by the idea, we developed a custom sensor setup to measure just that.},
  keywords={},
  doi={10.1109/MSPEC.2016.7419791},
  ISSN={1939-9340},
  month={Feb},}@INPROCEEDINGS{8190430,
  author={},
  booktitle={2017 IEEE Frontiers in Education Conference (FIE)}, 
  title={Technical sessions table of contents}, 
  year={2017},
  volume={},
  number={},
  pages={59-104},
  abstract={The following topics are dealt with: collaborative learning platforms; learning apps; education technologies; game-based teaching; game-based learning; curricula development; IS programs; ECE programs; CS programs; communication skills assessment; educational research; programming teaching; programming learning; student career development; undergraduate engineering; remote laboratories; face-to-face laboratories; design thinking; programming courses; phenomenography; cybersecurity education; gamification; professional skills development; disabled persons; blended learning environments; inverted classroom; kinesthetic experiential learning; Internet of Things; engineering education; STEM education; teaming research; software requirements; digital logic; academia-industry collaboration; MOOC; pattern recognition techniques; educational data analysis; faculty development; engineering student innovation; entrepreneurship; computational thinking; student retention; intercultural competence development; information literacy; mobile learning platforms; robotics; problem based learning; project based learning; Raspberry PI; and Arduino.},
  keywords={},
  doi={10.1109/FIE.2017.8190430},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{6545889,
  author={},
  booktitle={2013 IEEE 21st Symposium on Computer Arithmetic}, 
  title={Special session: Managing computation, precision, accuracy and performance on exascale systems [breaker page]}, 
  year={2013},
  volume={},
  number={},
  pages={37-37},
  abstract={ExaScale-level systems may be available in less than a decade. Computer architects are already thinking of, and planning ways to achieve such levels of performance in the near future. It can be expected that researchers and engineers will carry out scientific and engineering computations more complex than ever before, and will attempt breakthroughs not possible today. If the size of the problems solved on such machines scales accordingly, we may face new issues related to precision, accuracy, performance, and programmability. The purpose of this special session is to allow experts and others interested in ExaScale computing to present their thoughts about opportunities and challenges related to computational problems on ExaScalelevel systems. The session consists of three talks: (1)"Precision, Accuracy, Rounding, and Error Propagation" by Marius Cornea, Intel Corporation, USA; (2) "Managing the Dense Linear Algebra Software Stack" by Robert A. van de Geijn, University of Texas at Austin, USA; and (3) "Numerical Accuracy and Reproducibility at ExaScale" by Hong Diep Nguyen and Jim Demmel, UC Berkeley, USA.},
  keywords={},
  doi={10.1109/ARITH.2013.38},
  ISSN={1063-6889},
  month={April},}@ARTICLE{9761178,
  author={Mancarella, Pierluigi},
  journal={IEEE Power and Energy Magazine}, 
  title={Markets for Flexibility: It Don’t Mean a Thing If It Ain’t Got That Swing [Book Review]}, 
  year={2022},
  volume={20},
  number={3},
  pages={86-87},
  abstract={This book proposes a new wholesale electricity market design paradigm, with a focus on North America, for centrally managed electricity markets that are based on the novel concept of swing contracts. The author, a professor at Iowa State University, has been working on electricity market design and agent-based computational economics for many years. Her extensive academic, research, and industry experiences, as well as her training in both economics and mathematics, make her highly qualified to provide fresh thinking in this important area. The book proposes the adoption of swing contracts between the system operator and relevant resources to provide flexibility. This flexibility is represented in the form of future availability of dispatchable power paths (“reserve”) with prespecified physical attributes and economic attributes (for pricing purposes). The book contains rigorous mathematical descriptions of the proposed mechanism and implementations.},
  keywords={Book reviews;Power markets;Electricity supply industry;Costs;Investment;Power system;Contracts;Pricing},
  doi={10.1109/MPE.2022.3150811},
  ISSN={1558-4216},
  month={May},}@INPROCEEDINGS{4530438,
  author={Ohsawa, Yukio},
  booktitle={2008 Second Asia International Conference on Modelling & Simulation (AMS)}, 
  title={Chance Discovery and Chance Creation: A Data-Visualization Approach to Value Sensitive Innovation}, 
  year={2008},
  volume={},
  number={},
  pages={xx-xxi},
  abstract={Summary form only given. A scenario is a meaningful sequence of events. For the decision of human, it is essential to create valuable scenarios of the future and choose one to realize. This talk is composed of two topics: (1) computational methods for visualizing a scenario map: a figure visualizing the relations between events, on which humans can think about scenarios. The obtained scenarios can be regarded as patterns of event occurrences in the past or beneficial plans to be executed in the future. (2) Human's competencies for sensing a (or a sequence of) valuable event, and new criteria for evaluating the value of forthcoming events. We have been studying this talent from the viewpoint of cognitive science and business management.},
  keywords={Technological innovation;Humans;Game theory;Decision making;Visualization;Risk management;Companies;Annealing;Abstracts;Cognitive science},
  doi={10.1109/AMS.2008.188},
  ISSN={2376-1172},
  month={May},}
