@INPROCEEDINGS{7457534,
  author={Cooke, Laquana},
  booktitle={2016 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Metatuning: A pedagogical framework for a generative STEM education in game design-based learning}, 
  year={2016},
  volume={},
  number={},
  pages={207-214},
  abstract={While K-12 STEM Education test scores have been steadily improving over the past decade in the United States, achievement gaps still remain among minorities and women in STEM courses and careers. There are numerous factors that contribute to these disparities, such as poverty, low status and other sociocultural factors in classrooms that impede learning. Difficulties in STEM Education engagement and encumbered participation are often due to decontextualized learning - incongruence between meaningful contexts and learning processes. Game based learning methods are common STEM Ed models that provide youth with extrinsically motivating knowledge frameworks for learning, however, research has proven that even these procedural spaces often are disconnected from students' social and cultural realities. Amidst the STEM Ed achievement gaps problematic are similar disparities found in popular video game spaces, where there is a less than 20% chance that these same disparity groups will navigate computational worlds with protagonists that look like them. These gamers/students are lacking the “under-the-hood” (STEM) knowledge of the very games they engage with on a daily basis. This contradiction is central to this paper and the conceptualization of Metatuning - a game design pedagogical framework that aims to empower students to discover their identities as agents of change, and to see that game design can nurture their internal motivations. In this case study, Metatuning was used to foster an intrinsically motivated learning environment, where a young designer was able to iteratively design a social justice themed game that empowered her as a designer and an aspiring doctor.},
  keywords={Games;Education;Engineering profession;Cultural differences;Context;Navigation;Industries;Game based learning (GBL);game design;STEM Education;social justice},
  doi={10.1109/ISECon.2016.7457534},
  ISSN={},
  month={March},}@ARTICLE{9903579,
  author={Bako, Hannah K. and Liu, Xinyi and Battle, Leilani and Liu, Zhicheng},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Understanding how Designers Find and Use Data Visualization Examples}, 
  year={2023},
  volume={29},
  number={1},
  pages={1048-1058},
  abstract={Examples are useful for inspiring ideas and facilitating implementation in visualization design. However, there is little understanding of how visualization designers use examples, and how computational tools may support such activities. In this paper, we contribute an exploratory study of current practices in incorporating visualization examples. We conducted semi-structured interviews with 15 university students and 15 professional designers. Our analysis focus on two core design activities: searching for examples and utilizing examples. We characterize observed strategies and tools for performing these activities, as well as major challenges that hinder designers' current workflows. In addition, we identify themes that cut across these two activities: criteria for determining example usefulness, curation practices, and design fixation. Given our findings, we discuss the implications for visualization design and authoring tools and highlight critical areas for future research.},
  keywords={Data visualization;Interviews;Creativity;Visualization;Task analysis;Search problems;Faces;Examples;visualization design;idea generation;interview study;qualitative research},
  doi={10.1109/TVCG.2022.3209490},
  ISSN={1941-0506},
  month={Jan},}@INPROCEEDINGS{7806341,
  author={Alksher, Mostafa A. and Azman, Azreen and Yaakob, Razali and Kadir, Rabiah Abdul and Mohamed, Abdulmajid and Alshari, Eissa M.},
  booktitle={2016 Third International Conference on Information Retrieval and Knowledge Management (CAMP)}, 
  title={A review of methods for mining idea from text}, 
  year={2016},
  volume={},
  number={},
  pages={88-93},
  abstract={Idea mining is a new and interesting field in the areas of information retrieval research. The thoughts of people are helpful to improve strategic decision making. This paper demonstrates the efficient computational methods of idea characterization based concept by extracting the interesting hidden data from unstructured texts which come in many forms and sizes. It may be stored in patents, publications, reports, documents, Internet etc. We briefly discussed a number of successful text mining tools and text classification to extract the idea with a combination of idea mining measures.},
  keywords={Information retrieval;Text mining;Filtering;Knowledge management;Standards;Internet;Text mining;Idea mining;Information retrieval;Text classification},
  doi={10.1109/INFRKM.2016.7806341},
  ISSN={},
  month={Aug},}@ARTICLE{9690020,
  author={Kovalkov, Anastasia and Paaßen, Benjamin and Segal, Avi and Pinkwart, Niels and Gal, Kobi},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Automatic Creativity Measurement in Scratch Programs Across Modalities}, 
  year={2021},
  volume={14},
  number={6},
  pages={740-753},
  abstract={Promoting creativity is considered an important goal of education, but creativity is notoriously hard to measure. In this article, we make the journey from defining a formal measure of creativity, that is, efficiently computable to applying the measure in a practical domain. The measure is general and relies on core theoretical concepts in creativity theory, namely fluency, flexibility, and originality, integrating with prior cognitive science literature. We adapted the general measure for projects in the popular visual programming language Scratch. We designed a machine learning model for predicting the creativity of Scratch projects, trained and evaluated on human expert creativity assessments in an extensive user study. Our results show that opinions about creativity in Scratch varied widely across experts. The automatic creativity assessment aligned with the assessment of the human experts more than the experts agreed with each other. This is a first step in providing computational models for measuring creativity that can be applied to educational technologies, and to scale up the benefit of creativity education in schools.},
  keywords={Creativity;Semantics;Task analysis;Shape;Codes;Particle measurements;Atmospheric measurements;Automatic assessment tools;computer science education;creativity;distances;scratch},
  doi={10.1109/TLT.2022.3144442},
  ISSN={1939-1382},
  month={Dec},}@INPROCEEDINGS{4669780,
  author={Cai, Yi and Leung, Ho-fung},
  booktitle={2008 20th IEEE International Conference on Tools with Artificial Intelligence}, 
  title={Formalizing Object Typicality in Context-Aware Ontology}, 
  year={2008},
  volume={2},
  number={},
  pages={233-240},
  abstract={According to the studies of cognitive psychology, object typicality plays an important role in concept representation in human cognitive process. However, computational ontologies cannot reflect the typicality of objects in concepts. Besides, context is important in measuring object typicality. In this paper, we present a formal model of context-aware ontology with multi-prototype concept and object typicality based on studies of cognitive psychology. It can tackle the problem of formalizing object typicality in context-aware ontology, which is unsolved in previous models.},
  keywords={Ontologies;Psychology;Context modeling;Prototypes;Computer science;Humans;Knowledge representation;Particle measurements;Frequency estimation;Bicycles;Object Typicality;Ontology;Context},
  doi={10.1109/ICTAI.2008.81},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9454039,
  author={Misthou, Stavroula and Moumoutzis, Nektarios and Loukatos, Dimitrios},
  booktitle={2021 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Coding Club: a K-12 good practice for a STEM learning community}, 
  year={2021},
  volume={},
  number={},
  pages={955-963},
  abstract={STEM learning communities provide a structure for social interactions among students, their peers and STEM professionals that benefit students to acquire computational literacy and persistence in science disciplines. Focusing on STEM skills development at secondary education level, a female Computer Science teacher at the 7th public Junior High school of Athens Greece, founded the voluntary Coding Club “GreekCodersK12”. This K-12 education initiative ran for 4 years (2015-2019), formed a learning community based on creativity, innovation and digital skills enhancement and collaborated with researchers, professionals, scientists who contributed voluntarily in the Club’s projects. This paper presents the experiences gained and the lessons learned during this four-year period and throws light on the role of a potential Coding Club founder. The results of this learning path, indicate that a Coding Club is an inclusive after-school programme that can function as an umbrella for innovative activities like programming, educational robotics, STEM, STEAM and ESTEAM (Entrepreneurship – Science – Technology – Engineering – Art – Mathematics).},
  keywords={Training;Technological innovation;Transforms;Encoding;Libraries;Sustainable development;Robots;Good practice;Coding Club;STEM learning community;K-12 education initiative},
  doi={10.1109/EDUCON46332.2021.9454039},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{6567198,
  author={Fischer, Gerhard},
  booktitle={2013 International Conference on Collaboration Technologies and Systems (CTS)}, 
  title={From renaissance scholars to renaissance communities: Learning and education in the 21st century}, 
  year={2013},
  volume={},
  number={},
  pages={13-21},
  abstract={The understanding, framing, and support of learning, working, communicating, and collaborating is media-dependent: tools, materials, and social arrangements have always been involved in defining and conceptualizing these activities. Historically the emphasis has been to educate and support individual “Renaissance scholars”. In today's world, most of the significant problems are systemic problems that transcend not only the individual human mind but cannot be addressed by any one specialty discipline. To cope with these problems requires not only “Renaissance Scholars” but “Renaissance Communities” in which stakeholders coming from different disciplines can collaborate. Our research at the Center for Lifelong Learning & Design (L3D) over the past two decades has been focused on creating a new understanding of learning, new media, and new learning organizations. Our co-evolutionary perspective explores the dialectical relationship between: (1) how a deep understanding of learning creates innovative demands and design criteria for future generations of social-technical environments; (2) how the unique potential of computational media impacts and transforms learning by transcending "giftwrapping" and “technology-centered” approaches; and (3) how new learning organizations contribute to reconceptualizing and reinventing learning and education in the 21st century. The conceptual framework is illustrated by specific developments of social-technical environments that we have designed and evaluated including: collaborative, domain-oriented design environments, environments created by mass collaboration, and courses-as-seeds.},
  keywords={Communities;Collaboration;Organizations;Educational institutions;Media;Context;Renaissance Communities;meta-design;cultures of participation;social creativity;communities of interest},
  doi={10.1109/CTS.2013.6567198},
  ISSN={},
  month={May},}@INPROCEEDINGS{9620635,
  author={Lin, Kevin},
  booktitle={2021 Conference on Research in Equitable and Sustained Participation in Engineering, Computing, and Technology (RESPECT)}, 
  title={Do Abstractions Have Politics? Toward a More Critical Algorithm Analysis}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={The expansion of computer science (CS) education in K-12 and higher-education in the United States has prompted deeper engagement with equity that moves beyond inclusion toward a more critical CS education. Rather than frame computing as a value-neutral tool, a justice-centered approach to equitable CS education draws on critical pedagogy to ensure the rightful presence of political struggles by emphasizing the development of not only knowledge and skills but also CS disciplinary identities. While recent efforts have integrated ethics into several areas of the undergraduate CS curriculum, critical approaches for teaching data structures and algorithms in particular are undertheorized. Basic Data Structures remains focused on runtime-centered algorithm analysis. We argue for affordance analysis, a more critical algorithm analysis based on an affordance account of value embedding. Drawing on critical methods from science and technology studies, philosophy of technology, and human-computer interaction, affordance analysis examines how the design of computational abstractions such as data structures and algorithms embody affordances, which in turn embody values with political consequences. We illustrate 5 case studies of how affordance analysis refutes social determination of technology, foregrounds the limitations of data abstractions, and implicates the design of algorithms in disproportionately distributing benefits and harms to particular social identities within the matrix of domination.},
  keywords={Human computer interaction;Computer science;Ethics;Philosophical considerations;Affordances;Education;Tools;abstractions;affordances;algorithms;critical pedagogy;computing education;data structures;design justice;ethics;political identity;rightful presence},
  doi={10.1109/RESPECT51740.2021.9620635},
  ISSN={},
  month={May},}@INPROCEEDINGS{5429174,
  author={Jordan, Jeremy D. and Melouk, Sharif H. and Faas, Paul D.},
  booktitle={Proceedings of the 2009 Winter Simulation Conference (WSC)}, 
  title={Analyzing production modifications of a C-130 engine repair facility using simulation}, 
  year={2009},
  volume={},
  number={},
  pages={1770-1777},
  abstract={The LRAFB C-130 engine repair facility is one of the top T-56 engine refurbishing plants in the United States Air Force. Currently, the shop is prevented from testing potential contingencies within their environment due to the rapid nature of their engine repair process. A simulation approach is needed to test various scenarios and determine the maximum capacity the shop can handle in its current configuration. Particularly, the simulation describes the consequences of increasing engine production on the shops personnel and throughput production figures for several policy variations. A detailed verification and validation of the model are shown, establishing the computational efficacy of the model in preparation for the comparative analysis. The model is a starting block for an Air Force wide analysis of C-130 engine rebuilding production needs with an overarching goal of standardization in repair methods and efficient operations.},
  keywords={Engines;Analytical models;Lean production;Testing;Discrete event simulation;Laboratories;FAA;Operations research;Management information systems;Statistics},
  doi={10.1109/WSC.2009.5429174},
  ISSN={1558-4305},
  month={Dec},}@ARTICLE{8618305,
  author={Khabiri, E. and Li, Y. and Mazzoleni, P. and Vadgama, D.},
  journal={IBM Journal of Research and Development}, 
  title={Cognitive color palette creation using client message and color psychology}, 
  year={2019},
  volume={63},
  number={1},
  pages={4:1-4:10},
  abstract={Color psychology is the study of the effect of colors on human behavior. This area of study is interesting and challenging because there is no simple “one-size-fits all” mapping between a color and the message that color can evoke in a particular person. Nevertheless, many of our daily decisions are influenced by the color palettes being presented to us. In this paper, we propose a novel computational algorithm to create color palettes that convey certain messages. It starts by constructing a weighted graph of color categories and messages that are based on semantic similarities between vector representation of the messages and delta-E color similarities between colors. The color selection process for a given message includes applying a Personalized PageRank algorithm on the graph, treating the message nodes as the personalizing factors. As a result, we have a distribution of probabilities over all the color nodes that have higher probabilities for the nodes neighboring to given messages. Finally, palettes are ranked on the basis of visual aesthetics, novelty, and the conflicting/reinforcing messages they evoke. We have applied this work to several interesting use cases where artists and fashion designers used the resulting color palettes to assist their creation process.},
  keywords={Image color analysis;Color;Packaging;Psychology;Companies;Computer architecture;Visualization},
  doi={10.1147/JRD.2019.2893904},
  ISSN={0018-8646},
  month={Jan},}@INPROCEEDINGS{7925895,
  author={Zhang, Zeqi and Jiang, Chunxiao and Guo, Song and Ni, Zuyao and Ren, Yong},
  booktitle={2017 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Optimal Satellite Scheduling with Critical Node Analysis}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={Earth satellite networks are playing an increasingly important role in observation, surveillance and reconnaissance of specific targets or areas with dramatic growing of the demand for such services. The harsh and vulnerable space environment makes satellite nodes susceptible to a variety of attacks and prompts us to protect satellite networks by securing them with efficient defending strategy. In this paper, we propose a satellite scheduling problem in a vulnerable space environment. A set of complex operational constraints is imposed to make the best defending strategy between task requests and satellites under protection. To reduce the complexity, we decompose the original problem into two subproblems of satellite scheduling and satellite protection. A joint optimization algorithm is adopted to find near optimal solution. The results of extensive computational experiments show its effective and superior scheduling performance.},
  keywords={Satellites;Satellite broadcasting;Resource management;Biological system modeling;Space vehicles;Optimization;Investment},
  doi={10.1109/WCNC.2017.7925895},
  ISSN={1558-2612},
  month={March},}@INPROCEEDINGS{7910246,
  author={Im, Tacksoo and Siva, Sebastien and Freeman, Jason and Magerko, Brian and Hendler, Greg and Engelman, Shelly and Miller, Morgan and Villa, Brandi and McKlin, Tom},
  booktitle={2017 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Incorporating music into an introductory college level programming course for non-majors}, 
  year={2017},
  volume={},
  number={},
  pages={43-48},
  abstract={STEAM-based courses are increasingly becoming popular in introductory programming courses but not many of these efforts focus on non-major undergraduate students and less is known about its effectiveness with career-bound students at the collegiate level. This paper describes our results and the lessons learned in teaching and implementing an EarSketch based introductory programming course for non-majors. EarSketch is a computational music learning platform that has been used successfully at the high-school level to introduce students to programming. We have adapted the EarSketch curriculum to satisfy the requirements of an undergraduate level introductory programming course. We have deployed the curriculum at Georgia Gwinnett College starting in Spring 2016 with the goal of observing improvements in content knowledge and attitudes towards computing. We have observed statistically significant improvements in the sections using EarSketch. Although more data is required to confirm our results, we argue that the EarSketch based curriculum engages students positively in the field of computing.},
  keywords={Programming profession;Music;Complexity theory;Conferences;Education;Context;broadening participation;CS education;computing principles;music composition;music production;non-majors},
  doi={10.1109/ISECon.2017.7910246},
  ISSN={},
  month={March},}@INPROCEEDINGS{6701743,
  author={Koria, Ritin and Bartels, Francis. L. and Koeszegi, Sabine},
  booktitle={2013 IST-Africa Conference & Exhibition}, 
  title={Surveying national systems of innovation (NSI) using Free Open Source Software (foss): The case of Ghana}, 
  year={2013},
  volume={},
  number={},
  pages={1-12},
  abstract={In today's global knowledge-based economy, knowledge, its creation, accumulation and distribution, through institutions of human, organizational and social capital, plays an increasingly crucial role as the key factor in innovation and economic development. The production, distribution and processing of knowledge (especially scientific and technological) is increasingly performed within the domain of computational information and communication technologies (ICTs). Even though there is an asymmetric distribution of ICT resources, particularly between developed and developing countries the emergence of Free Open Source Software (FOSS) is a means to bridge the `digital divide'. This paper examines the use of FOSS for mapping and measuring the National System of Innovation (NSI) in Ghana and generating evidence based policy. Findings indicate the value of FOSS in mapping and measuring for evidence based policy and the crucial role of ICT in the NSI.},
  keywords={Technological innovation;Data collection;Economics;Government;Production;Educational institutions;Digital divide;Free Open Source Software (FOSS);Knowledge transfer;Knowledge accumulation;National Systems of Innovation (NSI);Ghana;Developing Countries},
  doi={},
  ISSN={},
  month={May},}@INPROCEEDINGS{5420609,
  author={Tuan, Tran Minh and Soueres, Philippe and Taix, Michel and Girard, Benoît},
  booktitle={2009 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, 
  title={Eye-centered vs body-centered reaching control: A robotics insight into the neuroscience debate}, 
  year={2009},
  volume={},
  number={},
  pages={568-573},
  abstract={Whether the central nervous system of primates uses a body-centered or an eye-centered frame for reaching is still a controversial debate in neurosciences. Does the proprioceptive information allow to represent the visual information with respect to the body or inversely, does it transform the hand position in retinal coordinates? In this paper, we implement and test two control schemes associated to each of these two hypotheses by using a computational approach from robotics. To this end, biological models of motor control are applied to a realistic dynamic model of upper body including a 4 DOF eye-neck kinematic chain and a 6DOF arm. Important characteristics, such as proprioceptive biases and sensory delay, are considered. Simulation results allow to compare the geometry of trajectories and illustrate the better robustness of the eye-centered control scheme with respect to biases and sensory delay. Applications to the control of the humanoid robot HRP2 are finally presented.},
  keywords={Robot control;Neuroscience;Biological system modeling;Robot kinematics;Delay;Central nervous system;Retina;Testing;Biology computing;Robot sensing systems},
  doi={10.1109/ROBIO.2009.5420609},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6400843,
  author={Srivastava, Rupesh Kumar and Steunebrink, Bas R. and Stollenga, Marijn and Schmidhuber, Jürgen},
  booktitle={2012 IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL)}, 
  title={Continually adding self-invented problems to the repertoire: First experiments with POWERPLAY}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  abstract={Pure scientists do not only invent new methods to solve given problems. They also invent new problems. The recent POWERPLAY framework formalizes this type of curiosity and creativity in a new, general, yet practical way. To acquire problem solving prowess through playing, POWERPLAY-based artificial explorers by design continually come up with the fastest to find, initially novel, but eventually solvable problems. They also continually simplify or speed up solutions to previous problems. We report on results of first experiments with POWERPLAY. A self-delimiting recurrent neural network (SLIM RNN) is used as a general computational architecture to implement the system's solver. Its weights can encode arbitrary, self-delimiting, halting or non-halting programs affecting both environment (through effectors) and internal states encoding abstractions of event sequences. In open-ended fashion, our POWERPLAY-driven RNNs learn to become increasingly general problem solvers, continually adding new problem solving procedures to the growing repertoire, exhibiting interesting developmental stages.},
  keywords={Neurons;Artificial neural networks;Recurrent neural networks;Encoding;Training;Computer architecture;Computers},
  doi={10.1109/DevLrn.2012.6400843},
  ISSN={2161-9476},
  month={Nov},}@ARTICLE{10287634,
  author={Dhumras, Himanshu and Shukla, Prashant Kumar and Bajaj, Rakesh K. and Boulila, Wadii and Shukla, Varun and Shukla, Piyush Kumar and Minchula, Vinodh Kumar and Chauhdary, Sajjad Hussain},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Industry 5.0 Enablers in Consumer Electronics Market Assessment Under T-Spherical Fuzzy Integrated Decision-Making Approach}, 
  year={2024},
  volume={70},
  number={1},
  pages={1443-1451},
  abstract={The prime focus on the deliberations related to Industry 5.0 lies in creativity, efficiency and resilience for adapting various organic components such as accurate decisions, customized demands in consumer electronics with promising/sustainable solutions. This transformation and paradigm shift inside the Industry 5.0 frame can be comprehensively understood by integrating the factors related to human values with the cutting-edge technologies of consumer electronics for compatibility with the issue of sustainable development. The present work proposes an integrated approach for extensive study with a set of criteria and possible Industry 5.0 enablers in consumer electronics using a novel decision-making approach. The approach comprises of  $T$ -spherical fuzzy information containment/processing through an analytic hierarchy process (AHP) and then utilizing the weighted aggregated sum product assessment (WASPAS) sequentially to obtain the necessary weights of selected criteria. Further, the obtained weights from AHP would be used in WASPAS for the computational assessment while finding the prioritization/ranking of industry 5.0 enablers. The results with the sensitivity analysis validate the robustness-cum-resilience of the proposed integrated approach with standard managerial implications and the findings take care of cognitive in the human socio-technical environment. The regulated adoption of Industry 5.0 enablers would help consumer electronics manufacturers in finding optimized solutions.},
  keywords={Industries;Consumer electronics;Fuzzy sets;Analytic hierarchy process;Sustainable development;Fourth Industrial Revolution;Business;T-spherical fuzzy information;Industry 5.0;enablers in consumer electronics;analytical hierarchy process;multi-criteria decision-making},
  doi={10.1109/TCE.2023.3325433},
  ISSN={1558-4127},
  month={Feb},}@INPROCEEDINGS{5716144,
  author={Iqbal, Azlan},
  booktitle={2010 International Conference on Intelligent and Advanced Systems}, 
  title={The relevance of universal metrics in relation to human aesthetic perception}, 
  year={2010},
  volume={},
  number={},
  pages={1-6},
  abstract={A computational aesthetics model developed for the game of international chess showed a good and positive correlation with human player aesthetic assessment. The unique approach taken here suggests that, in addition to things like personal taste and environmental factors, humans also likely assess beauty based on `universal metrics' within the domain itself. From the standpoint of artificial intelligence (AI), this means that weights for aesthetic features need not, for example, be determined by analyzing a particular data set of aesthetically-rated objects, or through consultation with human experts. Instead, certain metrics can be used as `building blocks' to formalize aesthetic principles or features in a logical and dynamic way. This is arguably an improvement over existing methods. The aesthetics model developed is explained and relevant experimental results are presented. The importance of universal metrics in the aesthetics of chess and other domains is also explored.},
  keywords={Games;Humans;Measurement;Computers;Materials;Correlation;Artificial intelligence;artificial intelligence;aesthetics;perception;metrics;chess;art},
  doi={10.1109/ICIAS.2010.5716144},
  ISSN={},
  month={June},}@INPROCEEDINGS{9962403,
  author={Lu, Justin and Seavey, Lauren and Zuk, Samuel and Dimino, James and Martin, Fred},
  booktitle={2022 IEEE Frontiers in Education Conference (FIE)}, 
  title={Evaluating Student Spatial Skills Learning in a Virtual Reality Programming Environment}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  abstract={In this research full paper, we examine students’ improvement in spatial visualization skills when using MYR (short for "My Reality"), a browser-based, cloud-hosted programming environment for beginning through advanced programmers to create immersive, three-dimensional virtual reality scenes.The research literature suggests that there is correlation between students’ spatial abilities and their success in programming. In this study, we conducted a three-week (six hour) virtual after-school program which introduced high school students with different programming backgrounds to coding in MYR. During the program, students learned the basics of MYR, introductory CS topics, and completed individual coding projects, creating an original MYR scene.A study examined changes in students’ spatial reasoning as a result of this intervention. The students’ performance in spatial skills was measured using the Revised Purdue Spatial Visualization Test: Visualization of Rotations (Revised PSVT:R) [1]. Students completed this instrument using a pre/post survey design. We analyzed the impact of the intervention using a paired samples T-test. We further developed a rubric for analyzing the sophistication of students’ MYR code and applied it to evaluating the programming expertise of our study participants.The program was hosted twice with two different groups of high school students. Most showed interest in MYR programming and expressed their creativity and learned skills in their original project. With the first group of students, we found increases in their spatial visualization performance after the intervention with MYR, though statistical significance was not reached. The second group of students had higher baseline prior experience in computing and spatial visualization skills; these students did not further increase in their spatial visualization skill.The analysis showed that the MYR has a potential to improve spatial skills and engage students’ interest in computing. We recommend that MYR and related computational environments be further studied and made available to students.},
  keywords={Visualization;Correlation;Instruments;Virtual reality;Encoding;Cognition;Programming profession;Computer science education;Spatial skills;Virtual reality},
  doi={10.1109/FIE56618.2022.9962403},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10489623,
  author={Bhardwaj, Diwakar and Bordoloi, Dibyhash and Deepak, A. and Srivastava, Arun Pratap and Mayuri, K and Khan, Akhilesh Kumar},
  booktitle={2023 International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)}, 
  title={Real-Time Ecg Analysis with Recurrent Neural Networks in Cloud-Based Healthcare}, 
  year={2023},
  volume={1},
  number={},
  pages={1-6},
  abstract={In order to analyze Electrocardiograms (ECGs) in real time, this research is the first to integrate Recurrent Neural Networks (RNNs) into a cloud-based healthcare system. By utilizing sophisticated computational algorithms and an interpretivist perspective, the research seeks to transform cardiac diagnosis. Though extremely useful, traditional ECG analysis techniques have processing speed as well as scalability issues. The suggested method instantaneously interprets ECG waveforms by utilizing RNNs' temporal modeling capabilities. This paradigm change makes it possible to identify cardiac problems in a timely manner, potentially improving patient outcomes. Setting up a scalable cloud system for effective data processing is part of the study methodology. The RNN model is trained, verified, and then incorporated into the cloud system using secondary ECG data. The system's efficacy is confirmed by performance evaluation criteria like processing speed, sensitivity, and accuracy. Scalability, safety of data, and interpretability issues in models are highlighted via critical analysis. Techniques for improved model openness, strict data protection policies, and thorough scalability testing are all included in the recommendations.},
  keywords={Technological innovation;Recurrent neural networks;Sensitivity;Scalability;Medical services;Transforms;Electrocardiography;data analysis;physiological;remote monitoring;Recurrent Neural Networks;performance},
  doi={10.1109/ICAIIHI57871.2023.10489623},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10575471,
  author={Harshjeet and Gogoi, Chandan and Snehalatha, N. and Amudha, S.},
  booktitle={2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={Enhancing Visual Creativity with Neural Style Transfer using Celery Backend Architecture}, 
  year={2024},
  volume={},
  number={},
  pages={966-974},
  abstract={Neural Style Transfer (NST) is an influential technique in the field of deep learning that combines the content of one image with the style of another, resulting in visually impressive compositions. By utilizing Convolutional Neural Networks (CNNs) such as VGG19, a well-known pretrained model that excels at extracting advanced characteristics from images, NST algorithms may efficiently isolate and merge content and style representations. This project aims to create a user-friendly Neural Style Transfer (NST) application. The frontend of the program will be constructed using React, enabling users to easily upload their content and style images. Next, the user can initiate the process of neural style transfer by clicking on the style transfer button. The computational process of style transfer is managed by a backend system that utilizes Celery, a distributed task queue, and Redis, an in-memory data structure store. This architectural design allows for effective asynchronous execution of style transfer activities, assuring the ability to handle large workloads while maintaining scalability and responsiveness. Our NST application combines advanced deep learning algorithms with modern web development technology to make artistic creativity accessible to everyone. Users may effortlessly produce compelling visual compositions with just a few clicks. Our website provides a smooth and entertaining experience for both beginners and expert users, whether they want to turn regular photos into works of art resembling famous styles or explore innovative combinations. The proposed NST application combines state-of-the-art algorithms with a user-friendly interface, making powerful AI-driven creativity accessible to everyone.},
  keywords={Deep learning;Visualization;Art;Scalability;Data structures;Convolutional neural networks;Task analysis;Neural Style Transfer;CNN;VGG19;Celery;Redis;Web Application;Python;Flask},
  doi={10.1109/ICAAIC60222.2024.10575471},
  ISSN={},
  month={June},}@ARTICLE{10415237,
  author={Vallarino, Mario and Iacono, Saverio and Bellanti, Edoardo and Vercelli, Gianni V.},
  journal={IEEE Transactions on Learning Technologies}, 
  title={A Flipped Remote Lab: Using a Peer-Assessment Tool for Learning 3-D Modeling}, 
  year={2024},
  volume={17},
  number={},
  pages={1140-1154},
  abstract={This article introduces a novel approach to remote laboratory instruction, specifically designed for teaching three-dimensional modeling using Blender software. The lab uses virtual machines to provide students with the necessary computational power to carry out the course activities, along with the correct version of the software. The flipped remote lab approach combines the elements of flipped classroom and peer assessment, making it suitable for face-to-face, totally online, or hybrid classes. Prior to each of the two lectures, students begin to practice by replicating the instructor's demonstrations in a set of concise tutorials. Upon completion of the assigned tasks, students carry out self-assessments of their own modeling, in addition to assessing two models created by their peers. A rubric comprising three questions facilitates the assessment process and allows providing feedback on each response. During the subsequent lecture, students work together with the instructor to address challenges encountered in their modeling, exploring also the advanced aspects of software usage that time constraints preclude in a traditional setting. The analysis of the flipped remote lab results reveals that student responses in peer-assessment activities are relevant to the posed questions. Moreover, the students who realized the models demonstrated a comparable level of rigor in self-assessment as their mates who reviewed their works. While students express a high degree of appreciation for the laboratory activities, a notable concern is the highlighted heavy workload. Increasing the allocated time for task completion can help mitigate the workload impact. The article concludes with insights gained from the implementation of the flipped remote lab approach.},
  keywords={Three-dimensional displays;Laboratories;Solid modeling;Software;Education;Virtual machining;Task analysis;Blender software;flipped classroom;peer assessment;remote lab;three-dimensional (3-D) modeling;virtual machines},
  doi={10.1109/TLT.2024.3358800},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10617440,
  author={Bhise, Ramkishan Baburao and Puyed, Ranjeet and Rane, Smita Kiran and Bhise, Swati Ramkishan},
  booktitle={2024 4th International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={Reexamining Disposition in AI Models Impact in Building Fiction based Characters}, 
  year={2024},
  volume={},
  number={},
  pages={1327-1332},
  abstract={As artificial intelligence (AI) continues to revolutionize various facets of human existence, its influence in creative domains, particularly literature, has increasingly come to be pronounced. The following paper will handle the ways that character development is changing in modern fiction. It investigates the ways in which AI technologies are outlining the way the creation, representation, and perception of characters in fiction are being developed. That means AI is advancing in character creation in ways that open up a whole new set of doors for writers: the use of powerful tools to generate, field, analyze, and refine their characters in ways previously unthinkable. Using the algorithms of natural language processing (NLP), these days, AI is used to help write dialogue, create characters with their traits, and sometimes even develop the entire character’s arc. This union of human creativity and computational powers doesn’t just make the process of writing faster but, rather, opens doors for new possibilities in innovative storytelling. AI-driven analytics help authors to pick up the insight into reader preferences and trends that tend to help them develop character traits and the storyline, most appealing to the readers. The application of machine-learning algorithms to vast repositories of literature seems to derive character dynamics and tropes that are so archetyped, but their renderings are much more nuanced and impactful. At the same time, this AI character raises very basic questions about authorship, creativity, and the nature of the story. As more and more writers adopt AI for character generation, they do raise some question about authenticity and originality.},
  keywords={Ethics;Sensitivity;Heuristic algorithms;Machine learning;Writing;Rendering (computer graphics);Market research;Artificial Intelligence;Characterization;Modern Fiction;Technology;Creativity;Narrative;AI-Generated Characters;Ethical Considerations;Storytelling;Literature},
  doi={10.1109/ICACITE60783.2024.10617440},
  ISSN={},
  month={May},}@ARTICLE{10227838,
  author={Nowak, Stan and Aseniero, Bon Adriel and Bartram, Lyn and Grossman, Tovi and Fitzmaurice, George and Matejka, Justin},
  journal={IEEE Computer Graphics and Applications}, 
  title={Identifying Visualization Opportunities to Help Architects Manage the Complexity of Building Codes}, 
  year={2023},
  volume={43},
  number={6},
  pages={75-86},
  abstract={We report a study investigating the viability of using interactive visualizations to aid architectural design with building codes. While visualizations have been used to support general architectural design exploration, existing computational solutions treat building codes as separate from, rather than part of, the design process, creating challenges for architects. Through a series of participatory design studies with professional architects, we found that interactive visualizations have promising potential to aid design exploration and sensemaking in early stages of architectural design by providing feedback about potential allowances and consequences of design decisions. However, implementing a visualization system necessitates addressing the complexity and ambiguity inherent in building codes. To tackle these challenges, we propose various user-driven knowledge management mechanisms for integrating, negotiating, interpreting, and documenting building code rules.},
  keywords={Codes;Buildings;Visualization;Interviews;Surveys;Automation;Data visualization},
  doi={10.1109/MCG.2023.3307971},
  ISSN={1558-1756},
  month={Nov},}@ARTICLE{10246990,
  author={Zhao, Le and Yao, Hongtai and Fan, Yajun and Ma, Haihua and Li, Zhihui and Tian, Meng},
  journal={IEEE Transactions on Aerospace and Electronic Systems}, 
  title={SceneNet: A Multifeature Joint Embedding Network With Complexity Assessment for Power Line Scene Classification}, 
  year={2023},
  volume={59},
  number={6},
  pages={9094-9116},
  abstract={Power line extraction is not only crucial for unmanned aerial vehicles (UAVs) obstacle avoidance, but also a fundamental step for fault diagnosis of power lines. Therefore, achieving robust and accurate extraction of power lines in aerial images is essential to enable intelligent UAVs inspection. Unfortunately, power line extraction is an extremely challenging task, and all the current methods attempt to utilize a single model to solve the problem of power line extraction in complex and variable scenes. This results in insufficient generalization ability and suboptimal computational efficiency. In this work, we propose a power line scene classification network based on complexity assessment, named SceneNet, which can provide a solution for tackling power line extraction challenges. First, we propose a human–machine hybrid reasoning model to obtain the ground truth of image complexity reasonably and build the first benchmark dataset that can be used for automatic classification research of power line scenes. Second, we propose an improved StyleGAN3 model and loop transfer learning strategy for data augmentation. Most importantly, the SceneNet comprises a multifeature joint embedding module and a feature encoding–decoding module. On one hand, it achieves the multilevel fusion of artificial features and high-dimensional semantic features. On the other hand, we use a self-attention mechanism to enable full use of the contextual association between each block of the fusion feature map. The SceneNet has successfully achieved the mapping and pattern recognition between the abstract concept and the concrete features. Experimental results demonstrate that the SceneNet is obviously superior to the existing 12 state-of-the-art models, and it provides guidance and delineation of applicable scenes for power line extraction methods.},
  keywords={Feature extraction;Complexity theory;Data mining;Inspection;Data models;Adaptation models;Standards;Human–machine hybrid reasoning;image complexity (IC) assessment;multifeature joint embedding;scene classification;UAVs inspection},
  doi={10.1109/TAES.2023.3313993},
  ISSN={1557-9603},
  month={Dec},}@INPROCEEDINGS{10323987,
  author={Reed, Andy and Dooley, Laurence S. and Mostefaoui, Soraya Kouadri},
  booktitle={2023 International Symposium on Networks, Computers and Communications (ISNCC)}, 
  title={Packet Filtering and Sampling for Efficient Slow Denial of Service Detection in Resource Scarce IoT Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={There has recently been considerable interest in automatic detection strategies for recognising application layer security threats such as Hypertext Transfer Protocol (HTTP) Slow Denial of-Service (Slow DoS) attacks in Internet of Things (IoT) networks. Most existing approaches however, fail to take cognisance of the substantial resource constraints imposed upon IoT environments, which limits the applicability and deployment of many Slow DoS detection mechanisms. This paper addresses this significant security threat for resource scarce IoT nodes and networks in proposing an accurate and computationally efficient approach to packet-based intrusion detection of HTTP Slow DoS activity. The paper both critically analyses and measures the impact of applying network attribute filtering and packet sampling to reduce the computational overheads on the resource constrained IoT Slow DoS detection node. The unique solution proposed uses a dataset synthesised from a live IoT environment comprising both legitimate and malicious network events in the form of legitimate HTTP traffic and Slow DoS attacks. Experimental results corroborate that combining filtering at the Border Router of only in-bound packets containing no TCP payload with a systematic packet sampling scheme at a sampling ratio of up to 1:64, the processing overheads on the detection node are significantly reduced. The novel contribution presented is a resource efficient solution, garnered by employing systematic sampling to seamlessly and accurately support selective attribute-based intrusion detection of HTTP Slow DoS attacks in IoT networks.},
  keywords={Systematics;Protocols;Intrusion detection;TCPIP;Information filters;Real-time systems;Energy efficiency;Internet of Things;Intrusion Detection;Slow DoS;Sampling;Attribute Filtering;Systematic Sampling},
  doi={10.1109/ISNCC58260.2023.10323987},
  ISSN={2768-0940},
  month={Oct},}@INPROCEEDINGS{7398384,
  author={Seaman, Bill},
  booktitle={2015 International Conference on Cyberworlds (CW)}, 
  title={Neosentient Architecture Generator}, 
  year={2015},
  volume={},
  number={},
  pages={8-13},
  abstract={This paper outlines an approach to a series of "open" purpose "architecture" generators and related systems. The word "architecture" is here defined in the broadest of linguistic manners. This paper outlines the long-term goals for the facilitation of the functional components of this 'system of systems', although the system will be designed to be extensible as a large-scale open source project. Three major components make up the system: 1) one or more databases, 2) a means to generate intelligent queries, and 3) a virtual media space to display media elements and processes as derived from the queries/interaction. I will begin by discussing precursors and historical problems related to computational creativity and symbiotic creative systems. Given the non-linear nature of the subject matter, the following text will progress in a modular manner, where much of the paper could we read in differing orders. Thus, it will not unfold in the linear manner of other more traditional IEEE papers, and should be explored with this intentionality by the reader. The project takes a multi-perspective approach to the subject matter in which no overarching hierarchy can be given, suggesting the need for such a form. Thus I will draw on the IEEE formatting related to "Component Heads" -- "components of your paper and are not topically subordinate to each other." This structure also mirrors the functionality of the system itself which seeks to explore dynamic heterarchical combinatorics as its overarching methodology as an intelligent system. Thus the reader may need to work harder at making the creative jumps that enable this analogue "system" to function by reading each of these different component heads in relation to each other and articulating their own connections between the components. This is a Koestler-like bisociational approach[1]. Thus the paper itself becomes an analogue combinatoric "architecture" used to discuss this project.},
  keywords={Computer architecture;Media;Artificial intelligence;Architecture;Context;Generators;Sensors;Generative Architecture;Generative Art;Recombinant Poetics;Recombinant Informatics;Generative Systems;Cybernetics;Systems Approach},
  doi={10.1109/CW.2015.55},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{4274657,
  author={Cui, Wanan and Song, Bin and Yue, Chaoyuan and Qin, Jiajun},
  booktitle={2006 IEEE International Conference on Systems, Man and Cybernetics}, 
  title={Evaluation of Criticality Analysis Measurements in Resource-Constrained Projects}, 
  year={2006},
  volume={6},
  number={},
  pages={4709-4716},
  abstract={Criticality analysis of activity and path is an important problem in resource-constrained projects. This paper proposes the method of minimal feasible sets (MFS) for the identification of critical activities and critical sequences. And then, we compare MFS with seven related previous methods. Computational results manifest that MFS does not perform inferior to other methods at least and excel them in most situations in establishing resource links and computing floats.},
  keywords={Processor scheduling;Project management;Chaos;Algorithm design and analysis;Geoscience;Delay effects;Cybernetics;Scheduling algorithm;Mathematical model;Risk management},
  doi={10.1109/ICSMC.2006.385048},
  ISSN={1062-922X},
  month={Oct},}@ARTICLE{9756272,
  author={Cao, Longbing},
  journal={IEEE Intelligent Systems}, 
  title={A New Age of AI: Features and Futures}, 
  year={2022},
  volume={37},
  number={1},
  pages={25-37},
  abstract={By reviewing the 70 years of AI, this article summarizes and discusses the paradigm transformations from the age of AI before the year 2000 to the new age of AI from the year 2000 onward. It reviews the AI thinking and features of various AI generations and paradigms during these two ages of AI and their transformations. The paper further summarizes several AI Formulas from the AI vision, system, goal, task, and process perspectives. Several important areas are highlighted in developing AI Futures: shrinking the gaps between human, natural and social AI, and developing human-like/level AI, meta AI, reflective AI, metasynthetic AI, data-driven AI, beyond ‘IID AI,’ actionable AI, and sustainable AI. In the new age of AI, we encourage your deep thinking of AI futures.},
  keywords={Machine vision;Artificial intelligence;Technology forecasting;Intelligent systems},
  doi={10.1109/MIS.2022.3150944},
  ISSN={1941-1294},
  month={Jan},}@ARTICLE{9324949,
  author={Garvey, Shunryu Colin},
  journal={IEEE Annals of the History of Computing}, 
  title={The “General Problem Solver” Does Not Exist: Mortimer Taube and the Art of AI Criticism}, 
  year={2021},
  volume={43},
  number={1},
  pages={60-73},
  abstract={This article reconfigures the history of artificial intelligence (AI) and its accompanying tradition of criticism by excavating the work of Mortimer Taube, a pioneer in information and library sciences, whose magnum opus, Computers and Common Sense: The Myth of Thinking Machines (1961), has been mostly forgotten. To convey the essence of his distinctive critique, the article focuses on Taube's attack on the general problem solver (GPS), the second major AI program. After examining his analysis of the social construction of this and other “thinking machines,” it concludes that, despite technical changes in AI, much of Taube's criticism remains relevant today. Moreover, his status as an “information processing” insider who criticized AI on behalf of the public good challenges the boundaries and focus of most critiques of AI from the past half-century. In sum, Taube's work offers an alternative model from which contemporary AI workers and critics can learn much.},
  keywords={Artificial intelligence;History;Computers;Information retrieval;Artificial Intelligence (AI);Information Processing;Cognitive Simulation;Computer Systems;Social Criticism},
  doi={10.1109/MAHC.2021.3051686},
  ISSN={1934-1547},
  month={Jan},}@INPROCEEDINGS{9795727,
  author={Alvarado-Landeo, Ismael and Surichaqui-Montalvo, Erick and Velasquez-Colorado, Kener and Huamanchahua, Deyby},
  booktitle={2022 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS)}, 
  title={Artificial Intelligence Applied in Human Medicine with the Implementation of Prostheses}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={The use of artificial intelligence (AI) in medicine is already a reality. Everywhere there is talk of the advantages that AI can mean for the future in our daily lives, as well as its possible applications. The future of "standard" medical practice could appear here ahead of schedule, where a patient could go to a computer before seeing a doctor. Through advances in AI, it becomes more possible for the days of misdiagnosis and treatment of the symptoms of the disease, rather than its root cause, to be left behind. Think about how many years of blood pressure measurements you have or how much storage you would need to remove so that you can fit a complete 3D image of an organ on your laptop. The idea of artificial intelligence in medicine may make you think of robots roaming the halls of a hospital in the distant future, but AI is already here.},
  keywords={Schedules;Three-dimensional displays;Prototypes;Artificial intelligence;Prognostics and health management;Robots;Medical diagnostic imaging;Artificial intelligence;prosthesis implantation;prosthetic rehabilitation;nanomaterials;modeling},
  doi={10.1109/IEMTRONICS55184.2022.9795727},
  ISSN={},
  month={June},}@INPROCEEDINGS{713806,
  author={Rocha, L.M.},
  booktitle={Proceedings of the 1998 IEEE International Symposium on Intelligent Control (ISIC) held jointly with IEEE International Symposium on Computational Intelligence in Robotics and Automation (CIRA) Intell}, 
  title={Syntactic autonomy}, 
  year={1998},
  volume={},
  number={},
  pages={706-711},
  abstract={The study of adapting and evolving autonomous agents should be based on a complex systems-theoretic framework which requires both self-organizing and symbolic dimensions. An inclusive framework based on the notions of semiotics and situated action is advanced to build models capable of representing, as well as evolving in their environments. Such undertaking is pursued by discussing the ways in which symbol and self-organization are irreducibly intertwined in evolutionary systems. This way, we re-think the notion of autonomy of evolving systems, and show that evolutionary systems are characterized by a particular type of syntactic autonomy. Developments in emergent computation in cellular automata are discussed as examples of the emergence of syntactic autonomy in computational environments. New results emphasizing this syntactic autonomy in cellular automata are presented.},
  keywords={Physics computing;Neural networks;State-space methods;Pattern recognition;Computer networks;Laboratories;Uniform resource locators;Autonomous agents;Genetic algorithms;Interference},
  doi={10.1109/ISIC.1998.713806},
  ISSN={2158-9860},
  month={Sep.},}@INPROCEEDINGS{4630414,
  author={Seising, Rudolf},
  booktitle={2008 IEEE International Conference on Fuzzy Systems (IEEE World Congress on Computational Intelligence)}, 
  title={Is there a concept of fuzziness in the epistemological systems of Heinrich Hertz and Ludwig Wittgenstein?}, 
  year={2008},
  volume={},
  number={},
  pages={498-505},
  abstract={"A picture is a model of reality", "A picture is a fact", and "We picture facts to ourselves" asserted Ludwig Wittgenstein in his Tractatus logico-philosophicus, thereby confirming the influence on his thinking - which he himself acknowledged - of Heinrich Hertz's Prinzipien der Mechanik (principles of mechanics). In this contribution the "picture" concept, which has a long tradition in philosophy, serves as the starting point of an interpretation of the relationship between real systems and theoretical structures of modern science. In addition, the approach dubbed as the "structuralist" approach of scientific theories in the 20th century will be extended and enhanced by the concept of "fuzzy sets" and "fuzzy relations". This fuzzy structuralist view on scientific theories enables us to combine philosophy of science with the methodologies of Computing with words (CW) and the computational theory of perceptions (CTP). Finally we give future prospects of this work.},
  keywords={Fuzzy systems;Conferences},
  doi={10.1109/FUZZY.2008.4630414},
  ISSN={1098-7584},
  month={June},}@INPROCEEDINGS{9041785,
  author={Jordan Rojas Dallaqua, Fernanda Beatriz and Fazenda, Álvaro Luiz and Faria, Fabio Augusto},
  booktitle={2019 15th International Conference on eScience (eScience)}, 
  title={ForestEyes Project: Can Citizen Scientists Help Rainforests?}, 
  year={2019},
  volume={},
  number={},
  pages={18-27},
  abstract={Scientific projects involving volunteers for analyzing, collecting data, and using their computational resources, known as Citizen Science (CS), have become popular due to advances in information and communication technology (ICT). Many CS projects have been proposed to involve citizens in different knowledge domain such as astronomy, chemistry, mathematics, and physics. This work presents a CS project called ForestEyes, which proposes to track deforestation in rainforests by asking volunteers to analyze and classify remote sensing images. These manually classified data are used as input for training a pattern classifier that will be used to label new remote sensing images. ForestEyes project was created on the Zooniverse.org CS platform, and to attest the quality of the volunteers' answers, were performed early campaigns with remote sensing images from Brazilian Legal Amazon (BLA). The results were processed and compared to an oracle classification (PRODES - Amazon Deforestation Monitoring Project). Two and a half weeks after launch, more than 35,000 answers from 383 volunteers (117 anonymous and 266 registered users) were received, completing all 2050 tasks. The ForestEyes campaigns' results have shown that volunteers achieved excellent effectiveness results in remote sensing image classification task. Furthermore, these results show that CS might be a powerful tool to quickly obtain a large amount of high-quality labeled data.},
  keywords={Citizen Science;Deforestation area detection;Rainforest;Tropical forest;Volunteered Thinking},
  doi={10.1109/eScience.2019.00010},
  ISSN={},
  month={Sep.},}@ARTICLE{10669020,
  author={Ye, Jinfei and Lu, Yang and Wang, Kuokuo and Jiao, Qingchun and Chen, Xuwen and Wang, Lijun},
  journal={IEEE Access}, 
  title={Design and Stage Analysis of a Non-Invasive Monitoring System for Determining Formaldehyde Release From Wood-Based Panels by the Chamber Method}, 
  year={2024},
  volume={12},
  number={},
  pages={137952-137969},
  abstract={With the extensive application of wood-based panels in the home decor industry, determining formaldehyde release form wood-based panels (FRWBP) is crucial for ensuring environmental air quality and human health. This article addresses the issues of insufficient monitoring of the testing stages for FRWBP and the difficulty in tracing the operation records of operator during determining FRWBP by the chamber method. It proposes a system for monitoring and analyzing the testing stages of FRWBP based on electrical monitoring. The system employs non-invasive sensing technology that does not interfere with normal testing process to collect real-time electrical usage data from the devices. The data is uploaded to an industrial computer for storage and processing. Statistical features of the electrical time series data are extracted using a sliding window approach and optimized with Principal Component Analysis (PCA). Subsequently, the binary tree support vector machine algorithm (BTSVM) optimized by k-means clustering algorithm is used to identify the detection states of the wood-based panels. Experimental results show that the system can achieve traceability of the formaldehyde detection stage records of artificial boards, and the designed algorithm model can also effectively identify the detection status of wood-based panels. The system and methods proposed in this paper have significant prospects for implementation in monitoring and traceability management within the testing industry.},
  keywords={Environmental monitoring;Temperature measurement;Support vector machines;Sensor phenomena and characterization;Noninvasive treatment;Formaldehyde;Principal component analysis;Air quality;FRWBP;chamber method;non-invasive;PCA;k-means;BTSVM},
  doi={10.1109/ACCESS.2024.3455375},
  ISSN={2169-3536},
  month={},}@ARTICLE{10433494,
  author={Okuno, Akifumi and Morishita, Yuya and Mototake, Yoh-Ichi},
  journal={IEEE Access}, 
  title={Autoregressive With Slack Time Series Model for Forecasting a Partially-Observed Dynamical Time Series}, 
  year={2024},
  volume={12},
  number={},
  pages={24621-24630},
  abstract={This study delves into the domain of dynamical systems, specifically the forecasting of dynamical time series defined through an evolution function. Traditional approaches in this area predict the future behavior of dynamical systems by inferring the evolution function. However, these methods may confront obstacles due to the presence of missing variables, which are usually attributed to challenges in measurement and a partial understanding of the system of interest. To overcome this obstacle, we introduce the autoregressive with slack time series (ARS) model, that simultaneously estimates the evolution function and imputes missing variables as a slack time series. Assuming time-invariance and linearity in the (underlying) entire dynamical time series, our experiments demonstrate the ARS model’s capability to forecast future time series. From a theoretical perspective, we prove that a 2-dimensional time-invariant and linear system can be reconstructed by utilizing observations from a single, partially observed dimension of the system.},
  keywords={Time series analysis;Mathematical models;Dynamical systems;Predictive models;Forecasting;Delays;Dynamics;Autoregressive processes;Autoregressive model;completely missing variables;dynamical system;slack time series},
  doi={10.1109/ACCESS.2024.3365724},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7840980,
  author={Bunn, Jenny},
  booktitle={2016 IEEE International Conference on Big Data (Big Data)}, 
  title={Mind the explanatory gap: Quality from quantity}, 
  year={2016},
  volume={},
  number={},
  pages={3240-3244},
  abstract={This paper makes a contribution to the development of computational archival science by thinking about and linking computational and archival thinking. It suggests that archival thinking and the archival problem space encompasses questions about the nature of consciousness, highlighting how these questions seem to be apparent within the fundamental archival principles of respect des fonds, provenance and original order. It seeks to shift attention back to provenance, not just in the sense of where a given object has come from, but also in the sense of the grounds on which it becomes an object and it suggests that the application of computational methods and tools for archival purposes and the integration of computational with archival thinking may offer a way to maintain awareness of this more philosophical dimension in practice.},
  keywords={Information processing;Organizations;Computers;Substrates;Context;Big data;consciousness;provenance;ontology},
  doi={10.1109/BigData.2016.7840980},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8954359,
  author={Aoki, Yasuhiro and Goforth, Hunter and Srivatsan, Rangaprasad Arun and Lucey, Simon},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={PointNetLK: Robust & Efficient Point Cloud Registration Using PointNet}, 
  year={2019},
  volume={},
  number={},
  pages={7156-7165},
  abstract={PointNet has revolutionized how we think about representing point clouds. For classification and segmentation tasks, the approach and its subsequent variants/extensions are considered state-of-the-art. To date, the successful application of PointNet to point cloud registration has remained elusive. In this paper we argue that PointNet itself can be thought of as a learnable "imaging" function. As a consequence, classical vision algorithms for image alignment can be brought to bear on the problem -- namely the Lucas & Kanade (LK) algorithm. Our central innovations stem from: (i) how to modify the LK algorithm to accommodate the PointNet imaging function, and (ii) unrolling PointNet and the LK algorithm into a single trainable recurrent deep neural network. We describe the architecture, and compare its performance against state-of-the-art in several common registration scenarios. The architecture offers some remarkable properties including: generalization across shape categories and computational efficiency -- opening up new paths of exploration for the application of deep learning to point cloud registration. Code and videos are available at https://github.com/hmgoforth/PointNetLK.},
  keywords={Point cloud compression;Deep learning;Training;Technological innovation;Shape;Imaging;Computer architecture;Deep Learning;3D from Multiview and Sensors;Motion and Tracking},
  doi={10.1109/CVPR.2019.00733},
  ISSN={2575-7075},
  month={June},}@ARTICLE{5675671,
  author={Mininno, Ernesto and Neri, Ferrante and Cupertino, Francesco and Naso, David},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Compact Differential Evolution}, 
  year={2011},
  volume={15},
  number={1},
  pages={32-54},
  abstract={This paper proposes the compact differential evolution (cDE) algorithm. cDE, like other compact evolutionary algorithms, does not process a population of solutions but its statistic description which evolves similarly to all the evolutionary algorithms. In addition, cDE employs the mutation and crossover typical of differential evolution (DE) thus reproducing its search logic. Unlike other compact evolutionary algorithms, in cDE, the survivor selection scheme of DE can be straightforwardly encoded. One important feature of the proposed cDE algorithm is the capability of efficiently performing an optimization process despite a limited memory requirement. This fact makes the cDE algorithm suitable for hardware contexts characterized by small computational power such as micro-controllers and commercial robots. In addition, due to its nature cDE uses an implicit randomization of the offspring generation which corrects and improves the DE search logic. An extensive numerical setup has been implemented in order to prove the viability of cDE and test its performance with respect to other modern compact evolutionary algorithms and state-of-the-art population-based DE algorithms. Test results show that cDE outperforms on a regular basis its corresponding population-based DE variant. Experiments have been repeated for four different mutation schemes. In addition cDE outperforms other modern compact algorithms and displays a competitive performance with respect to state-of-the-art population-based algorithms employing a DE logic. Finally, the cDE is applied to a challenging experimental case study regarding the on-line training of a nonlinear neural-network-based controller for a precise positioning system subject to changes of payload. The main peculiarity of this control application is that the control software is not implemented into a computer connected to the control system but directly on the micro-controller. Both numerical results on the test functions and experimental results on the real-world problem are very promising and allow us to think that cDE and future developments can be an efficient option for optimization in hardware environments characterized by limited memory.},
  keywords={Algorithm design and analysis;Optimization;Evolutionary computation;Training;Robots;Memory management;Hardware;Adaptive systems;compact genetic algorithms;differential evolution (DE);estimation distribution algorithms},
  doi={10.1109/TEVC.2010.2058120},
  ISSN={1941-0026},
  month={Feb},}@INPROCEEDINGS{7102580,
  author={Harman, Mark and Jia, Yue and Zhang, Yuanyuan},
  booktitle={2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)}, 
  title={Achievements, Open Problems and Challenges for Search Based Software Testing}, 
  year={2015},
  volume={},
  number={},
  pages={1-12},
  abstract={Search Based Software Testing (SBST) formulates testing as an optimisation problem, which can be attacked using computational search techniques from the field of Search Based Software Engineering (SBSE). We present an analysis of the SBST research agenda, focusing on the open problems and challenges of testing non-functional properties, in particular a topic we call 'Search Based Energy Testing' (SBET), Multi-objective SBST and SBST for Test Strategy Identification. We conclude with a vision of FIFIVERIFY tools, which would automatically find faults, fix them and verify the fixes. We explain why we think such FIFIVERIFY tools constitute an exciting challenge for the SBSE community that already could be within its reach.},
  keywords={Software testing;Search problems;Optimization;Software engineering;Energy consumption;Software},
  doi={10.1109/ICST.2015.7102580},
  ISSN={2159-4848},
  month={April},}@ARTICLE{1386655,
  author={Choy, R. and Edelman, A.},
  journal={Proceedings of the IEEE}, 
  title={Parallel MATLAB: Doing it Right}, 
  year={2005},
  volume={93},
  number={2},
  pages={331-341},
  abstract={MATLAB is one of the most widely used mathematical computing environments in technical computing. It is an interactive environment that provides high-performance computational routines and an easy-to-use, C-like scripting language. It started out as an interactive interface to EISPACK and LINPACK and has remained a serial program. In 1995, C. Moler of Mathworks argued that there was no market at the time for a parallel MATLAB. But times have changed and we are seeing increasing interest in developing a parallel MATLAB, from both academic and commercial sectors. In a recent survey, 27 parallel MATLAB projects have been identified. We expand upon that survey and discuss the approaches the projects have taken to parallelize MATLAB. Also, we describe innovative features in some of the parallel MATLAB projects. Then we will conclude with an idea of a "right" parallel MATLAB. Finally we will give an example of what we think is a "right" parallel MATLAB: MATLAB*P.},
  keywords={MATLAB;Concurrent computing;Mathematical model;Libraries;Distributed computing;Application software;Parallel processing;Eigenvalues and eigenfunctions;Linear systems;Mathematics;MATLAB;MATLAB;parallel;Star-P},
  doi={10.1109/JPROC.2004.840490},
  ISSN={1558-2256},
  month={Feb},}@ARTICLE{1039192,
  author={Ovaska, S.J. and VanLandingham, H.F. and Kamiya, A.},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 
  title={Fusion of soft computing and hard computing in industrial applications: an overview}, 
  year={2002},
  volume={32},
  number={2},
  pages={72-79},
  abstract={Soft computing (SC) is an emerging collection of methodologies which aims to exploit tolerance for imprecision, uncertainty, and partial truth to achieve robustness, tractability, and low total cost. It differs from conventional hard computing (HC) in the sense that, unlike hard computing, it is strongly based on intuition or subjectivity. Therefore, soft computing provides an attractive opportunity to represent the ambiguity in human thinking with real life uncertainty. Fuzzy logic (FL), neural networks (NN), and genetic algorithms (GA) are the core methodologies of soft computing. However, FL, NN, and GA should not be viewed as competing with each other, but synergistic and complementary instead. Considering the number of available journal and conference papers on various combinations of these three methods, it is easy to conclude that the fusion of individual soft computing methodologies has already been advantageous in numerous applications. On the other hand, hard computing solutions are usually more straightforward to analyze; their behavior and stability are more predictable; and, the computational burden of algorithms is typically either low or moderate. These characteristics. are particularly important in real-time applications. Thus, it is natural to see SC and HC as potentially complementary methodologies. Novel combinations of different methods are needed when developing high-performance, cost-effective, and safe products for the demanding global market. We present an overview of applications in which the fusion of soft computing and hard computing has provided innovative solutions for challenging real-world problems. A carefully selected list of references is considered with evaluative discussions and conclusions.},
  keywords={Computer applications;Computer industry;Fuzzy logic;Neural networks;Uncertainty;Robustness;Costs;Humans;Genetic algorithms;Computer networks},
  doi={10.1109/TSMCC.2002.801354},
  ISSN={1558-2442},
  month={May},}@ARTICLE{8648434,
  author={Lipka, Melanie and Sippel, Erik and Vossiek, Martin},
  journal={IEEE Access}, 
  title={An Extended Kalman Filter for Direct, Real-Time, Phase-Based High Precision Indoor Localization}, 
  year={2019},
  volume={7},
  number={},
  pages={25288-25297},
  abstract={Radio-based indoor localization is currently a very vibrant scientific research field with many potential use cases. It offers high value for customers, for example, in the fields of robotics, logistics, and automation, or in context-aware IT services. Especially for autonomous systems, dynamic human-machine interaction, or augmented reality applications, precise localization coupled with a high update rate is a key. In this paper, we present a completely novel localization concept whereby received radio signal phase values that are fed into an extended Kalman filter (EKF) without any preprocessing are evaluated. Standard preprocessing steps, such as angle-of-arrival estimation, beamforming, and time-of-flight or time-difference-of-arrival estimations are not required with this approach. The innovative localization concept benefits from the high sensitivity of radio signals' phase to distance changes and the fast and straightforward recursive computation offered by the EKF. It completely forgoes the computational burden of other phase-based high-precision localization techniques, such as synthetic aperture methods. To verify the proposed method, we use an exemplary setup employing a 24 GHz frequency-modulated continuous-wave (CW) single-input multiple-output secondary radar with 250 MHz bandwidth. A high-precision six-axis robotic arm serves as a 3D positioning reference. The test setup emulates a realistic industrial indoor environment with significant multipath reflections. Despite the challenging conditions and the rather low bandwidth, the results show an outstanding localization 3D RMSE of around 1.7 cm. The proposed method can easily be applied to nearly any type of radio signal with CW carrier and is an attractive alternative to common multilateration and multiangulation localization approaches. We think it is a quantum leap in wireless locating, as it has the potential for precise, simple, and low-cost wireless localization even with standard narrowband communication signals.},
  keywords={Kalman filters;Covariance matrices;Transmitters;Receiving antennas;Radar;Wireless sensor networks;Wireless communication;FMCW;radar;localization;extended Kalman filter;near field;indoor},
  doi={10.1109/ACCESS.2019.2900799},
  ISSN={2169-3536},
  month={},}@ARTICLE{9866607,
  author={Fan, Ying and Fan, Chen and He, Xiaofeng and Hu, Xiaoping and Zhou, Wenzhou and Wu, Xuesong and Shang, Hang},
  journal={IEEE Sensors Journal}, 
  title={Bionic Polarized Skylight Orientation Method Based on the Model Consistency of Polarization Patterns in Cloudy Weather}, 
  year={2022},
  volume={22},
  number={20},
  pages={19455-19465},
  abstract={Skylight polarized patterns provide fresh thinking for the human to use the information sources in nature for orientation, but this orientation method is susceptible to weather conditions. Especially, in the case of cloudy weather, the cloud directly leads to the decline of orientation precision. In this article, a robust bionic polarized skylight orientation method based on the model consistency of polarization patterns (MCOPPs) is proposed for cloudy weather. First, we made full use of the DOP information to preprocess the polarization information as an aid to the subsequent polarization light orientation. Then, based on the vertical feature of the E-vector of the polarized light and the scattering plane, we developed the MCOPP error criterion and proposed a two-step optimizing framework for the effective selection of the interior points. Finally, the outdoor static rotating experiment and the dynamic vehicle experiment are conducted for evaluating our algorithm. The experimental results demonstrate that MCOPP can realize an effective and robust polarized orientation under cloudy conditions, and the accuracy of orientation in the outdoor static experiment is within 0.5° and in the dynamic car experiment is within 0.7°. Compared with the other four classic methods, the RMSE of the orientation error can be decreased by 50.6% in the outdoor static experiment and by 46.0% in the dynamic vehicle experiment. Especially, the proposed MCOPP has lower computational complexity than the existing robust polarized skylight method.},
  keywords={Meteorology;Atmospheric modeling;Cloud computing;Rayleigh scattering;Clouds;Scattering;Heuristic algorithms;Bionic polarized skylight orientation;cloudy weather;pixelated polarized vision sensor;progressive sample consensus (PROSAC)},
  doi={10.1109/JSEN.2022.3199855},
  ISSN={1558-1748},
  month={Oct},}@INPROCEEDINGS{8906929,
  author={Vordonis, Dimitris and Paliouras, Vassilis},
  booktitle={2019 IEEE Nordic Circuits and Systems Conference (NORCAS): NORCHIP and International Symposium of System-on-Chip (SoC)}, 
  title={Sphere Decoder for Massive MIMO Systems}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={The increasing demand for higher data rates and for more connected devices has led to Massive MIMO (MMIMO) Technology. The large number of antennas makes the Maximum-Likelihood (ML) detector infeasible to be implemented due to high complexity, despite its optimal performance. Sphere Decoder (SD) has a bit error rate (BER) performance similar to ML detector, therefore making it more efficient (0.5-1.25 dB gain) than Linear Detectors (LD), proposed in the literature. However, the low complexity of LD and the non-deterministic behavior of SD are the main reasons that prohibit the use of sphere decoding methods in MMIMO systems. The results of this paper disrupt conventional thinking and show that there may be a future for SD in certain MMIMO system. The number of visited nodes during detection and the Initial Radius (IR) method are crucial for the computational complexity of SD. In this paper, an effective IR method, decreasing significantly the complexity and the number of visited nodes is proposed. Furthermore an optimization at tree searching further reduces the number of visited nodes, where in combination with an implementation featured with one-node-per-cycle architecture minimize the latency and make the SD attainable to large-scale systems for $E_{b}/N_{0}\geq 4 \ \mathrm{dB}$. Hardware aspects are investigated for both a Virtex-7 FPGA and a 28 nm ASIC technology.},
  keywords={massive MIMO;sphere decoding;initial radius;MIMO detection;eigenvalue problem;norm distance},
  doi={10.1109/NORCHIP.2019.8906929},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{1257862,
  author={Zhiru Zhang and Yiping Fan and Potkonjak, M. and Cong, J.},
  booktitle={ICCAD-2003. International Conference on Computer Aided Design (IEEE Cat. No.03CH37486)}, 
  title={Gradual relaxation techniques with applications to behavioral synthesis}, 
  year={2003},
  volume={},
  number={},
  pages={529-535},
  abstract={Heuristics are widely used for solving computational intractable synthesis problems. However, until now, there has been limited effort to systematically develop heuristics that can be applied to a variety of synthesis tasks. We focus on development of general optimization principles so that they can be applied to a wide range of synthesis problems. In particular, we propose a new way to realize the most constraining principle where at each step we gradually relax the constraints on the most constrained elements of the solution. This basic optimization mechanism is augmented with several new heuristic principles: minimal freedom reduction, negative thinking, calibration, simultaneous step consideration, and probabilistic modeling. We have successfully applied these optimization principles to a number of common behavioral synthesis tasks. Specifically, we demonstrate a systematic way to develop optimization algorithms for maximum independent set, time-constrained scheduling, and soft real-time system scheduling. The effectiveness of the approach and algorithms is validated on extensive real-life benchmarks.},
  keywords={Calibration;Permission;Application software;Computer science;Scheduling algorithm;Real time systems;Design optimization;Algorithm design and analysis;Heuristic algorithms;Ice},
  doi={10.1109/ICCAD.2003.159735},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10298533,
  author={Maipradit, Rungroj and Wang, Dong and Thongtanunam, Patanamon and Kula, Raula Gaikovina and Kamei, Yasutaka and McIntosh, Shane},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Repeated Builds During Code Review: An Empirical Study of the OpenStack Community}, 
  year={2023},
  volume={},
  number={},
  pages={153-165},
  abstract={Code review is a popular practice where developers critique each others' changes. Since automated builds can identify low-level issues (e.g., syntactic errors, regression bugs), it is not uncommon for software organizations to incorporate automated builds in the code review process. In such code review deployment scenarios, submitted change sets must be approved for integration by both peer code reviewers and automated build bots. Since automated builds may produce an unreliable signal of the status of a change set (e.g., due to “flaky” or non-deterministic execution behaviour), code review tools, such as Gerrit, allow developers to request a “recheck”, which repeats the build process without updating the change set. We conjecture that an unconstrained recheck command will waste time and resources if it is not applied judiciously. To explore how the recheck command is applied in a practical setting, in this paper, we conduct an empirical study of 66,932 code reviews from the OpenStack community. We quantitatively analyze (i) how often build failures are rechecked; (ii) the extent to which invoking recheck changes build failure outcomes; and (iii) how much waste is generated by invoking recheck. We observe that (i) 55% of code reviews invoke the recheck command after a failing build is reported; (ii) invoking the recheck command only changes the outcome of a failing build in 42% of the cases; and (iii) invoking the recheck command increases review waiting time by an average of 2,200% and equates to 187.4 compute years of waste-enough compute resources to compete with the oldest land living animal on earth. Our observations indicate that the recheck command is frequently used after the builds fail, but does not achieve a high likelihood of build success. Based on a developer survey and our history-based quantitative findings, we encourage reviewer teams to think twice before rechecking and be considerate of waste. While recheck currently generates plenty of wasted computational resources and bloats waiting times, it also presents exciting future opportunities for researchers and tool builders to propose solutions that can reduce waste.},
  keywords={Surveys;Codes;Automation;Animals;Computer bugs;Organizations;Syntactics;Code Review;Continuous Integration;Waste},
  doi={10.1109/ASE56229.2023.00030},
  ISSN={2643-1572},
  month={Sep.},}@INPROCEEDINGS{8939251,
  author={Shapsough, Salsabeel and Zualkernan, Imran},
  booktitle={2019 Sixth International Conference on Internet of Things: Systems, Management and Security (IOTSMS)}, 
  title={Requirements for an IoT Middleware for Utility-Scale Distributed Solar Farms}, 
  year={2019},
  volume={},
  number={},
  pages={51-57},
  abstract={The emergence of Internet of Things (IoT) has revolutionized the way people think about computational intelligence in real-life applications. It brought to life concepts such as smart cities, which could not have been realized using classic computing technologies. While domains like health, manufacturing, and agriculture have gained greatly from the introduction of internet-connected, low-cost smart monitoring and control devices, the energy sector remains the most significant application of IoT technologies. The most recent works on smart energy systems focus on the integration of renewable energy sources such as solar and wind. While renewable energy has been a key topic of research for decades, its adoption at large scale has been hindered by reliability and intermittency issues. Internet of Things can provide solutions to overcome such issues and enable grid integration by providing means for remote and real-time monitoring and performance analysis of solar facilities. This paper presents smart solar energy systems as an IoT application and derives primary system requirements of IoT middleware required for building efficient, scalable, and reliable grid-integrated large-scale and distributed smart solar farms.},
  keywords={Internet of Things;Middleware;Real-time systems;Monitoring;Meteorology;Solar energy;Smart grids;Internet of Things;distributed solar;PV;smart grid;IoT middleware},
  doi={10.1109/IOTSMS48152.2019.8939251},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10688269,
  author={Alekhya, V and Tamrakar, Deepesh and Swathi, B and Nagpal, Amandeep and Kumar, Ashwani and Al-Abadi, Noor K. Abed},
  booktitle={2024 OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 4.0}, 
  title={Robustness Analysis of Neuro-Inspired Architectures against Common Perturbations}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Making neuro-inspired structures more resistant to common difficulties is the focus of this study. AI and deep learning are crucial in many fields; therefore, neural networks must be reliable and durable. This post proposes a robust framework using 10 advanced tactics for a new and complete robustness approach. Our technique uses dropout, gradient masking, transfer learning, adversarial training, randomized smoothing, input preparation, strong activation functions, ensemble learning, Bayesian neural networks, and gradient masking. These strategies are aimed at addressing hostile assaults, noise, and environmental changes. Combining these approaches makes the system more versatile, making it ideal for self-driving vehicles, medical diagnostics, and hacking. We conducted comprehensive research to evaluate the proposed method’s accuracy, durability, resistance, generalization, computational cost, and real-world usage. Line charts illustrate the method’s strengths and weaknesses. These numbers demonstrate how the proposed approach differs from previous ones. They demonstrate its versatility and efficacy. Finally, our results demonstrate a reliable, versatile, and proven method for neural network resilience. Our method handles common modifications using sophisticated methods. This yields a forward-thinking, effective solution to AI environmental changes. The reliability of neuro-inspired systems has improved, which will affect artificial intelligence.},
  keywords={Training;Smoothing methods;Noise;Transfer learning;Robustness;Bayes methods;Ensemble learning;Innovation;Latency;Management;Network;NGMA;Performance;Proposed Method;Reliability;Scalability;Security;Technology;Throughput},
  doi={10.1109/OTCON60325.2024.10688269},
  ISSN={},
  month={June},}@ARTICLE{9927132,
  author={McKelvey, Fenwick},
  journal={IEEE Annals of the History of Computing}, 
  title={When the New Magic was New: The Claritas Corporation and the Clustering of America}, 
  year={2022},
  volume={44},
  number={4},
  pages={44-56},
  abstract={In 1982, geodemographics was “the new magic.” The system promised to pinpoint voters. One of its key developers, Jonathan Robbin, boasted, “Tell me someone's zip code, and I can predict what they eat, drink, drive—even think.” What was the secret? Robbin and his company, the Claritas Corporation, were among the first to merge newly digitized census data and computational social science into a geodemographic system called PRIZM. It produced new categories of populations known as clusters. These clusters provided a novel and legible form of computer demographics for marketers reliant on direct mail. Drawing on interviews and historical research, this article chronicles the understudied history of the Claritas Corporation. At a time of growing distress about microtargeting and behavioral advertising, the Claritas Corporation is a critical case to understand how computing changed how marketers and politicians distinguished, described, and marketed to Americans.},
  keywords={Codes;Behavioral sciences;History;Advertising;Technological innovation;Statistics;Sociology;geodemographics;clustering;microtargeting;business history},
  doi={10.1109/MAHC.2022.3214223},
  ISSN={1934-1547},
  month={Oct},}@INPROCEEDINGS{10575903,
  author={Mehta, Shiva and Khurana, Meenu and Dogra, Ayush and Hariharan, Shanmugasundaram},
  booktitle={2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={Advancing IoT Security through Federated Learning: A Comprehensive Approach}, 
  year={2024},
  volume={},
  number={},
  pages={561-566},
  abstract={IoT devices have changed into one of the mainstays in areas like houses, industry and education, resulting in a level of convenience and efficiency that has never been achieved before. Even though the most important advantage of the distributed network is raising the level of security, the problem of security vulnerabilities with the extended networks remains. This paper is devoted to a novel strategy of Federated Learning (FL) that could become an applied solution for enhancing the safety of the IoT. Therefore, based on its decentralized knowledge process, FL allows IoT devices to cooperate in achieving common purposes without endangering data pri vacy. The paper uses this thinking method to deal with scalability, model personalization, and non-IID data that aren’t IID distributing, suggesting solutions through model aggregation techniques or Artificial Intelligence (AI). Experimental evidence highlights that FL is very useful in enhancing IoT security irrespective of the diversity of its applications. To this end, residents of smart homes experienced a 17% increase in detecting the anomalies through the setting up of FL. This situation was replicated in the industrial Internet of Things, where the false positive rates were reduced from 20% to 5%, thus improving the system’s efficiency. Furthermore, in the FL context in healthcare IoT ecosystems, this blazes a trail for privacy-preserving data analytics, preserving patient confidentiality and systematic profiling of noteworthy health trends. These findings thus demonstrate that FL is a feasible way of dealing with the security challenges of IoT scalable, promptly and in a manner that maintains user privacy. The article takes part in a conversation about ways to strengthen the security of IoT networks. Such a framework is based on the computational power of IoT devices. It allows us to detect and prevent threats in time. Nonetheless, it urges extensive R&D attempts to be introduced to develop better security solutions in IoT. Without the involvement of different technologies, it won’t be easy to ensure safety and create some reliable IoT ecosystems.},
  keywords={Privacy;Federated learning;Scalability;Ecosystems;Safety;Internet of Things;Security;Internet of Things (IoT);Federated Learning (FL);Cybersecurity;Data Privacy;Decentralized Machine Learning},
  doi={10.1109/ICAAIC60222.2024.10575903},
  ISSN={},
  month={June},}@INPROCEEDINGS{6618933,
  author={Biswas, Arijit and Parikh, Devi},
  booktitle={2013 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Simultaneous Active Learning of Classifiers & Attributes via Relative Feedback}, 
  year={2013},
  volume={},
  number={},
  pages={644-651},
  abstract={Active learning provides useful tools to reduce annotation costs without compromising classifier performance. However it traditionally views the supervisor simply as a labeling machine. Recently a new interactive learning paradigm was introduced that allows the supervisor to additionally convey useful domain knowledge using attributes. The learner first conveys its belief about an actively chosen image e.g. "I think this is a forest, what do you think?". If the learner is wrong, the supervisor provides an explanation e.g. "No, this is too open to be a forest". With access to a pre-trained set of relative attribute predictors, the learner fetches all unlabeled images more open than the query image, and uses them as negative examples of forests to update its classifier. This rich human-machine communication leads to better classification performance. In this work, we propose three improvements over this set-up. First, we incorporate a weighting scheme that instead of making a hard decision reasons about the likelihood of an image being a negative example. Second, we do away with pre-trained attributes and instead learn the attribute models on the fly, alleviating overhead and restrictions of a pre-determined attribute vocabulary. Finally, we propose an active learning framework that accounts for not just the label-but also the attributes-based feedback while selecting the next query image. We demonstrate significant improvement in classification accuracy on faces and shoes. We also collect and make available the largest relative attributes dataset containing 29 attributes of faces from 60 categories.},
  keywords={Entropy;Vocabulary;Footwear;Training data;Training;Computational modeling;Equations;Active Learning;Attributes;Relative Feedback;Classification;Large vocabulary;Face images},
  doi={10.1109/CVPR.2013.89},
  ISSN={1063-6919},
  month={June},}@ARTICLE{7529181,
  author={Lee, Victor R. and Drake, Joel R. and Thayne, Jeffrey L.},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Appropriating Quantified Self Technologies to Support Elementary Statistical Teaching and Learning}, 
  year={2016},
  volume={9},
  number={4},
  pages={354-365},
  abstract={Wearable activity tracking devices associated with the Quantified Self movement have potential benefit for educational settings because they produce authentic and granular data about activities and experiences already familiar to youth. This article explores how that potential could be realized through explicit acknowledgment of and response to tacit design assumptions about how such technologies will be used in practice and strategic design for use in a classroom. We argue that particular practical adaptations that we have identified serve to ensure that the classroom and educational use cases are appropriately considered. As an example of how those adaptations are realized in actual elementary classrooms, we describe an effort to provide fifth-grade students each with their own Fitbit activity trackers in the context of a multi-week unit exploring core ideas in elementary statistics. Observational descriptions and transcript excerpts of students and teachers discussing their own Fitbit data are presented to illustrate what opportunities exist to leverage youth familiarity with daily activities in a way that targets development of statistical thinking. Quantitative written test results showing learning gains and differences between traditional and wearable device-enhanced instruction are also presented. Improvement on several statistical thinking constructs is identified, including in the areas of data display, conceptions of statistics, modeling variability, and informal inference.},
  keywords={Wearable computing;Context modeling;Biomedical monitoring;Pediatrics;Tracking;Computational modeling;Computers and education;user generated learning content;devices for learning},
  doi={10.1109/TLT.2016.2597142},
  ISSN={1939-1382},
  month={Oct},}@ARTICLE{9655236,
  author={Oliva-Maza, Ana and Ayuso-Escuer, Natalia and Coma-Rosell&#x00F3;, Teresa and Torres-Moreno, Enrique F.},
  journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, 
  title={Mystery of the Runaway Letrabytes: Inclusive Assessment of Phonological Awareness With Tangible Gamification}, 
  year={2021},
  volume={16},
  number={4},
  pages={424-432},
  abstract={The development of phonological awareness, i.e. the metacognitive skill that allows thinking and manipulating the language structure, from an early age is mandatory for the acquisition of literacy skills. Multisensory stimulation, curiosity and interest are fundamental for learning. In doing so, Communication Technologies have a key role because a learning-oriented use can encourage current digital natives&#x2019; interest and thinking. This paper presents a game with tangible technology designed for both intervention and diagnostic, formative and summative evaluation. The user experience was carried out during two weeks through a multiple case study with four kindergarten children. A multimedia adventure game was presented in which they had to solve phonological awareness challenges through the manipulation of tangible technology to achieve the final goal. The observation was recorded in the designed evaluation model, allowing the analysis of pre- and post-intervention data after the triangulation of data for subsequent qualitative analysis. The results show an improvement in phonological awareness, as well as the gamified experience marks. These promising outcomes support the use of such methodologies to a learner-centered education model.},
  keywords={Games;Educational programs;Visualization;Game theory;Object recognition;Computational modeling;Information and communication technology;Cognition;Phonological awareness;gamification;tangible interaction;inclusive evaluation;accessibility},
  doi={10.1109/RITA.2021.3136442},
  ISSN={1932-8540},
  month={Nov},}@INPROCEEDINGS{9649187,
  author={Callista, Annisa Syafarani and Nurul Pratiwi, Oktariani and Sutoyo, Edi},
  booktitle={2021 4th International Conference of Computer and Informatics Engineering (IC2IE)}, 
  title={Questions Classification Based on Revised Bloom's Taxonomy Cognitive Level using Naive Bayes and Support Vector Machine}, 
  year={2021},
  volume={},
  number={},
  pages={260-265},
  abstract={Education is an essential aspect in building the social value and norm to produce individuals who can think in high order thinking through learning and teaching activities. As technology keeps growing, an online learning platform has emerged. This platform is called e-Learning. e-Learning allows teachers to save many questions into the e-Learning question bank. However, these questions need to be reviewed so the questions can be matched with the achievement of competence. One educational identification standard that is often to improve the quality of the questions is Bloom's Taxonomy. Bloom's Taxonomy was created in 1956 and revised in 2001. This study compares the performance of the Support Vector Machine and Na&#x00EF;ve Bayes algorithms to classify quiz questions based on the cognitive level of Revised Bloom's Taxonomy. In this study, the dataset received two treatments in handling the imbalanced class. One dataset is using SMOTE method, and one another is not using any oversampling methods. The result shows that classification with oversampling datasets had better results than those without oversampling. The Support Vector Machine algorithm with SMOTE has the highest accuracy of 98%, rather than the Na&#x00EF;ve Bayes algorithm with SMOTE has an accuracy of 91%.},
  keywords={Support vector machines;Electronic learning;Computational modeling;Taxonomy;Education;Buildings;Classification algorithms;classification;revised bloom&#x2019;s taxonomy;SVM;NB;machine learning;SMOTE},
  doi={10.1109/IC2IE53219.2021.9649187},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9457749,
  author={Qiwei-Kong, Qiwei and Jing-He, Jing and Peizhuang-Wang, Peizhuang},
  booktitle={2020 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)}, 
  title={Factor space:a new idea for artificial intelligence based on causal reasoning}, 
  year={2020},
  volume={},
  number={},
  pages={592-599},
  abstract={In the rapid development of artificial intelligence in the last several years, machine learning is the mainstream method to realize artificial intelligence. What people usually call machine learning can be equivalent to statistical learning, which requires big data and powerful computing power; This is a machine learning trend driven by data, using algorithms to get a model with clear parameters, ignoring causal reasoning and focusing on statistical data; The machine learning method lacking logical causal reasoning will greatly hinder the advancement of artificial intelligence; How knowledge-driven causal reasoning provides new ideas for artificial intelligence is a question worth thinking about for scholars of artificial intelligence. Factor space theory that emphasizes causal reasoning will provide a new perspective and thinking for the development of artificial intelligence.},
  keywords={Machine learning algorithms;Human intelligence;Computational modeling;Statistical learning;Focusing;Market research;Cognition;Factor space;artificial intelligence;causal reasoning;probability and statistics},
  doi={10.1109/WIIAT50758.2020.00089},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9231672,
  author={Krebs, Eva and Jaschek, Corinna and von Thienen, Julia and Borchart, Kim-Pascal and Meinel, Christoph and Kolodny, Oren},
  booktitle={2020 IEEE Conference on Games (CoG)}, 
  title={Designing a Video Game to Measure Creativity}, 
  year={2020},
  volume={},
  number={},
  pages={407-414},
  abstract={Creativity is a central phenomenon in human life. World-famous scientists and artists are praised for their creative genius. Schools and universities seek to educate creativity in students and many employers want to hire creative personnel. However, the measurement of creativity is difficult up to the present day. Standard creativity tests typically require human expertise in the evaluation of test responses. This evaluation is often more time-intensive than taking the test itself. Moreover, creativity tests are still regularly conducted in a pen-and-paper format, rendering the data analysis all the more tedious. In this article, we propose a digital game for assessing creativity. It can be hosted online. The data analysis can be automated and conducted in real-time. The test is implemented as a tower defense game ("Immune Defense"). We submit that a video game constitutes a natural setting, as opposed to a formal testing scenario, and provides an opportunity to test real-life creativity. We use the game event data gathered during each round of the game to determine a player's creativity score. A study with 17 participants was performed to compare game-based creativity scores to scores obtained with a standard creativity test, the Alternative Uses Task. Our preliminary data validate the proposed approach.},
  keywords={Games;Creativity;Standards;Poles and towers;Particle measurements;Atmospheric measurements;Task analysis;Alternative uses task;automation;assessment;creativity;games for research;immune defense;measurement;video game},
  doi={10.1109/CoG47356.2020.9231672},
  ISSN={2325-4289},
  month={Aug},}@ARTICLE{9612182,
  author={Herremans, Dorien},
  journal={IEEE Access}, 
  title={aiSTROM–A Roadmap for Developing a Successful AI Strategy}, 
  year={2021},
  volume={9},
  number={},
  pages={155826-155838},
  abstract={A total of 34% of AI research and development projects fail or are abandoned, according to a recent survey by Rackspace Technology of 1,870 companies. In this perspective paper, a new STrategic ROadMap, aiSTROM, is presented that empowers managers to create an AI strategy. A comprehensive approach is provided that guides managers and lead developers through the various challenges in the implementation process. In the aiSTROM framework, the top  $n$  potential projects (typically 3-5) are first identified. For each of those, seven areas of focus are thoroughly analysed. These areas include creating a data strategy that takes into account unique cross-departmental machine learning data requirements, security, and legal requirements. aiSTROM then guides managers to think about how to put together an interdisciplinary artificial intelligence (AI) implementation team given the scarcity of AI talent. Once an AI team strategy has been established, it needs to be positioned within the organization, either cross-departmental or as a separate division. Other considerations include AI as a service (AIaas) and outsourcing development. Looking at new technologies, one has to consider challenges such as bias, the legality of black-box models, and keeping humans in the loop. Next, like any project, value-based key performance indicators (KPIs) need to be defined to track and validate the progress. Depending on the company’s risk strategy, a SWOT analysis (strengths, weaknesses, opportunities, and threats) can help further classify the shortlisted projects. Finally, one should make sure that the strategy includes continuous education of employees to enable a culture of adoption. This unique and comprehensive framework offers a practical tool for managers and lead developers.},
  keywords={Artificial intelligence;Companies;Big Data;Task analysis;Tools;Software;Lead;Artificial intelligence;computational and artificial intelligence;engineering management;project management;system implementation;technical management},
  doi={10.1109/ACCESS.2021.3127548},
  ISSN={2169-3536},
  month={},}@ARTICLE{10013660,
  author={Zhang, Chenkai and Deguchi, Daisuke and Okafuji, Yuki and Murase, Hiroshi},
  journal={IEEE Access}, 
  title={More Persuasive Explanation Method for End-to-End Driving Models}, 
  year={2023},
  volume={11},
  number={},
  pages={4270-4282},
  abstract={With the rapid development of autonomous driving technology, a variety of high-performance end-to-end driving models (E2EDMs) are being proposed. In order to understand the computational methods of E2EDMs, pixel-level explanations methods are used to obtain the explanations of the E2EDMs. However, little attention has been paid to the excellence of the explanations of E2EDMs. Therefore, in order to build trustworthy E2EDMs, we focus on improving the persuasibility of the explanations of E2EDMs. We propose an object-level explanation method (main approach) for E2EDMs, which masks the objects in the image and then treats the change in the prediction result as the importance of the objects, then we explain the E2EDM by the importance of each object. To further validate the effectiveness of object-level explanations, we propose another approach (validation approach), which trains E2EDMs with object information as input and generates the importance of objects using general explanation methods. Both approaches generate object-level explanations, in order to compare these object-level explanations with traditional pixel-level explanations, we propose experimental methods to measure the persuasibility of explanations of E2EDMs through a subjective and objective method. The subjective method evaluates persuasibility based on the extent to which participants think the importance of features indicated by the explanations is correct. The objective method evaluates the persuasibility based on the human annotation similarity between provided with only the important part of images and provided with the complete images. The experimental results show that the object-level explanations are more persuasive than the traditional pixel-level explanations.},
  keywords={Task analysis;Predictive models;Pipelines;Autonomous vehicles;Computational modeling;Autonomous driving;Convolutional neural networks;Autonomous driving;convolutional neural network;end-to-end model;explainability},
  doi={10.1109/ACCESS.2023.3235739},
  ISSN={2169-3536},
  month={},}@ARTICLE{8764449,
  author={Poria, Soujanya and Majumder, Navonil and Mihalcea, Rada and Hovy, Eduard},
  journal={IEEE Access}, 
  title={Emotion Recognition in Conversation: Research Challenges, Datasets, and Recent Advances}, 
  year={2019},
  volume={7},
  number={},
  pages={100943-100953},
  abstract={Emotion is intrinsic to humans and consequently, emotion understanding is a key part of human-like artificial intelligence (AI). Emotion recognition in conversation (ERC) is becoming increasingly popular as a new research frontier in natural language processing (NLP) due to its ability to mine opinions from the plethora of publicly available conversational data on platforms such as Facebook, Youtube, Reddit, Twitter, and others. Moreover, it has potential applications in health-care systems (as a tool for psychological analysis), education (understanding student frustration), and more. In Addition, ERC is also extremely important for generating emotion-aware dialogues that require an understanding of the user’s emotions. Catering to these needs calls for effective and scalable conversational emotion-recognition algorithms. However, it is a difficult problem to solve because of several research challenges. In this paper, we discuss these challenges and shed light on recent research in this field. We also describe the drawbacks of these approaches and discuss the reasons why they fail to successfully overcome the research challenges in ERC.},
  keywords={Emotion recognition;Task analysis;Context modeling;Taxonomy;Natural language processing;Pragmatics;Emotion recognition;sentiment analysis;dialogue systems;natural language processing},
  doi={10.1109/ACCESS.2019.2929050},
  ISSN={2169-3536},
  month={},}@ARTICLE{8746184,
  author={Miklosik, Andrej and Kuchta, Martin and Evans, Nina and Zak, Stefan},
  journal={IEEE Access}, 
  title={Towards the Adoption of Machine Learning-Based Analytical Tools in Digital Marketing}, 
  year={2019},
  volume={7},
  number={},
  pages={85705-85718},
  abstract={Exponential technological expansion creates opportunities for competitive advantage by applying new data-oriented approaches to digital marketing practices. Machine learning (ML) can predict future developments and support decision-making by extracting insights from large amounts of generated data. This functionality greatly impacts and streamlines the strategic decision-making process of organizations. The research gap analysis revealed that a little is known about marketers' attitude toward, and knowledge about, ML tools and their adoption and utilization to support strategic and operational management. The research presented here focuses on the selection and adoption of the ML-driven analytical tools by three distinct groups: marketing agencies, media companies, and advertisers. Qualitative and quantitative research was conducted on a sample of these organizations operating in Slovakia. The findings highlight: 1) the important role of intelligent analytical tools in the creation and deployment of marketing strategies; 2) the lack of knowledge about emerging technologies, such as ML and artificial intelligence (AI); 3) the potential application of the ML tools in marketing, and; 4) the low level of adoption and utilization of the ML-driven analytical tools in marketing management. A framework consisting of enablers and a process map was developed to help organizations identify the opportunities and successfully execute projects that are oriented toward the deployment and adoption of the analytical ML tools in digital marketing.},
  keywords={Tools;Decision making;Strategic planning;Companies;Internet;Big data;data-driven analytical tools;digital marketing;machine learning (ML);marketing agencies;marketing analysis},
  doi={10.1109/ACCESS.2019.2924425},
  ISSN={2169-3536},
  month={},}@ARTICLE{9590485,
  author={Hussain, Arif and Kim, Chul-Hwan and Mehdi, Arif},
  journal={IEEE Access}, 
  title={A Comprehensive Review of Intelligent Islanding Schemes and Feature Selection Techniques for Distributed Generation System}, 
  year={2021},
  volume={9},
  number={},
  pages={146603-146624},
  abstract={Detection of unintentional islanding, defined as inadvertently separation of distributed generators (DGs) from the utility grid, is a major challenging issue for modern distribution networks. Islanding detection becomes problematic especially when the local generation matches or closely matches the local load. Therefore, there are strict requirements for accurate, fast, and reliable islanding detection of renewables and DG-based systems. Various islanding schemes have been proposed in the literature, which can be categorized as remote, local, and intelligent-classifier-based schemes. Recently, intelligent schemes have gained attention due to their superior properties and advantages relative to traditional approaches. This paper overviews the shift in research from traditional schemes to intelligent islanding schemes. It also highlights the major obstacles, challenges, advantages and disadvantages, and future research directions of intelligent schemes. In this study, the intelligent-classifier-based islanding detection schemes presented over the last decade are analyzed objectively and comprehensively from all aspects of islanding detection. This research further highlights feature selection schemes and the most common parameters used for islanding detection. Finally, based on a detailed and critical analysis, the findings and potential recommendations are presented.},
  keywords={Islanding;Power systems;Frequency measurement;Circuit breakers;Phasor measurement units;Frequency control;Voltage measurement;Active islanding schemes;distribution generation;electrical power system;intelligent-classifiers;islanding detection;microgrids;passive islanding schemes;remote islanding schemes},
  doi={10.1109/ACCESS.2021.3123382},
  ISSN={2169-3536},
  month={},}@ARTICLE{8839118,
  author={Jacob, Sunil and Menon, Varun G. and Al-Turjman, Fadi and P. G., Vinoj and Mostarda, Leonardo},
  journal={IEEE Access}, 
  title={Artificial Muscle Intelligence System With Deep Learning for Post-Stroke Assistance and Rehabilitation}, 
  year={2019},
  volume={7},
  number={},
  pages={133463-133473},
  abstract={Stroke is one of the prime reasons for paralysis throughout the world caused due to impaired nervous system and resulting in disability to move the affected body parts. Rehabilitation is the natural remedy for recovering from paralysis and enhancing the quality of life. Brain Computer Interface (BCI) controlled assistive technology is the new paradigm, providing assistance and rehabilitation for the paralysed. But, most of these devices are error prone and also hard to get continuous control because of the dynamic nature of the brain signals. Moreover, existing devices like exoskeletons brings additional burden on the patient and the caregivers and also results in mental fatigue and frustration. To solve these issues Artificial Muscle Intelligence with Deep Learning (AMIDL) system is proposed in this paper. AMIDL integrates user intentions with artificial muscle movements in an efficient way to improve the performance. Human thoughts captured using Electroencephalogram (EEG) sensors are transformed into body movements, by utilising microcontroller and Transcutaneous Electrical Nerve Stimulation (TENS) device. EEG signals are subjected to pre-processing, feature extraction and classification, before being passed on to the affected body part. The received EEG signal is correlated with the recorded artificial muscle movements. If the captured EEG signal falls below the desired level, the affected body part will be stimulated by the recorded artificial muscle movements. The system also provides a feature for communicating human intentions as alert message to caregivers, in case of emergency situations. This is achieved by offline training of specific gesture and online gesture recognition algorithm. The recognised gesture is transformed into speech, thus enabling the paralysed to express their feelings to the relatives or friends. Experiments were carried out with the aid of healthy and paralysed subjects. The AMIDL system helped to reduce mental fatigue, miss-operation, frustration and provided continuous control. The thrust of lifting the exoskeleton is also reduced by using light weight wireless electrodes. The proposed system will be a great communication aid for paralysed to express their thoughts and feelings with dear and near ones, thereby enhancing the quality of life.},
  keywords={Electroencephalography;Exoskeletons;Muscles;Robot kinematics;Robot sensing systems;Task analysis;Artificial muscle intelligence;assistivetechnologies;BCI;EEG;exoskeleton;healthcare;intelligent solutions;deep learning system;paralyzed;stroke},
  doi={10.1109/ACCESS.2019.2941491},
  ISSN={2169-3536},
  month={},}@ARTICLE{9026942,
  author={Yang, Zaoli and Chang, Jinping},
  journal={IEEE Access}, 
  title={Interval-Valued Pythagorean Normal Fuzzy Information Aggregation Operators for Multi-Attribute Decision Making}, 
  year={2020},
  volume={8},
  number={},
  pages={51295-51314},
  abstract={The interval-valued Pythagorean fuzzy (IVPF) sets, describing the membership and non-membership degrees from interval values, can address uncertain information, while the normal fuzzy number (NFN) can depict normal distribution information in anthropogenic activity and natural environment. By combining the advantages of both operations, in this study, we proposed the interval-valued Pythagorean normal fuzzy (IVPNF) sets by introducing the NFN into IVPF environment. Firstly, we defined the conception, the operational laws, score function, accuracy function of IVPNF sets. Secondly, we presented four information aggregation operators to aggregate IVPNF information, including the IVPNF weighted averaging (IVPNFWA) operator, IVPNF weighted geometric (IVPNFWG) operator, the generalized IVPNFWA operator, and the generalized IVPNFWG operator. In addition, we analyzed some desirable properties of monotonicity, commutativity, and idempotency for the proposed four operators. Finally, a numerical example on multi-attribute decision-making problem is given to verify the practicality of the proposed operators, and the comparative and sensitive analysis are used to show the effectiveness and flexibility of our proposed approach.},
  keywords={Fuzzy sets;Decision making;Linguistics;Gaussian distribution;Complexity theory;Quality function deployment;Normal fuzzy number;interval-valued Pythagorean normal fuzzy;information aggregation operators;multi-attribute decision-making},
  doi={10.1109/ACCESS.2020.2978976},
  ISSN={2169-3536},
  month={},}@ARTICLE{8244274,
  author={Dai, Yinglong and Wang, Guojun},
  journal={IEEE Access}, 
  title={Analyzing Tongue Images Using a Conceptual Alignment Deep Autoencoder}, 
  year={2018},
  volume={6},
  number={},
  pages={5962-5972},
  abstract={Artificial intelligence can learn some concepts by analyzing sensory data similarly to humans. This paper explores how artificial neural networks (ANNs) can learn abstract concepts by analyzing tongue images based on concepts from traditional Chinese medicine (TCM), which is a discipline that relies heavily on practitioner experience. A computer-aided method will be investigated that analyzes sensory data for TCM practitioners. This paper proposes capitalizing on deep learning techniques. A method called the conceptual alignment deep auto-encoder (CADAE) is proposed to analyze tongue images that represent different body constitution (BC) types, which are the underlying concepts in TCM. In the first step, CADAE encodes the images to a representation space; in the second step, it decodes the patterns. The experiments demonstrate that CADAE can learn effective representations of abstract concepts aligned with BC types by encoding the tongue images. Furthermore, the representation space of the hidden conceptual neurons can be visualized by a decoder network. The experiments also demonstrate that ANNs acquire different data perspectives when different loss functions are used for training. Numerous representation spaces of ANNs remain to be explored. To some extent, our exploration demonstrates that artificial intelligence (AI) has the ability to learn some concepts in a manner similarly to human beings. Based on this ability, AI shows promise in helping humans form new effective concepts that can facilitate medical development and alleviate the burdens of medical practitioners.},
  keywords={Tongue;Machine learning;Medical diagnostic imaging;IEEE Constitution;Biological system modeling;Neurons;Conceptual alignment deep autoencoder;deep learning;representation learning;tongue image;traditional Chinese medicine},
  doi={10.1109/ACCESS.2017.2788849},
  ISSN={2169-3536},
  month={},}@ARTICLE{9730885,
  author={Alghamdi, Turki Ali and Javaid, Nadeem},
  journal={IEEE Access}, 
  title={A Survey of Preprocessing Methods Used for Analysis of Big Data Originated From Smart Grids}, 
  year={2022},
  volume={10},
  number={},
  pages={29149-29171},
  abstract={In this paper, a brief survey of data preprocessing methods is presented. Specifically, the data preprocessing methods used in the smart grid (SG) domain are surveyed. Also, with the advent of SG, data collection on a large scale became possible. The data is essential for electricity demand, generation and price forecasting, which plays an important role in making energy efficient decisions, and long and short term predictions regarding energy generation, consumption and storage. However, the forecasting accuracy decreases when data is used in raw form. Hence, data preprocessing is considered essential. This paper provides an overview of the data preprocessing methods and a detailed discussion of the methods used in the existing literature. A comparison of the methods is also given. A survey of closely related survey papers is also presented and the papers are compared based on their contributions. Moreover, based on the discussion of the data preprocessing methods, a narrative is built with a critical analysis. Finally, future research directions are discussed to guide the readers.},
  keywords={Big Data;Mathematical models;Data preprocessing;Forecasting;Machine learning;Deep learning;Data models;Data analytics;data preprocessing;integration;normalization;smart grid;smart meter;transformation},
  doi={10.1109/ACCESS.2022.3157941},
  ISSN={2169-3536},
  month={},}@ARTICLE{8693724,
  author={Alhroob, Essam and Mohammed, Mohammed Falah and Lim, Chee Peng and Tao, Hai},
  journal={IEEE Access}, 
  title={A Critical Review on Selected Fuzzy Min-Max Neural Networks and Their Significance and Challenges in Pattern Classification}, 
  year={2019},
  volume={7},
  number={},
  pages={56129-56146},
  abstract={At present, pattern classification is one of the most important aspects of establishing machine intelligence systems for tackling decision-making processes. The fuzzy min-max (FMM) neural network combines the operations of an artificial neural network and fuzzy set theory into a common framework. FMM is considered one of the most useful neural networks for pattern classification. This paper aims to 1) analyze the FMM neural network in terms of its impact in addressing pattern classification problems; 2) examine models that are proposed based on the original FMM model (i.e., existing FMM-based variants); 3) identify the challenges associated with FMM and its variants, and; 4) discuss future trends and make recommendations for improvement. The review is conducted based on a methodical protocol. Through a rigorous searching and filtering process, the relevant studies are extracted and comprehensively analyzed to adequately address the defined research questions. The findings indicate that FMM plays a critical role in providing solutions to pattern classification issues. The FMM model and a number of FMM-based variants are identified and systematically analyzed with respect to their aims, improvements introduced and results achieved. In addition, FMM and its variants are critically analyzed with respect to their benefits and limitations. This paper shows that the existing FMM-based variants still encounter issues in terms of the learning process (expansion, overlap test, and contraction), which influence the classification performance. Based on the review findings, research opportunities are suggested to propose a new model to enhance the number of existing FMM models, particularly in terms of their learning process by minimizing hyperbox overlap pertaining to different classes as well as avoiding membership ambiguity of the overlapped region. In short, this review provides a comprehensive and critical reference for researchers and practitioners to leverage FMM and its variants for undertaking pattern classification tasks.},
  keywords={Neural networks;Analytical models;Brain modeling;Neurons;Complexity theory;Fuzzy set theory;Task analysis;Fuzzy min–max;pattern classification;neural network;FMM models},
  doi={10.1109/ACCESS.2019.2911955},
  ISSN={2169-3536},
  month={},}@ARTICLE{9229421,
  author={Yuan, Chenxi and Moghaddam, Mohsen},
  journal={IEEE Access}, 
  title={Attribute-Aware Generative Design With Generative Adversarial Networks}, 
  year={2020},
  volume={8},
  number={},
  pages={190710-190721},
  abstract={The designers' tendency to adhere to a specific mental set and heavy emotional investment in their initial ideas often limit their ability to innovate during the design ideation process. The shrinking time-to-market and the growing diversity of users' needs further exacerbate this gap. Recent advances in deep generative models have created new possibilities to overcome the cognitive obstacles of designers through automated generation or editing of design concepts. This article explores the capabilities of generative adversarial networks (GAN) for automated, attribute-aware generative design of the visual attributes of a product. Specifically, a design attribute GAN (DA-GAN) model is developed for automated generation of fashion product images with the desired visual attributes. Experiments on a large fashion dataset signify the potentials of GAN for attribute-aware generative design, verify the ability of editing attributes with relatively higher accuracy and uncover several key challenges and research questions for future work.},
  keywords={Generative adversarial networks;Gallium nitride;Clothing;Task analysis;Faces;Facial features;Visualization;Design automation;generative modeling;conceptual design and ideation},
  doi={10.1109/ACCESS.2020.3032280},
  ISSN={2169-3536},
  month={},}@ARTICLE{9208659,
  author={Choi, Byeong-Guk and Lee, Eun S. and Kim, Yun-Su},
  journal={IEEE Access}, 
  title={Optimal Structure Design of Ferromagnetic Cores in Wireless Power Transfer by Reinforcement Learning}, 
  year={2020},
  volume={8},
  number={},
  pages={179295-179306},
  abstract={In this paper, a reinforcement learning algorithm is applied for the first time to find a ferromagnetic core structure with optimal coupling coefficient between transmitting (Tx) and receiving (Rx) coils of a wireless power transfer (WPT) system. Since formula-based theoretical design is not available due to the non-linear magnetic field distortion stems from the presence of the ferromagnetic core in a WPT system, the proposed design has been achieved through finite element analysis (FEA) simulation-based data learning. The proposed design methods are so general that they can be applied to any conventional WPT coil types. We applied the proposed algorithm to the ferromagnetic core structure design of a simple dipole coil first. By training only 2.3 % data out of total possible cases, it is experimentally verified that the core structure obtained by the proposed method has a coupling coefficient 7 % higher than that of the example design level in the case of 98 cm distance between Tx and Rx coils.},
  keywords={Coils;Magnetic cores;Couplings;Learning (artificial intelligence);Magnetic fields;Shape;Machine learning algorithms;Ferromagnetic core;wireless power transfer (WPT);coil design;reinforcement learning;neural network},
  doi={10.1109/ACCESS.2020.3027765},
  ISSN={2169-3536},
  month={},}@ARTICLE{9599669,
  author={Park, Youngki and Shin, Youhyun},
  journal={IEEE Access}, 
  title={Tooee: A Novel Scratch Extension for K-12 Big Data and Artificial Intelligence Education Using Text-Based Visual Blocks}, 
  year={2021},
  volume={9},
  number={},
  pages={149630-149646},
  abstract={Many approaches have been proposed to teach the basic concepts of big data and artificial intelligence to K-12 students based on block-based programming languages, such as Scratch. Using these approaches, young students can easily experience big data and artificial intelligence through a drag-and-drop approach. However, it remains difficult for them to perform more complex tasks, such as directly collecting data from the web or exploiting custom-made machine learning algorithms. In this paper, we propose a novel Scratch extension that allows Scratch to communicate with text-based programming languages such as Python and JavaScript using WebSockets. Unlike other Scratch extensions, our extension greatly enhances the extensibility of Scratch given its use of “text-based visual blocks” so that messages can be freely exchanged through a minimum number of blocks. In order for students to use these blocks easily, the blocks are designed such that they can be used as if talking with a friend named “Tooee.” In order to show how this extension can help students create big data and artificial intelligence programs, we present eight example applications that students can easily implement. These are (1) Weather Forecast, (2) Top 5 Movies in Theaters, (3) COVID-19 Dashboard, (4) Saving Quiz Results to a CSV File, (5) Facial Image Classification, (6) Color Classification, (7) Object Classification, and (8) Handwriting Recognition. Our analyses and experimental results show that Tooee has several advantages over other educational environments.},
  keywords={Big Data;Visualization;Machine learning;Social networking (online);Servers;Blogs;Data models;Artificial intelligence education;big data education;K-12;Scratch;Tooee},
  doi={10.1109/ACCESS.2021.3125060},
  ISSN={2169-3536},
  month={},}@ARTICLE{9963925,
  author={Rahman, Shahid and Uddin, Jamal and Khan, Habib Ullah and Hussain, Hameed and Khan, Ayaz Ali and Zakarya, Muhammad},
  journal={IEEE Access}, 
  title={A Novel Steganography Technique for Digital Images Using the Least Significant Bit Substitution Method}, 
  year={2022},
  volume={10},
  number={},
  pages={124053-124075},
  abstract={Communication has become a lot easier in this era of technology, development of high-speed computer networks, and the inexpensive uses of Internet. Therefore, data transmission has become vulnerable to and unsafe from different external attacks. Every communication body wants to secure their data while communicating over the Internet. The internet has various benefits but the main demerit is the privacy and security and the transmission of data over insecure network or channel may happen. Various techniques used for secure communication in order to address these issues, steganography plays an important role. Steganography is the process of obfuscation that makes something incomprehensible and unclear. Different image steganography research methods are proposed recently but each has their advantages and disadvantages and still have necessity to develop some better image steganography mechanisms to achieve the reliability between the basics criteria of image steganography. Therefore, the proposed work, in this paper, is based on the Least Significant Bit (LSB) substitution method. The LSB substitution method can minimize the error rate in embedding process and can achieve greater reliability in criteria, using novel algorithm based on value difference. In this paper, we proposed a novel technique in steganography within the digital images such is RGB, Gray Scale, Texture, Aerial images to achieve higher security, imperceptibility, capacity, and robustness as compared with existing methods. The experimental outcomes of the suggested approach prove further developed strength and justify the feasibility of our research. Through numerical simulations, we observed that the proposed strategy outperformed the next-best current methodology by 5.561 percent in terms of PSNR Correlation score. Additionally, the proposed approach achieved a 6.43 percent better score in PSNR with a variable measure of code inserted in similar images with distinct dimensions. Furthermore, encrypting the same amount of information in images of varying sizes resulted in approximately 6.77 percent improvements. Embedding different sizes of a particular secret message in a different image (such as Gray, Texture, Aerial and RGB images) came out with about 5.466 percent of better score.},
  keywords={Steganography;Data privacy;Error analysis;Digital images;Current measurement;Numerical simulation;Robustness;Image steganography;LSB;image quality assessment metrics;histogram analysis;image;capacity;robustness},
  doi={10.1109/ACCESS.2022.3224745},
  ISSN={2169-3536},
  month={},}@ARTICLE{9187930,
  author={Isa, Wan Malini Wan and Zin, Nor Azan Mat and Rosdi, Fadhilah and Sarim, Hafiz Mohd and Wook, Tengku Siti Meriam Tengku and Husin, Supyan and Jusoh, Sufian and Lawi@Ali, Syahrol Khairuddin},
  journal={IEEE Access}, 
  title={An Ontological Approach for Creating a Brassware Craft Knowledge Base}, 
  year={2020},
  volume={8},
  number={},
  pages={163434-163446},
  abstract={Terengganu brassware is a local craft product with high artistic value and traditional craftsmanship that involves a lot of creativity and elaborate artistry. This cultural heritage is in danger of disappearing because the current younger generation lacks interest, creativity and artistic skills to continue the craftsmanship. Therefore, gathering detailed knowledge of the craft from ageing practitioners can preserve the heritage. This article reports the study on brassware intangible heritage knowledge base development using an ontological approach. The ontology modelling used Ontology Development 101. Content validation result by experts found that the brassware ontology is complete, consistent, concise, precise and clear. Evaluation results show that the experts agreed on content representation (mean ≥3.80), and the ontology meets all the quality criteria (mean ≥4.03). The brassware craft ontology contributes to the intangible heritage preservation effort for one of the almost extinct local culture and practices. This intangible heritage knowledge base can be applied for the development of semantic search, mobile and gaming applications to attract and disseminate heritage information to young people. Additionally, the ontological design can serve as a guide for the design and development of a knowledge base for other types of heritage.},
  keywords={Ontologies;Cultural differences;Knowledge based systems;Global communication;Creativity;Data models;Interviews;Intangible cultural heritage;knowledge base;knowledge representation;ontology evaluation},
  doi={10.1109/ACCESS.2020.3022795},
  ISSN={2169-3536},
  month={},}@ARTICLE{9104906,
  author={E, Haihong and Zhan, Zecheng and Song, Meina},
  journal={IEEE Access}, 
  title={Table-to-Dialog: Building Dialog Assistants to Chat With People on Behalf of You}, 
  year={2020},
  volume={8},
  number={},
  pages={102313-102320},
  abstract={Artificial Intelligence (AI) personal assistant has attracted much attention from both academia and industry. Almost all existing AI personal assistants serve as service terminals to chat with human users for certain tasks. We are instead interested in building AI personal assistants for a different yet important dialog scenario, where they chat with people to fulfill specific tasks on behalf of their human users. As the personal assistants are playing a requester role, instead of a service terminal role, the conversation goal becomes delivering or requesting information according to specific user requests precisely and efficiently. The challenge for the conversation policy is that all user requests must be delivered precisely, while the challenge for the response generation is that it's generally expected for machine generated responses to cover multiple information slots, either requesting or delivering, to make the conversation efficient. In this paper, we present Table-to-Dialogue, a novel approach to address the above challenges when building a requester role AI personal assistant. We employ an encoder-decoder network to learn explicit conversation policy, which generates the corresponding information slots based on the conversation context and the user request table. We further integrate a novel Multi-Slot Constrained Bi-directional Decoder (MS-CBD) into the above encoder-decoder network, to generate machine response according to the multiple slot values and their intermediate representations from the policy decoder. Different from the existing single direction text decoder approaches, MS-CBD leverage the bi-directional context of the response when generating it to enhance the semantic coherence. The experiments shows that our approach significantly outperform the state-of-the-art conversation approaches on automatic and human evaluation metrics.},
  keywords={Decoding;Bidirectional control;Artificial intelligence;Task analysis;Buildings;Semantics;Coherence;Dialogue system;sequence generation;deep learning;constrained decoding;table-to-text;natural language process},
  doi={10.1109/ACCESS.2020.2998432},
  ISSN={2169-3536},
  month={},}@ARTICLE{10223039,
  author={Guo, Ziyue and Zhu, Zongyang and Li, Yizhi and Cao, Shidong and Chen, Hangyue and Wang, Gaoang},
  journal={IEEE Access}, 
  title={AI Assisted Fashion Design: A Review}, 
  year={2023},
  volume={11},
  number={},
  pages={88403-88415},
  abstract={This review explores the integration of enhanced personalization and seamless multimodal interfaces in the field of fashion design and recommendation. We examine the increasing demand for personalized fashion experiences and the potential of multimodal interfaces in facilitating effective communication between designers and users. By leveraging user preferences, body measurements, and style choices, artificial intelligence (AI) systems can deliver highly personalized fashion recommendations. The integration of various input modalities, including text, images and sketches, enables designers and users to communicate their design ideas with ease. The primary results highlight the transformative potential of enhanced personalization and seamless multimodal interfaces, empowering designers and consumers to co-create unique and personalized designs. This paradigm shift fosters a deeper level of engagement and creativity within the fashion industry. Embracing this advancement unlocks unprecedented opportunities for designers, brands, and consumers, ushering in a new era of innovation and creativity in fashion design.},
  keywords={Artificial intelligence;Task analysis;Feature extraction;Surveys;Context modeling;Adaptation models;Deep learning;Clothing industry;Artificial intelligence;deep learning;fashion design},
  doi={10.1109/ACCESS.2023.3306235},
  ISSN={2169-3536},
  month={},}@ARTICLE{9439934,
  author={Nabizadeh, Amir Hossein and Jorge, Joaquim and Gama, Sandra and Gonçalves, Daniel},
  journal={IEEE Access}, 
  title={How Do Students Behave in a Gamified Course?—A Ten-Year Study}, 
  year={2021},
  volume={9},
  number={},
  pages={81008-81031},
  abstract={Gamified learning aims to motivate students using game elements. Although gamification can enhance students' enjoyment and engagement, it is unclear how different students behave in and interact with gamified contexts. To this end, we analyze how different students interact with a gamified course. We devised such an experimental course on Multimedia Content Production (MCP), and ran it for ten years. At each year, we modified it after students' feedback from the previous year. We determined student groups applying clustering techniques to learner performance data, independently analyzed the resulting clusters in terms of behavior, engagement, performance, and also compared those pairwise. Our analysis identified four different student groups (profiles/clusters) according to their performance and interactions with the course across all years. We found out that the best performing students were those that had significantly more interactions with course materials and consistently ranked highest. In addition, we found that performance indicators for students of all groups became stable within the first month after course start, allowing final grades to be predicted with high accuracy by then. Furthermore, all were deadline driven and became mainly active at the end of the semesters (indicating a lack of self-regulation skills). Moreover, we did not find any specific relation between students' groups and gaming profiles (Brainhex categories). Finally, we propose practical implications and guidelines for designing compelling gamified learning experiences.},
  keywords={Games;Education;Unified modeling language;Tools;Task analysis;Syntactics;Semantics;Brainhex categories;gamification;gameful learning;student behavior;clustering},
  doi={10.1109/ACCESS.2021.3083238},
  ISSN={2169-3536},
  month={},}@ARTICLE{9817125,
  author={Ma, Zongbao and Nejat, Mohammad Hossein and Vahdat-Nejad, Hamed and Barzegar, Behnam and Fatehi, Saeed},
  journal={IEEE Access}, 
  title={An Efficient Hybrid Ranking Method for Cloud Computing Services Based on User Requirements}, 
  year={2022},
  volume={10},
  number={},
  pages={72988-73004},
  abstract={An increase in the number of cloud services makes service selection a challenging issue for cloud users. It is important to determine the best service that can fulfill user requirements. To this end, this paper proposes a hybrid multiple-attribute decision-making (MADM) model. The proposed method considers service measurement index cloud (SMICloud) structure for qualitative attributes of cloud services as well as user requirements based on fuzzy values to consider vague user requirements. Analytical hierarchy process (AHP) and fuzzy logic are used to rank cloud services. Furthermore, a fuzzy Delphi filtering method is proposed to decrease the execution time of ranking cloud services. In experiments, different aspects such as accuracy, execution time, scalability, and sensitivity analysis are investigated. The results confirm that the proposed method outperforms available methods in terms of execution time and scalability. Furthermore, the experiments show that the proposed method has achieved an accuracy of 96%.},
  keywords={Cloud computing;Quality of service;Costs;Scalability;Frequency division multiplexing;Fuzzy systems;Ranking (statistics);Cloud computing;quality of service (QoS);Fuzzy Delphi method;cloud user requirement;cloud service ranking},
  doi={10.1109/ACCESS.2022.3189172},
  ISSN={2169-3536},
  month={},}@ARTICLE{9145755,
  author={Luna, José María and Fournier-Viger, Philippe and Ventura, Sebastián},
  journal={IEEE Access}, 
  title={Extracting User-Centric Knowledge on Two Different Spaces: Concepts and Records}, 
  year={2020},
  volume={8},
  number={},
  pages={134782-134799},
  abstract={The growing demand for eliciting useful knowledge from data calls for techniques that can discover insights (in the form of patterns) that users need. Methodologies for describing intrinsic and relevant properties of data through the extraction of useful patterns, however, work on fixed input data, and the data representation, therefore, constrains the discovered insights. In this regard, this paper aims at providing foundations to make the descriptive knowledge that is extracted by pattern mining more user-centric by relying on flexible data structures defined on two different perspectives: concepts and data records. In this sense, items in data can be grouped into abstract terms through subjective hierarchies of concepts, whereas data records can also be organized based on the users' subjective perspective. A series of easy-to-follow toy examples are considered for each of the two perspectives to demonstrate the usefulness and necessity of the proposed foundations in pattern mining. Finally, aiming at experimentally testing whether classical pattern mining algorithms can be adapted to such flexible data structures, the experimental analysis comprises different methodologies, including exhaustive search, random search, and evolutionary approaches. All these approaches are based on well-known and widely recognized techniques to demonstrate the usefulness of the provided foundations for future research works and more efficient and specifically designed algorithms. Obtained insights demonstrate the importance of working with subjectivity: an item is a type of soda but belongs to a pack, including two or more soda types.},
  keywords={Data mining;Grammar;Taxonomy;Data structures;Encoding;Toy manufacturing industry;Databases;Pattern mining;space of concepts;space of records;user-centric knowledge},
  doi={10.1109/ACCESS.2020.3010852},
  ISSN={2169-3536},
  month={},}@ARTICLE{10399479,
  author={Kumar, Rakesh and Gupta, Meenu and Abraham, Ajith},
  journal={IEEE Access}, 
  title={A Critical Analysis on Vertebra Identification and Cobb Angle Estimation Using Deep Learning for Scoliosis Detection}, 
  year={2024},
  volume={12},
  number={},
  pages={11170-11184},
  abstract={Scoliosis is a complicated spinal deformity, and millions of people are suffering from this disease worldwide. Early detection and accurate scoliosis assessment are vital for effective clinical management and patient outcomes. The Cobb Angle (CA) measurement is the most precise method for calculating scoliotic curvature, which plays an essential role in diagnosing and treating scoliosis. This letter has conducted a systematic review to analyze scoliosis detection by vertebra identification and CA estimation using the Preferred Reporting Item for Systematic Review and Meta-Analysis (PRISMA) guidelines. The major scientific databases such as Scopus, Web of Science (WoS), and IEEE Xplorer are explored, where 2017–2023 publications are considered. The article selection process is based on keywords like “Vertebra Identification,” “CA Estimation,” “Scoliosis Detection,” “Deep Learning (DL),” etc. After rigorous analysis, 413 articles are extracted, and 44 are identified for final consideration. Further, several investigations based on the previous work are discussed along with its Proposed Solutions (PS).},
  keywords={Scoliosis;Estimation;Diseases;X-ray imaging;Systematics;Deep learning;Computed tomography;Convolutional neural networks;Vertebra identification;scoliosis detection;CA measurement;DL;convolutional neural network (CNN)},
  doi={10.1109/ACCESS.2024.3353794},
  ISSN={2169-3536},
  month={},}@ARTICLE{9722845,
  author={Sahoh, Bukhoree and Haruehansapong, Kanjana and Kliangkhlao, Mallika},
  journal={IEEE Access}, 
  title={Causal Artificial Intelligence for High-Stakes Decisions: The Design and Development of a Causal Machine Learning Model}, 
  year={2022},
  volume={10},
  number={},
  pages={24327-24339},
  abstract={A high-stakes decision requires deep thought to understand the complex factors that stop a situation from becoming worse. Such decisions are carried out under high pressure, with a lack of information, and in limited time. This research applies Causal Artificial Intelligence to high-stakes decisions, aiming to encode causal assumptions based on human-like intelligence, and thereby produce interpretable and argumentative knowledge. We develop a Causal Bayesian Networks model based on causal science using  $d$ -separation and do-operations to discover the causal graph aligned with cognitive understanding. Causal odd ratios are used to measure the causal assumptions integrated with the real-world data to prove the proposed causal model compatibility. Causal effect relationships in the model are verified based on causal P-values and causal confident intervals and approved less than 1% by random chance. It shows that the causal model can encode cognitive understanding as precise, robust relationships. The concept of model design allows software agents to imitate human intelligence by inferring potential knowledge and be employed in high-stakes decision applications.},
  keywords={Artificial intelligence;Software agents;Decision making;Bayes methods;Cognitive processes;Deep learning;Machine learning;Artificial intelligence;counterfactuals;causal science;do-calculus;causal inference;cognitive computing},
  doi={10.1109/ACCESS.2022.3155118},
  ISSN={2169-3536},
  month={},}@ARTICLE{10250775,
  author={Psychogyios, Konstantinos and Leligou, Helen C. and Melissari, Filisia and Bourou, Stavroula and Anastasakis, Zacharias and Zahariadis, Theodore},
  journal={IEEE Access}, 
  title={SAMStyler: Enhancing Visual Creativity With Neural Style Transfer and Segment Anything Model (SAM)}, 
  year={2023},
  volume={11},
  number={},
  pages={100256-100267},
  abstract={Neural Style Transfer (NST) is a popular technique of computer vision where the content of an image is blended with the style of another, which results in a fused image with certain properties of both original images. This approach has practical applications in various domains and has garnered significant attention in both industry and academia. An interesting application of this technique is segmented style transfer where a segmentation algorithm is used to locate objects within an image and then the style transfer method is performed locally, producing images with different styles for different objects. This approach opens up possibilities for creating visually striking compositions by seamlessly blending various artistic styles onto specific objects within an image, allowing for a new level of creative expression. This paper proposes a novel method that combines Segment Anything Model (SAM), a state-of-the-art vision transformer-based image segmentation model developed by Facebook, with style transfer. Our approach includes performing localized style transfer in selected segmentation regions of an image using classical style transfer algorithms. To ensure smooth transitions between the stylized and non-stylized border we also develop our loss function with a border smoothing technique. Experimental results demonstrate the robustness and effectiveness of the proposed methodology, including the ability to infuse multiple artistic styles into different objects within an image. The contributions of this work include integrating SAM with style transfer, proposing a novel loss function, evaluating the segmented style transfer in multiple content regions, comparing with state-of-the-art approaches, and experimenting with multiple style images for diverse stylization. Our primary focus centers on creating a model that serves as a digital painter across a wide range of image genres and artistic styles.},
  keywords={Image segmentation;Visualization;Semantics;Computer vision;Transformers;Real-time systems;Social networking (online);Machine learning;Segment anything model;segment anything;segmentation;machine learning;style transfer},
  doi={10.1109/ACCESS.2023.3315235},
  ISSN={2169-3536},
  month={},}@ARTICLE{9715110,
  author={Shahroz, Mobeen and Mushtaq, Muhammad Faheem and Majeed, Rizwan and Samad, Ali and Mushtaq, Zaigham and Akram, Urooj},
  journal={IEEE Access}, 
  title={Feature Discrimination of News Based on Canopy and KMGC-Search Clustering}, 
  year={2022},
  volume={10},
  number={},
  pages={26307-26319},
  abstract={The internet provides a very vast amount of sources of news and the user has to search for desirable news by spending a lot of time because the user always prefers their related interest, desirable and informative news. The clustering of the news article having a great impact on the preferences of the user. The unsupervised learning techniques such that K-means Clustering and Spectral Clustering are proposed to categorize the news articles by extracting discriminant features that help the user to search and get informative news without wasting time. The BBC news articles dataset is used to perform experiments that consist of 2225 news articles. The TF-IDF feature extraction technique is used with K-means clustering and Spectral clustering to get the most similar clusters to categorize the news articles in respective domains. Those domains are sports, tech, entertainment, politics, and business. The clustering algorithms are evaluated using adjusted rand index, V-measure, homogeneity score, completeness score, and Fowlkes mallows score. The experimental results illustrated that K-means clustering performs better than spectral clustering using the TF-IDF feature extraction approach. But to improve the results the canopy centroid selection is used with the grid search optimization technique to optimize the results of the Kmeans and named its as a K-Means using Grid Search based on Canopy (KMGC-Search). The experimental results shows the proposed approach can be used as a viable method for the categorization of news articles.},
  keywords={Feature extraction;Clustering algorithms;Machine learning;Training;Text mining;Search engines;Companies;News categorization;K-means;clustering;canopy;machine learning;TF-IDF;grid search},
  doi={10.1109/ACCESS.2022.3152159},
  ISSN={2169-3536},
  month={},}@ARTICLE{10480434,
  author={Gupta, Meenu and Kumar, Rakesh and Abraham, Ajith},
  journal={IEEE Access}, 
  title={Adversarial Network-Based Classification for Alzheimer’s Disease Using Multimodal Brain Images: A Critical Analysis}, 
  year={2024},
  volume={12},
  number={},
  pages={48366-48378},
  abstract={Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that represents a significant and growing public health challenge. This work concisely summarizes AD, encompassing its pathophysiology, risk factors, clinical manifestations, diagnosis, treatment, and ongoing research. The main goal of managing AD is to reduce symptoms while improving the lives of those impacted. This letter has conducted a systematic review to analyze the prediction of AD using the Preferred Reporting Item for Systematic Review and Meta-Analysis (PRISMA) guidelines. The major scientific databases such as Scopus, Web of Science (WoS), and IEEE Xplorer are explored, where 2018–2023 publications are considered. The article selection process is based on keywords like “Alzheimer’s disease,” “Brain Images,” “Deep Learning (DL),” etc. After rigorous analysis, 946 articles were extracted, and 42 were identified for final consideration. Further, several investigations based on the previous work are discussed along with its Proposed Solutions (PS). Finally, a case study on AD detection using the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset and AD Detection Network (ADD-NET) implementation is presented.},
  keywords={Magnetic resonance imaging;Brain modeling;Feature extraction;Training;Computed tomography;Classification algorithms;Analytical models;Alzheimer's disease;Convolutional neural networks;Generative adversarial networks;Positron emission tomography;Biomarkers;Systematics;Alzheimer;brain images;convolutional neural network;generative adversarial network;machine learning;magnetic resonance imaging;positron emission tomography;biomarkers;P-TAU;amyloid beta;systematic review;meta-analysis},
  doi={10.1109/ACCESS.2024.3381956},
  ISSN={2169-3536},
  month={},}@ARTICLE{10341230,
  author={Mondal, Uttam and Mahapatra, Tanmoy and Xin, Qin and Pal, Madhumangal},
  journal={IEEE Access}, 
  title={Generalized m-Polar Fuzzy Planar Graph and Its Application}, 
  year={2023},
  volume={11},
  number={},
  pages={138399-138413},
  abstract={Planarity of crisp graphs is a well-established field, whereas planarity within a fuzzy framework has seen recent development and extensive exploration. In an  $m$ -polar fuzzy graph ( $m$ PFG), each node and edge is associated with  $m$ -components, connected through minimal relationships. However, if one desires to incorporate maximum, average, or other intermediate relationships between nodes and edges, the  $m$ PFG concept becomes inadequate as in the  $m$ -polar fuzzy model, only minimum relation is considered. To address this limitation, a generalized model of  $m$ PFG is introduced in this article, allowing for a broader range of relationships to be considered simultaneously. This paper also discusses the properties of generalized  $m$ -polar fuzzy environments and generalized  $m$ -polar fuzzy graphs ( $\text{G}m$ PFGs), highlighting their isomorphism. Several significant findings and insights are presented in this paper. The article delves into the properties and characteristics of generalized  $m$ -polar fuzzy planar graphs ( $\text{G}m$ PFPGs) and explores various intriguing aspects related to them. Additionally, a novel concept of a generalized  $m$ -polar fuzzy dual graph ( $\text{G}m$ PFDG) is introduced, derived from  $\text{G}m$ PFPGs. The paper establishes a relationship between the dual of a  $\text{G}m$ PFG and  $\text{G}m$ PFG, examining their properties in the context of dual  $\text{G}m$ PFPGs. Lastly, the article discusses an illustrative example of a social group network problem assessing the group’s activity based on attributes such as cooperation, team spirit, awareness, controlling power, good behaviour, and creativity.},
  keywords={Social groups;Behavioral sciences;Uncertainty;Image edge detection;Graph theory;Sustainable development;Social networking (online);Fuzzy systems;Fuzzy graph;m-polar fuzzy graph;planarity of generalized m-polar fuzzy graph;dual of generalized m-polar fuzzy planar graph;fuzzy face},
  doi={10.1109/ACCESS.2023.3339220},
  ISSN={2169-3536},
  month={},}@ARTICLE{10410841,
  author={Mubin, Omar and Alnajjar, Fady and Trabelsi, Zouheir and Ali, Luqman and Parambil, Medha Mohan Ambali and Zou, Zhao},
  journal={IEEE Access}, 
  title={Tracking ChatGPT Research: Insights From the Literature and the Web}, 
  year={2024},
  volume={12},
  number={},
  pages={30518-30532},
  abstract={This article presents a scientometric and literature analysis of current research on ChatGPT, a conversational AI technology developed by OpenAI. Using various databases, 103 relevant articles were retrieved and analyzed through scientometric, quantitative, and application-based approaches. A Google trend analysis and comparison with other generative AI and chatbot technologies were also carried out. The study provides insights into the distribution of ChatGPT publications across different countries and regions, the network of co-occurring keywords, authorship analysis, article typology, and publishing entities. The findings offer a comprehensive overview of the current state of ChatGPT research, highlighting key directions for future research. The study finds that ChatGPT has gained significant attention and interest in online platforms, particularly in technology, education, and healthcare, and highlights potential ethical and legal concerns related to its use. Its applications extend to several literary and text generation areas. We do note that the sample of extracted publications is lower than anticipated due to the niche area of investigation. The article is relevant to researchers, practitioners, and policymakers interested in the field of AI-powered language models, especially ChatGPT.},
  keywords={Chatbots;Bibliometrics;Education;Artificial intelligence;Task analysis;Market research;Search engines;Natural language processing;Open Access;ChatGPT;artificial intelligence;natural language processing;NLM},
  doi={10.1109/ACCESS.2024.3356584},
  ISSN={2169-3536},
  month={},}@ARTICLE{10229152,
  author={Al-Tawil, Marwan and Dimitrova, Vania and Thakker, Dhavalkumar and Abu-Salih, Bilal},
  journal={IEEE Access}, 
  title={Emerging Exploration Strategies of Knowledge Graphs}, 
  year={2023},
  volume={11},
  number={},
  pages={94713-94731},
  abstract={The utilization of semantic web technologies has led to the development of knowledge graphs represented as triples that allow for the exploration of specific and cross-domains. Despite the advantages of semantic links between entities in facilitating user exploration, they can also lead to an overwhelming number of exploration choices that can cause confusion, frustration, uncertainty, and a sense of being lost in the abundant graph, particularly for users who are not familiar with the domain. Thus, identifying exploration strategies is critical to improving user exploration and increasing exploration utility. This study aims to identify exploration strategies that promote knowledge utility (i.e., increase users’ domain knowledge) and exploration experience (i.e., provide users with a positive and pleasant feeling). To accomplish this goal, an experimental user study was conducted, involving lay users in the musical instrument domain, where they were presented with an exploration task and then allowed to freely explore musical instruments. Parameters related to exploration paths were used to analyze the exploration patterns that users follow during their exploration. The findings reveal exploration strategies that promote knowledge utility and exploration experience. This research contributes to the literature on intelligent methods of guiding user exploration through knowledge graphs to enhance exploration effectiveness, which can have broad applications in knowledge graph utilization.},
  keywords={Task analysis;Knowledge graphs;Resource description framework;Instruments;Music;Navigation;Data visualization;Semantic Web;Knowledge graphs;knowledge utility;exploration experience;exploration paths;exploration strategies},
  doi={10.1109/ACCESS.2023.3308514},
  ISSN={2169-3536},
  month={},}@ARTICLE{10413447,
  author={Ghanadian, Hamideh and Nejadgholi, Isar and Osman, Hussein Al},
  journal={IEEE Access}, 
  title={Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models}, 
  year={2024},
  volume={12},
  number={},
  pages={14350-14363},
  abstract={Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.},
  keywords={Synthetic data;Task analysis;Data models;Chatbots;Mental health;Social networking (online);Social factors;Artificial intelligence;Deep learning;Mental health;Synthetic data;Artificial intelligence;deep learning;large language models;suicide detection;synthetic data generation;transformer based models},
  doi={10.1109/ACCESS.2024.3358206},
  ISSN={2169-3536},
  month={},}@ARTICLE{10620272,
  author={Yavas, Cemil Emre and Kim, Jongyeop and Chen, Lei},
  journal={IEEE Access}, 
  title={Mastering Precision in Pivotal Variables Defining Wine Quality via Incremental Analysis of Baseline Accuracy}, 
  year={2024},
  volume={12},
  number={},
  pages={105429-105459},
  abstract={This study investigates the application of machine learning (ML) algorithms to enhance the precision of wine quality assessment, focusing specifically on Portuguese red wine. Amidst the growing interest in leveraging artificial intelligence (AI) for sensory analysis, our research distinguishes itself by employing a rigorous methodological framework. Our approach, named the ‘Incremental Analysis of Baseline Accuracy,’ identifies the chemical variables most predictive of wine quality. This framework aims to streamline the predictive process by pinpointing key variables that significantly influence quality assessments. In this paper, we demonstrate the feasibility of a methodology that precisely determines the criticality of chemical inputs, both their exact values and their correct order, to identify which inputs significantly contribute to the quality assessment of a sensory perception, such as taste. The centerpiece of our paper is a vibrant 3D pie chart that illustrates the percentage criticality of different input variables for perceiving the quality of red wine. This chart symbolizes the essence of our paper: a ‘pie’ representing the empirical conclusion, not mere conjecture. Through this paper, we have shown that it is possible to quantify a qualitative, perceptual aspect like taste perception, which is often believed to be assessable only through subjective conjecture. Moreover, our findings, facilitated by the Incremental Analysis of the Baseline Accuracy method, demonstrate that this perception can be systematically quantified, challenging traditional assumptions about sensory analysis.},
  keywords={Accuracy;Random forests;Support vector machines;Boosting;Predictive models;Analytical models;Prediction algorithms;Artificial intelligence;Machine learning;Algorithm comparison;artificial intelligence (AI);chemometric variables;data analysis;machine learning (ML);Portuguese red wine;predictive analytics;random forest model;sensory analysis;variable selection;wine quality assessment},
  doi={10.1109/ACCESS.2024.3436603},
  ISSN={2169-3536},
  month={},}@ARTICLE{10258158,
  author={Liu, Yiying and Ko, Young Chun},
  journal={IEEE Access}, 
  title={The Optimization of Digital Art Teaching Platform Based on Information Technology and Deep Learning}, 
  year={2023},
  volume={11},
  number={},
  pages={107287-107296},
  abstract={The study aims to improve the daily teaching level of the school and make students enjoy better teaching methods. Firstly, the Internet of Things (IoT) and deep learning (DL) are deeply studied through information technology (IT). Secondly, the calculation methods based on the IoT and DL are analyzed, through which the research model is constructed. Finally, a digital teaching platform is established through the research model to conduct a real-time statistical survey of students and teachers. The results show that students are leading in the daily teaching process. According to the survey results, most students spend 3 to 4 hours in daily extra-curricular learning; 45% of them acquire knowledge mainly through classroom learning, and 23% through online learning. Their main difficulty in learning is learning ability, accounting for 48%. Moreover, it is an energy problem, accounting for 28%. 64% of students are passive learning, far more than 37% of active learning students. This study combines multiple fields across disciplines, such as IT, IoT, and DL. Digital art teaching platforms usually focus on creativity and performance, and combining IoT and DL can provide art students with a more personalized, real-time teaching experience, and promote the cross-application of digital art and cutting-edge technologies.},
  keywords={Education;Digital art;Internet of Things;Sensors;Real-time systems;Optimization;Surveys;Information technology;Deep learning;Information technology;Internet of Things;deep learning;digitization;teaching platform},
  doi={10.1109/ACCESS.2023.3318120},
  ISSN={2169-3536},
  month={},}@ARTICLE{10423763,
  author={Fang, Fulai and Jiang, Xiaohong},
  journal={IEEE Access}, 
  title={The Analysis of Artificial Intelligence Digital Technology in Art Education Under the Internet of Things}, 
  year={2024},
  volume={12},
  number={},
  pages={22928-22937},
  abstract={This study aims to explore the integration of Internet of Things (IoT) technology and artificial intelligence (AI) in art education, assessing its impact on learners’ experiences and learning outcomes. The study first proposes a digital teaching system that enables the IoT and Generative Adversarial Networks (GANs) to play a role in art education by monitoring students’ creative state in real-time, providing immediate feedback, and facilitating the generation of creative works. The system framework includes sensor nodes, an IoT platform, a GAN model, and a user interface to build a real-time interactive environment. Sensor nodes constantly collect physiological, movement, and environmental data from students, and the GAN model receives student data from the IoT platform, combining creative input from students to generate artwork in real-time. The generated works are transmitted to the discriminator through the IoT platform, which evaluates their quality and provides real-time feedback. Students interact with the system through the user interface, observe the generated artwork, adjust generator parameters, and propose new ideas. These interactions influence further artistic creation. The WikiArt public art creation dataset is selected to establish the experimental foundation, and the experimental evaluation focuses on image generation quality, system performance, and student learning outcomes. It is compared with Deep Convolutional Generative Adversarial Network (DCGAN) and Variational Autoencoder (VAE) models. The research results indicate that the designed IoT and GANs integrated system remarkably outperforms DCGAN and VAE in image generation quality, with an Inception Score of 4.5, which is more diverse and recognizable than other models. Regarding system performance, the IoT and GANs integrated system is significantly ahead in image generation speed and user interaction, with a transmission speed of up to 200 Mbps. Regarding student learning outcomes, the system performs excellently in emotional feedback, learning outcomes, and creative work quality, achieving 80% satisfaction and 90% positive feedback. Overall, the research conclusion clearly points out that the integration of IoT and GANs has a significant and comprehensive effect on improving the quality of art education. This study expands the field of art education by integrating IoT and GANs, enhancing students’ creative experiences, and providing innovative methods for art teaching in the digital age.},
  keywords={Education;Art;Artificial intelligence;Real-time systems;Generative adversarial networks;Internet of Things;Image synthesis;Electronic learning;Internet of Things technology;generative adversarial network;art education;digital teaching},
  doi={10.1109/ACCESS.2024.3363655},
  ISSN={2169-3536},
  month={},}@ARTICLE{10531721,
  author={Park, Dabin and Lee, Geonju and Kim, Seonhyeong and Seo, Taewoong and Oh, Hayoung and Ju Kim, Seog},
  journal={IEEE Access}, 
  title={Probability-Based Multi-Label Classification Considering Correlation Between Labels— Focusing on DSM-5 Depressive Disorder Diagnostic Criteria}, 
  year={2024},
  volume={12},
  number={},
  pages={70289-70296},
  abstract={The incidence of depressive disorder in Korea is the highest among OECD countries. The proportion of patients in their 20s is the highest. However, social gaze and false perception are causing problems such as not visiting the hospital or delaying the visit. Accordingly, we suggest a Korean model for predicting depressive disorders using data from online communities widely used by people in their 20s. In many countries, including South Korea, depressive disorders are diagnosed using DSM-5 (Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition) published by the American Psychiatric Association. We propose a model that predicts the probability of a user’s speech corresponding to nine criteria for diagnosing DSM-5 depressive disorder, following advice obtained through periodic meetings with a psychiatrist. The prediction performance was improved by using the correlation between each criterion in the model implementation stage.},
  keywords={Depression;Social networking (online);Correlation;Blogs;Data models;Predictive models;Artificial intelligence;Natural language processing;Psychiatry;Mental health;Artificial intelligence;correlation;depressive disorder;multi-label classification;natural language processing;psychiatry in AI},
  doi={10.1109/ACCESS.2024.3401704},
  ISSN={2169-3536},
  month={},}@ARTICLE{9968012,
  author={Carta, Salvatore M. and Consoli, Sergio and Giuliani, Alessandro and Podda, Alessandro Sebastian and Recupero, Diego Reforgiato},
  journal={IEEE Access}, 
  title={CulturAI: Semantic Enrichment of Cultural Data Leveraging Artificial Intelligence}, 
  year={2022},
  volume={10},
  number={},
  pages={127328-127344},
  abstract={In this paper, we propose an innovative tool able to enrich cultural and creative spots (gems, hereinafter) extracted from the European Commission Cultural Gems portal, by suggesting relevant keywords (tags) and YouTube videos (represented with proper thumbnails). On the one hand, the system queries the YouTube search portal, selects the videos most related to the given gem, and extracts a set of meaningful thumbnails for each video. On the other hand, each tag is selected by identifying semantically related popular search queries (i.e., trends). In particular, trends are retrieved by querying the Google Trends platform. A further novelty is that our system suggests contents in a dynamic way. Indeed, as for both YouTube and Google Trends platforms the results of a given query include the most popular videos/trends, such that a gem may constantly be updated with trendy content by periodically running the tool. The system has been tested on a set of gems and evaluated with the support of human annotators. The results highlighted the effectiveness of our proposal.},
  keywords={Cultural differences;Data analysis;Videos;Urban areas;Video on demand;Global communication;Market research;Semantics;Machine learning;Social networking (online);Computer science in cultural heritage;heterogeneous data analysis;modeling;interlinking;and browsing;semantic-aware representation of cultural data;machine learning;social media},
  doi={10.1109/ACCESS.2022.3226070},
  ISSN={2169-3536},
  month={},}@ARTICLE{10418213,
  author={Ali, Mumtaz and Arshad, Muhammad and Uddin, Ijaz and Ali, Gauhar and Asim, Muhammad and ELAffendi, Mohammed},
  journal={IEEE Access}, 
  title={A Resource Aware Memory Requirement Calculation Model for Memory Constrained Context-Aware Systems}, 
  year={2024},
  volume={12},
  number={},
  pages={19320-19329},
  abstract={Smart spaces are physical environments equipped with sensors, actuators, and other computing devices to gather data and provide intelligent services to users. These spaces are made possible by ubiquitous computing, particularly context-aware computing. Although these systems are mainly implemented on mobile and other resource-constrained wearable devices, different techniques have been adopted for their implementation. Rule-based reasoning is a relatively easy-to-implement approach that can solve real-world problems. Rule-based systems rely on a set of assertions that constitute the working memory and a set of rules that govern what should be done with the set of assertions. Despite its relative simplicity, the working memory size is a critical factor in developing these systems, particularly for resource-constrained devices. In this paper, we propose techniques for efficiently calculating the working memory size. Our results show that all three techniques, DWM, APS, and SAPS, performed well in different ways. However, APS and SAPS consumed from 25% to 100% less memory than existing techniques.},
  keywords={Memory management;Context modeling;Cognition;Smart spaces;Heuristic algorithms;Task analysis;Smart devices;Context-aware systems;rule-based reasoning;working memory},
  doi={10.1109/ACCESS.2024.3361317},
  ISSN={2169-3536},
  month={},}@ARTICLE{10445254,
  author={Ye, Tian},
  journal={IEEE Access}, 
  title={The Analysis of Optimization Strategy of Industrial Design in Automatic Sketch Generation Based on Deep Learning}, 
  year={2024},
  volume={12},
  number={},
  pages={32361-32368},
  abstract={This study is devoted to exploring the strategy of automatic sketch generation and optimization of industrial design based on deep learning. By combining the Generative Adversarial Network (GAN) with the optimization algorithm, this paper proposes an innovative method to realize the automatic generation of high-quality and diverse industrial design sketches. In the experiment, this paper selects SketchyCAD and other public data sets, trains them through deep learning model, and introduces genetic algorithm(GA) and differential evolution algorithm to optimize the parameters. In terms of experimental results, we observed that the quality of generated sketches was significantly improved, and the design sketches generated by the mode (GAN+GA) were more realistic and innovative. The introduction of optimization strategy further improves the generation effect and intelligently adjusts the model parameters to adapt to different design styles. In this paper, the influence of hyperparameter tuning is analyzed in detail, and it is found that the adjustment of learning rate plays a key role in generating quality and diversity. However, the experiment also revealed some challenges and room for improvement. We noticed that the generated results may have the risk of over-fitting in the training process, and with the increase of training times, the diversity gradually decreased. This suggests that more complex model structure and richer data sets are needed to improve the generalization performance. Generally speaking, this study provides new ideas and methods for the integration of deep learning and industrial design. By innovatively combining generation model and optimization algorithm, this research has contributed beneficial research results to the development of industrial design automation. This research is of great significance to promote the intelligence and innovation in the field of industrial design.},
  keywords={Deep learning;Optimization;Data models;Convolutional neural networks;Generative adversarial networks;Shape measurement;Deep learning;Genetic algorithms;Optimization methods;Industrial engineering;Design engineering;Automatic programming;Graphics;Deep learning;sketch generation;optimization strategy;industrial design;generative adversarial network;genetic algorithm},
  doi={10.1109/ACCESS.2024.3370438},
  ISSN={2169-3536},
  month={},}@ARTICLE{10676986,
  author={Fanani, Ahmad Zainul and Maulana Syarif, Arry and Fajar Shidik, Guruh and Marjuni, Aris},
  journal={IEEE Access}, 
  title={Expressing and Developing Melodic Phrases in Gamelan Skeletal Melody Generation Using Genetic Algorithm}, 
  year={2024},
  volume={12},
  number={},
  pages={130512-130523},
  abstract={A novel approach was proposed to develop a composition generation system for creating note sequences representing question-and-answer phrases (QAPs) in melodic phrases. Using a small dataset containing fewer than 10 compositions, the system is expected to generate new melodies that extend beyond the limitations of the original dataset. The modeling of note sequence data and selecting appropriate notes in specific sequences within the melody were chosen for gamelan skeletal melody generation using the Genetic Algorithm (GA) method. Gamelan, a traditional musical ensemble from Java, was selected as the focus of this research, with experiments centered on the gamelan skeletal melody, which plays a role similar to chord progressions in Western music. The evaluation was conducted by statistically analyzing the sequence of notations generated from the dataset and through expert testing. The experimental results demonstrate that the proposed method can generate compositions with well-formed melodic phrases through a small dataset containing varying lengths, data mapping, feature selection based on QAP patterns, and GA. GA can enhance creativity in creating note sequences and new QAP patterns, including novel patterns.},
  keywords={Music;Genetic algorithms;Creativity;Nanoelectromechanical systems;Generative adversarial networks;Feature extraction;Question answering (information retrieval);Melody generation;melodic phrase;questions and answer phrases;genetic algorithm;gamelan},
  doi={10.1109/ACCESS.2024.3457880},
  ISSN={2169-3536},
  month={},}@ARTICLE{10630499,
  author={Jiang, Rong and Mou, Xiaofei},
  journal={IEEE Access}, 
  title={The Analysis of Multi-Track Music Generation With Deep Learning Models in Music Production Process}, 
  year={2024},
  volume={12},
  number={},
  pages={110322-110330},
  abstract={This study aims to explore the application of deep learning models in multi-track music generation to enhance the efficiency and quality of music production. Considering the limited capability of traditional methods in extracting and representing audio features, a multi-track music generation model based on the Bidirectional Encoder Representations from Transformers (BERT) Transformer network is proposed. This model first utilizes the BERT model to encode and represent music data, capturing semantic and emotional information within the music data. Subsequently, the encoded music features are inputted into the Transformer network to learn the temporal relationships and structural patterns among music sequences, thereby generating new multi-track music compositions. The performance of this model is evaluated, revealing that compared to other algorithms, the proposed model achieves an accuracy of 95.98% in music generation prediction, with an improvement in precision by 4.77%. Particularly, the model demonstrates significant advantages in predicting pitch of music tracks. Hence, the multi-track music generation model proposed in this study exhibits excellent performance in accuracy and pitch prediction, offering valuable experimental reference for research and practice in the field of multi-track music generation.},
  keywords={Music;Transformers;Mathematical models;Deep learning;Encoding;Bidirectional control;Production;Deep learning;transformer;music generation;multi-track music;BERT},
  doi={10.1109/ACCESS.2024.3439989},
  ISSN={2169-3536},
  month={},}@ARTICLE{10663721,
  author={Martín-Moncunill, David and García Laredo, Eduardo and Carlos Nieves, Juan},
  journal={IEEE Access}, 
  title={POTDAI: A Tool to Evaluate the Perceived Operational Trust Degree in Artificial Intelligence Systems}, 
  year={2024},
  volume={12},
  number={},
  pages={133097-133109},
  abstract={There is evidence that a user’s subjective confidence in an Artificial Intelligence (AI)-based system is crucial in its use, even more decisive than the objective effectiveness and efficiency of the system. Therefore, different methods have been proposed for analyzing confidence in AI. In our research, we set out to evaluate how the degree of perceived trust in an AI system could affect a user’s final decision to follow AI recommendations. To this end, we established trustworthy criteria that such an evaluation should meet by following a co-creation approach with a multidisciplinary group of 10 experts. After a systematic review of 3,204 articles, we found that none of the tools met the inclusion criteria. Thus, we introduce the so-called “Perceived Operational Trust Degree in AI” (POTDAI) tool that is based on the findings from the expert group and the literature analysis, with a methodology that adds rigor to that employed previously to create similar evaluation tools. We propose a short questionnaire for quick and easy application, inspired by the original version of the Technology Acceptance Model (TAM) with six Likert-type items. In this way, we also respond to the need pointed out by authors such as Vorm and Combs to extend the TAM to address questions related to user perception in systems with an AI component. Thus, POTDAI can be used alone or in combination with TAM to obtain additional information on its usefulness and ease of use.},
  keywords={Artificial intelligence;Law enforcement;Education;Testing;Reliability;Monitoring;Cooperative systems;Human factors;Trusted computing;Artificial intelligence;cooperative systems;human-computer interaction;human factors;trustworthy AI;technology acceptance model},
  doi={10.1109/ACCESS.2024.3454061},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9177542,
  author={Adams, Janet and Hagras, Hani},
  booktitle={2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, 
  title={A Type-2 Fuzzy Logic Approach to Explainable AI for regulatory compliance, fair customer outcomes and market stability in the Global Financial Sector}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={The field of Artificial Intelligence (AI) is enjoying unprecedented success and is dramatically transforming the landscape of the financial services industry. However, there is a strong need to develop an accountability and explainability framework for AI in financial services, based on a risk-based assessment of appropriate explainability levels and techniques by use case and domain. This paper proposes a risk management framework for the implementation of AI in banking with consideration of explainability and outlines the implementation requirements to enable AI to achieve positive outcomes for financial institutions and the customers, markets and societies they serve. The work presents the evaluation of three algorithmic approaches (Neural Networks, Logistic Regression and Type 2 Fuzzy Logic with evolutionary optimisation) for nine banking use cases. We review the emerging regulatory and industry guidance on ethical and safe adoption of AI from key markets worldwide and compare leading AI explainability techniques. We will show that the Type-2 Fuzzy Logic models deliver very good performance which is comparable to or lagging marginally behind the Neural Network models in terms of accuracy, but outperform all models for explainability, thus they are recommended as a suitable machine learning approach for use cases in financial services from an explainability perspective. This research is important for several reasons: (i) there is limited knowledge and understanding of the potential for Type-2 Fuzzy Logic as a highly adaptable, high performing, explainable AI technique; (ii) there is limited cross discipline understanding between financial services and AI expertise and this work aims to bridge that gap; (iii) regulatory thinking is evolving with limited guidance worldwide and this work aims to support that thinking; (iv) it is important that banks retain customer trust and maintain market stability as adoption of AI increases.},
  keywords={Artificial intelligence;Fuzzy logic;Industries;Ethics;Data models;Uncertainty;Government;Regulatory Compliance;Accountability and Explainability;Type-2 Fuzzy Logic;Neural Networks},
  doi={10.1109/FUZZ48607.2020.9177542},
  ISSN={1558-4739},
  month={July},}@ARTICLE{8951256,
  author={Chakraborty, Koyel and Bhattacharyya, Siddhartha and Bag, Rajib},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={A Survey of Sentiment Analysis from Social Media Data}, 
  year={2020},
  volume={7},
  number={2},
  pages={450-464},
  abstract={In the current era of automation, machines are constantly being channelized to provide accurate interpretations of what people express on social media. The human race nowadays is submerged in the idea of what and how people think and the decisions taken thereafter are mostly based on the drift of the masses on social platforms. This article provides a multifaceted insight into the evolution of sentiment analysis into the limelight through the sudden explosion of plethora of data on the internet. This article also addresses the process of capturing data from social media over the years along with the similarity detection based on similar choices of the users in social networks. The techniques of communalizing user data have also been surveyed in this article. Data, in its different forms, have also been analyzed and presented as a part of survey in this article. Other than this, the methods of evaluating sentiments have been studied, categorized, and compared, and the limitations exposed in the hope that this shall provide scope for better research in the future.},
  keywords={Social networking (online);Sentiment analysis;Clustering algorithms;Indexes;Computer science;Tools;Business;Clustering;community;sentiment analysis;social media;social networks},
  doi={10.1109/TCSS.2019.2956957},
  ISSN={2329-924X},
  month={April},}@ARTICLE{8736019,
  author={Zhang, Yongping and Xu, Xiwei and Liu, Ang and Lu, Qinghua and Xu, Lida and Tao, Fei},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Blockchain-Based Trust Mechanism for IoT-Based Smart Manufacturing System}, 
  year={2019},
  volume={6},
  number={6},
  pages={1386-1394},
  abstract={Integrated and collaborative manufacturing system develops as massive data are obtained by the Internet of Things (IoT) technology. However, the “trust tax” imposed on manufacturers during their countless collaborations with customers, suppliers, distributors, governments, service providers, and other manufacturers is very high. Blockchain is an emerging technology that can lead to more transparent, secure, and efficient transactions. It represents a new paradigm, as well as new thinking, of how data can be securely stored, integrated, and communicated among different stakeholders, organizations, and systems that unnecessarily trust each other. Blockchain is greatly useful for reducing the “trust tax,” especially beneficial for the small- and medium-sized enterprises that must tolerate much heavier trust tax than the established manufacturers. This paper investigates the blockchain-based security and trust mechanism and elaborates a particular application of blockchain for quality assurance, which is one of the strategic priorities of smart manufacturing. Data generated in a smart manufacturing process can be leveraged to retrieve material provenance, facilitate equipment management, increase transaction efficiency, and create a flexible pricing mechanism. The dairy industry is used to instantiate the value propositions of blockchain for quality assurance.},
  keywords={Blockchain;Smart manufacturing;Finance;Collaboration;Peer-to-peer computing;Smart contracts;Blockchain;quality assurance;smart manufacturing;trust},
  doi={10.1109/TCSS.2019.2918467},
  ISSN={2329-924X},
  month={Dec},}@ARTICLE{9143412,
  author={Lv, Zhihan and Qiao, Liang and Wang, Qingjun and Piccialli, Francesco},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={Advanced Machine-Learning Methods for Brain-Computer Interfacing}, 
  year={2021},
  volume={18},
  number={5},
  pages={1688-1698},
  abstract={The brain-computer interface (BCI) connects the brain and the external world through an information transmission channel by interpreting the physiological information of the brain during thinking activities. The effective classification of electroencephalogram (EEG) signals is the key to improving the performance of the system. To improve the classification accuracy of EEG signals in the BCI system, the transfer learning algorithm and the improved Common Spatial Pattern (CSP) algorithm are combined to construct a data classification model. Finally, the effectiveness of the proposed algorithm is verified. The results show that in actual and imagined movements, the accuracy of the left- and right-hand movements at different speeds is higher than when the speeds are the same. The proposed Adaptive Composite Common Spatial Pattern (ACCSP) and Self Adaptive Common Spatial Pattern (SACSP) algorithms have good classification effects on 5 subjects, with an average classification accuracy rate of 83.58 percent, which is an increase of 6.96 percent compared with traditional algorithms. When the training sample size is 10, the classification accuracy of the ACCSP algorithm is higher than that of the traditional CSP algorithm. The improved CSP algorithm combined with transfer learning embodies a good classification effect in both ACCSP and SACSP. Especially, the performance of SACSP mode is better. Combining the improved CSP algorithm proposed with the CSP-based transfer learning algorithm can improve the classification accuracy of the BCI classifier.},
  keywords={Electroencephalography;Classification algorithms;Machine learning;Brain modeling;Machine learning algorithms;Visualization;Brain-computer interface;machine learning;transfer learning;EEG signals;motor imagination;common spatial pattern},
  doi={10.1109/TCBB.2020.3010014},
  ISSN={1557-9964},
  month={Sep.},}@ARTICLE{609829,
  author={Hatton, L.},
  journal={IEEE Computational Science and Engineering}, 
  title={The T experiments: errors in scientific software}, 
  year={1997},
  volume={4},
  number={2},
  pages={27-38},
  abstract={Extensive tests showed that many software codes widely used in science and engineering are not as accurate as we would like to think. It is argued that better software engineering practices would help solve this problem, but realizing that the problem exists is an important first step.},
  keywords={Software measurement;Aerodynamics;Software testing;Laboratories;Computer industry;Area measurement;Application software;Radio access networks;Floating-point arithmetic;Fault detection},
  doi={10.1109/99.609829},
  ISSN={1558-190X},
  month={April},}
