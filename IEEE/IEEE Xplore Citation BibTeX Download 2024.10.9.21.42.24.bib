@INPROCEEDINGS{552698,
  author={Kosheleva, O. and Cabrera, S.D. and Gibson, G.A. and Koshelev, M.},
  booktitle={Proceedings of IEEE 5th International Fuzzy Systems}, 
  title={Fast implementations of fuzzy arithmetic operations using fast Fourier transform (FFT)}, 
  year={1996},
  volume={3},
  number={},
  pages={1958-1964 vol.3},
  abstract={In engineering applications of fuzzy logic, the main goal is not to simulate the way the experts really think, but to come up with a good engineering solution that would (ideally) be better than the expert's control. In such applications, it makes perfect sense to restrict ourselves to simplified approximate expressions for membership functions. If we need to perform arithmetic operations with the resulting fuzzy numbers, then we can use simple and fast algorithms that are known for operations with simple membership functions. In other applications, especially the ones that are related to humanities, simulating experts is one of the main goals. In such applications, we must use membership functions that capture every nuance of the expert's opinion; these functions an therefore complicated, and fuzzy arithmetic operations with the corresponding fuzzy numbers become a computational problem. In this paper, we design a new algorithm for performing such operations. This algorithm uses fast Fourier transforms (FFTs) to reduce computation time from O(n/sup 2/) to O(nlog(n)) (when n is the number of points x at which we know the membership functions /spl mu/(x)). To compute FFT even faster, we propose to use special hardware.},
  keywords={Data processing;Fuzzy logic;Humans;Fuzzy control;Digital arithmetic;Temperature control;Heat engines;Psychology;Decision making;Marine vehicles},
  doi={10.1109/FUZZY.1996.552698},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10476921,
  author={Bu, Yinyan and Rajamäki, Robin and Sarangi, Pulak and Pal, Piya},
  booktitle={2023 57th Asilomar Conference on Signals, Systems, and Computers}, 
  title={Harnessing Holes for Spatial Smoothing with Applications in Automotive Radar}, 
  year={2023},
  volume={},
  number={},
  pages={1308-1312},
  abstract={This paper studies spatial smoothing using sparse arrays in single-snapshot Direction of Arrival (DOA) estimation. We consider the application of automotive MIMO radar, which traditionally synthesizes a large uniform virtual array by appropriate waveform and physical array design. We explore deliberately introducing holes into this virtual array to leverage resolution gains provided by the increased aperture. The presence of these holes requires re-thinking DOA estimation, as conventional algorithms may no longer be easily applicable and alternative techniques, such as array interpolation, may be computationally expensive. Consequently, we study sparse array geometries that permit the direct application of spatial smoothing. We show that a sparse array geometry is amenable to spatial smoothing if it can be decomposed into the sum set of two subsets of suitable cardinality. Furthermore, we demonstrate that many such decompositions may exist-not all of them yielding equal identifiability or aperture. We derive necessary and sufficient conditions to guarantee identifiability of a given number of targets, which gives insight into choosing desirable decompositions for spatial smoothing. This provides uniform recovery guarantees and enables estimating DOAs at increased resolution and reduced computational complexity. 1},
  keywords={Geometry;Sufficient conditions;Smoothing methods;Direction-of-arrival estimation;Estimation;Apertures;Radar applications},
  doi={10.1109/IEEECONF59524.2023.10476921},
  ISSN={2576-2303},
  month={Oct},}@INPROCEEDINGS{5568730,
  author={Siming Wang and Yingli Fan},
  booktitle={2010 The 2nd Conference on Environmental Science and Information Application Technology}, 
  title={A vision location algorithm for CCD camera based on geometric knowledge}, 
  year={2010},
  volume={1},
  number={},
  pages={430-433},
  abstract={In this paper, a simple and practical new algorithm was proposed to solve the monocular vision-based camera positioning of spatial objects as well as the alternating invariance principle based on projective geometry. The new algorithm avoids the cumbersome camera calibration and the accurate solution of matrix equations. It solves the non-linear single-mapping of single chart taken by non-standard orders CCD camera from the 2D image plane to the true 3D planar according to a simple geometrical relationship. It also revises the lens to reach the high accuracy and the low computational. The experimental result shows that this new algorithm has a high availability in several cases, and it provides a new way of thinking for the measurement, positioning as well as three-dimensional reconstruction of the computer vision problems.},
  keywords={Optical imaging;camera spatial orientation;geometric knowledge;the cross-ratio invariance;computer vision},
  doi={10.1109/ESIAT.2010.5568730},
  ISSN={},
  month={July},}@ARTICLE{6362366,
  author={Boroni, G. and Clausse, A. and D'Amato, J. P. and Bauza, C. G.},
  journal={IEEE Latin America Transactions}, 
  title={Thermal insulation in houses and sheds}, 
  year={2012},
  volume={10},
  number={5},
  pages={2195-2201},
  abstract={Thermal insulation is usually needed for large buildings because of the requirement to comply with quality standards while for residential houses usually the builders suggest some kind of insulation. in general, the users do not know the subject and think that both heating and cooling of rooms is solved using air conditioning systems. Moreover, most people do not know how to reduce electricity bills, gas, etc. and they spend large amounts of money because they believe that is the price to pay for these services. In this paper is presented a computational tool to analyze the influence of thermal insulation on heat transfer by conduction through the roof of a certain room. The application displays the advantages of installing thermal insulation in different weather conditions in various regions of Argentina, and provides economic arguments for design and evaluation of each work.},
  keywords={Artificial intelligence;Thermal management;Insulation;Biological system modeling;Human computer interaction;Decision support systems;Energy conservation;Insulation thermal factors},
  doi={10.1109/TLA.2012.6362366},
  ISSN={1548-0992},
  month={Sep.},}@INPROCEEDINGS{8190711,
  author={Mishra, Sumita and Raj, Rajendra K. and Tymann, Paul and Fagan, Jamie and Miller, Sage},
  booktitle={2017 IEEE Frontiers in Education Conference (FIE)}, 
  title={CyberCSP: Integrating cybersecurity into the computer science principles course}, 
  year={2017},
  volume={},
  number={},
  pages={1-5},
  abstract={The demand for cybersecurity professionals is projected to grow substantially, with the US Bureau of Labor Statistics reporting that employment in cybersecurity within the US will grow by 18% from 2014 to 2024, much faster than the average for all occupations. As creating a cyberspace workforce has become a matter of national security for every country, cybersecurity needs to be taught at all levels, to all students, in the educational system. The good news is that cybersecurity is also a topic that students from a wide variety of backgrounds find interesting, and as a result, it motivates them to study computing too. Over the past two decades, there has been an increased effort worldwide to incorporate computer science and computational thinking into the middle and high school curriculum. The CS10K initiative in the US has led to projects to introduce computer science at the K-12 educational level. One of these initiatives, the new Advanced Placement (AP) course in Computer Science Principles (CSP), was designed to introduce computer science in an engaging way, show students how computing is relevant in their lives, and to attract a diverse group of students to computing. The CSP Curriculum Framework allows for multiple implementations of the CSP course, permitting course designers to develop courses to engage and attract specific groups of students and that focus on specific themes in computing. This paper describes an approach to develop a new CSP course, CyberCSP, which integrates cybersecurity first principles throughout the course. The approach builds on an CSP course that was created from a previous collaboration between the Computer Science Department at Rochester Institute of Technology, Rochester, New York, and the Webster Central School District in Webster, New York. The paper discusses the background, details of the earlier CSP course, how relevant cybersecurity content was identified, and then integrated into the CSP course to create the CyberCSP variant of the Computer Science Principles course.},
  keywords={Computer science;Collaboration;Employment;Computer crime},
  doi={10.1109/FIE.2017.8190711},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9962741,
  author={Agarwal, Jutshi and Piatt, Emily and Imbrie, P. K.},
  booktitle={2022 IEEE Frontiers in Education Conference (FIE)}, 
  title={Team formation in engineering classrooms using multi-criteria optimization with genetic algorithms}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The research-to-practice paper presents applications of genetic algorithms using multi-criterion optimization to designate student-teams in an academic setting. Teamwork skills are becoming a more desirable trait in industry today and hence more instructors are using teamwork in their engineering courses. ABET also requires engineering degree programs to have student outcomes that provide them with "an ability to function effectively on a team whose members together provide leadership, create a collaborative and inclusive environment, establish goals, plan tasks, and meet objectives." This, however, comes with its challenges because the literature suggests that random or student-selected teams tend to lead to dysfunctional behaviors. Instructor-designated academic teams based on skills, learning personalities, and demographics are known to be more effective in promoting learning and positive interactions. Creating optimal homogeneous or heterogeneous teams based on multiple criteria (e.g., prior knowledge, skills, abilities, psychosocial, demographics) can be a complex and time-consuming task when done manually, especially when large numbers of students are involved.This study presents an expansion of previous work that used single-criterion genetic algorithm optimization of teams in a first-year classroom. The research question answered in this study is, how do teams formed using an algorithm that optimizes multiple criteria with genetic algorithms represent heterogeneity when compared to teams formed manually? Using a Vector Evaluated Genetic Algorithm (VEGA), optimization of multiple skills is conducted to attain uniform heterogeneity in the classroom. The algorithm uses discrete integer-type representations as a basic unit of team configuration. Self-reported student competency data on three different computational skills were used. Teams were formed for approximately 1300 students enrolled in a first-year engineering design thinking course at a large Midwestern University. Four-member teams were maximized with a minimum number of teams with 3 students in each section. Average skills of the teams are calculated and the standard deviation in class is minimized for each of three skills parallelly. The algorithm also aims to maintain diversity of teams based on gender and ethnicity.Results presented include visualization of team-configurations and comparison with teams formed manually using the same criteria. The aim of the algorithm is to optimize students into teams that have skills and demographics uniformly distributed across the classroom. Future implications of this study include the potential to use flexible algorithm-based team formations that are built with standard genetic operators so that optimization criteria can be modified by the instructor. Such algorithms can reduce the time needed to manually form teams by a considerable amount and optimize the distribution of skills more uniformly. Steps to further this study will involve investigating whether teams formed using these criteria are more effective.},
  keywords={Industries;Leadership;Genetics;Question answering (information retrieval);Teamwork;Behavioral sciences;Task analysis;genetic algorithm;multi-criteria optimization;team formation},
  doi={10.1109/FIE56618.2022.9962741},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{6182548,
  author={Yonghu Chang and Feng Liu},
  booktitle={Proceedings of 2011 International Conference on Computer Science and Network Technology}, 
  title={Wireless sensor intrusion detection system based on the theory of evidence}, 
  year={2011},
  volume={4},
  number={},
  pages={2811-2814},
  abstract={According to the feature that normal data and abnormal data in wireless sensor networks have no significant difference, this paper proposes intrusion detection model based on D-S evidence theory. Intrusion detection model views the standard deviation between data flow and historical data of each sensor as intrusion detection feature value, and then all these values treated as a group of data will be clustered. At last, the model fuses the clustering results by using D-S evidence theory to obtain a comprehensive assessment result, which can reflect the security of the sensor. The way of this algorithm to recognize the target is similar to human thinking, with high reliability, and has obvious advantages on computational complexity.},
  keywords={Communication system security;Wireless communication;Hardware;Wireless sensor networks;Educational institutions;IDS;Wireless sensor network;evidence theory;BPN},
  doi={10.1109/ICCSNT.2011.6182548},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9323777,
  author={Chaabane, Ferdaous and Réjichi, Safa and Tupin, Florence},
  booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Comparison Between Multitemporal Graph Based Classical Learning and LSTM Model Classifications for Sits Analysis}, 
  year={2020},
  volume={},
  number={},
  pages={144-147},
  abstract={Very High Resolution (VHR) multispectral Satellite Image Time Series (SITS) enables the production of temporal land cover maps, thanks to high spatial, temporal and spectral resolution of modern earth observation programs. Besides, statistical learning methods applied to SITS monitoring and analysis have created relatively efficient semi-automatic classification techniques. It would therefore be natural to think that the use of deep learning methods on SITS would lead to advances comparable to those known in the field of computer vision. However, when applied to concrete cases, the results are not as convincing. This paper proposes a comparison between a SOTAG (Spatial-Object Temporal Adjacency Graphs) SVM based spatio-temporal classification approach and the Recurrent Neuronal Network (RNN), LSTM (Long Short-Term Memory) model which is trained by historical SITS. The trained LSTM networks are then used to predict new time series data. Both methods perform a spatio-temporal map indicating the temporal profiles of cartographic regions. The proposed approaches will be applied on real and simulated SITS data. We will demonstrate that both results are comparable despite computational times and algorithms complexity.},
  keywords={Support vector machines;Remote sensing;Deep learning;Monitoring;Indexes;Image color analysis;Classification algorithms;SITS analysis;temporal profiles classification;Graph based SVM classification;RNN;LSTM model etc.},
  doi={10.1109/IGARSS39084.2020.9323777},
  ISSN={2153-7003},
  month={Sep.},}@INPROCEEDINGS{6860891,
  author={Thomas, Gabriel and Annamalai, Manickavasagan},
  booktitle={2014 IEEE International Instrumentation and Measurement Technology Conference (I2MTC) Proceedings}, 
  title={Texture analysis using income inequality metrics}, 
  year={2014},
  volume={},
  number={},
  pages={988-992},
  abstract={Texture analysis on digital images can be used to correctly segment areas of an image and/or classify different objects within the field of view of a digital camera. Depending on the application, one can use a Gray Level Co-occurrence Matrix (GLCM) to detect patterns or a simple contrast measure such as variance can be a good metric as well. In this work, our main objective is to define a set of new texture metrics simple enough to be computationally efficient so that fast processing is feasible. Thus in our previous two texture techniques mentioned before, GLCM and variance, metrics such as variance would be selected for comparison purposes as they require less computational time. Thinking outside the box, we would like to introduce the use of income inequality metrics used in the field of economy to measure the distribution of income and wealth inequality within a population. We found that these metrics can be used on texture analysis of digital images.},
  keywords={Measurement;Indexes;Training;Sociology;Statistics;Computer vision;Computers;texture analysis;Gini index;Theil index;Atkinson Index;entropy;income inequality metrics},
  doi={10.1109/I2MTC.2014.6860891},
  ISSN={1091-5281},
  month={May},}@ARTICLE{4302680,
  author={Shum, Simon Buckingham},
  journal={IEEE Software}, 
  title={There's Nothing Like a Good Argument ...}, 
  year={2007},
  volume={24},
  number={5},
  pages={21-23},
  abstract={Since computing pioneers Vannevar Bush and Doug Engelbart envisioned computational support for argumentation, many have pursued the exciting vision of tools for capturing and augmenting collective reasoning. Designers would be able to capture their deliberations on the fly during design sessions, with intuitive visualizations assisting participatory analysis by diverse stakeholders. These traces would later help recover design rationale. When managing requirements, we can think of argument schemes as reusable patterns for tightening up deliberations. Project reviews are an obvious candidate, where decisions must be justified, often to be signed off, and resources committed. As meeting capture becomes a practical reality, we have the basis for requirements platforms that provide new forms of multimedia requirements and rationale traceability.},
  keywords={Indexing;Engineering management;Software engineering;Software testing;System testing;Design engineering;Knowledge engineering;Software libraries;Software tools;Real time systems;software requirements;argument schemes;concept mapping;tools},
  doi={10.1109/MS.2007.148},
  ISSN={1937-4194},
  month={Sep.},}@INPROCEEDINGS{5692316,
  author={Soria-Alcaraz, Jorge A. and Santigo-Montero, Raúl, and Carpio, Martín},
  booktitle={2010 IEEE Electronics, Robotics and Automotive Mechanics Conference}, 
  title={One Criterion for the Selection of the Cardinality of Learning Set Used by the Associative Pattern Classifier}, 
  year={2010},
  volume={},
  number={},
  pages={80-84},
  abstract={The Associative Pattern Classifier (CAP) is a novel approach to solve the pattern classification problem. Recent experiments of the behavior of this classifier in different applications have given encouraging results. Due a this evidence, It has been thinking about the existence of a minimum number for which a higher value of samples used in the learning phase of this classifier brings a very low effect over their classification performance. This paper present an empiric way to obtain this minimum number based in the structure of the used database. this method allows us to define a minimum size for the set used in the learning phase of CAP for which the final classification performance will be reasonably stable, optimizing time and computational resources in the process.},
  keywords={Databases;Glass;Lenses;Training;Vectors;Support vector machine classification;Associative memory;CAP;Learning phase;Pattern Classification problem;Pattern Recognition},
  doi={10.1109/CERMA.2010.20},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8470577,
  author={Darrah, Timothy and Hutchins, Nicole and Biswas, Gautam},
  booktitle={ISR 2018; 50th International Symposium on Robotics}, 
  title={Design and Development of a Low-Cost Open-Source Robotics Education Platform}, 
  year={2018},
  volume={},
  number={},
  pages={1-4},
  abstract={The impact of robotics has grown beyond research laboratories and industrial facilities into home environments and primary and secondary school classrooms. Of particular interest to us are robots for education. In general, educational robotics kits are expensive and proprietary, or cheap and unreliable. This research seeks to bridge that gap by providing a hands on open-source robotics learning environment that is both inexpensive and reliable. In this paper, we review the applicability of such environments to support the synergistic learning of computational thinking (CT) and STEM, with an emphasis on Computer Science (CS) concepts and practices. The CT and Advanced Placement CS Principles frameworks (from the US) govern the design and implementation of our system. We discuss the hardware system of the robot and the accompanying software architecture that runs on Linux-based single board computers. We conclude with results from a small pilot study analyzing the usability and curricular effectiveness of the system.},
  keywords={},
  doi={},
  ISSN={},
  month={June},}@INPROCEEDINGS{773593,
  author={Yhao Yongping and Huang Fang and Guo Jingjun},
  booktitle={IEEE 1999 International Geoscience and Remote Sensing Symposium. IGARSS'99 (Cat. No.99CH36293)}, 
  title={Desertification research based on digital Earth}, 
  year={1999},
  volume={1},
  number={},
  pages={646-648 vol.1},
  abstract={Digital Earth is the trend for geospatial research, it will help effective and efficient sharing of spatial data all over the world. In this paper, the authors through analyzing the developing background and trend of information society, think that with the development of global spatial information infrastructure, the technologies needed for digital Earth such as computational science, satellite imagery, and metadata etc. have matured. So it is the time to do some experimental application research based on digital Earth. Desertification is a key reason to influence environment change, it is a spatial related globalization problem. Now with the development of remote sensing, geographic information system, and network technology, people have with the probability to deal with mass desertification data through Internet, and the direction of it is to connect with digital Earth. So the author selected Horqin desertification area as an experimental region with the technology support of them and got an good result. According to the dynamic research, for the people's activity, the desertification in the area developed fast from 1950s to 1970s, and more fast than before from 1970s to 1990s. If detracted the people's bad factor to the area or by the help of them, the ecological environment would be recovered again. The research result is gotten by commuter rather than go to investigation in the place, so the method will have an important meaning for the general improvement and the ecological environment recovering of Horqin sandy area, it also has a good role for making decision by the support of digital Earth technology for government.},
  keywords={Earth;Image analysis;Information analysis;Geoscience;Satellites;Globalization;Remote sensing;Geographic Information Systems;IP networks;Government},
  doi={10.1109/IGARSS.1999.773593},
  ISSN={},
  month={June},}@INPROCEEDINGS{8456081,
  author={Jäger, Markus and Nadschläger, Stefan and Küng, Josef},
  booktitle={2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)}, 
  title={Concepts for Trust Propagation in Knowledge Processing Systems - A Brief Introduction and Overview}, 
  year={2018},
  volume={},
  number={},
  pages={1502-1505},
  abstract={What is "Trust"? Everybody has a sense of trusting people or institutions, but how is trust defined? The definition of trust always depends on the specific field of research and application, which makes it hard to answer this question in general at a computational level. Thinking of knowledge processing systems we face this question twice. How can we define and calculate trust values for the input data and, more challenging, what is the trust value of the output? Within this paper we consider a binary, a probabilistic, an opinion-space and - our recently developed approach - a weighted arithmetic mean trust model. Then we show ways, how knowledge processing systems can handle these trust values and propagate them through a network of processing steps in a way that the final results are representative. With these presented and developed models, we can give insights to the topic of defining and propagating trust in knowledge processing systems.},
  keywords={Probabilistic logic;Knowledge engineering;Semantic Web;Cognition;Uncertainty;Conferences;Measurement;Trust;Propagation;Knowledge Processing Systems;Trust Metrics;Trust Models;Precision},
  doi={10.1109/TrustCom/BigDataSE.2018.00212},
  ISSN={2324-9013},
  month={Aug},}@INPROCEEDINGS{4663749,
  author={Reed, Daniel A.},
  booktitle={2008 IEEE International Conference on Cluster Computing}, 
  title={Clouds, clusters and ManyCore: The revolution ahead}, 
  year={2008},
  volume={},
  number={},
  pages={1-1},
  abstract={Without doubt, scientific discovery, business practice and social interactions are moving rapidly from a world of homogeneous and local systems to a world of distributed software, virtual organizations and cloud computing infrastructure, all powered by multicore processors and large-scale infrastructure. In science, a tsunami of new experimental and computational data and a suite of increasingly ubiquitous sensors pose vexing problems in data analysis, transport, visualization and collaboration. In society and business, software as a service and cloud computing are empowering distributed groups. Letpsilas step back and think about the longer term future. Where is the technology going and what are the implications? What architectures are appropriate? How to we manage power and scale? What are the right size building blocks? How do we come to grips with the fact that our clusters and data centers are now bigger than the Internet was just a few years ago? How do we develop and support malleable software? What is the ecosystem of components in which distributed, data rich applications will operate? How do we optimize performance and reliability? How do we program these systems?},
  keywords={},
  doi={10.1109/CLUSTR.2008.4663749},
  ISSN={2168-9253},
  month={Sep.},}@INBOOK{10183895,
  author={Paulo, Sergio Rufino Henrique and Ramjee, Prasad},
  booktitle={6G Visions for a Sustainable and People-centric Future: From Communications to Services, the CONASENSE Perspective}, 
  title={2 CONASENSE, Challenges, and Use Cases Beyond 2030}, 
  year={2023},
  volume={},
  number={},
  pages={5-14},
  abstract={6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770227506},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10183895},}@INPROCEEDINGS{10372895,
  author={Chung, Victor and Bravo, Jessie and Heredia, Armando Moreno and Alarcón, Roger},
  booktitle={2023 IEEE 3rd International Conference on Advanced Learning Technologies on Education & Research (ICALTER)}, 
  title={Digital Competence of Mathematics teachers based on DigCompEdu in Regular Basic Education in the Lambayeque region}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={The current study aimed to assess the digital competence level among 41 mathematics teachers from the regular basic education sector in the public domain of the Lambayeque region. Utilizing the European Framework for the Digital Competence of Educators (DigCompEdu), key areas such as Professional Engagement, Teaching and Learning, and Open Education were scrutinized. Findings indicated a competent level in Professional Engagement, yet they revealed that teachers are still at initial stages regarding the integration of digital tools in teaching and the use of open educational resources. Although variables like gender, age, and academic background showed no significant differences, it was noted that both the technological infrastructure of institutions and support for professional development positively impact digital competences. This underlines the importance of reinforcing educational policies related to training and digital resources to promote a substantial improvement in mathematics teaching, as a key factor for the development of students’ critical and computational thinking.},
  keywords={Training;Education;Europe;Open Educational Resources;Market research;Mathematics;digital competencies;teacher;DigCompEdu;mathematics;regular basic education},
  doi={10.1109/ICALTER61411.2023.10372895},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{736857,
  author={Leon de la Barra, G.E. and Leon de la Barra, M.B. and Urbina, A.M.},
  booktitle={FIE '98. 28th Annual Frontiers in Education Conference. Moving from 'Teacher-Centered' to 'Learner-Centered' Education. Conference Proceedings (Cat. No.98CH36214)}, 
  title={Real and virtual workshops in mathematics [engineering education]}, 
  year={1998},
  volume={1},
  number={},
  pages={319-321 vol.1},
  abstract={It is well known that many engineering students, mainly freshmen have a lack of teamwork and effective communication skills. It is also apparent that the amazing development of multimedia computer software and communication technologies have made more evident those weaknesses and, at the same time, have shown that many freshman students need to be trained, in order to use more efficiently the computational technology. In order to overcome these weaknesses, the authors have designed a long-term program in mathematics organized in stages and oriented to freshman engineering and architecture students. In the first stage, they ran two workshops incorporated to the regular first year maths course of engineering and architecture and developed in the classroom. In both workshops, they used cooperative learning techniques and divergent thinking methods. They also have developed a new assessment scheme to evaluate the students' performance. In the second stage they have offered a special course in mathematics for freshman architecture students that combines a traditional lecture format with "hands on" student's activities, i.e., by using multimedia resources and Internet tools as instructional media.},
  keywords={Engineering education},
  doi={10.1109/FIE.1998.736857},
  ISSN={0190-5848},
  month={Nov},}@INPROCEEDINGS{5203821,
  author={Ferrin, Giovanni and Snidaro, Lauro and Foresti, Gian Luca},
  booktitle={2009 12th International Conference on Information Fusion}, 
  title={Structuring relations for fusion in intelligence}, 
  year={2009},
  volume={},
  number={},
  pages={1621-1626},
  abstract={Humans daily infer causal structure from patterns of correlation and learn about categories and hidden properties of objects based on experience and knowledge. A Bayesian approach seems to best model human reasoning over structures, relations and links, and it is possible to provide a detailed computational account of how a number of basic structural forms can be inferred from various types of data (feature sets, similarity matrices, relations). In the literature some algorithms have been proposed that generate candidate model structures from graph grammars, compute the probability of the data given each candidate model, and identify the model with maximum posterior probability given the data. The structural representation, being generated by algorithms comparable to human thinking (according to the cognitive sciences community) should be also easily understandable and usable by analysts for further investigation.},
  keywords={Intelligent structures;Humans;Intelligent sensors;Bayesian methods;Logic;Mathematics;Computer science;Fusion power generation;Inference algorithms;Algorithm design and analysis;Hard soft data fusion;Defense and intelligence;Probability Theory;Bayesian inference},
  doi={},
  ISSN={},
  month={July},}@INBOOK{10183902,
  author={Ernestina, Cianca and Mauro, De Sanctis and Tommaso, Rossi},
  booktitle={6G Visions for a Sustainable and People-centric Future: From Communications to Services, the CONASENSE Perspective}, 
  title={7 Localization of Low Complexity and Low Power Consumption IoRT Terminals}, 
  year={2023},
  volume={},
  number={},
  pages={97-106},
  abstract={6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770227506},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10183902},}@INPROCEEDINGS{609948,
  author={Ramamritham, K.},
  booktitle={Proceedings Third International Workshop on Object-Oriented Real-Time Dependable Systems}, 
  title={Issues in achieving temporal and semantic coherency in distributed real-time applications}, 
  year={1997},
  volume={},
  number={},
  pages={161-162},
  abstract={Modern information-intensive applications require timely access to temporally accurate data. This demands the collection, integration and processing of temporally-coherent data and its display in a "continuous" fashion. When utilizing several pieces of information, each must be fresh relative to the use of that information-and together, they must be relatively consistent. The techniques used must ensure temporal coherency among the data being integrated. When information from multiple media must be processed and presented, the quality of the final information must "make sense". This leads to semantic coherency requirements. Techniques must support the processing of such data under strict timing concerns too. Timeliness is an important QoS (quality of service) parameter. The impedance mismatch between what users think they want and what the system components involved are and what they can deliver, plus the multiplicity of components that must be orchestrated together makes the problem of guaranteeing a specified QoS a challenging one. Specifically, we need (1) precise ways of specifying QoS requirements and (2) an integrated platform supporting hard real-time control tasks, multimedia data and a distributed data repository, built over a common set of computational resources. In this paper, we elaborate on these two needs.},
  keywords={Quality of service;Jitter;Streaming media;Production facilities;Storms;Auditory displays;Timing;Concrete;Fuses;Sensor fusion},
  doi={10.1109/WORDS.1997.609948},
  ISSN={},
  month={June},}@INPROCEEDINGS{9869125,
  author={Lai, Ah–Fur and Lin, Hsing–Hsuan and Yang, Cheng-Ying and Liang, Dan–Ling},
  booktitle={2022 IEEE International Conference on Consumer Electronics - Taiwan}, 
  title={The Effect of integrating Peer Tutoring Strategy in Programming Learning}, 
  year={2022},
  volume={},
  number={},
  pages={487-488},
  abstract={Programming ability is a fundamental skill for engineers. The purpose of this study was to integrate the peer tutoring strategy in Scratch programming learning for students. This study designed six learning modules including three procedure-oriented structures, procedure definition and call, game design, and debug. A quasi experiment design was adopted for conducting a learning experiment in a junior high school in Taipei city. The learning experiment lasted for one and half month. The research results revealed that peer tutoring strategy has significant positive impact on Scratch achievement. In addition, Programming learning can enhance the students' computational thinking abilities by peer tutoring or general teaching method significantly.},
  keywords={Urban areas;Education;Games;Programming;Consumer electronics},
  doi={10.1109/ICCE-Taiwan55306.2022.9869125},
  ISSN={2575-8284},
  month={July},}@INPROCEEDINGS{8232245,
  author={Ichien, Masumi and Emura, Masafumi and Ogawa, Masatsugu and Yano, Masafumi},
  booktitle={OCEANS 2017 - Anchorage}, 
  title={Swarm control for collaborative continuous searching with “autonomous and adaptive control”}, 
  year={2017},
  volume={},
  number={},
  pages={1-5},
  abstract={Autonomous swarm control, which is expected to be able to handle multiple unmanned vehicles (UxVs), is an important technology that can be applied to many operations and incorporated in many systems. For operations in real environments, we have to consider severe conditions under which communications between UxVs may be inadequate and the environment changes unexpectedly. In addition to optimality, adaptability (meaning robustness to severe and unexpected conditions) is important in real situations. However, there are no quantitative benchmarks for algorithms to have both optimality and adaptability. Here, to reconcile optimality and adaptability, we have developed an “autonomous and adaptive control”. The distinctive features of this algorithm is that it simply uses the purposes of a system, such as efficiencies, to control elements and it has a distributed optimization architecture without a centralized control unit. We think that it is promising for autonomous swarm control with optimality and adaptability in real environments. In this paper, we benchmark several swarm control algorithms including our own. We compare two conventional algorithms with ours in a scenario involving a continuous search operation where the UxVs keep moving and searching. We also devise performance indicators for this operation and evaluate the algorithms in terms of them. The results obtained from computational simulations show that our algorithm maintains the efficiency of the search operation at a high level. That means the algorithm is a promising approach for achieving both optimality and adaptability.},
  keywords={Uncertainty;Adaptation models;Adaptive control;Indexes;Actuators;Unmanned vehicles;Benchmark testing},
  doi={},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10004399,
  author={Chuang, Ching-Wei and Cheng, Harry H.},
  booktitle={2022 18th IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications (MESA)}, 
  title={Learning Algebra with Robotics in Math Classes}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={An increasing number of tools have been created to assist students in learning mathematics. Robots have been regarded as an especially powerful tool to help students master mathematics since students can simultaneously learn mathematics, programming, robotic control, and computational thinking. Although a number of educational robots and curricula have been developed, some of them do not comply with math standards, so they are primarily suitable for after-school programs, camps, or workshops. Students might not be able to focus on learning mathematics now that writing a program might be difficult for them due to debugging. In this paper, mathematics curricula that meet math standards are developed with a block-based programming platform, Roboblocky. Linkbots are utilized as robots in the curricula to teach and learn mathematics in school settings. Students learn mathematics by observing the motions of robots in simulations or on real mats. Most students improved greatly in mathematics after using the curricula. It is expected that the curricula based on Roboblocky will continue to be improved to enable more middle and high school students to be successful in learning mathematics.},
  keywords={Mechatronics;Embedded systems;Educational robots;Debugging;Writing;Mathematics;Mathematical models;mathematics curriculum;block-based program-ming;RoboBlocky;educational robots;Linkbots},
  doi={10.1109/MESA55290.2022.10004399},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10560485,
  author={P., Sreeja B. and G, Rajeshkumar and B, Alagu Kiruthika and N, Sasi Prabha and R, Varshini and J, Afzal},
  booktitle={2024 7th International Conference on Devices, Circuits and Systems (ICDCS)}, 
  title={Enabling Secure and Effective Deduplication in Multi Clouds}, 
  year={2024},
  volume={},
  number={},
  pages={55-59},
  abstract={Distributed storage, which is one of the main functions of distributed computing, enables clients of cloud services to think of their data as being stored in the cloud and to share it with qualified customers. In distributed storage, stable deduplication has been widely researched because it can eliminate overt repetitiveness within scrambled data to reduce storage space significantly. In the field of safety and protection, many current continuous deduplication schemes highlight to a large extent the associated characteristics: information classification, label consistency, access control animal attack assaults. One technique for ensuring the accuracy of information in garage outsourcing is confirmed information possession. The article discusses the development of a green PDP scheme for a distributed cloud garage to facilitate provider migration scalability and statistics, where we keep in mind the lifecycle of multiple cloud service providers to maintain and maintain collaborative customer statistics. The cooperative scheme relies entirely on verifiable homomorphic reactions. Completeness, knowledge soundness, and zero-knowledge qualities may all be satisfied by our multi-proof zero-knowledge proof system, which strengthens the security of our system. The experiment shows that this solution has lower computational and communication overhead than non-cooperative approaches.},
  keywords={Performance evaluation;Cloud computing;Scalability;Data integrity;Green products;Distributed databases;Probabilistic logic;Secure deduplication;Access control;Authorized deduplication system;Tag consistency;Brute-force attacks},
  doi={10.1109/ICDCS59278.2024.10560485},
  ISSN={2644-1802},
  month={April},}@INPROCEEDINGS{10293084,
  author={Tabbal, Judie and Kabbara, Aya and Hassan, Mahmoud},
  booktitle={2023 Seventh International Conference on Advances in Biomedical Engineering (ICABME)}, 
  title={Insights Into Electrophysiological Brain States Dynamics}, 
  year={2023},
  volume={},
  number={},
  pages={216-219},
  abstract={The human brain is a marvel of complex and dynamic networks that enable us to move, sense, think, and remember. How do these networks constantly reconfigure themselves in real-time to process information? To answer this question, we need reliable methods able to capture the dynamics of the dominant functional 'states'. However, this task is challenging due to the diversity of the available pipelines that are difficult to evaluate. Here, we present an overview of a computational framework that combines electrophysiological data with dynamic functional connectivity approach (dFC) followed by dimensionality reduction methods. We highlighted the utility of such framework in tracking the dynamics of key brain network states. Then, we provide a practical example on real MEG data during fast motor task. Our analysis evaluated the effectiveness of the proposed framework including several instances of decomposition and clustering techniques in capturing relevant spatial and temporal patterns of brain network reconfiguration.},
  keywords={Dimensionality reduction;Pipelines;Electrophysiology;Real-time systems;Reliability;Task analysis;Biomedical engineering;Electrophysiological data;dynamic Functional Connectivity (dFC);brain network states},
  doi={10.1109/ICABME59496.2023.10293084},
  ISSN={2377-5696},
  month={Oct},}@INBOOK{10183906,
  author={Kwang-Cheng, Chen and Joseph, McElroy},
  booktitle={6G Visions for a Sustainable and People-centric Future: From Communications to Services, the CONASENSE Perspective}, 
  title={6 An Introduction to Quantum Imaging and Hologram}, 
  year={2023},
  volume={},
  number={},
  pages={79-96},
  abstract={6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770227506},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10183906},}@INPROCEEDINGS{8939672,
  author={Yamamoto, Tosh and Pang, Chris and Ong, Benson and Shih, Juling and Chu, Hui-Chun and Shih, Meilun},
  booktitle={2019 Pacific Neighborhood Consortium Annual Conference and Joint Meetings (PNC)}, 
  title={The Curriculum Development for Global AGILE Problem-Based Learning in Social Entrepreneurship in Global Teams}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper deals with a progress report on the execution of the sense making in the curriculum development for global AGILE Problem-Based Learning incorporating computational thinking enhanced with ICT, which has been based on the collaborative endeavors between School of Business Management at Nanyang Polytechnic University in Singapore (NPU) and Center for Teaching and Learning at Kansai University (KU), intending to foster the Vision 2020 skills as well as the future work skills defined by Institute of the Future. Although Problem-Based Learning has been ubiquitous in the realm of the face-to-face onsite learning environment, the project is based on PBL in which project team members with common interests in entrepreneurship from both universities organize several teams to aim for startup business plans with simulation in the virtual learning environment. The paper will walk readers through the rationale behind such curriculum as well as the entire process of the curriculum development from the initial preparation to the final product including the assessment. The key factors of such curriculum development are elaborated in the conclusion.},
  keywords={Handheld computers;Education;Computer science;Information management;Collaborative work;Entrepreneurship;global AGILE learning;ICT-enhanced education;virtual collaborative learning environment;social entrepreneurship},
  doi={},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{5591087,
  author={Sandner, Thorben and Kehlenbeck, Matthias and Breitner, Michael H.},
  booktitle={2010 Workshops on Database and Expert Systems Applications}, 
  title={Visualization of Automated Compliance Monitoring and Reporting}, 
  year={2010},
  volume={},
  number={},
  pages={364-368},
  abstract={Compliance management is a critical financial and legal subject for organizations. It is operationally implemented by embedding internal controls into business processes and their supporting IT systems. Challenges arise from the complexity of real-life processes and systems, their continuous monitoring and the timely communication of thereby detected problems. In order to realize effective and efficient monitoring, the responsible persons must be supported by suitable compliance software. This compliance software should enable the responsible persons to get both high-level information regarding the overall compliance status and low-level information regarding possible problems. Furthermore, it should not be limited to passive reporting components for compliance management, but also allow for interactive user interfaces, which facilitate the proactive supervision of tasks. The aim of this work is to encourage the responsible persons to analyze and explore compliance information through their appropriate visualization. Thus, unique and valuable human strengths, such as lateral thinking, can be used aside from the computational strengths of compliance software during control monitoring.},
  keywords={Monitoring;Data visualization;Unified modeling language;Organizations;Standards organizations;Process control;IT compliance;IT risk management;IS security;Visualization;Dashboard},
  doi={10.1109/DEXA.2010.77},
  ISSN={2378-3915},
  month={Aug},}@INPROCEEDINGS{8286668,
  author={Shruthi, S. and Jose, A. M. and Anuroop, P. R.},
  booktitle={2017 International Conference on Communication and Signal Processing (ICCSP)}, 
  title={Improvisation of cluster efficiency using min-cut algorithm in social networks}, 
  year={2017},
  volume={},
  number={},
  pages={1641-1644},
  abstract={Social network is one of the vibrant topic and allow researcher to think in various dimension to provide results with wide scope. In this paper we are aimed at optimizing cluster to enhance the result. It helps to increase the computational performance of a social network as well as maintaining the valid nodes for bidirectional interaction between end users. Proposed methodology applies Girvan Newman clustering algorithm along with minimum cut algorithm for optimization purpose which makes effective interaction with in social communication network. Our research includes two major phases in it. During first phase we apply Girvan Newman algorithm to cluster the nodes with common behavior, properties and characteristics. In the second phase, application of minimum cut algorithm will be done into clustered social network nodes. The major objective is to analyze network nodes and make them stable and active and to remove the nodes that are not interacting with any network nodes that is inactive nodes. Such inactive nodes make the less efficiency and inaccurate communication. For these kind of problem, we are going to apply minimum cut algorithm. It will maximize the effective bidirectional interaction by removing the unwanted, noisy and inconsistent nodes from these clusters.},
  keywords={Social network services;Clustering algorithms;Algorithm design and analysis;Data mining;Signal processing algorithms;Buildings;Optimization;Cluster efficiency;Girvan-Newman;min-cut;social networks},
  doi={10.1109/ICCSP.2017.8286668},
  ISSN={},
  month={April},}@INPROCEEDINGS{9028498,
  author={Marcolino, Anderson S. and Praça, Elaine A. and Silva, Eduardo G. da},
  booktitle={2019 IEEE Frontiers in Education Conference (FIE)}, 
  title={Towards A Practical Approach to Improve the Interdisciplinary Teaching and Learning Process through M-learning Innovative Projects}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={This research to practice work in progress has two main objectives: i) the improvement of interdisciplinary teaching and learning processes in an integrated course of informatics in high school course and; ii) turning students into learners by the designing and development of innovative features for m-learning applications. Such objectives are integrated each other, since the improvement in the teaching and learning processes will not be restricted in the proposal and use of a practical framework for the improvement of students' skills in the computational thinking, but also in the use of the m-learning features and applications to improve educational issues faced by both students and teachers. In this perspective, active-learning and problem-based learning theories were considered to support the proposal of a series of activities composing a framework to be adopted to achieve the target objectives. The interdisciplinary teaching and learning processes improvement has its roots at the proposal of solutions for problems into disciplines of high school curricula through the innovative m-learning features to be designed and developed by the students. In this paper it is discussed the motivations about the proposal of this project, the teaching and learning implications in the context of a integrated course of informatics in high school course, its planning and a pilot conduction of mainly initial activities with the volunteers students. Such activities include: (a) the identification of problems and the planning of solutions based on m-learning features; (b) the design and development phases of an initial set features; and (c) a preliminary evaluation of usability of some mockups of m-learning application. At the end, the identified evidence are discussed, mainly those related with the implications for the interdisciplinary scenario for the teaching and learning processes, the initial identification of benefits in the perspective of the participation of students as learners and the future work, as well.},
  keywords={Education;Informatics;Organizations;Proposals;Software;Schedules},
  doi={10.1109/FIE43999.2019.9028498},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{8389107,
  author={Bhagtani, Anshul and Choudhury, Tanupriya and Raj, Gaurav and Sharma, Mukul},
  booktitle={2017 3rd International Conference on Applied and Theoretical Computing and Communication Technology (iCATccT)}, 
  title={An efficient survey to detect Alzheimer disease using data mining techniques}, 
  year={2017},
  volume={},
  number={},
  pages={64-70},
  abstract={Data Mining is a computational process of discovering a certain pattern in huge datasets. It is an essential process where technical processes are applied to get patterns. Alzheimer's disease should be detected very early so that preventive measures can be taken. Alzheimer's disease is a chronic disorder that worsens over time. AD is a disease which progresses slowly and is characterized by loss of neurons. The symptoms of dementia keep on worsening over a number of years. It leads to loss of memory which disrupts the life of that person. Reasoning skills and thinking ability is also affected. The most spread disease in Western Europe is dementia and it is least spread in Sub-Saharan Africa. On an average rate, two in three people with Alzheimer are women.},
  keywords={Communications technology;Dementia;Alzheimer disease;CDR;MRI;Dementia},
  doi={10.1109/ICATCCT.2017.8389107},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9620577,
  author={Bevan, Katie and Zeitz, Melissa and Chouinard, Rachel and Rita, Laura and Wohler, Scott},
  booktitle={2021 Conference on Research in Equitable and Sustained Participation in Engineering, Computing, and Technology (RESPECT)}, 
  title={Choose Your Own Adventure - Designing Equity-focused CS/CT modules for K-5 Elementary Schools}, 
  year={2021},
  volume={},
  number={},
  pages={1-1},
  abstract={How do Oprah, the multimedia mogul, and Edison, the inventor of the telephone, both inspire teachers and students to learn computational thinking? A CS/CT focused module was developed by two grade 4 teachers that would introduce culturally relevant role models to students in an urban school district. The module engages students through a “Choose Your Own Adventure” activity focusing on perseverance and conditionals. Students create Scratch projects, using a Makey Makey, to model what would happen if one of their historical role models gave up on their dreams. This module is just one example of the nineteen modules created by members of CSforALL Springfield, a Research Practice Partnership working with the University of Massachusetts in Amherst, Massachusetts. The partnership allows for collaboration between educators from Springfield, MA Public Schools and Researchers from the University. We will spotlight this module to show how the module was designed and taught to make it an engaging, equitable learning experience for all students and share their learning outcomes along the way. Our goal is to share how we designed and integrated culturally responsive Computer Science curriculum at the elementary level that will ensure equitable learning for all students. Our goal is to show how we engaged dyads in a design based collaborative process to produce a module for their grade level.},
  keywords={Collaboration;US Government;Telephone sets;Science - general;Focusing;Education;Conferences;computer science education;K12 computing;research practice partnership;culturally responsive curriculum;pedagogy},
  doi={10.1109/RESPECT51740.2021.9620577},
  ISSN={},
  month={May},}@INPROCEEDINGS{7296523,
  author={Muhammad, Jean and Boonthum-Denecke, Chutima},
  booktitle={2015 Research in Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT)}, 
  title={Computing pre-college program: Initial impact to first-year student in computer science}, 
  year={2015},
  volume={},
  number={},
  pages={1-1},
  abstract={The Department of Computer Science at Hampton University was awarded the HBCU-UP TIP Project to reform three gateway courses and implement an intensive computing summer bridge program (SBP) in an effort to improve student academic performance and increase retention and graduation rates in the major. By integrating Computational Thinking into lower-level courses, the proposed project also seeks to strengthen Computer Science students and better prepare them to meet the modern demands in the field. In the first year of the project there have been several changes to the curriculum content of the gateway courses as well as the implementation of the summer pre-college program. The summer 2014 was the first computing pre-college program. There were nineteen participants currently in the summer program. The students were engaged and excited to be a part of this program. The Computer Science Seminar course served as the initiative for a supplemental undergraduate research award request. The course focused not only ensuring the students understand computer science as a field of study, but also how computer science impacts all fields of study and everything in their daily lives. There were several speakers, FBI, Industry, University faculty, and previous graduates. The initial results has been extremely rewarding as we noticed from their performance in the first semester program course, CS1. This poster will discuss the curriculum we used during the summer program, sample exercises, feedback from students as well as lesson learnt for us to improve next year program.},
  keywords={Computer science;Pre-college engineering;Logic gates;Seminars;Industries;Bridges},
  doi={10.1109/RESPECT.2015.7296523},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10479387,
  author={Jinnouchi, Snmika and Tsunoda, Masateru},
  booktitle={2023 30th Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={Visualizing Program Behavior with a Ball and Pipes for Computer Science Unplugged}, 
  year={2023},
  volume={},
  number={},
  pages={663-664},
  abstract={Computer science unplugged (CS unplugged) is a method of teaching computer science and computational thinking. The aim of our study is to illustrate program behavior and to prevent confusion about the program stack through visualization. To facilitate recognition, we used a toy consisting of a ball, pipes, and magnetic panels. The ball represents which line of code is executed, similar to the program counter. To demonstrate the feasibility of the proposed method, we present three examples based on the proposed method. The examples are necessity of loop to wait user input, necessity of loop to keep program running, and software testing. We conducted an experiment with nine participants to evaluate the effectiveness of the proposed method. The result suggested that the proposed method is expected to be effective.},
  keywords={Computer science;Software testing;Visualization;Codes;Toy manufacturing industry;Education;Software engineering;education;computer science unplugged;program counter},
  doi={10.1109/APSEC60848.2023.00099},
  ISSN={2640-0715},
  month={Dec},}@INBOOK{10183914,
  author={Rute, C. Sofia and Ramjee, Prasad},
  booktitle={6G Visions for a Sustainable and People-centric Future: From Communications to Services, the CONASENSE Perspective}, 
  title={8 Conclusions and Future Scope Perspective}, 
  year={2023},
  volume={},
  number={},
  pages={107-110},
  abstract={6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770227506},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10183914},}@INPROCEEDINGS{10565656,
  author={García, Alfredo and Gonzalez, Juan Manuel and Guerrero, Josefina},
  booktitle={2023 XIII International Conference on Virtual Campus (JICV)}, 
  title={Application of the STEM Methodology in the Development of a Closed-Loop Control System}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={The STEM methodology has been applied in different study approaches, covering different areas such as arts, internet of things, computational thinking, among others. In this paper, two necessary approaches are addressed for the implementation of a closed-loop control system. The first approach (programming) is directly related to the software implementation and the second approach addresses the hardware instrumentation part. Both approaches are developed in a practical teaching case, from a STEM Maker workshop which consisted of 15 sessions with duration 2 hours each one. Each session consisted of 4 stages: Stage 1 (Theoretical concepts), Stage 2 (Practical Example), Stage 3 (Practice) and Stage 4 (challenge). Through these four stages, the development of skills of the attendees in the areas of programming and electronics was encouraged, applying the STEM Maker strategy. From some evaluation instruments, data was collected about the development of skills of the assistants in the implementation of software and hardware instrumentation, acquired in the STEM Maker workshop. The results indicated that approximately 70% of the workshop attendees developed the necessary skills to propose solutions to problems in their current context where the application of programming and/or electronics intervenes. The product obtained from the practice is described as a temperature control which integrates a feedback signal, this system has a wide field of applications which allowed the students of the STEM Maker workshop to achieve a project related to the individual context of each one.},
  keywords={Conferences;Instruments;Education;Collaboration;Programming;Software;Hardware;STEM Methodology;closed-loop;control;Maker movement;learning approach},
  doi={10.1109/JICV59748.2023.10565656},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9786390,
  author={Fajar, Yoga and Komarudin},
  booktitle={2022 7th International Conference on Business and Industrial Research (ICBIR)}, 
  title={Bi-objective optimization Integration of Multi-Resource Preventive Production and Maintenance Planning}, 
  year={2022},
  volume={},
  number={},
  pages={577-581},
  abstract={In this competitive industry era, industry should think about how to efficient their process of production. In the foundry and smelting industry, downtime not only increases make span and reduces machine availability, but also increases energy consumption. That means strategy to keep the production stabile is very important to minimize energy wasting. This condition need good condition machinery, and required optimum maintenance strategy. Modeling Production planning system with machine unavailability intervals has gained more attention to life cycle cost of manufacturing companies. Modelling production planning subjected to maintenance activities decreases machine degradation rate and unscheduled unavailability that may result lower breakdown of production. In this paper will In this paper, we propose Bi-objective optimization approach for energy aware scheduling considering continuous energy consumption cost and preventive maintenance multi resource (machine and dies as tools). Multi objective goal programming is proposed to solve this problem. The extensive computational experiments are conducted. The results show that the integrated optimization method of production scheduling and preventive maintenance outperforms the method with Corrective maintenance as a case study model for this problem, results also show the effects of different flexibilities of resources for job processing.},
  keywords={Industries;Energy consumption;Schedules;Costs;Job shop scheduling;Processor scheduling;Production planning;bi-objective optimization;multi resource of preventive maintenance;goal programming;integrating production and maintenance},
  doi={10.1109/ICBIR54589.2022.9786390},
  ISSN={},
  month={May},}@INPROCEEDINGS{9620583,
  author={Delacoudray, Chalece A. and Newton, Sunni H. and Alemdar, Meltem and Grossman, Sabrina and Garrett, Stephen and Freeman, Jason and Wilson, Joycelyn and Barbot, Hilah and Moore, Roxanne},
  booktitle={2021 Conference on Research in Equitable and Sustained Participation in Engineering, Computing, and Technology (RESPECT)}, 
  title={Your Voice is Power: Integrating Computing, Music, Entrepreneurship, and Social Justice Learning}, 
  year={2021},
  volume={},
  number={},
  pages={1-2},
  abstract={Computational thinking has become pervasive across many technical and creative disciplines. Creating a computationally literate workforce capable of recognizing and eliminating algorithmic discrimination requires diverse perspectives and lived experiences. Diversity within computing is a persistent problem; in 2014, several large tech companies released diversity reports and made commitments to improvement. As of 2020, improvements have been minor, especially for Black employees. Compared to US demographics, the percentage of Black and Latinx students pursuing degrees in computing remains low, even as numbers improve in STEM more broadly. It is more important than ever to prioritize a diverse computing workforce and a computationally literate workforce, more broadly, whose interests reside with equitable outcomes.},
  keywords={Entrepreneurship;Companies},
  doi={10.1109/RESPECT51740.2021.9620583},
  ISSN={},
  month={May},}@INBOOK{10183916,
  author={Rute, C. Sofia and Ramjee, Prasad},
  booktitle={6G Visions for a Sustainable and People-centric Future: From Communications to Services, the CONASENSE Perspective}, 
  title={1 Introduction}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770227506},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10183916},}@INPROCEEDINGS{6321809,
  author={Jin Zeng and Chao Peng and Chao Li and Lei Nie},
  booktitle={World Automation Congress 2012}, 
  title={Passenger ticket theory and empirical research based on valuation of travel time}, 
  year={2012},
  volume={},
  number={},
  pages={1-4},
  abstract={Since the passenger line is completed, its revenue has become the key to sustainable development. How to build flexible and adapt to the market demand for multi-level ticket pricing theory are the problems to be solved. This paper will be thinking of the valuation of travel Time and passenger line price in China, construct passenger ticket theory based on the valuation of travel time, and consider the comfort factor, determine the computational model for our valuation of travel time. On this foundation, the Beijing-Shanghai passenger dedicated line as an example, to calculate the ticket price and analysis on its rationality for the future, trying to give a more reasonable basis for passenger ticket pricing.},
  keywords={Rail transportation;Fatigue;Cost accounting;Pricing;Economics;Rails;passenger dedicated line;valuation of travel time;pricing;Comfort},
  doi={},
  ISSN={2154-4824},
  month={June},}@INPROCEEDINGS{4959143,
  author={Zhang, Shucui and Zhang, Yulin},
  booktitle={2009 First International Workshop on Education Technology and Computer Science}, 
  title={Research on System Methodology and Cognitive Methods in Computation Subject}, 
  year={2009},
  volume={2},
  number={},
  pages={752-755},
  abstract={Methodology is the theory of methods in recognizing and reforming the world. It is divided into three layers: philosophy methodology, general science methodology and concrete science methodology. System methodology as one of the basic methods that research computer science, is a general science methodology. This paper aims to discuss the fundamental principles of system methodology, at the same time, emphasizes on the thinking mode and method in computational subject.},
  keywords={Concrete;Control systems;Science - general;Output feedback;Computer science;Computer networks;Educational institutions;Cybernetics;Computer science education;Educational technology;philosophy methodology;systematology;system method},
  doi={10.1109/ETCS.2009.428},
  ISSN={},
  month={March},}@INPROCEEDINGS{6413340,
  author={Saraf, M. and Mohammadi, K. and Mosavi, M. R.},
  booktitle={2011 1st International eConference on Computer and Knowledge Engineering (ICCKE)}, 
  title={GMM-Guided gradient descent learning of RBF Neural Network with its application on robust GPS satellites selection}, 
  year={2011},
  volume={},
  number={},
  pages={139-143},
  abstract={In this paper, a novel gradient descent learning algorithm based on Gaussian Mixture Model (GMM) applied on Radial Basis Function Neural Network (RBFNN) is proposed in order to approximate the functions which have high non-linear order. How we can choose the strategy of gradient descent including learning coefficients selecting and really is it optimized to learn the same for all feature vectors?, are the challenges made us to think precisely on those. In this study, GMM estimates the probability density of the feature space and then the optimal learning rates can be evaluated proportional to these probabilities. These cause the neurons to learn correspondence with the feature distribution likelihoods. Considering robust satellite subset selection, Geometric Dilution of Precision (GDOP) factor is calculated for all subset of satellites and then the subset with lowest value is selected for positioning, but it is so non-linear and has computational burden to navigation systems. We use the proposed method to approximate it. The results on real GPS measurements demonstrate that it significantly track the non-linearity of GPS GDOP.},
  keywords={Global Positioning System;Neurons;Vectors;Approximation methods;Satellites;Approximation algorithms;Mathematical model;Gaussian Mixture Model (GMM);Geometric Dilution of Precision (GDOP);Gradient Descent Algorithm;Radial Basis Function Neural Network (RBFNN)},
  doi={10.1109/ICCKE.2011.6413340},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10213204,
  author={Tong, Xiaoyi and Zhou, Xuchuan},
  booktitle={2023 3rd International Symposium on Computer Technology and Information Science (ISCTIS)}, 
  title={Hyperspectral band selection algorithm based on artificial bee colony fusion genetic idea}, 
  year={2023},
  volume={},
  number={},
  pages={323-329},
  abstract={Hyperspectral images occupy a very important position when it comes to remote sensing imaging due to their multi band and high precision characteristics. However, due to the redundancy caused by various bands and the large amount of calculation, Reducing the size of hyperspectral photographs is important. This article proposes a program that combines cross genetic thinking with artificial bee colony algorithm (hereinafter referred to as Ag) to select the features of hyperspectral images, In the preprocessing stage, the initial feature set of the image is screened by using the outlier detection method based on the percentage level, and the feature set after the initial screening is selected by Ag algorithm. Finally, the selected band combination is sent to the neural network combining three-dimensional convolution and two-dimensional convolution for training, Experimental results on the Pavia University and Indian Pines datasets show that the algorithm has good convergence, and the band combination obtained with low computational complexity can achieve better classification accuracy and consistency in image classification.},
  keywords={Convolution;Redundancy;Neural networks;Feature extraction;Genetics;Artificial bee colony algorithm;Classification algorithms;Artificial bee colonies;feature selection;application status;hyperspectral remote sensing images;outlier detection methods;convolutional neural networks},
  doi={10.1109/ISCTIS58954.2023.10213204},
  ISSN={},
  month={July},}@INPROCEEDINGS{5976900,
  author={Kim, Jong-Hwan},
  booktitle={2011 International Conference on Pattern Analysis and Intelligence Robotics}, 
  title={Intelligence technology for cyber-physical robot system}, 
  year={2011},
  volume={1},
  number={},
  pages={1-1},
  abstract={Human beings will be living in a ubiquitous world in which all information technology devices are fully networked so that they can offer us desired services at any place and anytime. This shift has hastened the ubiquitous revolution, which has further manifested itself in the new multidisciplinary research area, ubiquitous robotics. It initiates the third generation of robotics following the first generation of the industrial robot and the second generation of the personal robot. A fairy tale introduced Genie, which upon springing from a lamp served Aladdin. The ubiquitous era brings us to the threshold of the realization of this dream, through ubiquitous robotics. Moreover, the robots shall have their own genome in which a specific personality is encoded. This concept leads to the research on genetic robotics. Cyber-physical robot system (CPRS) combines these new concepts of next generation robots for the convergence of computational and physical systems. This talk introduces the recent progress and development of ubiquitous robot, genetic robot and CPRS along with the new classification of robot intelligence. Ubiquitous robot is composed of three forms of robots: software robot, embedded robot and mobile robot to represent an amalgamation of the tripartite personification of entities of perception, thinking and action. Genetic robot has its own genetic codes to represent a specific personality. CPRS conjoins and coordinates the software agents and physical robots including software and hardware resources. Special emphasis in this talk is placed on intelligence technology for the CPRS to realize cognitive intelligence, social intelligence, behavioural intelligence, ambient intelligence, genetic intelligence and swarm intelligence. The intelligence technology shall provide us with seamless, calm, and context-aware services in a networked environment.},
  keywords={Robot kinematics;Service robots;Genetics;Artificial intelligence;Software;Context-aware services},
  doi={10.1109/ICPAIR.2011.5976900},
  ISSN={},
  month={June},}@INPROCEEDINGS{6417523,
  author={Mengying Zhang and Yu Zhu},
  booktitle={7th International Conference on Communications and Networking in China}, 
  title={Resource allocation for decode-and-forward relay-assisted SC-FDMA systems}, 
  year={2012},
  volume={},
  number={},
  pages={441-445},
  abstract={In this paper, we investigate the resource allocation for decode-and-forward (DF) relay-assisted SC-FDMA systems. Considering the subcarrier adjacency restriction of SC-FDMA, we present an optimal algorithm which refers to the set partitioning problem. In order to reduce the computational complexity of the optimal resource allocation, we also propose a suboptimal algorithm which is based on the greedy heuristic thinking. Simulation results show that the spectral efficiency of the optimal algorithm is much higher than that of the round robin algorithm. It is also shown that the greedy algorithm, which has much lower complexity, performs quite close to the optimal algorithm.},
  keywords={Resource management;Algorithm design and analysis;Relays;Partitioning algorithms;Greedy algorithms;Complexity theory;Uplink;3GPP;SC-FDMA;cooperative relay;resource allocation;set partitioning problem;greedy algorithm},
  doi={10.1109/ChinaCom.2012.6417523},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8389728,
  author={Gautham, B S and Lal, N Dayananda and Murthy, Narasimha},
  booktitle={2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS)}, 
  title={Protective and efficacious cloud evaluating schema}, 
  year={2017},
  volume={},
  number={},
  pages={1655-1659},
  abstract={There is much thinking nowadays about unsanctioned access to personal information. Different strategies have been suggested in survey process, since authors suggest augments with respect to expenditure and process evaluation instance therefore it depends on ciphering the complete information. This article expresses an introduction to cloud computational schema which differentiates information reckoning on significant properties. Most precisely the significant user information would get encrypted with secure encryption algorithm provided with better key size, where in lower significant information may not be ciphered. This methodology helps debasing the process charges and complicatedness of information storage, since there is no compulsion for applying similar refined encryption procedure for all user records. The outcome of introducing suggested schema results in exhibition of amelioration and effectiveness than further open frameworks. There are few of the embellishments chosen and it can be known in the following pages basically to suit the modern demands.},
  keywords={Cloud computing;Encryption;Servers;Google;Data analysis;Standards;AES(Advance Encryption Standard);DES(Data Encryption Standard);TLS(Transport Level Security);SHA(Secure Hash Algorithm)},
  doi={10.1109/ICECDS.2017.8389728},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{1263434,
  author={Kwan, T.T. and Terstriep, J.A.},
  booktitle={Supercomputing '93:Proceedings of the 1993 ACM/IEEE Conference on Supercomputing}, 
  title={Experiments with a gigabit neuroscience application on the CM-2}, 
  year={1993},
  volume={},
  number={},
  pages={133-142},
  abstract={To help evaluate the supercomputers, the authors selected a computational neuroscience simulation program that has a bandwidth requirement in excess of 1.5 Gb/s. The simulation runs on the Thinking Machines CM-2 and the target visualization engine is the Convex C3880. The authors benchmarked the various operations required to transmit data from the CM-2 to the Convex C3880. The results show that the parallel to serial data transformation operation on the CM-2 and the network interfaces are the major bottlenecks.},
  keywords={Neuroscience;Supercomputers;Bandwidth;Data visualization;High-speed networks;High performance computing;Testing;Performance evaluation;Computer graphics;Workstations},
  doi={10.1145/169627.169671},
  ISSN={1063-9535},
  month={Nov},}@INPROCEEDINGS{10526168,
  author={Manikandan, G and Kumar, B Murugesa and Bharathi, A and Anandakumar, K and Senthilkumar, R},
  booktitle={2023 International Conference on New Frontiers in Communication, Automation, Management and Security (ICCAMS)}, 
  title={ORPN Algorithm used to diagnosis and identify plant diseases based on image segmentation using deep learning techniques}, 
  year={2023},
  volume={1},
  number={},
  pages={1-5},
  abstract={Digital With a growing global population comes a correspondingly higher need for food, making plant disease modernization in agricultural areas a top priority for all nations. Improving productivity is crucial to India’s economy. Consequently, the detection of disease in greeneries plays a key role in the development sector. The accuracy and precision of diagnosing diseases in plants and animals have also been enhanced by the increased use of expertise in modern times. One solution to the problem of classifying different populations is the prospect of grouping in AI techniques. We aim to provide insight into the present state of the illnesses and how to detect them rapidly using computational reasoning. The article suggests thinking about how to use AI techniques to automatically detect plant diseases. This research paper uses the O-RPN (Optimized District Proposition Network) to isolate and control the leaves in a complicated ecosystem. The O-RPN computation incorporates the signs component using Chan-Vese (CV) techniques. The district-based CV calculation yields encouraging results for noise- and weak-edge-free image segmentation. In addition, we compare CNN and SVM using a unique dataset related to plant illnesses.},
  keywords={Support vector machines;Plant diseases;Adaptation models;Image segmentation;Sociology;Predictive models;Feature extraction;Feature Extraction;AI technique;CNN model;SVM model;Disease Prediction;segmentation},
  doi={10.1109/ICCAMS60113.2023.10526168},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9323681,
  author={Marinoni, Andrea and Chlaily, Saloua and Jutten, Christian},
  booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Addressing Reliability of Multimodal Remote Sensing to Enhance Multisensor Data Fusion and Transfer Learning}, 
  year={2020},
  volume={},
  number={},
  pages={3896-3899},
  abstract={In literature, we find many examples showing that, contrary to what one might think, multimodal remote sensing analysis might be suboptimal. Given the high computational complexity typically required by multimodal investigation in order to properly extract information from multiple sources, there is a need to assess its actual benefit during image preprocessing. This urgency becomes indeed crucial when targeting transfer learning in remote sensing, as understanding the actual relationship between diverse sensors is fundamental to accurately characterize the considered scenes. In this work, we derive a reliability metric by means of an information theory-based approach. The proposed metric is able to estimate how confident one can be of the considered datasets when characterizing each pixel in the considered region of interest. Experimental results on real datasets show how this quantity can be used to improve the understanding of the scenes, and to enhance multisensor transfer learning.},
  keywords={Remote sensing;Reliability;Measurement;Information retrieval;Data mining;Signal to noise ratio;Image sensors},
  doi={10.1109/IGARSS39084.2020.9323681},
  ISSN={2153-7003},
  month={Sep.},}@INBOOK{8333151,
  author={Wiberg, Mikael},
  booktitle={The Materiality of Interaction: Notes on the Materials of Interaction Design}, 
  title={2 The Material Turn}, 
  year={2018},
  volume={},
  number={},
  pages={27-44},
  abstract={Whether we think of interaction design as a design tradition aimed at giving form to interaction with and through computational objects or as being about user interface design, it is hard to escape the fact that the user interface to a large extent defines the scene and the form of the interaction. Without adopting a fully deterministic perspective, it is nevertheless a fact that if the user interface is screen-based and graphical and the input modality is mouse-based, then it is likely that the form of that interaction—that is, what the turn-taking looks like and what is demanded by the user—is very similar to other screen-based interfaces with similar input devices. However, the design space for the form of interaction is growing quickly. While command-based interfaces and text-based interfaces defined almost the whole design space in the 1970s, developments since then, including novel ways of bringing sensors, actuators, and smart materials to the user interface, have certainly opened up a broader design space for interaction design.},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262344692},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/8333151},}@INPROCEEDINGS{10151565,
  author={Kumar, Sakshi Rajesh and Tyagi, Firoz and Hasija, Yasha},
  booktitle={2023 2nd International Conference on Smart Technologies and Systems for Next Generation Computing (ICSTSN)}, 
  title={In-Silico medication of vitiligo by targeting 6AAH protein and riboflavin Ligand}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Depigmentation of the skin is a primary symptom of the vitiligo disorder. By reducing their self-esteem and causing them psychological distress, it lowers patients’ quality of life. The study made use of a number of computational tools, including Cyto Hubba, BioVia Discovery Studio through, Open babel, Drug bank, Avogadro, Auto dock, and Protein-Interaction Ligand profiler. The interaction between 6AAH and (Myristic acid, Heptadecanoic acid, Riboflavin, Propanol, 2,6-Dimethyl-7-octene-2,3,6-trio1) has been examined in this study using Cyto Hubba and PILP clustering interactions, followed by Molecular Docking of Protein and Ligand. Due to its polygenic nature, vitiligo is frequently associated with a number of autoimmune or autoinflammatory disorders, including thyroid disease, psoriasis, atopic dermatitis, diabetes mellitus, and pernicious anaemia. Hence, it is conceivable to think about riboflavin as a possible drug for Vitiligo treatment. The findings imply that riboflavin laboratory tests reveal its inhibitory potential on skin depigmentation},
  keywords={Proteins;Drugs;Psychology;Eczema;Skin;Diabetes;Next generation networking;gene expression;vitiligo;reversal gene;treatment;depigmentation;drugs},
  doi={10.1109/ICSTSN57873.2023.10151565},
  ISSN={},
  month={April},}@INPROCEEDINGS{8818860,
  author={Kafai, Yasmin B.},
  booktitle={2019 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Designing and Debugging with Electronic Textiles: Diversifying Participation and Deepening Learning in K-12 Computer Science Education (Invited Keynote)}, 
  year={2019},
  volume={},
  number={},
  pages={1-1},
  abstract={We are witnessing a remarkable comeback of computer programming in schools. While computers seem to be accessible everywhere, particularly outside school, where children and youth are connecting to wider networks of other young users, their capacity to wield such devices critically, creatively, and selectively is decidedly less potent. Learning the language of computers introduces students to processes for thinking and solving problems and for engaging creatively and critically with digital media. Using the example of electronic textiles—computational artifacts in which circuits are stitched with conductive thread to connect microcontrollers and control sensors and actuators, I describe how we can broaden access, diversify representation, and deepen learning. More importantly, I illustrate how the introduction of crafting with computing in schools that serve marginalized populations can help diversify who makes and the kinds of artifacts that are being made, how projects can introduce more complex programming concepts and practices, and what kind of tools we can design to support novice programmers in coding and debugging hybrid artifacts.},
  keywords={Smart textiles;Programming profession;Media;Debugging;Yarn;Visualization;Statistics},
  doi={10.1109/VLHCC.2019.8818860},
  ISSN={1943-6106},
  month={Oct},}@INPROCEEDINGS{9813884,
  author={Mohd, Tauheed Khan and Majumdar, Subhrajit and Mathur, Akshay and Javaid, Ahmad},
  booktitle={2022 IEEE International Conference on Electro Information Technology (eIT)}, 
  title={Cybersecurity Based Simulation of Connected Automated Vehicles for Instructional Use}, 
  year={2022},
  volume={},
  number={},
  pages={032-036},
  abstract={A car moving at a speed of x mph, comes to a sudden halt after traveling y miles. What is the time taken by the car to reach z miles ahead of y? A high school student probably gets frustrated by questions like these on the ground that inquiries in arithmetic. The idea of implementing hacking on a smart car should improve student’s interest and motivate them to pursue careers in STEM-related areas. However, if the same example was demonstrated to them using a smart car prototype which was hacked, then there is a good chance they can get attracted towards Technology and Computing. When similar examples, involving the various other topics in their syllabus, are shown, they’ll probably get to see the real-life applications of the topics they study during high school and after that. This paper introduces a new attempt that aims at inclining the interest of high school students towards the courses in the STEM (which have an escalating carrier aspect), improving their computational thinking capability, and making them aware of today’s cybersecurity issues.},
  keywords={Solid modeling;Machine learning algorithms;Prototypes;Virtual reality;Machine learning;Market research;Motion pictures;cybersecurity;education;vehicular simulation},
  doi={10.1109/eIT53891.2022.9813884},
  ISSN={2154-0373},
  month={May},}@INBOOK{10183901,
  author={},
  booktitle={6G Visions for a Sustainable and People-centric Future: From Communications to Services, the CONASENSE Perspective}, 
  title={6G Visions for a Sustainable and People-centric Future: From Communications to Services, the CONASENSE Perspective}, 
  year={2023},
  volume={},
  number={},
  pages={i-xxii},
  abstract={6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770227506},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10183901},}@INPROCEEDINGS{9351412,
  author={Zakirova, F.M and Abdullaeva, N.I and Murtazaeva, U.I},
  booktitle={2020 International Conference on Information Science and Communications Technologies (ICISCT)}, 
  title={Educational and research competencies in the training of the course “Discrete mathematics” for training bachelors in computer engineering}, 
  year={2020},
  volume={},
  number={},
  pages={1-4},
  abstract={In this paper we consider the control problem of ensemble of trajectories for one In recent years, the importance of discrete mathematics has increased dramatically. This is not the name of a branch of mathematics such as number theory, algebra, calculus. This is a separate branch of knowledge, which is called “discrete” (individual). However, there are also processes of continuous mathematics, that is, it becomes a continuous whole. Discrete data can only take integer values, while continuous data can take any value. Discrete mathematics was created several decades ago and is the mathematical language of computer science. Scientists have found that the mathematical disciplines taught in universities are insufficient for learning a programming language. Therefore, they combine additional maths topics into one course, now called discrete mathematics. Discrete mathematics is the foundation of computer science and theoretical computer science. Without learning discrete mathematics, we miss the essence of the logic of computer science. Due to the multiplicity of objects within discrete mathematics, rational clarity in solving programming issues is possible. Every field in computer science is associated with discrete objects, be it databases, network components, computer organization, compilers, network programming, and so on. Essentially, discrete mathematics studies the concepts of counting, mathematical structures, logic, recursion, computational modeling, graph theory and algorithms, and many other disciplines. Evidence, a basic concept in discrete mathematics that includes deductive thinking, simplification, pattern identification, mathematical notation, working within constraints and conditions. This does not mean that a formal course in discrete mathematics is necessary or should be required for programmers. However, many of the concepts discussed in discrete mathematics are applied using this science. In this article, we will look at the basic postulates of discrete mathematics that are necessary to learn the basics of programming.},
  keywords={Training;Information science;Program processors;Organizations;Mathematics;Trajectory;Programming profession;discrete mathematics;programming;computer engineering;informatics;modeling;algorithms;determinants},
  doi={10.1109/ICISCT50599.2020.9351412},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8103440,
  author={Shapiro, Ben},
  booktitle={2017 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Emerging paradigms for CS education and their implications for visual languages (Invited keynote)}, 
  year={2017},
  volume={},
  number={},
  pages={1-1},
  abstract={Most of today's approaches to introductory computer science education reflect a 1970s view of computer science: students typically create single-threaded programs that do local IO. Some of the technologies used within these educational experiences include post-70s visual language elements like blocks to assist with the syntax of programming, but the semantics of the programming have generally remained frozen in time. Yet, the field of computer science has progressed enormously since the 1970s: multi-core computing, distributed systems, and machine learning are now ubiquitous, and have deep philosophical and practical ramifications for computer science education, including our definitions of what computational thinking is, and for how we design new programming languages, including visual languages. I will compare the current state of the art of novice programming tools and theories to the current state of computer science, and describe how new conceptual frameworks and visual programming tools could support contemporary computer science education.},
  keywords={Visualization;Programming profession;Computer science education;Tools;Syntactics},
  doi={10.1109/VLHCC.2017.8103440},
  ISSN={1943-6106},
  month={Oct},}@INBOOK{10183903,
  author={},
  booktitle={6G Visions for a Sustainable and People-centric Future: From Communications to Services, the CONASENSE Perspective}, 
  title={About the Editors}, 
  year={2023},
  volume={},
  number={},
  pages={113-114},
  abstract={6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770227506},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10183903},}@INPROCEEDINGS{8783237,
  author={Filipe Rozeno Rodrigues, José and Rodrigo Acosta, Plabiany and Ramalho, Thiago and Marques de Aquino, Wellington and Corrêa de Lima, Anderson and Bailo, Daniel},
  booktitle={2018 XIII Latin American Conference on Learning Technologies (LACLO)}, 
  title={Parallel Computing: Unplugging to Learn}, 
  year={2018},
  volume={},
  number={},
  pages={41-44},
  abstract={Technological devices programmed through parallel computing are increasingly present in people's daily lives. They are responsible for processing images that we see on computers, televisions, cell phones and games. It is a fact that parallel processing is a reality, so computer professionals need to know the peculiarities of this form of programming. However, teaching parallel computing is not a simple task, the computational thinking parallel is quite different from that for the sequential processing. This work, then proposes a new methodology for teaching parallel computing for young beginners in programming. Our technique is based on principles of unplugged computing, like to learn doing and playing. We believe that unplugged computing can be very useful in teaching the difficult concepts of parallel computing 1},
  keywords={Parallel processing;Education;Hardware;Computers;Games;Programming profession;computing;parallelism;high performance;challenges;teaching},
  doi={10.1109/LACLO.2018.00019},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7100484,
  author={Singh, Ajay},
  booktitle={2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Plant intelligence: A new approach to soft computing}, 
  year={2015},
  volume={},
  number={},
  pages={1429-1432},
  abstract={This paper presents a review of the literature on plant's abilities to possess intelligence. The paper also tries to find answers to the learning and remembering capabilities of plants. The paper reviews experiments performed on plants to prove their abilities to think and remember. The paper also reviews the acacia plant's ability to control ants using chemical ecology. These characteristics of plants open gates for future development of a new intelligence system based on the secret life of plants. Based upon the available plant intelligence information computer scientists have already started using new soft computing algorithms for complex computational applications.},
  keywords={Chemicals;Environmental factors;Insects;Feeds;Immune system;Artificial intelligence},
  doi={},
  ISSN={},
  month={March},}@INPROCEEDINGS{10578675,
  author={Bahr, Tobias},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Piloting of a Computer Science Content Knowledge Test for 10th Grade Students*}, 
  year={2024},
  volume={},
  number={},
  pages={01-05},
  abstract={New (interdisciplinary) Computer Science (CS) subjects in K-12 education have been introduced in recent years. Most of them have educational plans derived from CS Frame-works such as the K-12 CS Framework. To some extent the educational plans have the same core topic areas: data and coding (including data compression and data structures), algorithms (in-volving variables and software projects), computers and networks (covering topics like logic tables and data transmission) and information society and data security (consisting of collection and processing of personal data and asymmetric encryption). Various Computer Science assessment tests such as the SCS1, MG-CSCI, PSIv1 and the Fairy Assessment have been developed for different age groups. These tests mostly include computational thinking, programming or topics that could be categorized in the first two core topic areas data and coding and algorithms. Hence, the research desideratum was to develop a test specifically for measuring the four core topic areas. These core topic areas are part of the educational plan of the new interdisciplinary subject IMP (Informatics, Mathematics, Physics) for secondary schools in Germany. The test was piloted with 156 (m = 117, f = 37, o = 2) 10th grade students, approximately aged 16 at the end of the lower secondary level. We used the Item-Response-Theory (IRT) to validate the test. This work in progress paper presents translated items and the psychometric evaluation of the piloted test. The contribution for both researchers and educators in the CS education research field is the set of items of the research-based CS test in the four core topic areas for 10th grade students that includes item sets for the areas computers and networks and information society and data security.},
  keywords={Knowledge engineering;Data security;Software algorithms;Encoding;Software;Mathematics;Logic;Programming;Education;Instruments;Assessment tools},
  doi={10.1109/EDUCON60312.2024.10578675},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10170028,
  author={Tseng, Chun-Hsiung and Lin, Chi-Cheng and Ho, Shu-Ling},
  booktitle={2023 IEEE 3rd International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB)}, 
  title={Effect of Operation Span on IoT Courses for Junior High School Students in Taiwan}, 
  year={2023},
  volume={},
  number={},
  pages={22-23},
  abstract={Learning how to program has become a trend in Taiwan even for younger students. IoT is a topic to interest new learners in programming. Given the fact that there are already plenty of tools e.g. Micro:bit and Arduino designed to make IoT programming simple and full of fun, it is usually believed that adopting IoT topics is beneficial for younger students learning how to program. However, younger students’ learning performance in programming courses varies dramatically depending on the tools mentioned above. There are many metrics to predict the academic achievements of young students. Among them, the operation span is an objective one. Operation span mainly assesses one’s working memory capacity. According to the research results, one’s working memory capacity predicts individual high-level cognitive performance. Furthermore, students’ cognitive performance was highly related to their learning performance in programming courses. Nevertheless, the relationship between operation span and the learning performance of programming courses for junior high school students has not been researched yet. In Taiwan, computer programming has already been included as a mandatory subject in the junior high school curriculum for developing students' computational thinking and problem-solving skills. As such, understanding the relationship between OSPAN and programming performance is crucial for effective teaching and learning in this subject. We designed an experiment for an IoT-related after-school club in a junior high school to evaluate the relationship between students’ operation span and learning performance.},
  keywords={Measurement;Education;Programming;Big Data;Market research;Internet of Things;Problem-solving;operation_span;cognitive_ability;learning},
  doi={10.1109/ICEIB57887.2023.10170028},
  ISSN={},
  month={April},}@INPROCEEDINGS{1623647,
  author={Bansal, S.},
  booktitle={Vehicle Navigation and Information Systems Conference, 1991}, 
  title={Impact of emerging semiconductor technology on transportation vehicles in the year 2000}, 
  year={1991},
  volume={2},
  number={},
  pages={371-376},
  abstract={We were requested to predict the future specifications of the electronic materials, electronic packages and micro processors for high performance computer systems going as far out as the year 2000 and beyond. These were to be based on the emerging requirements of the end users. Literature and conferences yielded very little quantitative data. As a result, we understood to design and develop a deterministic and macroscopic model based on physics, math, VLSI design, architecture and integration level considerations. The resulting model transcended the electronic world from system performance to microprocessor description to packaging specifications and required material's specifications. Based on this model, it is likely, that the world will see an integration of 100 million transistors on a single chip providing clock frequencies approaching 213 MHz and CPU power near about 238 MIPS. Transportation is a major business for Alcoa. We have used our model to examine what architectural directions the Mobile 2000 would take for satisfying its command and control, navigational, entertainment, communication, engine, transmission and body/cockpit control and management systems. A scenario is developed based on the current and emerging requirements for the above functions leading to the automobile of the year 2000. This is then translated to yield control and system requirements which then are converted to the total computational requirements. The requirements are used to define the future system specifications based on our model's predictions. Alternative architectures are then presented. Cautions and caveats are discussed based on our experience on several large scale Computer Integrated Manufacturing (CIM) networks', design development and implementation. It is imperative to bring the large scale systems thinking to Mobile 2000's automation and support systems so that the classical pitfalls of cost, performance, lack of planning, ad hoc and proliferation of incompatible systems does not take place in this exciting arena.},
  keywords={Transportation;Vehicles;Power system modeling;Electronics packaging;Communication system control;Computer integrated manufacturing;Semiconductor materials;Semiconductor device packaging;High performance computing;Physics},
  doi={10.1109/VNIS.1991.205783},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{4733999,
  author={Boulicaut, Jean-François},
  booktitle={2008 IEEE International Conference on Data Mining Workshops}, 
  title={If Constraint-Based Mining is the Answer: What is the Constraint? (Invited Talk)}, 
  year={2008},
  volume={},
  number={},
  pages={730-730},
  abstract={Constraint-based mining has been proven to be extremely useful. It has been applied not only to many pattern discovery settings (e.g., for sequential pattern mining) but also, recently, on classification and clustering tasks (see, e.g., ). It appears as a key technology for an inductive database perspective on knowledge discovery in databases (KDD), and constraint-based mining is indeed an answer to important data mining issues (e.g., for supporting a priori relevancy and subjective interestingness but also to achieve computational feasibility). However, few authors study the nature of constraints and their semantics. Considering several examples of non trivial KDD processes, we discuss the Hows, Whys, and Whens of constraints in a broader context than. Our thesis is that most of the typical data mining methods are constraint-based techniques and that it is worth studying and designing them as such. In many cases, we exploit constraints that are not really explicit (e.g., the objective function optimization of a clustering for a given similarity measure) and/or constraints whose operational semantics are relaxed w.r.t. their declarative counterparts (e.g., the optimization constraint is not enforced because of some local optimization heuristics). We think that is important to explicit every primitive constraint and the operators that combine them because this constitutes the declarative semantics of the constraints and thus the mining queries. Then, a well-studied challenge is to design some operational semantics like correct and complete solvers and/or relaxation schemes for more or less complex constraints. Designing complete solvers has been extensively studied in useful but yet limited settings (see, e.g., the algorithms for exploiting combinations of monotonic and anti-monotonic primitives). It is however clear that many relevant constraints lack from such nice properties. On another hand, understanding constraint relaxation strategies remains fairly open, certainly because of its intrinsically heuristic nature. Interestingly, the recent approaches that suggest global pattern or model construction based on local patterns enable to revisit the relaxation issue thanks to constraint back propagation possibilities. This can be discussed within a case study on constrained co-clustering.},
  keywords={Databases;Data mining;Constraint optimization;Constraint theory;Clustering algorithms;Cyclic redundancy check;Conferences;Algorithm design and analysis;FETs;Itemsets;constraints;data mining;inductive databases},
  doi={10.1109/ICDMW.2008.96},
  ISSN={2375-9259},
  month={Dec},}@INPROCEEDINGS{10332926,
  author={De Rezende Freitas, Elias José and Guimarães, Marcos Prado and Ramos, João Vitor and Da Silva Júnior, Carlos Dias},
  booktitle={2023 Latin American Robotics Symposium (LARS), 2023 Brazilian Symposium on Robotics (SBR), and 2023 Workshop on Robotics in Education (WRE)}, 
  title={A Robotics Club in High School: an experience report}, 
  year={2023},
  volume={},
  number={},
  pages={683-688},
  abstract={Educational Robotics provides a dynamic and effective platform for fostering diverse skills and competencies. In this context, this paper explores creating and implementing a robotics club in a high school. The proposed methodology emphasizes the educational tripod: teaching, research, and extension. Therefore, the paper outlines the club’s conception, the sources of inspiration, and the achieved outcomes within the school and local community. It also highlights the activities and small projects developed by the students and the active participation of the club members in the Brazilian National Robotics Olympics. Furthermore, through student reports and an internal survey, the paper emphasizes the remarkable development of desired competencies, including creativity, teamwork, problem-solving, and computational thinking.},
  keywords={Training;Surveys;Video on demand;Social networking (online);Software;Teamwork;Problem-solving;Educational Robotics;Robotics Club;Learning},
  doi={10.1109/LARS/SBR/WRE59448.2023.10332926},
  ISSN={2643-685X},
  month={Oct},}@INPROCEEDINGS{7777734,
  author={Rodrigues, J. A. and Loja, M. A. R. and Barbosa, J. I.},
  booktitle={2016 2nd International Conference of the Portuguese Society for Engineering Education (CISPEE)}, 
  title={Using the finite element method to understand calculus}, 
  year={2016},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper presents a complementary, alternative teaching and learning methodology based on the use of the finite element method to illustrate mathematical models and to explore their (numerical) solutions in the context of vector calculus properties understanding. This methodology is illustrated via a set of examples focused on specific engineering problems, but its scope can also be widened to other scientific areas. The examples presented on this paper allow concluding that this approach may be an interesting way to re-think and complement the perspective usually considered in the transmission of mathematical concepts. The use of a freeware finite element method computational package, FreeFEM++ may also be an important issue to stimulate the dissemination of this phenomena modelling and comprehension approach.},
  keywords={Mathematical model;Heating;Laplace equations;Finite element analysis;Steady-state;Calculus;Thermal conductivity;Mathematical models;Finite element method;Vector calculus},
  doi={10.1109/CISPEE.2016.7777734},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9957013,
  author={Zhang, W. and Xie, J. and Wang, R. and Yuan, E. and Tang, Y. and Wu, Y.},
  booktitle={Fourth International Conference on Computer Science and Educational Informatization (CSEI 2022)}, 
  title={Research on practical teaching reform of computer composition based on PBL+CDIO mode}, 
  year={2022},
  volume={2022},
  number={},
  pages={255-260},
  abstract={In order to strengthen the concept of engineering education and cultivate students' professional ability and professional quality in teaching, aiming at the problems existing in the practical teaching of computer composition course, we put forward reform measures in aspects of experimental system, teaching design, organizational form and assessment method by using PBL+CDIO mode, strive to resolve in the practice teaching, How to embody "learning-centered"? How to cultivate students' computer system ability and computational thinking? How to evaluate the students for the cultivation of ability and quality. From the perspective of teaching effect, students' systematic ability and learning autonomy have been significantly improved compared with previous years.},
  keywords={},
  doi={10.1049/icp.2022.1481},
  ISSN={},
  month={Sep.},}@INBOOK{10710556,
  author={Togelius, Julian},
  booktitle={Artificial General Intelligence}, 
  title={12 CONCLUSION}, 
  year={2024},
  volume={},
  number={},
  pages={185-201},
  abstract={Writing a book about artificial general intelligence in 2023 means chasing a moving target. I started working on this book before ChatGPT was released, quickly gained tens of millions of users, and reinvigorated the AGI debate. As I am finalizing this book in October 2023, there is intense discussion among both technologists and politicians about AI regulation. By the time you read this, much will have happened in terms of both technology and policy. But my descriptions of how the underlying computational methods work will still be true, and I think the various points I make throughout the book about both natural and artificial intelligence will still apply.},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262380157},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10710556},}@INPROCEEDINGS{10315732,
  author={Ramírez-Trejos, Ellioth and González-Torres, Antonio and Sancho-Chavarría, Lilliana and Navas-Sú, José and Garita, Cesar and Monge-Fallas, Jorge},
  booktitle={2023 42nd IEEE International Conference of the Chilean Computer Science Society (SCCC)}, 
  title={Automatic Assessment of Programming Exercises Using Syntactic Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper proposes a method to grade programming exam questions automatically. Our motivation is that there are no robust and scalable automatic methods for the analysis of computational thinking from source code programmed by elementary-level students. The approach to this problem supports the improvement of PC development in primary and secondary school students. The validation of the method is performed through the assessment of the answers of primary school students to programming exercises using a programming language called LIE++. The method assesses student answers using several techniques such as the analysis of programming structures, code clones and the execution of code based on input and output values defined during the specification of the exercises. The use of these techniques provides specific scores to obtain a grade of the student’s answer. The source code analysis and scoring of exercise answers is carried out using high-performance computing for improving system response time. This research contributes a scalable method for the automatic evaluation of exams, which we expect to support the development of PC.},
  keywords={Computer languages;Codes;Source coding;High performance computing;Cloning;Programming;Syntactics;Automatic evaluation;source code analysis;abstract syntax trees},
  doi={10.1109/SCCC59417.2023.10315732},
  ISSN={2691-0632},
  month={Oct},}@INPROCEEDINGS{10589958,
  author={Sun, Yue and Xiao, Wen},
  booktitle={2024 6th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Analysis of Blended Learning Behaviour Based on K-Means Clustering Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={315-318},
  abstract={As blended learning models gain popularity, analyzing the online learning behaviors of college students has emerged as a crucial approach to enhancing teaching effectiveness. The objective of this study is to conduct a comprehensive analysis of the learning behavior data from 44 students specializing in computer-related subjects on the online platform of the “Introduction to Computational Thinking” course, utilizing clustering algorithms. Subsequently, we utilized the Pearson correlation coefficient method to delve into the intricate relationship between diverse behavioral traits and academic performance. Our research has revealed that cluster analysis is adept at discerning behavioral disparities among students. Specifically, we identified four types of learning groups with different learning characteristics. Furthermore, a notable correlation was observed between homework scores and key evaluation metrics, including academic performance. Based on these findings, this study proposes targeted learning strategies and teaching suggestions, aiming to help educators better guide students in learning and improve the effectiveness of blended learning.},
  keywords={Measurement;Analytical models;Correlation;Federated learning;Education;Clustering algorithms;Solids;blended learning;learning behavior analysis;clustering analysis;correlation analysis},
  doi={10.1109/CSTE62025.2024.00065},
  ISSN={},
  month={April},}@INPROCEEDINGS{9925899,
  author={Pretelli, Adele and Klopfenstein, Lorenz Cuno and Francesco, Gian Marco Di and Paolini, Brendan Dominic and Bogliolo, Alessandro},
  booktitle={2022 IEEE 2nd IoT Vertical and Topical Summit for Tourism (IoTT)}, 
  title={All Aboard: One Year of Accessible and Inclusive Remote School Trips}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid spread of the CoViD-19 pandemic in early 2020 and the adoption of social distancing and "stay-at-home" orders gave rise to the sudden need for schools to be able to provide effective remote teaching. In Italy and elsewhere, the introduction of distance learning technologies has significantly impacted the education of students and limited their social interaction and activities, among which are school trips and other scholastic experiences. To support the constrained educational possibilities of Italian schools, we developed "ActiveViewer", a technological platform that enables massive and interactive remote events, and performed a year-long large-scale experiment, providing a series of massive remote school trips to several Italian cities. We designed a new school trip format, named "CodyTrip" that merges coding and computational thinking with elements of traditional school outings, and provides an engaging experience for participants. In this paper, we present the format and five online trips performed during the school year 2020/2021. The results based on user feedback support the adoption of the tool not only as a stopgap measure for school outings throughout the pandemic but as an accessible and inclusive tool to widen the possibilities of cultural tourism.},
  keywords={COVID-19;Pandemics;Education;Urban areas;Sociology;Human factors;Particle measurements;CoViD-19;distance learning;educational technology;virtual tourism},
  doi={10.1109/IoTT56174.2022.9925899},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{7797363,
  author={Bortoletto, Antonio C. and Minami, Mario and Kurashima, Celso S.},
  booktitle={2016 IEEE International Symposium on Consumer Electronics (ISCE)}, 
  title={DSP altered feedback system for anti-stuttering applications}, 
  year={2016},
  volume={},
  number={},
  pages={5-6},
  abstract={An altered feedback system aims to help people that suffer of stuttering and speech fluency disorder. The basic therapy approach is to modify the original voice and to present it back to his/her ear. By hearing the altered signal, he/she thinks someone else is talking the same words together, which results in a natural fluent speech. Our system modifies the voice pitch frequency and reduces background noise. The output signal produces a comfortable and natural altered feedback voice. The hardware implementation with a low-cost DSP processor presents a satisfactory real-time computational performance and low energy consumption.},
  keywords={Digital signal processing;Speech;Speech processing;Power demand;Signal processing algorithms;Adaptive filters;Real-time systems;speech/voice processing;digital signal processing},
  doi={10.1109/ISCE.2016.7797363},
  ISSN={2159-1423},
  month={Sep.},}@INPROCEEDINGS{488476,
  author={Huffman, J.},
  booktitle={Proceedings of WESCON '93}, 
  title={The Zen of fuzzy logic and neural networks}, 
  year={1993},
  volume={},
  number={},
  pages={451-454},
  abstract={The modern technologies of fuzzy logic and neural networks are based on operations on truth values or degrees of class membership. They operate more closely to the manner that we currently believe humans use to think and control. Once you understand the underlying functionality you can find ways to apply the technologies to otherwise difficult to solve problems. If we take human thought and action as one baseline for intelligence, then neural nets, fuzzy logic and their hybrids can be seen as more intelligent platforms. These more intelligent tools allow users to re-frame the problem space to a larger systems view. An implementor no longer has to be concerned with the underlying physics of a system, or with control theory details. The problem space is expanded to a higher level while the lower level part is passed off to the core computational method. This paper proposes the effects of a whole new approach to problem solving enabled by neural/fuzzy technologies.},
  keywords={Fuzzy logic;Neural networks;Space technology;Problem-solving;Humans;Computer networks;Marketing and sales;Springs;Marine vehicles;Physics},
  doi={10.1109/WESCON.1993.488476},
  ISSN={1095-791X},
  month={Sep.},}@ARTICLE{9380389,
  author={Tzimpragos, Georgios and Volk, Jennifer and Vasudevan, Dilip and Tsiskaridze, Nestan and Michelogiannakis, George and Madhavan, Advait and Shalf, John and Sherwood, Timothy},
  journal={IEEE Micro}, 
  title={Temporal Computing With Superconductors}, 
  year={2021},
  volume={41},
  number={3},
  pages={71-79},
  abstract={Creating computing systems able to address our ever-increasing needs, especially as we reach the end of CMOS transistor scaling, will require truly novel methods of computing. However, the traditional logic abstractions and the digital design patterns we understand so well have coevolved with the hardware technology that has embodied them. As we look past CMOS, there is no reason to think that those same abstractions best serve to encapsulate the computational potential inherent to emerging devices. We posit that a new and radically more efficient foundation for computing lies at the intersection of superconductor electronics and delay-coded computation. Building on recent work in race logic, we show that superconducting circuits can naturally compute directly over temporal relationships between pulse arrivals; that the computational relationships between those pulse arrivals can be formalized through a functional extension to a temporal predicate logic used in the verification community; and that the resulting architectures can operate asynchronously and describe real and useful computations. We verify our hypothesis through a combination of detailed analog circuit models and layout designs, a formal analysis of our abstractions, and an evaluation of several superconducting temporal accelerators.},
  keywords={Superconducting logic circuits;Logic gates;Delays;Superconductivity;Semantics;Hardware;Josephson junctions},
  doi={10.1109/MM.2021.3066377},
  ISSN={1937-4143},
  month={May},}@INPROCEEDINGS{8658572,
  author={Lobo de Aguiar Gomes, Ludymila and Reginaldo Hughes Carvalho, José and Lauschner, Tanara and Nakamura, Fabilo G. and de Freitas, Rosiane},
  booktitle={2018 IEEE Frontiers in Education Conference (FIE)}, 
  title={Encouraging Women to Pursue a Computer Science Career in the Context of a Third World Country}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={This innovative practice full paper presents a set of engaging actions aimed to encourage women to pursue a Computer Science career in a city of a third world country (Manaus, Brazil). Despite worldwide efforts to promote gender equality, typically, women account for less than 30% of the workforce in technological areas. In third world countries, the situation is much more unbalanced. Poor educational and economic conditions, allied with a chauvinism culture contaminated by sexism and stereotypes, are strong forces that repel the young girls from IT areas. As a result, the percentage of women in local Computer Science majors is lower than expected. The authors detail a program to involve girls from all school levels in computer science career, which is indeed the adaptation of a national program, combined with indigenous elements. The mentioned adaptation was a key success factor to catch the attention of students and local educators. Some activities that are included in this program are lectures at scientific, technological and gender discussion events, realization of dynamics in schools for the dissemination of computational thinking in children and young students, training students to take part in programming contests and develop knowledge into real computational applications. These actions resulted in highlights achieved in programming contests and prizes obtained through application development, and have provided a more conducive academic environment to discuss issues related to the female gender in science and technology fields. Besides the fundamentals of the program, the authors present the results of the last three initiatives, which happened in conjunction with local events, and the promising opportunities perceived in Computer Science major of a local university.},
  keywords={Engineering profession;Conferences;Programming profession;STEM;gender equality;diversity politics, STEM education;women inclusion and leadership},
  doi={10.1109/FIE.2018.8658572},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{1383168,
  author={Lumetta, S.S. and Krishnamurthy, A. and Culler, D.E.},
  booktitle={Supercomputing '95:Proceedings of the 1995 ACM/IEEE Conference on Supercomputing}, 
  title={Towards Modeling the Performance of a Fast Connected Components Algorithm on Parallel Machines}, 
  year={1995},
  volume={},
  number={},
  pages={32-32},
  abstract={We present and analyze a portable, high-performance algorithm for finding connected components on modern distributed memory multiprocessors. The algorithm is a hybrid of the classic DFS on the subgraph local to each processor and a variant of the Shiloach-Vishkin PRAM algorithm on the global collection of subgraphs. We implement the algorithm in Split-C and measure performance on the the Cray T3D, the Meiko CS-2, and the Thinking Machines CM-5 using a class of graphs derived from cluster dynamics methods in computational physics. On a 256 processor Cray T3D, the implementation outperforms all previous solutions by an order of magnitude. A characterization of graph parameters allows us to select graphs that highlight key performance features. We study the effects of these parameters and machine characteristics on the balance of time between the local and global phases of the algorithm and find that edge density, surface-to-volume ratio, and relative communication cost dominate performance. By understanding the effect of machine characteristics on performance, the study sheds light on the impact of improvements in computational and/or communication performance on this challenging problem.},
  keywords={Parallel machines;Clustering algorithms;Phase change random access memory;Concurrent computing;Computer science;Performance analysis;Algorithm design and analysis;Physics computing;Costs;Computer vision;performance modeling (modelling);connected components;distributed memory;parallel machines;hybrid algorithm},
  doi={10.1145/224170.224275},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9885427,
  author={Joseph, Ushus Maria and Jacob, Mendus},
  booktitle={2022 International Conference on Computing, Communication, Security and Intelligent Systems (IC3SIS)}, 
  title={Developing a Real time model to Detect SMS Phishing Attacks in Edges using BERT}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Phishing is the enchanting utilization of automated trades to cheat and exploit clients. Phishing attacks exertion to get intriguing, private information, for instance, usernames, passwords, charge card information, and affiliation confirmations, absolutely. By acting like a real individual or foundation through telephone or email, electronic aggressors utilize social expecting to push occurrences toward performing unequivocal activities like tapping on a perilous collusion or affiliation or wilfully uncovering private data. Nowadays, aggressors use different correspondence mediums to talk with the adversities, for instance, email, message (SMS), telephone, and others. No matter what the quick movement of Internet show based illuminating affiliations, SMS genuinely remains an obvious correspondence relationship in our lives as of in the relatively recent past. For example, a few affiliations consider that messages are more convincing than messages. This is thinking about the way that 82% of SMSs are explored inside 5 min., yet clients simply open one of each four messages they get. The significance of generally suggests irritating or unconstrained messages got by phone clients through Short Messaging Service (SMS). The SMS phishing is another strategy where the phisher works the SMS as a medium to visit with individuals being suggested and this system is seen as smishing (SMS+phishing). In any case, SMS is one of the potential instruments to really chat with others through phones without the web. As Transfer Learning from colossal degree set up models ends up being more inevitable in Natural Language Processing (NLP), working these huge models in on-the-edge as well as under obliged computational arrangement or confirmation monetary plans stays testing. Phones are famous with engineers since they're expected fast responses pondering insignificant huge information. For seeing phishing attacks in low computational contraptions we can use a quantized model. This work focuses on seeing SMS phishing attacks continuously with the help of BERT in edges. Not the slightest bit like reliable language depiction models, BERT expected to pre-train basic bidirectional depictions from unlabeled text by customarily shaping on both left and right setting in all layers.},
  keywords={},
  doi={10.1109/IC3SIS54991.2022.9885427},
  ISSN={},
  month={June},}@INPROCEEDINGS{10578908,
  author={Possaghi, Isabella and Papavlasopoulou, Sofia},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Challenges in Digital STEM Education Delivery: A Case Study from the Teachers' Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={In the last decade, educational reforms introduced technologies and digital tools to a higher degree, serving as powerful catalysts in educational innovation for creating, managing, and delivering content in STEM education with a focus on computational and engineering subjects. However, in the small reality of the classroom, some discrepancies arise between policy objectives and everyday practice. The research community emphasises the importance of providing technology infusions based on educators' pedagogical beliefs as well as needs rooted in the authentic scholarly environment. Considering this perspective when orchestrating in-classroom technology can support educators in their daily experiences and enhance their digital competencies. To contribute to this aim, we propose a case study carried out via interviews with fellow primary and secondary teachers, tackling challenges in STEM (Science, Technology, Engineering, and Mathematics), including Computer Science (CS) and Computational thinking (CT) education delivery. Along with the teachers' perspectives, our study aims to obtain a detailed account of the classroom's internal dynamics as perceived by the teachers. The most prominent findings concern the disparity among educators' proficiency in technology endorsement, impacting the consistency in content delivery, the complexity of the assessment of students' learning process if it is digital-based, and the inclusivity and trustworthiness of online content. Finally, we suggest guidance for a further mindful in-school uptake of technology to support teachers in orchestrating content delivery with educational technologies and enhance their confidence in this aspect.},
  keywords={Computer science;Technological innovation;Catalysts;Educational technology;Complexity theory;Stakeholders;Interviews;Digital Literacy;STEM;Digital Education;Learning;Educational Technology;Teachers},
  doi={10.1109/EDUCON60312.2024.10578908},
  ISSN={2165-9567},
  month={May},}@ARTICLE{8932345,
  author={Oliveira, Tiago and Stringhini, Denise and Santos Craibas, José Jailson},
  journal={IEEE Latin America Transactions}, 
  title={A Practical and Systemic Curricular Approach to Teach Computer Systems}, 
  year={2019},
  volume={17},
  number={08},
  pages={1349-1362},
  abstract={The design of computational systems is an important matter that must be especially present in Computer Engineering curriculum. Traditionally, Computer Engineering curriculum address this theme in a compartmentalized way in specific curricular units. This organization creates a fragmented view of the complex computational systems development, understood here as the specification, design, implementation and integration of the lines of computer architecture and organization, systems engineering, compilers, operating systems and computer networks. To avoid this fragmented view, this article proposes a systemic and curricular approach, integrating hardware and software, which allows students to design a complex computer system over three years of their academic trajectories. This approach was validated in a Computer Engineering course at the Federal University of São Paulo, bringing positive results in relation to students' motivation and enthusiasm, as well as encouraging creative and innovative thinking.},
  keywords={Software;Hardware;Field programmable gate arrays;Unified modeling language;IEEE transactions;Organizations;Education;teaching of computer systems;curricular and systemic approach;hardware and software designs},
  doi={10.1109/TLA.2019.8932345},
  ISSN={1548-0992},
  month={August},}@INPROCEEDINGS{8965997,
  author={Jia, Jizheng and Zhao, Qiyang},
  booktitle={2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)}, 
  title={Siamese Score: Detecting Mode Collapse for GANs}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Despite large strides in terms of generative adversarial networks (GANs) for image generation, evaluating and comparing GANs remains an open question. Several measures have been introduced, however, there is no consensus in terms of the best score. In this paper, we delve into the widely-used metric Inception Score (based on KL divergence), revealing that it fails to detect intra-class mode collapse. Meanwhile, Wasserstein distance has received much attention in comparing distributions in recent years but suffers heavy computational burden in high dimensional space. Our idea is that we can find specific embedding space where Euclidean distance could mimic Wasserstein distance to solve the heavy computational problem. This space can be found using a Siamese network, which could be trained quickly because of shared weights. We also apply several proposed new techniques to get better image embedding. To evaluate our proposed metric (Siamese Score), we simulate mode collapse using K-means clustering performed on real data set. To further validate it, we perform an empirical study on several GAN models and use the generated images to do the task. Experiments show that Siamese Score can detect mode collapse and is time-efficient compared with Inception Score and we think our score can be complementary to Inception Score.},
  keywords={},
  doi={10.1109/CISP-BMEI48845.2019.8965997},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{6972195,
  author={Fekete, Krisztián and Pelle, Ádám and Csorba, Kristóf},
  booktitle={2014 IEEE 36th International Telecommunications Energy Conference (INTELEC)}, 
  title={Energy efficient code optimization in mobile environment}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={Nowadays the mobile devices energy consumption has become a very serious issue. Due to the fast growing mobile industry the current devices usually contain wireless (Wi-Fi, 3G, 4G and Bluetooth), GPS and other heavy network sensitive technologies. The cell battery manufacturers usually cannot keep the pace with this fast altering environment and demands, hence the devices get inappropriate battery. Recently many researchers deal with this topic trying to find out a reasonable solution for energy optimization without compromising the functionality of the devices. A possible approach to deal with the problem today and achieve the desired result is the code side optimization. The market based mobile application distribution model makes this challenge harder. Sometimes the code quality of the uploaded applications are poor and the market owners are not able to force the developers to write clear and energy efficient code, they can only give them recommendations. The question is coming up: how could we still encourage the individual developers and companies to write optimized and a bit more standardized code? The answer could be delivering them tools to facilitate the refactoring and code quality managing processes. One way we can deal with energy problem is to reorganize the heavy computational tasks out of the device to the cloud or to just another machine. This technique is called “offloading”. In this paper we are going to introduce a new code generation extension for software engineers which is aiming to automate the offload to web services. Those services can then be easily deployed to any desired location to ease the mobile devices computational task. We think this tool would be really helpful to the community and the industrial users also.},
  keywords={Optimization;Mobile communication;Visualization;Measurement;Software;Mobile handsets;Generators},
  doi={10.1109/INTLEC.2014.6972195},
  ISSN={2158-5210},
  month={Sep.},}@ARTICLE{9409047,
  author={Yahia, Nesrine Ben and Hlel, Jihen and Colomo-Palacios, Ricardo},
  journal={IEEE Access}, 
  title={From Big Data to Deep Data to Support People Analytics for Employee Attrition Prediction}, 
  year={2021},
  volume={9},
  number={},
  pages={60447-60458},
  abstract={In the era of data science and big data analytics, people analytics help organizations and their human resources (HR) managers to reduce attrition by changing the way of attracting and retaining talent. In this context, employee attrition presents a critical problem and a big risk for organizations as it affects not only their productivity but also their planning continuity. In this context, the salient contributions of this research are as follows. Firstly, we propose a people analytics approach to predict employee attrition that shifts from a big data to a deep data context by focusing on data quality instead of its quantity. In fact, this deep data-driven approach is based on a mixed method to construct a relevant employee attrition model in order to identify key employee features influencing his/her attrition. In this method, we started thinking `big' by collecting most of the common features from the literature (an exploratory research) then we tried thinking `deep' by filtering and selecting the most important features using survey and feature selection algorithms (a quantitative method). Secondly, this attrition prediction approach is based on machine, deep and ensemble learning models and is experimented on a large-sized and a medium-sized simulated human resources datasets and then a real small-sized dataset from a total of 450 responses. Our approach achieves higher accuracy (0.96, 0.98 and 0.99 respectively) for the three datasets when compared previous solutions. Finally, while rewards and payments are generally considered as the most important keys to retention, our findings indicate that `business travel', which is less common in the literature, is the leading motivator for employees and must be considered within HR policies to retention.},
  keywords={Big Data;Organizations;Radio frequency;Predictive models;Support vector machines;Data models;Analytical models;Deep people analytics;employee attrition;retention;prediction;interpretation;policies recommendation},
  doi={10.1109/ACCESS.2021.3074559},
  ISSN={2169-3536},
  month={},}@ARTICLE{9940938,
  author={Wang, Ziyuan and Wang, Li},
  journal={IEEE Access}, 
  title={An Attention Approach for Dimensionality Reduction That Can Correct Feature Collection Skewness}, 
  year={2022},
  volume={10},
  number={},
  pages={117273-117280},
  abstract={It has been demonstrated that adding an attention mechanism to a convolutional neural network enhances network performance. However, in practice, the skewness error during the extraction process affects the feature information owing to the implementation of the global average pooling operation, which eventually lowers the performance of the network design. We think that when the weight is activated, the spatial information is effectively captured while the extraction range of the channel information is narrowed. We also think that because the weight is activated using multiple local extraction substitutions, the influence of skewness error can be effectively reduced. As a result, we suggest dimensionality reduction attention(RA) in this study as a new type of attention mechanism. Dimensionality reduction attention is a method of combining spatial information and channel information into a new feature distribution by aggregating dimensionality reduction of feature information, in contrast to other attentions that act on distinct feature tensors in space and channel. Under the premise of capturing long-distance context information and guaranteeing feature coordinates, it may realize the locality of spatial information through this operation and identify the local information of each channel. To completely display the important feature information, the produced feature maps are then encoded into two complimentary attention maps along the spatial and channel directions, respectively. Our dimension reduction focus is a straightforward and all-encompassing module. We run tests on various datasets using various deep architectures and various class designs. The outcomes of the trial demonstrate that our attention-based approach has clear benefits.},
  keywords={Feature extraction;Dimensionality reduction;Tensors;Convolutional neural networks;Convolution;Three-dimensional displays;Convolutional neural network;attention mechanism;feature extraction network},
  doi={10.1109/ACCESS.2022.3220245},
  ISSN={2169-3536},
  month={},}@ARTICLE{8762113,
  author={Dey, Niladri Sekhar and Gunasekhar, T.},
  journal={IEEE Access}, 
  title={A Comprehensive Survey of Load Balancing Strategies Using Hadoop Queue Scheduling and Virtual Machine Migration}, 
  year={2019},
  volume={7},
  number={},
  pages={92259-92284},
  abstract={The recent growth in the demand for scalable applications from the consumers of the services has motivated the application development community to build and deploy the applications on cloud in the form of services. The deployed applications have significant dependency on the infrastructure available with the application providers. Bounded by the limitations of available resource pools on-premises, many application development companies have migrated the applications to third party cloud environments called data centers. The data center owners or the cloud service providers are entitled to ensure high performance and high availability of the applications and at the same time the desired scalability for the applications. Also, the cloud service providers are also challenging in terms of cost reduction and energy consumption reductions for better manageability of the data center without degrading the performance of the deployed applications. It is to be noted that the performance of the application does not only depend on the responsiveness of the applications rather also must be measured in terms of service level agreements. The violation of the service level agreements or SLA can easily disprove the purpose of application deployments on cloud-based data centers. Thus, the data center owners apply multiple load balancing strategies for maintaining the desired outcomes from the application owners at the minimized cost of data center maintainability. Hence, the demand of the research is to thoroughly study and identify the scopes for improvements in the parallel research outcomes. As the number of applications ranging from small data-centric applications coming with the demand of frequent updates with higher computational capabilities to the big data-centric application as big data analytics applications coming with efficient algorithms for data and computation load managements, the data center owners are forced to think for efficient algorithms for load managements. The algorithms presented by various research attempts have engrossed on application specific demands for load balancing using virtual machine migrations and the solution as the proposed algorithms have become application problem specific. Henceforth, the further demand of the research is a guideline for selecting the appropriate load balancing algorithm via virtual machine migration for characteristics-based specific applications. Hence, this paper presents a comprehensive survey on existing virtual machine migration and selection processes to understand the specific application-oriented capabilities of these strategies with the advantages and bottlenecks. Also, with the understanding of the existing measures for load balancing, it is also important to furnish the further improvement strategies, which can be made possible with a detailed understanding of the parallel research outcomes. Henceforth, this paper also equips the study with guidelines for improvements and for further study. Nonetheless, the study cannot be completed without the mathematical analysis for better understanding and experimental analysis on different standards of datasets for better conclusive decisions. Hence, this paper also presents the discussion on mathematical models and experimental result analysis for the conclusive decision on the improvement factors and the usability of the migration methods for various purposes. Finally, this paper is a comprehensive survey on the background of the research, recent research outcomes using mathematical modeling and experimental studies on various available datasets, and finally identify the scopes of improvements considering various aspects such as execution time, mean time before a VM migration, mean time before a host shutdown, number of node shutdowns, SLA performance degradation, VM migrations, and energy consumption.},
  keywords={Task analysis;Load management;Cloud computing;Data centers;Resource management;Virtual machining;Indexes;Data center;load balancing;task scheduler;FIFO;FAIR;capacity;hybrid;LATE;SAMR;context-aware;threshold;IQR;LR;MAD;LRR;THR;VM consolidation;VM migration;MC;MMT;RS;MU;PlanetLab;metric;VM migration analysis;energy consumption analysis;SLA analysis},
  doi={10.1109/ACCESS.2019.2927076},
  ISSN={2169-3536},
  month={},}@ARTICLE{10325513,
  author={Simonetti, Marco and Perri, Damiano and Gervasi, Osvaldo},
  journal={IEEE Access}, 
  title={Variational Methods in Optical Quantum Machine Learning}, 
  year={2023},
  volume={11},
  number={},
  pages={131394-131408},
  abstract={The computing world is rapidly evolving and advancing, with new ground-breaking technologies emerging. Quantum Computing and Quantum Machine Learning have opened up new possibilities, providing unprecedented computational power and problem-solving capabilities while offering a deeper understanding of complex systems. Our research proposes new variational methods based on a deep learning system based on an optical quantum neural network applied to Machine Learning models for point classification. As a case study, we considered the binary classification of points belonging to a certain geometric pattern (the Two-Moons Classification problem) on a plane. We think it is reasonable to expect benefits from using hybrid deep learning systems (classical + quantum), not just in terms of accelerating computation but also in understanding the underlying phenomena and mechanisms. This will result in the development of new machine-learning paradigms and a significant advancement in the field of quantum computation. The selected dataset is a set of 2D points creating two interleaved semicircles and is based on a 2D binary classification generator, which aids in evaluating the performance of particular methods. The two coordinates of each unique point,  $x_{1}$  and  $x_{2}$ , serve as the features since they present two disparate data sets in a two-dimensional representation space. The goal was to create a quantum deep neural network that could recognise and categorise points accurately with the fewest trainable parameters possible.},
  keywords={Quantum computing;Quantum mechanics;Logic gates;Computers;Nonlinear optics;Optical network units;Deep learning;Feedforward neural networks;Neural networks;Quantum computing;variational methods;deep learning;quantum feed-forward neural networks;optical quantum computing},
  doi={10.1109/ACCESS.2023.3335625},
  ISSN={2169-3536},
  month={},}@ARTICLE{8732419,
  author={Rappaport, Theodore S. and Xing, Yunchou and Kanhere, Ojas and Ju, Shihao and Madanayake, Arjuna and Mandal, Soumyajit and Alkhateeb, Ahmed and Trichopoulos, Georgios C.},
  journal={IEEE Access}, 
  title={Wireless Communications and Applications Above 100 GHz: Opportunities and Challenges for 6G and Beyond}, 
  year={2019},
  volume={7},
  number={},
  pages={78729-78757},
  abstract={Frequencies from 100 GHz to 3 THz are promising bands for the next generation of wireless communication systems because of the wide swaths of unused and unexplored spectrum. These frequencies also offer the potential for revolutionary applications that will be made possible by new thinking, and advances in devices, circuits, software, signal processing, and systems. This paper describes many of the technical challenges and opportunities for wireless communication and sensing applications above 100 GHz, and presents a number of promising discoveries, novel approaches, and recent results that will aid in the development and implementation of the sixth generation (6G) of wireless networks, and beyond. This paper shows recent regulatory and standard body rulings that are anticipating wireless products and services above 100 GHz and illustrates the viability of wireless cognition, hyper-accurate position location, sensing, and imaging. This paper also presents approaches and results that show how long distance mobile communications will be supported to above 800 GHz since the antenna gains are able to overcome air-induced attenuation, and present methods that reduce the computational complexity and simplify the signal processing used in adaptive antenna arrays, by exploiting the Special Theory of Relativity to create a cone of silence in over-sampled antenna arrays that improve performance for digital phased array antennas. Also, new results that give insights into power efficient beam steering algorithms, and new propagation and partition loss models above 100 GHz are given, and promising imaging, array processing, and position location results are presented. The implementation of spatial consistency at THz frequencies, an important component of channel modeling that considers minute changes and correlations over space, is also discussed. This paper offers the first in-depth look at the vast applications of THz wireless products and applications and provides approaches for how to reduce power and increase performance across several problem domains, giving early evidence that THz techniques are compelling and available for future wireless communications.},
  keywords={Wireless communication;Wireless sensor networks;Antenna arrays;Bandwidth;Communication system security;Cognition;Imaging;mmWave;millimeter wave;5G;D-band;6G;channel sounder;propagation measurements;Terahertz (THz);array processing;imaging;scattering theory;cone of silence;digital phased arrays;digital beamformer;signal processing for THz;position location;channel modeling;THz applications;wireless cognition;network offloading},
  doi={10.1109/ACCESS.2019.2921522},
  ISSN={2169-3536},
  month={},}@ARTICLE{539739,
  author={Nieuwejaar, N. and Kotz, D. and Purakayastha, A. and Sclatter Ellis, C. and Best, M.L.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={File-access characteristics of parallel scientific workloads}, 
  year={1996},
  volume={7},
  number={10},
  pages={1075-1089},
  abstract={Phenomenal improvements in the computational performance of multiprocessors have not been matched by comparable gains in I/O system performance. This imbalance has resulted in I/O becoming a significant bottleneck for many scientific applications. One key to overcoming this bottleneck is improving the performance of multiprocessor file systems. The design of a high-performance multiprocessor file system requires a comprehensive understanding of the expected workload. Unfortunately, until recently, no general workload studies of multiprocessor file systems have been conducted. The goal of the CHARISMA project was to remedy this problem by characterizing the behavior of several production workloads, on different machines, at the level of individual reads and writes. The first set of results from the CHARISMA project describe the workloads observed on an Intel iPSC/860 and a Thinking Machines CM-5. This paper is intended to compare and contrast these two workloads for an understanding of their essential similarities and differences, isolating common trends and platform-dependent variances. Using this comparison, we are able to gain more insight into the general principles that should guide multiprocessor file-system design.},
  keywords={File systems;Application software;Concurrent computing;Computer Society;Performance gain;Production;Student members;System performance;Scientific computing;Supercomputers},
  doi={10.1109/71.539739},
  ISSN={1558-2183},
  month={Oct},}@ARTICLE{6949509,
  author={Cummings, Mary Missy},
  journal={IEEE Intelligent Systems}, 
  title={Man versus Machine or Man + Machine?}, 
  year={2014},
  volume={29},
  number={5},
  pages={62-69},
  abstract={Allocating roles and functions between the human and computer is critical in defining efficient and effective system architectures. However, past methodologies for balancing the roles and functionalities between humans and computers in complex systems have little connection to different types of required cognition, behaviors, or tasks, or don't address the role of uncertainty in the environment. To augment these previous role allocation approaches, this article presents a modification to the skill, rule, and knowledge-based behavior taxonomy that includes expertise and uncertainty. Skill-based behaviors are the best candidates for automation, assuming significant sensor performance assumptions can be met, but rule and knowledge-based reasoning are better suited for human-computer collaboration. Such systems should be designed so that humans harness the raw computational and search power of computers for state-space reduction, but also allow them the latitude to apply their expertise in uncertain situations through inductive reasoning for potentially creative, out-of-the-box thinking.},
  keywords={Human computer interaction;Automation;Human factors;Man machine systems;Resource management;Information processing;automation;computer-supported collaborative work;systems analysis and design;interactive systems;intelligent systems},
  doi={10.1109/MIS.2014.87},
  ISSN={1941-1294},
  month={Sep.},}@ARTICLE{642945,
  author={Ramaswamy, S. and Sapatnekar, S. and Banerjee, P.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={A framework for exploiting task and data parallelism on distributed memory multicomputers}, 
  year={1997},
  volume={8},
  number={11},
  pages={1098-1116},
  abstract={Distributed Memory Multicomputers (DMMs), such as the IBM SP-2, the Intel Paragon, and the Thinking Machines CM-5, offer significant advantages over shared memory multiprocessors in terms of cost and scalability. Unfortunately, the utilization of all the available computational power in these machines involves a tremendous programming effort on the part of users, which creates a need for sophisticated compiler and run-time support for distributed memory machines. In this paper, we explore a new compiler optimization for regular scientific applications-the simultaneous exploitation of task and data parallelism. Our optimization is implemented as part of the PARADIGM HPF compiler framework we have developed. The intuitive idea behind the optimization is the use of task parallelism to control the degree of data parallelism of individual tasks. The reason this provides increased performance is that data parallelism provides diminishing returns as the number of processors used is increased. By controlling the number of processors used for each data parallel task in an application and by concurrently executing these tasks, we make program execution more efficient and, therefore, faster.},
  keywords={Parallel processing;Data structures;Random access memory;Optimizing compilers;Costs;Scalability;Runtime;Concurrent computing;Distributed computing;Program processors},
  doi={10.1109/71.642945},
  ISSN={1558-2183},
  month={Nov},}@ARTICLE{7562319,
  author={Yang, Xin-She and Deb, Suash and Fong, Simon and He, Xingshi and Zhao, Yu-Xin},
  journal={Computer}, 
  title={From Swarm Intelligence to Metaheuristics: Nature-Inspired Optimization Algorithms}, 
  year={2016},
  volume={49},
  number={9},
  pages={52-59},
  abstract={Nature has provided rich models for computational problem solving, including optimizations based on the swarm intelligence exhibited by fireflies, bats, and ants. These models can stimulate computer scientists to think nontraditionally in creating tools to address application design challenges.},
  keywords={Particle swarm optimization;Metaheuristics;Molecular computing;swarm intelligence;metaheuristics;nature-inspired computing;emerging computing paradigms},
  doi={10.1109/MC.2016.292},
  ISSN={1558-0814},
  month={Sep.},}@ARTICLE{10194240,
  author={Wang, Xingxia and Yang, Jing and Wang, Yutong and Miao, Qinghai and Wang, Fei-Yue and Zhao, Aijun and Deng, Jian-Ling and Li, Lingxi and Na, Xiaoxiang and Vlacic, Ljubo},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={Steps Toward Industry 5.0: Building “6S” Parallel Industries With Cyber-Physical-Social Intelligence}, 
  year={2023},
  volume={10},
  number={8},
  pages={1692-1703},
  abstract={Very recently, intensive discussions and studies on Industry 5.0 have sprung up and caused the attention of researchers, entrepreneurs, and policymakers from various sectors around the world. However, there is no consensus on why and what is Industry 5.0 yet. In this paper, we define Industry 5.0 from its philosophical and historical origin and evolution, emphasize its new thinking on virtual-real duality and human-machine interaction, and introduce its new theory and technology based on parallel intelligence (PI), artificial societies, computational experiments, and parallel execution (the ACP method), and cyber-physical-social systems (CPSS). Case studies and applications of Industry 5.0 over the last decade have been briefly summarized and analyzed with suggestions for its future development. We believe that Industry 5.0 of virtual-real interactive parallel industries has great potentials and is critical for building smart societies. Steps are outlined to ensure a roadmap that would lead to a smooth transition from CPS-based Industry 4.0 to CPSS-based Industry 5.0 for a better world which is Safe in physical spaces, Secure in cyberspaces, Sustainable in ecology, Sensitive in indi-vidual privacy and rights, Service for all, and Smartness of all.},
  keywords={Industries;Privacy;Service robots;Robot kinematics;Buildings;Smart contracts;Transportation;ACP;artificial intelligence;CPS;CPSS;Industry 4.0;Industry 5.0;parallel industries;parallel intelligence},
  doi={10.1109/JAS.2023.123753},
  ISSN={2329-9274},
  month={August},}@ARTICLE{5009467,
  author={Gertner, Izidor and Shamash, Moshe},
  journal={IEEE Transactions on Computers}, 
  title={VLSI Architectures for Multidimensional Fourier Transform Processing}, 
  year={1987},
  volume={C-36},
  number={11},
  pages={1265-1274},
  abstract={It is often desirable in modern signal processing applications to perform two-dimensional or three-dimensional Fourier transforms. Until the advent of VLSI it was not possible to think about one chip implementation of such processes. In this paper several methods for implementing the multidimensional Fourier transform together with the VLSI computational model are reviewed and discussed. We show that the lower bound for the computation of the multidimensional transform is O(n2 log2 n). Existing nonoptimal architectures suitable for implementing the 2-D transform, the RAM array transposer, mesh connected systolic array, and the linear systolic matrix vector multiplier are discussed for area time tradeoff. For achieving a higher degree of concurrency we suggest the use of rotators for permutation of data. With ``hybrid designs'' comprised of a rotator and one-dimensional arrays which compute the one-dimensional Fourier transform we propose two methods for implementation of multidimensional Fourier transform. One design uses the perfect shuffle for rotations and achieves an AT2p of O(n2 log2 n· log2 N). An optimal architecture for calculation of multidimensional Fourier transform is proposed in this paper. It is based on arrays of processors computing one-dimensional Fourier transforms and a rotation network or rotation array. This architecture realizes the AT2p lower bound for the multidimensional FT processing.},
  keywords={Computer architecture;Arrays;Transforms;Discrete Fourier transforms;Random access memory;Fourier transforms;Microprocessors;Cube connected cycles;hybrid designs;mesh connected systolic array;multidimensional Fourier transform;necklaces;optimal architecture;perfect shuffle;RAM array transposer;rotation network;VLSI complexity},
  doi={10.1109/TC.1987.5009467},
  ISSN={1557-9956},
  month={Nov},}@ARTICLE{4135849,
  author={Snyder, Richard V.},
  journal={IEEE Microwave Magazine}, 
  title={Practical aspects of microwave filter development}, 
  year={2007},
  volume={8},
  number={2},
  pages={42-54},
  abstract={Design of practical filters involves consideration of a large variety of disciplines and factors. These include the electrical, physical, and economic properties of resonant and coupled elements, the materials and processes used for fabrication (properties and cost factors), and the labor cost associated with assembly and adjustment. Modeling is a vital asset in the design process, but the real properties of filter elements must be incorporated into the modeling process, using an evolutional method in which the model is adjusted to compensate for the unavoidable nonideal nature of the elements, stray couplings, and the like. This is similar to the older, laboratory "cut and try" method, but far less costly and time-consuming. This implies that modeling should accept available measured data as input. Designers should always think about minimizing production labor, considering manufacturing tolerances possibly as a trade-off against tuning time and recognizing that availability of skilled labor is more than simply a cost but rather a constraint on delivery rate. Continued development of accurate and complete models of parts, enclosures, and interconnects, in conjunction with ever-better computational capabilities, could (if properly used) enable rapid and accurate designs of filters with very predictable and producible results},
  keywords={Microwave filters;Costs;Economic forecasting;Resonance;Fabrication;Assembly;Process design;Laboratories;Production;Manufacturing},
  doi={10.1109/MMW.2007.335528},
  ISSN={1557-9581},
  month={April},}@ARTICLE{7971992,
  author={Burleson, Winslow S. and Harlow, Danielle B. and Nilsen, Katherine J. and Perlin, Ken and Freed, Natalie and Jensen, Camilla Nørgaard and Lahey, Byron and Lu, Patrick and Muldner, Kasia},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Active Learning Environments with Robotic Tangibles: Children's Physical and Virtual Spatial Programming Experiences}, 
  year={2018},
  volume={11},
  number={1},
  pages={96-106},
  abstract={As computational thinking becomes increasingly important for children to learn, we must develop interfaces that leverage the ways that young children learn to provide opportunities for them to develop these skills. Active Learning Environments with Robotic Tangibles (ALERT) and Robopad, an analogous on-screen virtual spatial programming environment for educational Human Robot Interaction (HRI), have been developed. Evaluations of these in the context of free play and open-ended learning activities show that both systems afford opportunities for young children to engage in spatial programming, creating improvisational and sequential programs that mediate interactions between the environment, robots, and humans in responsive and creative ways. These systems demonstrate innovative opportunities for advancing mixed reality spatial programming activities as a form of HRI that fosters engaging seamless cyberlearning experiences, across formal and informal environments.},
  keywords={Robots;Computers;Electronic mail;Programming profession;Education;Context;Computers and education;human-computer interaction;robotics},
  doi={10.1109/TLT.2017.2724031},
  ISSN={1939-1382},
  month={Jan},}@ARTICLE{8263146,
  author={Wang, Yue and Jiao, Yanmei and Xiong, Rong and Yu, Hongsheng and Zhang, Jiafan and Liu, Yong},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={MASD: A Multimodal Assembly Skill Decoding System for Robot Programming by Demonstration}, 
  year={2018},
  volume={15},
  number={4},
  pages={1722-1734},
  abstract={Programming by demonstration (PBD) transforms the robot programming from the code level to automated interface between robot and human, promoting the flexibility of robotized automation. In this paper, we focus on programming the industrial robot for assembly tasks by parsing the human demonstration into a series of assembly skills and compiling the skill to the robot executables. To achieve this goal, an identification system using multimodal information to recognize the assembly skill, called MASD, is proposed including: 1) an initial learning stage using a hierarchical model to recognize the action by considering the features from action-object effect, gesture, and trajectory and 2) a retrospective thinking stage using a segmentation method to cut the continuous demonstrations into multiple assembly skills optimally. Using MASD, the demonstration of assembly tasks can be explained with high accuracy in real time, driving a hypothesis that a PBD system on the top of MASD can be extended to more realistic assembly tasks beyond pure positional moving and picking. In experiments, the skill identification module is used to recognize the five kinds of assembly skills in demonstrations of both single and multiple assembly skills, and outperforms the comparative action identification methods. Besides integrated with the MASD, the PBD system can generate the program based on the demonstration and successfully enable an ABB industrial robotic arm simulator to assemble a flashlight and a switch, verifying the initial hypothesis. Note to Practitioners-In the conventional robotized automation, the key role of the robot mainly owes to its capacity for repeating a wide variety of tasks with high speed and accuracy in long term, with a cost of days to months of programming for deployment. On the other hand, the new trend of customization brings the new characteristics: production in short cycle and small volume. This irreversible momentum urges the robot to switch from task to task efficiently. The biggest bottleneck here is the tedious programming, which also has high prerequisites for most practitioners in manufacturing. This situation motivates the development of a PBD system that can understand the assembly skills performed by the human experts in the demonstration and accordingly generate the program for robot's execution of the taught task. In this paper, we present a skill decoding system to parse the observational raw demonstration into symbolic sequences, which is the crucial bridge to enable the automatic programming. The system achieves high performance in recognition and is tailored for the PBD in assembly tasks by considering both advantages and disadvantages in the background of assembly, such as controllable environment and limited computational resources. It is particularly useful for assembly tasks with modularized actions based on a set of standard parts. At the perspective of industrial application, the PBD upon the proposed system is a promising solution to improve the flexibility of manufacture, which is expected to be true in midterm but an important step toward this goal.},
  keywords={Service robots;Activity recognition;Robot learning;Robot programming;Real-time systems;Activity recognition;robot learning;robot programming},
  doi={10.1109/TASE.2017.2783342},
  ISSN={1558-3783},
  month={Oct},}@ARTICLE{9138392,
  author={López-Belmonte, Jesús and Marín-Marín, José-Antonio and Soler-Costa, Rebeca and Moreno-Guerrero, Antonio-José},
  journal={IEEE Access}, 
  title={Arduino Advances in Web of Science. A Scientific Mapping of Literary Production}, 
  year={2020},
  volume={8},
  number={},
  pages={128674-128682},
  abstract={Technology and computer learning have acquired a great projection in the field of education. Arduino arises from current technological innovations with the intention of promoting a new approach to learning through machines. The objective of this research is to analyze the evolution of the Arduino concept in the scientific literature. To achieve this aim, a bibliometric methodology based on scientific mapping and an analysis of co-words has been used. The scientific production of Arduino indexed in Web of Science has been analyzed. We have worked with an analysis unit of 346 documents. The results of this research show that the scientific production on Arduino in the field of education starts in 2010 until today. The communications in the congresses to present the results of the investigations developed are the most used means of diffusion. The National University of Distance Education and the Lucian Blaga University of Sibiu are particularly noteworthy. The authors with more scientific production in this field of study are Bogdan, M. and Castro, M. It is significant that the collection of studies on this subject is carried out, above all, by EDULEARN Proceedings and INTED Proceedings. It can be concluded that the field of study on Arduino in the educational field is relatively recent, so that today, the basis for scientific research is still being established. However, the most relevant aspects in this field of study are physic experiments, computational thinking and computer-based learning.},
  keywords={Education;Production;Bibliometrics;Tools;Software;Robots;Hardware;Arduino;documentary analysis;educational innovation;educative technology;scientific mapping},
  doi={10.1109/ACCESS.2020.3008572},
  ISSN={2169-3536},
  month={},}@ARTICLE{1044182,
  author={Korner, E. and Matsumoto, G.},
  journal={IEEE Engineering in Medicine and Biology Magazine}, 
  title={Cortical architecture and self-referential control for brain-like computation}, 
  year={2002},
  volume={21},
  number={5},
  pages={121-133},
  abstract={Discusses a new approach to understanding how the brain organizes computation. Progress in understanding the brain function under constant interactions with the sensory environment is hampered by inadequate models and theories. Obviously, current models and theories of brain computing still appear irrelevant when they are confronted with real-world problems. We argue that architecture in the brain does not reflect the result of thinking, the ready-made algorithm for solving a problem. Rather it should reflect the control that generates the constraints to select a proper algorithm for a specific problem that is posed by the input-or to create a new one if the application of the previously acquired ones does not provide a sufficient solution. We propose that a value system (based on a genetically imprinted a priori knowledge on coarse behavioral evaluation of sensory input) and neocortical columnar architecture are crucial elements of future artificial neural systems that are expected to emulate the performance of the brain. This should be the case especially for those cognitive tasks that appear easy for animals in their everyday life but turn out to be hopelessly tricky for the current generation of computers. In order to advance beyond the well known paradigms of current computational theory, we need a more functional understanding of brain-type computation.},
  keywords={Computer architecture;Brain modeling;Knowledge representation;Biological neural networks;Neuroscience;Control systems;Approximation algorithms;Computer networks;Signal processing;Intelligent systems},
  doi={10.1109/MEMB.2002.1044182},
  ISSN={1937-4186},
  month={Sep.},}@ARTICLE{9416889,
  author={Aragón, Mario Ezra and López-Monroy, Adrian Pastor and González-Gurrola, Luis Carlos and Montes-y-Gómez, Manuel},
  journal={IEEE Transactions on Affective Computing}, 
  title={Detecting Mental Disorders in Social Media Through Emotional Patterns - The Case of Anorexia and Depression}, 
  year={2023},
  volume={14},
  number={1},
  pages={211-222},
  abstract={Millions of people around the world are affected by one or more mental disorders that interfere in their thinking and behavior. A timely detection of these issues is challenging but crucial, since it could open the possibility to offer help to people before the illness gets worse. One alternative to accomplish this is to monitor how people express themselves, that is for example what and how they write, or even a step further, what emotions they express in their social media communications. In this article, we analyze two computational representations that aim to model the presence and changes of the emotions expressed by social media users. In our evaluation we use two recent public data sets for two important mental disorders: Depression and Anorexia. The obtained results suggest that the presence and variability of emotions, captured by the proposed representations, allow to highlight important information about social media users suffering from depression or anorexia. Furthermore, the fusion of both representations can boost the performance, equalling the best reported approach for depression and barely behind the top performer for anorexia by only 1 percent. Moreover, these representations open the possibility to add some interpretability to the results.},
  keywords={Depression;Social networking (online);Mental disorders;Mental health;Task analysis;Linguistics;Blogs;Mental disorders;emotional patterns;machine learning},
  doi={10.1109/TAFFC.2021.3075638},
  ISSN={1949-3045},
  month={Jan},}@INPROCEEDINGS{8363230,
  author={Plaza, Pedro and Sancristobal, Elio and Carro, German and Castro, Manuel and Blazquez, Manuel},
  booktitle={2018 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Scratch day to introduce robotics}, 
  year={2018},
  volume={},
  number={},
  pages={208-216},
  abstract={Scratch Day is made up of a global network of events. Its main goal is to bring people together to celebrate Scratch. Scratch is a free encryption platform that can be used online and offline for children. Scratch Day events bring together young people from the Scratch community. During these meetings, attendees share projects, learn from each other and welcome newcomers. Robotics and computational thinking are ideal tools for developing science, technology, engineering and mathematics (STEM) pedagogy. Currently, innovation and motivation of students during the learning process are promoted by educational robotics tools. Robots are increasingly integrated into our society. To such an extent that robots are becoming more and more common in our everyday environment. This paper presents a workshop which is focused on two main objectives. The first one is to celebrate Scratch Day promoting Scratch locally. On the other hand, this event is aimed to present a robotic educational tool for people as the first step to get into robotics world. This workshop is aimed on those adults who want to discover what possibilities Scratch brings in the introduction to robotics. Throughout this workshop an initiation to Scratch is developed in the context of educational robotics. As the most significant results throughout the workshop, it is clearly demonstrated that Scratch is an ideal tool for children and adults with no previous programming or robotic experience to begin learning both through hands-on experiences. Throughout this work the importance of combining theory and practice is shown in order to include fun tasks intertwined with the challenges of applying theory to problem solving.},
  keywords={Robots;Conferences;Programming profession;Tools;STEM;education;programming;robotics;STEM},
  doi={10.1109/EDUCON.2018.8363230},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{4032543,
  author={Goth, Christoph and Frohberg, Dirk and Schwabe, Gerhard},
  booktitle={2006 Fourth IEEE International Workshop on Wireless, Mobile and Ubiquitous Technology in Education (WMTE'06)}, 
  title={The Focus Problem in Mobile Learning}, 
  year={2006},
  volume={},
  number={},
  pages={153-160},
  abstract={Mobile learning has a lot of potential for supporting learning in situations such as in a museum, at a tourist sight or when exploring biological phenomena at a riverside. There learners can interact with their environment and still make use of the advantages of computational power. However, we have found many of such projects hindered by placing the technology too much in the focus of the learner. Instead of interacting with the environment, we found the learners interacting with the device, heads down and ignoring the environment. We found the issue of focus to be a massive problem, one which needs a completely new metaphor for the design of an educational and technical setting. Until now, the mobile devices have been interpreted as small desktops, always in the foreground of the learners' focus. Instead, we propose a different approach, deduced from the usage of mobile phones. Mobile applications need to be designed explicitly to free the learners' focus and push the application to the background. The good news is that the actual changes to be made in existing systems are not as fundamental as one may think},
  keywords={Legged locomotion;Biology computing;Mobile handsets;Handheld computers;Glass;Guidelines;Humans;Filters;Computer crashes},
  doi={10.1109/WMTE.2006.261366},
  ISSN={},
  month={Nov},}
