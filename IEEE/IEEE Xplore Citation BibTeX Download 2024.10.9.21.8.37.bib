@INPROCEEDINGS{9018582,
  author={Pancieri, Jussara and Siqueira, Fábio Ventorim and Oliveira, Márcia Gonçalves de and Santos, Marcelo Cardoso Lima dos},
  booktitle={2019 Latin American Robotics Symposium (LARS), 2019 Brazilian Symposium on Robotics (SBR) and 2019 Workshop on Robotics in Education (WRE)}, 
  title={Robotics in the Resocialization of Youngsters and Teenagers in Socio-Educational Measures}, 
  year={2019},
  volume={},
  number={},
  pages={429-434},
  abstract={This paper presents a proposal and an experience report of an educational robotics course integrated to the process of resocialization of youngsters and teenagers in socio-educational measures. This proposal adopts a teaching approach oriented to the development of comprehension, analysis, logical reasoning, creativity and collaboration skills in order to develop in these young people real world problemsolving skills. The main challenge of this proposal is to favor the assimilation of the contents and the development of robotics practice outside the classroom, since, in accommodation, no course material is accessible from paper and pencil to robotics practice instruments. Thus, the main differential of this work is literally working the computational thinking in spaces of deprivation of liberty in order to develop ideas for problem solving tasks. The results of this developed experience point to excellent opportunities for resocialization and professional orientation of young people in socio-educational measures through the teaching of robotics.},
  keywords={Robots;Education;Electronic components;Proposals;Programming profession;Problem-solving;resocialization, educational robotics, youngsters and teenagers in socio-educational measures},
  doi={10.1109/LARS-SBR-WRE48964.2019.00082},
  ISSN={2643-685X},
  month={Oct},}@INPROCEEDINGS{10366359,
  author={Boya-Lara, Carlos and Diaz-Solano, Daniela and Fehrenbach, Aaron},
  booktitle={2023 VI Congreso Internacional en Inteligencia Ambiental, Ingeniería de Software y Salud Electrónica y Móvil (AmITIC)}, 
  title={Educational robotics to enhance knowledge and skills in higher education: A systematic review}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Because of its ability to prepare students for the 21st century world of work, educational robotics (RE) has assumed a prominent role in education. Following the methodology provided by Kitchenham, we conducted a systematic literature review (SLR) to provide a comprehensive overview of studies, research, and practices related to robotics education in higher education. The study focuses on identifying the most commonly used RE hardware-based platforms in academic research publications, the type of knowledge intended to be imparted, and the skills or competencies reinforced by the platforms. Within the findings we can underline that there is no exclusive platform, but rather commercial ones are used, made by the researchers themselves, and even adapted from robots that were not designed for instructional purposes. Moreover, the subjects intended to be taught were all related to Science, Technology, Engineering and Mathematics (STEM) and oriented to electrical engineering, electronics, robotics, and computer science professions. On the other hand, the skills that improved the most were computational thinking, cooperation and sophisticated problem solving, which are essential for 21st century job descriptions.},
  keywords={Knowledge engineering;Electrical engineering;Computer science;Systematics;Bibliographies;Education;Software;educational robotics;higher education;educational platforms;systematic literature reviews (SLR);STEM},
  doi={10.1109/AmITIC60194.2023.10366359},
  ISSN={},
  month={Oct},}@ARTICLE{8949532,
  author={Kuai, Hongzhi and Zhang, Xiaofei and Yang, Yang and Chen, Jianhui and Shi, Bin and Zhong, Ning},
  journal={IEEE Access}, 
  title={THINKING-LOOP: The Semantic Vector Driven Closed-Loop Model for Brain Computing}, 
  year={2020},
  volume={8},
  number={},
  pages={4273-4288},
  abstract={High complexity, meaning a model in which components interact in multiple ways and follow certain local rules, is a huge challenge for brain research. This paper presents a semantic vector-driven closed-loop model, namely THINKING-LOOP, for brain computing to improve the understanding and development of complex cognition. The proposed model is a three-layer fusion of data, information and knowledge with human intelligence, which exploits ontological knowledge modeling, rule-based reasoning and a human-computer interaction mechanism. The interaction and collaboration within the model depend on a pair of complementary schemes in a loop: the top-down scheme from the knowledge layer to the data layer that is used to search for stable cognitive patterns; and the bottom-up scheme from the data layer to the knowledge layer that is used to deeply analyze cognitive functions. As a key factor, human beings participate in the whole learning process of the model, which in turn assists human beings to make decisions. To verify the applicability of the present model in cognitive research, a series of fMRI experiments and analytic methods (e.g. statistical tests and network topology analysis) were conducted. The results show that the proposed model is able to take into account the characteristics of different types of brain patterns and cognitive functions, thereby achieving reasonable decision-making level.},
  keywords={Brain modeling;Computational modeling;Functional magnetic resonance imaging;Cognition;Semantics;Informatics;Human computer interaction;Expert systems;human computer interaction;brain informatics;fMRI;data mining},
  doi={10.1109/ACCESS.2019.2963070},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10650372,
  author={Peng, Yong and Liu, Mao and Shi, Zheyu and Bao, Shengli},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={SPAFusion: Multi-focus Image Fusion based on Shift Patch Attention}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Constrained by the finite depth of field (DOF) in optical cameras, imaging devices face difficulties in achieving complete sharpness across all objects or areas within the same scene. Multi-focus image fusion (MFIF) technology has emerged in response to this challenge. This technique combines complementary information from multiple partially focused images to generate an all-in-focus fused image. The fully clear image is the foundation of subsequent visual tasks. However, existing methods rarely focus on the fusion of image sequence, even though image sequence are more common in practical scenarios. In this paper, we have proposed a novel MFIF generative model based on transformer encoder, termed as SPAFusion. We think that MFIF should focus on patches from the same regions within the source images. Therefore, the attention mechanism of our model is based on patches. We further introduce a shift patch mechanism to integrate long-range dependencies. Benefit from the patch attention and shift patch mechanisms, our model boasts a significantly reduced parameter count and computational complexity compared to existing transformer-based MFIF models. Additionally, the introduction of the shift patch mechanism enables the model to integrate long-range dependencies, allowing it to incorporate both intra-domain and cross-domain contextual information. Finally, we employ pooling to obtain the fused image, enabling our model to support the fusion of image sequence. Experiments show the superiority of our SPAFusion compared to the state-of-the-art MFIF models.},
  keywords={Analytical models;Visualization;Computational modeling;Transformers;Image sequences;Task analysis;Computational complexity;Multi-Focus;Image Fusion;Transformer;Patch Attention;Shift Patch},
  doi={10.1109/IJCNN60899.2024.10650372},
  ISSN={2161-4407},
  month={June},}@ARTICLE{9354557,
  author={Abernathey, Ryan P. and Augspurger, Tom and Banihirwe, Anderson and Blackmon-Luca, Charles C. and Crone, Timothy J. and Gentemann, Chelle L. and Hamman, Joseph J. and Henderson, Naomi and Lepore, Chiara and McCaie, Theo A. and Robinson, Niall H. and Signell, Richard P.},
  journal={Computing in Science & Engineering}, 
  title={Cloud-Native Repositories for Big Scientific Data}, 
  year={2021},
  volume={23},
  number={2},
  pages={26-35},
  abstract={Scientific data have traditionally been distributed via downloads from data server to local computer. This way of working suffers from limitations as scientific datasets grow toward the petabyte scale. A “cloud-native data repository,” as defined in this article, offers several advantages over traditional data repositories—performance, reliability, cost-effectiveness, collaboration, reproducibility, creativity, downstream impacts, and access and inclusion. These objectives motivate a set of best practices for cloud-native data repositories: analysis-ready data, cloud-optimized (ARCO) formats, and loose coupling with data-proximate computing. The Pangeo Project has developed a prototype implementation of these principles by using open-source scientific Python tools. By providing an ARCO data catalog together with on-demand, scalable distributed computing, Pangeo enables users to process big data at rates exceeding 10 GB/s. Several challenges must be resolved in order to realize cloud computing’s full potential for scientific research, such as organizing funding, training users, and enforcing data privacy requirements.},
  keywords={Cloud computing;Training data;Computational modeling;Reproducibility of results;Collaboration;Reliability;Distributed databases},
  doi={10.1109/MCSE.2021.3059437},
  ISSN={1558-366X},
  month={March},}@INPROCEEDINGS{1174227,
  author={Richardson, K.A.},
  booktitle={36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the}, 
  title={On the limits of bottom-up computer simulation: towards a nonlinear modeling culture}, 
  year={2003},
  volume={},
  number={},
  pages={9 pp.-},
  abstract={In the complexity and simulation communities there is growing support for the use of bottom-up computer-based simulation in the analysis of complex systems. The presumption is that because these models are more complex than their linear predecessors they must be more suited to the modeling of systems that appear, superficially at least, to be (compositionally and dynamically) complex. Indeed the apparent ability of such models to allow the emergence of collective phenomena from quite simple underlying rules is very compelling. But does this 'evidence' alone 'prove' that nonlinear bottom-up models are superior to simpler linear models when considering complex systems behavior? Philosophical explorations concerning the efficacy of models, whether they be formal scientific models or our personal worldviews, has been a popular pastime for many philosophers, particularly philosophers of science. This paper offers yet another critique of modeling that uses the results and observations of nonlinear mathematics and bottom-up simulation themselves to develop a modeling paradigm that is significantly broader than the traditional model-focused paradigm. In this broader view of modeling we are encouraged to concern ourselves more with the modeling process rather than the (computer) model itself and embrace a nonlinear modeling culture. This emerging view of modeling also counteracts the growing preoccupation with nonlinear models over linear models.},
  keywords={Computer simulation;Computational modeling;Mathematical model;Predictive models;Analytical models;Educational institutions;Coherence;Mathematics;Iron;Physics},
  doi={10.1109/HICSS.2003.1174227},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{8622046,
  author={Chandrashekara, Arjun Ankathatti and Talluri, Radha Krishna Murthy and Sivarathri, Sai Swathi and Mitra, Reshmi and Calyam, Prasad and Kee, Kerk and Nair, Satish},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)}, 
  title={Fuzzy-Based Conversational Recommender for Data-intensive Science Gateway Applications}, 
  year={2018},
  volume={},
  number={},
  pages={4870-4875},
  abstract={Neuro-scientists are increasingly relying on parallel and distributed computing resources for analysis and visualization of their neuron simulations. Although science gateways have democratized relevant high performance/throughput resources, users require expert knowledge about programming and infrastructure configuration that is beyond the repertoire of most neuroscience programs. These factors become deterrents for the successful adoption and the ultimate diffusion (i.e., systemic spread) of science gateways in the neuroscience community. In this paper, we present a novel intuitionistic fuzzy logic based conversational recommender that can provide guidance to users when using science gateways for research and education workflows. The users interact with a context-aware chatbot that is embedded within custom web-portals to obtain simulation tools/resources to accomplish their goals. In order to ensure user goals are met, the chatbot profiles a user's cyberinfrastructure and neuroscience domain proficiency level using a `usability quadrant' approach. Simulation of user queries for an exemplary neuroscience use case demonstrates that our chatbot can provide step-by-step navigational support and generate distinct responses based on user proficiency.},
  keywords={Neuroscience;Fuzzy logic;Logic gates;Neurons;Tools;Computational modeling;Usability;Conversational Recommenders;Intutionistic Fuzzy Logic;Mamdani Inference;Neuroscience Workflows;Science Gateways;Virtual Agents;Guided User Interfaces},
  doi={10.1109/BigData.2018.8622046},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{5937784,
  author={Jensen, Jeff C. and Lee, Edward A. and Seshia, Sanjit A.},
  booktitle={2011 IEEE International Symposium of Circuits and Systems (ISCAS)}, 
  title={An introductory capstone design course on embedded systems}, 
  year={2011},
  volume={},
  number={},
  pages={1199-1202},
  abstract={We review an introductory course in embedded systems that characterizes embedded systems not by resource constraints, but rather by interactions with the physical world. This course teaches students the basics of models, analysis tools, and design for embedded systems. Traditional undergraduate courses in embedded systems focus on ad-hoc engineering practices and the use of existing modeling techniques, often omitting critical analysis and meta-modeling; we emphasize model-based design of embedded and cyber-physical systems. Students learn how to model the physical world with continuous time differential equations, and how to model computation using logic and discrete models such as state machines. Students evaluate these modeling techniques through the use of meta-modeling, illuminating the interplay of practical design with formal models of systems that incorporate both physical dynamics and computation. Students learn formal techniques to specify and verify desired behavior. A combination of structured labs and design projects solidifies these concepts when applied to the design of embedded and cyber-physical systems with real-time and concurrent behaviors.},
  keywords={Computational modeling;Embedded systems;Robot sensing systems;Mathematical model;Laboratories;Accelerometers},
  doi={10.1109/ISCAS.2011.5937784},
  ISSN={2158-1525},
  month={May},}@INPROCEEDINGS{6928187,
  author={Bosse, Tibor and Mogles, Nataliya},
  booktitle={2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)}, 
  title={Spread of Situation Awareness in a Group: Population-Based vs. Agent-Based Modelling}, 
  year={2014},
  volume={3},
  number={},
  pages={206-213},
  abstract={This paper compares population-based and agent-based simulation of the dynamics of group Situation Awareness. The question how Situation Awareness spreads among a team of agents is important for numerous applications. In this paper, a population-based and an agent-based model of this process are proposed, and applied to a case study in aviation. A number of relevant simulations of the models are performed, to investigate whether the behaviour of the population-based model can approximate the pattern produced by the agent-based model. It was demonstrated that, especially for larger populations, the dynamics of the agent-based simulations can be approximated by population-based simulations, since both models demonstrate a similar pattern.},
  keywords={Computational modeling;Atmospheric modeling;Mathematical model;Air traffic control;Aircraft;Sociology;Statistics;group situation awareness;aviation;agent-based vs. Population-based simulation},
  doi={10.1109/WI-IAT.2014.169},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9892833,
  author={Del Fabbro, Olivier and Christen, Patrik},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Philosophy-Guided Modelling and Implementation of Adaptation and Control in Complex Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Control was from its very beginning an important concept in cybernetics. Later on, with the works of W. Ross Ashby, for example, biological concepts such as adaptation were interpreted in the light of cybernetic systems theory. Adaptation is the process by which a system is capable of regulating or controlling itself in order to adapt to changes of its inner and outer environment maintaining a homeostatic state. In earlier works we have developed a system metamodel that on the one hand refers to cybernetic concepts such as structure, operation, and system, and on the other to the philosophy of individuation of Gilbert Simondon. The result is the so-called allagmatic method that is capable of creating concrete models of systems such as artificial neural networks and cellular automata starting from abstract building blocks. In this paper, we add to our already existing method the cybernetic concepts of control and especially adaptation. In regard to the system metamodel, we rely again on philosophical theories, this time the philosophy of organism of Alfred N. Whitehead. We show how these new meta-theoretical concepts are described formally and how they are implemented in program code. We also show what role they play in simple experiments. We conclude that philosophical abstract concepts help to better understand the process of creating computer models and their control and adaptation. In the outlook we discuss how the allagmatic method needs to be extended in order to cover the field of complex systems and Norbert Wiener's ideas on control.},
  keywords={Adaptation models;Philosophical considerations;Codes;Computational modeling;Process control;Control systems;Organisms;adaptation;control;complex systems modelling and simulation;cybernetics;meta-modelling;meta-programming;philosophy of individuation;philosophy of organism},
  doi={10.1109/IJCNN55064.2022.9892833},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{5439574,
  author={van Dam, Koen H. and Adhitya, Arief and Srinivasan, Rajagopalan and Lukszo, Zofia},
  booktitle={2008 First International Conference on Infrastructure Systems and Services: Building Networks for a Brighter Future (INFRA)}, 
  title={Nuances of benchmarking agent-based and equation-based models of an oil refinery supply chain}, 
  year={2008},
  volume={},
  number={},
  pages={1-6},
  abstract={Benchmarking is not only about making comparisons but, through these, learning lessons to improve actual performance or knowledge. Comparing modelling paradigms based only on the conceptual model specifications is not enough; rather a well-defined benchmarking process and the execution of experiments are required. A benchmarking strategy is applied to three models of an oil refinery supply chain, using the agent-based or equation-based paradigm. Despite the different paradigms, the models share the same assumptions and model boundaries and an attempt is made to provide same initial conditions and stochastics. The benchmarking process shows that clear definitions of the modelling paradigms are needed to avoid confusion and to enable mining of specific and guiding conclusions from the benchmarking studies. Agent-based models and equation-based models rely on different modelling attributes: The first are mostly identified by the model elements (i.e. individuals) while the latter are mostly identified by the system description elements (i.e. equations). We present a way to visualize this and to add nuance to the choice of labels to allow for the conclusions of the benchmarking study to be generalised beyond the models that are compared, to learn about the advantages and shortcomings of modelling paradigms. Finally, some misconceptions regarding agent-based modelling are identified. The lessons learnt apply to supply chain domain but are extensible to other domains.},
  keywords={Oil refineries;Supply chains;Chemical technology;Chemical industry;Electronic mail;Differential equations;Chemical engineering;Power engineering and energy;Computational modeling;Stochastic processes},
  doi={10.1109/INFRA.2008.5439574},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8644945,
  author={Zhang, Weiwen and Liu, Yong and Wang, Long and Li, Zengxiang and Mong Goh, Rick Siow},
  booktitle={2018 IEEE 24th International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={Cost-Efficient and Latency-Aware Workflow Scheduling Policy for Container-Based Systems}, 
  year={2018},
  volume={},
  number={},
  pages={763-770},
  abstract={Container technology is being adopted to simplify workflow execution. In this paper, we investigate a workflow scheduling policy for container-based systems. A workflow, representing an application, consists of a set of tasks. Each task can be executed in a container within a virtual machine (VM), where the container packaging the function for the task should be loaded into the VM before task execution. To reduce the workflow execution time and the network bandwidth consumption, we propose a cost-efficient and latency-aware workflow scheduling algorithm that strategically loads the containers into VMs and executes the tasks on the VMs. The algorithm is based on “Stretch Out and Compact”, which can stretch out the tasks along the resources by critical path analysis and then find the inefficient slots within the computing resources and eventually compact the tasks into those slots. We introduce a concept of “virtual task” into the algorithm, where container loading is regarded as a virtual task that should be executed before the real task. The introduction of the virtual task can be more effective in finding the inefficient slots for the compaction, thus resulting in a more efficient workflow scheduling policy. Simulation results show that compared to the algorithms that fully or selectively load the dockers, the proposed algorithm can achieve less execution time while saving network bandwidth consumption for loading dockers.},
  keywords={Task analysis;Containers;Loading;Scheduling algorithms;Scheduling;Computational modeling;Workflow scheduling;resource efficiency;container-based systems},
  doi={10.1109/PADSW.2018.8644945},
  ISSN={1521-9097},
  month={Dec},}@INPROCEEDINGS{5250677,
  author={Zhou, Jiayu and Jin, Lifeng and Han, Sherwin},
  booktitle={2009 8th IEEE International Conference on Cognitive Informatics}, 
  title={Unified hierarchical iterate model of human conceptualization and cognition}, 
  year={2009},
  volume={},
  number={},
  pages={44-51},
  abstract={In this paper, we propose a hierarchically iterate model of human conceptualization and cognition. Based on the theory of dual structure of cognition and related physiological evidence, we firstly propose the notion of concept space in human brain and a corresponding conceptualization model. Conceptualization is the process of forming concepts in our brain. The concept of cognition process is then defined to introduce our unified iterative cognition model. The hierarchy within the iterative cognition is the logic of human cognition. Some visual cognition examples are employed to investigate our cognition model. With our conceptualization and cognition model, the processes of auditory cognition, visual cognition and more over, language understanding could be explained under a unified theoretical framework. Separate papers describing specific usages of the framework will be published.},
  keywords={Humans;Cognition;Brain modeling;Algebra;Logic;Mathematics;Physics computing;Computational modeling;Information technology;Education;Cognitive Computing;Iterative Cognition Model;Perception-Cognition Dual Model},
  doi={10.1109/COGINF.2009.5250677},
  ISSN={},
  month={June},}@INPROCEEDINGS{9823673,
  author={Rawat, Ujjwal and Singh, Surender},
  booktitle={2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={Challenges in Music Generation Using Deep Learning}, 
  year={2022},
  volume={},
  number={},
  pages={553-558},
  abstract={Owing to its massive potential, the field of Artificial Intelligence is booming at an unprecedented rate. With the increase in efficiency and accuracy in prediction, classification, translation, and other traditional tasks, deep learning has also witnessed a surge in applications in various other sectors, one of them being music generation. This paper provides a brief introduction to the process of creating fresh new music from a collection of existing music as the sample, using deep learning architectures and training techniques. The creation of music using automated processes in the absence of human intelligence is not a fresh proposal and has been influencing human curiosity for a long time. Being an innovative and complex venture, it poses certain unorthodox challenges which are needed to be addressed. This paper focuses on the analysis of these challenges and explores the scope of this fascinating pursuit.},
  keywords={Deep learning;Training;Computational modeling;Reinforcement learning;Streaming media;Proposals;Artificial intelligence;Deep learning;Music;Music Generation Systems;Challenges},
  doi={10.1109/ICACITE53722.2022.9823673},
  ISSN={},
  month={April},}@ARTICLE{10106116,
  author={Nofre, David},
  journal={IEEE Annals of the History of Computing}, 
  title={“Content Is Meaningless, and Structure Is All-Important”: Defining the Nature of Computer Science in the Age of High Modernism, c. 1950–c. 1965}, 
  year={2023},
  volume={45},
  number={2},
  pages={29-42},
  abstract={The purpose of this article is to historize the definition of computer science, particularly the characteristic ambiguity of the discipline toward the computer. This ambiguity is foundational to computer science and has its roots in the response of university computer centers to the commercialization of computing in the mid-1950s. University computing experts developed an understanding of the activity of computing disentangled from the computer itself, a conceptual shift that went together with a parallel process of dematerialization of the notion of computer. These transformations were facilitated by the ascendance of a high modernist agenda in the sciences in the United States. University computing experts embraced the high modernist agenda and developed analogies across programs, notations, and a notion of the computer now understood as a model of computation. This immaterial conflation of notations, programs, and representations of the machine, would become one of the core tenets of computer science.},
  keywords={Programming;History;Computational modeling;Computer languages;Writing;Switches;Software;Computer science;computer programming;programming languages;high modernism;abstraction},
  doi={10.1109/MAHC.2023.3266359},
  ISSN={1934-1547},
  month={April},}@ARTICLE{10366259,
  author={Aliyu, Ibrahim and Oh, Seungmin and Ko, Namseok and Um, Tai-Won and Kim, Jinsul},
  journal={IEEE Access}, 
  title={Dynamic Partial Computation Offloading for the Metaverse in In-Network Computing}, 
  year={2024},
  volume={12},
  number={},
  pages={11615-11630},
  abstract={The computing in the network (COIN) paradigm is a promising solution that leverages unused network resources to perform tasks to meet computation-demanding applications, such as the metaverse. In this vein, we consider the partial computation offloading problem in the metaverse for multiple subtasks in a COIN environment to minimize energy consumption and delay while dynamically adjusting the offloading policy based on the changing computational resource status. The problem is NP-hard, and we transform it into two subproblems: the task-splitting problem (TSP) on the user side and the task-offloading problem (TOP) on the COIN side. We model the TSP as an ordinal potential game and propose a decentralized algorithm to obtain its Nash equilibrium (NE). Then, we model the TOP as a Markov decision process and propose the double deep Q-network (DDQN) to solve for the optimal offloading policy. Unlike the conventional DDQN algorithm, where intelligent agents sample offloading decisions randomly within a certain probability, the COIN agent explores the NE of the TSP and the deep neural network. Finally, the simulation results reveal that the proposed model approach allows the COIN agent to update its policies and make more informed decisions, leading to improved performance over time compared to the traditional baseline.},
  keywords={Task analysis;Metaverse;Resource management;X reality;Dynamic scheduling;Delays;Optimization;Computational offloading;deep reinforcement learning;game theory;in-network computing;metaverse},
  doi={10.1109/ACCESS.2023.3344817},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{1408688,
  author={Barr, R.E.},
  booktitle={34th Annual Frontiers in Education, 2004. FIE 2004.}, 
  title={The current status of graphical communication in engineering education}, 
  year={2004},
  volume={},
  number={},
  pages={S1D/8-S1D13 Vol. 3},
  abstract={Graphics has always been a requisite form of communication for engineering practice. The history of major engineering accomplishments is replete with examples of graphical communications: from styli etchings on clay tablets to near-recent blueprint drawings. In the last two decades, engineering graphics instruction has been significantly influenced by the advancement of computers and other new technologies. During this short span, the discipline has gone from teaching manual drafting and pencil drawings to the use of 3-D computer modeling and simulation software. This paper briefly reviews the evolution of graphical communication in engineering practice, and focuses on the current status of graphical communication in the engineering curriculum. This report is bolstered by results of a recent survey conducted at the 2003 annual meeting of the Engineering Design Graphics Division of ASEE. The survey proposed an extensive list of student outcomes for engineering graphical communication, as mandated by the new ABET EC2000 outcomes requirement criterion 3 (g): "an ability to communicate effectively." Graphics faculty ranked these graphics student outcomes, and accompanying performance criteria, on level of importance in the modern curriculum. The results represent a consensus of current thinking on engineering graphical communication education.},
  keywords={Engineering education;Engineering drawings;Computer graphics;History;Etching;Computer aided instruction;Technical drawing;Computational modeling;Computer simulation;Design engineering},
  doi={10.1109/FIE.2004.1408688},
  ISSN={0190-5848},
  month={Oct},}@INPROCEEDINGS{6041941,
  author={Uehara, Minoru},
  booktitle={2011 14th International Conference on Network-Based Information Systems}, 
  title={Metabolic Computing}, 
  year={2011},
  volume={},
  number={},
  pages={370-375},
  abstract={In this paper, we propose a metabolic computing model for realizing a sustainable information system. We think that this metabolic computing model has both high fault tolerance and sustainability. We also propose a realistic architecture of the metabolic computing model. A metaboloid is a processing unit in this architecture. A set of metaboloids is organized as a mesh-connected NORMA (No Remote Memory Access). However, the network may change because of metabolism. Therefore, metaboloids have to achieve homeostasis to manage running tasks. We propose two new algorithms in this paper, namely bubbling and drifting.},
  keywords={Computational modeling;Recycling;Routing;Biochemistry;Computer architecture;Shape;Mobile ad hoc networks;metabolic computing},
  doi={10.1109/NBiS.2011.62},
  ISSN={2157-0426},
  month={Sep.},}@INPROCEEDINGS{4561708,
  author={Lan, Chung Hsien and Tseng, Chung Cheng and Lai, K. Robert},
  booktitle={2008 Eighth IEEE International Conference on Advanced Learning Technologies}, 
  title={Developing a Negotiation-Based Intelligent Tutoring System to Support Problem Solving: A Case Study in Role-Play Learning}, 
  year={2008},
  volume={},
  number={},
  pages={356-360},
  abstract={A negotiation-based intelligent tutoring system of which the tutor and learner agents in playing problem-specific roles is developed to assist learner in problem solving through a negotiation mechanism. During the problem solving, fuzzy constraint-directed negotiation is employed to coordinate the mutual thinking between tutor and learner agents, and it can resolve the cognition differences and thereby reach a consensus more effectively. To embody the idea of the proposed methodology, a real-world example relevant to the software cost estimation is described to illustrate how a negotiation can be used for supporting the problem solving in a tutoring learning environment.},
  keywords={Intelligent systems;Problem-solving;Intelligent agent;Computational modeling;Cognition;Feedback;Computer networks;Information management;Computer science;Costs},
  doi={10.1109/ICALT.2008.115},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{6132813,
  author={Uehara, Minoru},
  booktitle={2011 Third International Conference on Intelligent Networking and Collaborative Systems}, 
  title={Proposal of an Evolutional Architecture for Metabolic Computing}, 
  year={2011},
  volume={},
  number={},
  pages={287-292},
  abstract={In our previous paper, we proposed metabolic computing model in order to realize sustainable information system. We think that metabolic computing model has high fault tolerance and sustainability. We also proposed a realistic architecture of metabolic computing model. Metaboloid is a processing unit in this architecture. A set of metaboloids is organized as mesh connected NORMA. However, in simple metabolism, the specification of architecture is not changed. So, even if manufacturing technology of hardware is innovative, the performance will not be improved. In this paper, we propose an evolutional architecture for metabolic computing model. In this architecture, if the specification is portable and if the difference between specifications is only 1, a set of metaboloids of which specification is different can work together.},
  keywords={Computational modeling;Recycling;Computer architecture;Biochemistry;Routing;Waste materials;Fault tolerance;metabolic computing},
  doi={10.1109/INCoS.2011.138},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7250369,
  author={Li, Hong and He, ZhangQing and Li, SheZhong},
  booktitle={2015 10th International Conference on Computer Science & Education (ICCSE)}, 
  title={Teaching innovation and practice of the basic computer course based on the principle of individualized teaching and classified cultivation}, 
  year={2015},
  volume={},
  number={},
  pages={867-869},
  abstract={This paper proposes an innovation thought based on the individualized teaching and classified cultivation to solve the problems which exist in the basic computer courses teaching. Through the conversion of teaching concept, the integration of teaching content, the optimization of teaching methods, the reform of evaluation form, teachers could leave more time for students to think, learn and practice independently. In this way, objectives of talents cultivation and needs of students are in perfect combination, fully displaying the cultivation of innovative awareness and practical ability.},
  keywords={Education;Computers;Hardware;Technological innovation;Software;Computational modeling;Databases;the basic computer course;individualized teaching;classified cultivation;teaching innovation},
  doi={10.1109/ICCSE.2015.7250369},
  ISSN={},
  month={July},}@INPROCEEDINGS{4536993,
  author={Wanyu Deng and Qinghua Zheng and Lin Chen},
  booktitle={2008 12th International Conference on Computer Supported Cooperative Work in Design}, 
  title={An Improved Aggregated One-Dependence Estimator: On Non-rigid Cross Validation}, 
  year={2008},
  volume={},
  number={},
  pages={270-276},
  abstract={This paper proposed an improved Bayesian classifier which holds excellent classification accuracy and proper time cost. More important, the thinking of nonrigid cross validation which is proposed in the paper can be generalized to other fields.},
  keywords={Bayesian methods;Computational efficiency;Error analysis;Niobium;Computer science;Telecommunications;Costs;Terminology;Predictive models;Accuracy;Naïve Bayes;Classifier;Cross Validation},
  doi={10.1109/CSCWD.2008.4536993},
  ISSN={},
  month={April},}@INPROCEEDINGS{9782950,
  author={Fedotov, Gennady V. and Zakharova, Ludmila V. and Alymova, Olga V.},
  booktitle={2022 VI International Conference on Information Technologies in Engineering Education (Inforino)}, 
  title={To the Issue of the Balanced Program "Engineering and Computer Graphics" for Engineering Specialties}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Currently, there is a need for good geometric training of students in engineering graphics courses at the university, using advanced computer tools.Well-developed spatial thinking is important for any discipline. The Power Engineering Design Department (MPEI) is constantly looking for different ways to solve the above-mentioned problem, modernizing traditional training programs. We propose the consolidated methodology of teaching engineering students the discipline "Engineering and computer graphics", based on the diverse experience of specialists of different ages, education and professional development.},
  keywords={Training;Knowledge engineering;Power engineering;Computational modeling;Computer graphics;Manuals;Task analysis;drawing;computer graphics;AutoCAD;dwg - format;jpg - format;pdf - format;Model;Sheet;Drawing layers;project},
  doi={10.1109/Inforino53888.2022.9782950},
  ISSN={},
  month={April},}@INPROCEEDINGS{6330161,
  author={Mulobe, N. J. and Huan, Z.},
  booktitle={2012 Proceedings of the 9th Industrial and Commercial Use of Energy Conference}, 
  title={Energy efficient technologies and energy saving potential for cold rooms}, 
  year={2012},
  volume={},
  number={},
  pages={1-7},
  abstract={Food processing demands a considerable and continuous energy supply and the rise in the price of electricity in South Africa has put much pressure on the industry. This has forced a re-think and development of alternative energy efficiency technology. In South Africa's cold storage chain the entire refrigeration system is among the most energy-intensive areas, but also offers opportunity for short and long term saving. It also provides an opportunity for enhancement of sustainable development and cold chain management. This paper presents a combination of three efficient technologies in those areas: (1) Airflow pattern optimisation through a computer assisted simulation model in which overall energy efficiency of cooling facilities is dependent not only on the energy generation efficiency of the refrigeration system, but also utilisation efficiency of all cooling facilities. Optimal airflow pattern of a cold room would move heat effectively to a refrigeration system, hence increasing both energy efficiency and refrigeration distribution. (2) Variable speed drive (VSDs) technology on evaporator fans motors: VSDs reduce motor electricity consumption by 30-60%; other benefits include prolonging equipment life through motor speed adjustments according to load. (3) Minimising heat transmission load by heat conduction transfer - coloured and shaded external walls being a major factor. Such technologies saved energy, thus reducing cold chain facilities' demand. The system was also cost-efficient and, inter-alia, research detailed in this paper contributed towards alleviating South Africa's energy problems.},
  keywords={Energy consumption;Energy efficiency;Fans;Atmospheric modeling;Computational modeling;Resistance},
  doi={},
  ISSN={2166-059X},
  month={Aug},}@INPROCEEDINGS{10013327,
  author={Liu, Zeying and Cui, Pengshuai and Hu, Yuxiang and Dong, Yongji and Tang, Kaifei and Xue, Lei},
  booktitle={2021 International Conference on Advanced Computing and Endogenous Security}, 
  title={A programmable data plane that supports definable computing}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={For current Internet is confronted with some defects such as structural rigidity, single function, and protocol-independent, the functions, performance and efficiency of the Internet were promoted from the perspective of the data plane, it proposes to support computing definable programmable data based on the full-dimensional defined polymorphic smart network. It uses in-network calculations to offload network functions to programmable network elements (programmable switches) to improve operational efficiency and flexibility. This article first uses the protocol-independent P4 language to realize the definable forwarding of the data plane; on this basis, a new forwarding model is designed, adding calculation functions that are not originally supported by P4, and the calculation is definable; finally, DES encryption is used as the calculation Function verification, and think and discuss the experimental process.},
  keywords={Program processors;Computational modeling;Programming;Software;Data models;Encryption;Internet;polymorphic network;computing definable;programmable data plane;computing acceleration},
  doi={10.1109/IEEECONF52377.2022.10013327},
  ISSN={},
  month={April},}@ARTICLE{8049612,
  author={Mertz, Leslie},
  journal={IEEE Pulse}, 
  title={Reading Minds: Brain-Decoding Scientists Move Closer to Discovering the Keys to Unlock the Brain}, 
  year={2017},
  volume={8},
  number={5},
  pages={13-18},
  abstract={When you see or think about an object, your brain engages in a unique pattern of activity tied specifically to that object. That's how you know a cat is a cat, and not a dog or a house or a cloud. Using functional magnetic resonance imaging (fMRI) and other techniques, scientists are not only able to measure those activity patterns but are also deciphering what each pattern means. Essentially, they are beginning to read minds.},
  keywords={Brain modeling;Computational modeling;Image reconstruction;Neuroscience;Decoding;Visualization},
  doi={10.1109/MPUL.2017.2729412},
  ISSN={2154-2317},
  month={Sep.},}@INPROCEEDINGS{9188403,
  author={Zhang, Zhaochen and Jiang, Wei and Mao, Xiaobin},
  booktitle={2020 39th Chinese Control Conference (CCC)}, 
  title={Research on Command Information System Architecture for Human-Computer Fusion}, 
  year={2020},
  volume={},
  number={},
  pages={65-70},
  abstract={In the intelligent war, building a "computer brain" that can understand, think and cooperate with human is one of the development directions of the future command information system. The design concept of command information system architecture for human-computer fusion is proposed, which is the transfer of human intelligence to computer intelligence. The system composition of the core elements such as the game confrontation deduction environment is designed innovatively. The operational mechanisms before and during the war are elaborated. The command information system architecture reference model of human-computer fusion is formed. Finally, the Department of Defense Architecture Framework (DoDAF) is used to verify the top-level guidance of architecture design to the construction of human-computer fusion system through the typical application case of future operation.},
  keywords={Games;Knowledge engineering;Computational modeling;Information systems;Training;Computer architecture;Brain modeling;human-computer fusion;command information system;architecture;game confrontation},
  doi={10.23919/CCC50068.2020.9188403},
  ISSN={1934-1768},
  month={July},}@INPROCEEDINGS{4488999,
  author={Šátek, Václav and Kunovský, Jirí and Petrek, Jirí},
  booktitle={Tenth International Conference on Computer Modeling and Simulation (uksim 2008)}, 
  title={Multiple Arithmetic in Dynamic System Simulation}, 
  year={2008},
  volume={},
  number={},
  pages={597-598},
  abstract={A very interesting and promising numerical method of solving systems of ordinary differential equations based on Taylor series has appeared. The potential of the Taylor series has been exposed by many practical experiments and a way of detection and solution of large systems of ordinary differential equations has been found. Generally speaking, a stiff system contains several components, some of them are heavily suppressed while the rest remain almost unchanged. This feature forces the used method to choose an extremely small integration step and the progress of the computation may become very slow. There are many (implicit) methods for solving stiff systems of ODE’s, from the most simple such as implicit Euler method to more sophisticated (implicit Runge-Kutta methods) and finally the general linear methods. Usually a quite complicated auxiliary system of equations has to be solved in each step. These facts lead to immense amount of work to be done in each step of the computation. These are the reasons why one has to think twice before using the stiff solver and to decide between the stiff and non-stiff solver.},
  keywords={Taylor series;Eigenvalues and eigenfunctions;Differential equations;Jacobian matrices;Computer simulation;Computational modeling;Digital arithmetic;Information technology;Continuous time systems;High performance computing;Stiff systems;Modern Taylor Series Method;Differential equations;Continous system modelling;Multiple arithmetic},
  doi={10.1109/UKSIM.2008.46},
  ISSN={},
  month={April},}@INPROCEEDINGS{6735932,
  author={Yang, Tianyi and Nguyen, Nguyen and Jin, Yu-Fang and Lindsey, Merry L.},
  booktitle={2013 IEEE International Workshop on Genomic Signal Processing and Statistics}, 
  title={Parameter distribution estimation in first order ODE}, 
  year={2013},
  volume={},
  number={},
  pages={62-65},
  abstract={With development of new technologies applied to biological experiments, more and more data are generated every day. To make predictions in biological systems, mathematical modeling plays a critical role. Ordinary differential equations (ODEs) contribute to a large portion in mathematical modeling. In which parameters are inevitable. Noise is intrinsic in all experiments. Therefore, to think of parameters as statistical distributions is a realistic treatment. In this paper, we discuss in a 1st order ODE common in biological systems, how to calculate parameter distribution analytically according to the experimentally observed output assumed to be normal distribution. Conditions on when parameter can be correctly estimated are elucidated.},
  keywords={Mathematical model;Biological systems;Computational modeling;Biological system modeling;Genomics;Bioinformatics},
  doi={10.1109/GENSIPS.2013.6735932},
  ISSN={2150-301X},
  month={Nov},}@INPROCEEDINGS{4639103,
  author={Church, Luke},
  booktitle={2008 IEEE Symposium on Visual Languages and Human-Centric Computing}, 
  title={Improving experiences of computation}, 
  year={2008},
  volume={},
  number={},
  pages={264-265},
  abstract={Experiences of computation vary widely between people. Users ranging from artists to scientists struggle to create programs to meet their needs. Further, the usability implications of designers 'thinking computationally' about social relations such as 'friendship' are highlighted by problems of privacy in Facebook and similar systems. This variability in the experience of computation is more than just an annoyance. Many believe that increasing access to computation will help progress other fields. If they are correct, then these problematic experiences represent a barrier to such progress. This research seeks to addresses this variability in the experience of computation. Computation for creativity, science and society are discussed.},
  keywords={Security;Programming;Usability;Biology;Computers;Computational modeling;Programming profession},
  doi={10.1109/VLHCC.2008.4639103},
  ISSN={1943-6106},
  month={Sep.},}@INPROCEEDINGS{9610480,
  author={Hu, Jianquan and Kong, Yanbo},
  booktitle={2021 International Conference on Computers, Information Processing and Advanced Education (CIPAE)}, 
  title={Competency Training Ability of College Counselors Based on Intelligent Computing}, 
  year={2021},
  volume={},
  number={},
  pages={25-28},
  abstract={College counselors are an important part of the faculty of colleges and universities, the backbone of the ideological and political education of college students, and the main force in the work of college students. The 21st century we live in is a highly intelligent era. With the continuous emergence of intelligent computing as a typical technical means in contemporary network technology, the relationship between intelligent computing and people&#x0027;s life and work is getting closer and closer. However, college counselors are also facing many new problems and challenges. Therefore, how to improve the use of intelligent computing and better improve the competence of counselors has become a difficult problem for colleges and universities. Based on this, this article launched a research on the competency training ability of college counselors based on intelligent computing. This article uses behavioral incident interview method, literature analysis method and questionnaire survey method to carry out research. Through interviews with counselors, the competency characteristics of counselors are obtained, and the competency model of counselors is established. By consulting the literature, compiling questionnaires, designing a complete set of questionnaires in line with the research, and issuing questionnaires to 60&#x0025; of college counselors and teachers to obtain the most authentic data. Collect relevant data through questionnaire surveys, and then enter the collected data into the database for data analysis. By consulting related materials, using publicly published papers and works at home and abroad as references, we can obtain basic theoretical support and background materials, as well as the current status and development level of the research on the competence of counselors. The survey results show that counselors have a strong understanding of work. Generally, 45&#x0025; are familiar with them, 18&#x0025; are relatively familiar, and few are very familiar. 40&#x0025; of counselors think they have average competence. 44 &#x0025; of counselors voluntarily signed up and wanted to participate in training to improve themselves. 51&#x0025; of counselors believe that the best time for a training session is half a day. Regarding the training goals, only a small number of instructors have clear training goals. It can be seen that the research on the competence training ability of college counselors is of extremely high value.},
  keywords={Training;Computers;Data analysis;Databases;Computational modeling;Force;Information processing;Intelligent Computing;College Counselors;Competency Training;Questionnaire Survey},
  doi={10.1109/CIPAE53742.2021.00015},
  ISSN={},
  month={May},}@INPROCEEDINGS{7991086,
  author={Yoshida, Tsutomu and Shirase, Masaaki},
  booktitle={2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW)}, 
  title={A digital content sharing model using proxy re-encryption without server access}, 
  year={2017},
  volume={},
  number={},
  pages={243-244},
  abstract={In this paper, we proposes a digital content sharing scheme using proxy re-encryption, in which we don't need to access any server when sharing content, and a person, who is not owner of a content but shares it from an owner of it, cannot sublet it to other person. We think such property provides an efficient DRM system. Moreover, we provide experimental result of the scheme.},
  keywords={Copyright protection;Encryption;Public key;Computational modeling;Servers;Electronic publishing},
  doi={10.1109/ICCE-China.2017.7991086},
  ISSN={},
  month={June},}@INPROCEEDINGS{10033178,
  author={Nitsche, Anna-Maria and Franczyk, Bogdan and Schumann, Christian-Andreas},
  booktitle={2022 IEEE 28th International Conference on Engineering, Technology and Innovation (ICE/ITMC) & 31st International Association For Management of Technology (IAMOT) Joint Conference}, 
  title={System Dynamics Modeling for Smart and Collaborative Last Mile Networks}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  abstract={This paper presents a comprehensive model of smart and collaborative last mile supply networks. Facing a multitude of challenges such as economic pressure, demographic change, and environmental demands, urban last mile supply networks are increasingly strained. Various solutions and strategies such as the integration of novel technologies and collaborative approaches are discussed in the literature and tested in case studies. The application of artificial intelligence for supply networks holds potential for future urban logistics optimization and is thus considered a relevant research avenue. A design science approach comprising system dynamics-based modeling is chosen due to last mile networks' inherent complexity. Systems thinking has proven to be useful in urban logistics and smart city research contexts as it enables researchers and practitioners to achieve a more holistic perspective. The proposed model contributes to a better understanding of last mile network complexity as well as the underlying interdependencies.},
  keywords={Economics;Smart cities;Biological system modeling;Computational modeling;Collaboration;Complexity theory;Systems thinking;last mile;urban logistics;supply chain collaboration;supply chain management;artificial intelligence;system dynamics},
  doi={10.1109/ICE/ITMC-IAMOT55089.2022.10033178},
  ISSN={},
  month={June},}@INPROCEEDINGS{7352681,
  author={Mavroeidis, Vasileios and Koubias, Stavros},
  booktitle={2013 International Conference on Engineering, Technology and Innovation (ICE) & IEEE International Technology Management Conference}, 
  title={A collaborative business model in hi-tech environments which incorporate the knowledge triangle initiative}, 
  year={2013},
  volume={},
  number={},
  pages={1-11},
  abstract={The purpose of this paper is to propose a collaborative business model of measuring business excellence (MBE) by applying principles of Network Management and Systems Thinking. The proposed model is defined by the interaction of system variables giving the opportunity of a reliable and fair score as well as objective decision-making with regard to the areas that are susceptible of continuous improvement. Such a model is referred to be applicable in ecosystems which run the Knowledge Triangle initiative driven by EIT (E.U. initiative to re-address innovation boost which is mainly hosted by the European Institute of Innovation and Technology, in Europe).},
  keywords={Business;Technological innovation;Collaboration;Europe;Computational modeling;Systems thinking;Context;Business Excellence Models;Total Quality Management;Collaboration Networks;Knowledge Triangle;Performance Management},
  doi={10.1109/ITMC.2013.7352681},
  ISSN={},
  month={June},}@INPROCEEDINGS{10631247,
  author={Clemm, Christian and Stobbe, Lutz and Wimalawarne, Kishan and Druschke, Jan},
  booktitle={2024 Electronics Goes Green 2024+ (EGG)}, 
  title={Towards Green AI: Current Status and Future Research}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={The immense technological progress in artificial intelligence research and applications is increasingly drawing attention to the environmental sustainability of such systems, a field that has been termed ‘Green AI’. With this contribution we aim to broaden the discourse on Green AI by investigating the current status of approaches to both environmental assessment and ecodesign of AI systems. We propose a life-cycle-based system thinking approach that accounts for the four key elements of these software-hardware-systems: model, data, server, and cloud. We conduct an exemplary estimation of the carbon footprint of relevant compute hardware and highlight the need to further investigate methods for Green AI and ways to facilitate wide-spread adoption of its principles. We envision that AI could be leveraged to mitigate its own environmental challenges, which we denote as ‘AI4greenAI’.},
  keywords={Computational modeling;Green products;Estimation;Hardware;Data models;Systems thinking;Servers;artificial intelligence;machine learning;energy consumption;environmental impact;sustainable design},
  doi={10.23919/EGG62010.2024.10631247},
  ISSN={},
  month={June},}@ARTICLE{7040622,
  author={Lopez, Sonia and Cervantes, Jose Antonio and Robles, Francisco Abelardo and Ramos, Felix},
  journal={IEEE Latin America Transactions}, 
  title={Computational Model of Motor Planning for Virtual Creatures: a Biologically Inspired Model}, 
  year={2015},
  volume={13},
  number={1},
  pages={10-17},
  abstract={The development of computational models that emulate human cognitive functions is challenging. Nevertheless, we think that cognitive systems will allow to correct several problems of behavior like credibility, or wrong behavior that occur in some areas such as: virtual reality, artificial life, autonomous agents, humanoid robots, human-computer interaction. In this paper we propose a biological inspired computational model for motor planning applied to virtual creatures. We present the results of a case study taken from Neurosciences to validate our model. Also, the flow of information in our model emulating the flow of information of the human brain is presented.},
  keywords={Computational modeling;Biological system modeling;Monitoring;Solid modeling;Visualization;Planning;Robots;autonomous agents;Cognitive systems;motor planning;virtual reality},
  doi={10.1109/TLA.2015.7040622},
  ISSN={1548-0992},
  month={Jan},}@INPROCEEDINGS{8122725,
  author={Dimirovski, Georgi M. and Wang, Rui and Yang, Bin},
  booktitle={2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Delay and recurrent neural networks: Computational cybernetics of systems biology?}, 
  year={2017},
  volume={},
  number={},
  pages={906-911},
  abstract={Science of Neural Networks, and even much more so computing applications, have undergone developments beyond any predictions since McCullock-Pitts artificial neuron (1943) up via Hopfield's neurons (1982, 1984) to Kasabov spiking-neurons neucube (2014) and evolving connectionist systems (2003). Still computational functionality of all kinds of neural network implies guaranteed operating steady-state equilibrium is fast-reached first. On the other side of this spectrum Science of Neurophysiology yielded insights converging to Systems Biology approach Gayton-Hall (2006). It appeared, on the crossroad of these findings with Kolmogorov's representation superposition and Hilbert's Thirteen problem certain rater delicate subtle issues emerged Sprecher (2017). This paper gives one perception of these issues and suggested a revised view on the foundations of past developments, possibly by re-thinking own stability results for recurrent neural networks which possess time-varying delays.},
  keywords={Neurons;Delays;Stability criteria;Cybernetics;Recurrent neural networks;Mathematical model;approximation computational models;artificial neurons;artificial recurrent neural networks;complex netwroks;cybernetics;human neural networks;living neurons},
  doi={10.1109/SMC.2017.8122725},
  ISSN={},
  month={Oct},}@ARTICLE{8945390,
  author={Qiu, Liqing and Tian, Xiangbo and Sai, Shiqi and Gu, Chunmei},
  journal={IEEE Access}, 
  title={LGIM: A Global Selection Algorithm Based on Local Influence for Influence Maximization in Social Networks}, 
  year={2020},
  volume={8},
  number={},
  pages={4318-4328},
  abstract={Influence maximization is to select k nodes from social networks to maximize the expected number of nodes activated by these selected nodes. Influence maximization problem plays a vital role in commercial marketing, news propagation, rumor control and public services. However, the existing algorithms for influence maximization usually tend to select one aspect from efficiency and accuracy as its main improving objective. This method of excessively pursuing one metric often leads to performing poorly in other metrics. Hence, we think that algorithms for influence maximization should make a suitable compromise between computation efficiency and result accuracy instead of excessively pursuing for one metric. Based on the above understanding, this paper proposes a new algorithm, called Global Selection Based on Local Influence (LGIM). The basic idea of the proposed algorithm is following: if a node can influence another node with large influence, the node also has large influence. Therefore, a two-stage filtering strategy of candidate nodes is proposed, which can reduce a large number of running time. Moreover, this paper also proposes a new objective function to estimate the influence spread of a node set. In summarize, the proposed algorithm utilizes the two-stage filtering strategy of candidate nodes to avoid unnecessary computation, and adopts a new objective function to replace time-consuming Monte-Carle simulations. Experimental results on six real-world social networks demonstrate that the proposed algorithm outperforms other four comparison algorithms when comprehensively considering computation efficiency and result accuracy.},
  keywords={Social networking (online);Integrated circuit modeling;Heuristic algorithms;Greedy algorithms;Computational modeling;Technological innovation;Linear programming;Social networks;influence maximization;local influence;global selection},
  doi={10.1109/ACCESS.2019.2963100},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9910069,
  author={Chen, Shiyang and Huang, Shaoyi and Pandey, Santosh and Li, Bingbing and Gao, Guang R. and Zheng, Long and Ding, Caiwen and Liu, Hang},
  booktitle={SC21: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={E.T.: Re-Thinking Self-Attention for Transformer Models on GPUs}, 
  year={2021},
  volume={},
  number={},
  pages={1-14},
  abstract={Transformer-based deep learning models have become a ubiquitous vehicle to drive a variety of Natural Language Processing (NLP) related tasks beyond their accuracy ceiling. However, these models also suffer from two pronounced challenges, that is, gigantic model size and prolonged turnaround time. To this end, we introduce E.T. that rE-thinks self-attention computation for Transformer models on GPUs with the following contributions: First, we introduce a novel self-attention architecture, which encompasses two tailored self-attention operators with corresponding sequence length-aware optimizations, and operation reordering optimizations. Second, we present an attention-aware pruning design which judiciously uses various pruning algorithms to reduce more computations hence achieves significantly shorter turnaround time. For the pruning algorithms, we not only revamp the existing pruning algorithms, but also tailor new ones for transformer models. Taken together, we evaluate E.T. across a variety of benchmarks for Transformer, BERTBASE and DistilBERT, where E.T. presents superior performance over the mainstream projects, including the popular Nvidia Enterprise solutions, i.e., TensorRT and FasterTransformer.},
  keywords={Deep learning;Tensors;Computational modeling;High performance computing;Computer architecture;Benchmark testing;Transformers},
  doi={10.1145/3458817.3476138},
  ISSN={2167-4337},
  month={Nov},}@INPROCEEDINGS{8952440,
  author={Dominguez, Xavier and Arboleya, Pablo and Mantilla-Perez, Paola and El-Sayed, Islam and Gimenez, Nuria and Millan, Manuel Alberto Diaz},
  booktitle={2019 IEEE Vehicle Power and Propulsion Conference (VPPC)}, 
  title={Visual Analytics-Based Computational Tool for Electrical Distribution Systems of Vehicles}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={The present work provides a solid understanding on the challenges and opportunities of visual analytics (VA) use for the development of electrical distribution systems (EDS) of vehicles. First, the need for a VA-based software platform is justified to address the associated information overload and problem complexity. Later, a detailed background on the preceding use of VA in electrical systems as well in the automotive industry is provided. Based on the previous context and agile software implementation, specific guidelines for the development of a novel and functional VA-based computational tool are then provided to appropriately visualize, analyze and simulate in-car EDS.},
  keywords={Tools;Software;Automotive engineering;Industries;Wiring;Visual analytics;Wires},
  doi={10.1109/VPPC46532.2019.8952440},
  ISSN={1938-8756},
  month={Oct},}@INPROCEEDINGS{6046249,
  author={Erra, Ugo and Scanniello, Giuseppe},
  booktitle={Workshop on Empirical Requirements Engineering (EmpiRE 2011)}, 
  title={Assessing think-pair-square in distributed modeling of use case diagrams}, 
  year={2011},
  volume={},
  number={},
  pages={77-84},
  abstract={In this paper, we propose a new method for the modeling of use case diagrams in the context of global software development. It is based on think-pair-square, a widely used cooperative method for active problem solving. The validity of the developed technology (i.e., the method and its supporting environment) has been assessed through two controlled experiments. In particular, the experiments have been conducted to compare the developed technology with a brainstorming session based on face-to-face interaction. The comparison has been performed with respect to the time needed to model use case diagrams and the quality of the produced models. The data analysis indicates a significant difference in favor of the brainstorming session for the time, with no significant impact on the requirements specification.},
  keywords={Computational modeling;Brain modeling;Unified modeling language;Programming;Software systems;Context;Controlled experiments;Global software engineering;Functional modeling;Requirements engineering},
  doi={10.1109/EmpiRE.2011.6046249},
  ISSN={2329-6356},
  month={Aug},}@ARTICLE{10535493,
  author={Uzam, Murat and El-Sherbeeny, Ahmed M. and Guo, Weiwen and Li, Zhiwu},
  journal={IEEE Access}, 
  title={Design of an Improved Think Globally Act Locally Approach for the Computation of Petri Nets Based Liveness Enforcing Supervisors of FMSs}, 
  year={2024},
  volume={12},
  number={},
  pages={74367-74388},
  abstract={An improved think-globally-act-locally (ITGAL) method is proposed in this paper for the computation of a liveness enforcing/deadlock prevention supervisor containing of a set control places (CPs) for a Petri net (PN) model of a flexible manufacturing system (FMS) suffering from deadlocks. The proposed method is especially suitable for generalized PN classes containing weighted arcs such as S4R and S4PR. It leads to optimal or near-optimal liveness-enforcing supervisors without solving intractable integer linear programming problems. By using a recently proposed optimality test for CPs, the proposed ITGAL method provides improved behavioral permissiveness and/or reduced structural complexity of the CPs. The applicability of the proposed method is shown by means of a number of typical FMS examples.},
  keywords={System recovery;Computational modeling;Law;Frequency modulation;Petri nets;Vectors;Flexible manufacturing systems;Flexible manufacturing system (FMS);deadlock;deadlock prevention;Petri net (PN);liveness enforcing supervisor (LES);optimality test},
  doi={10.1109/ACCESS.2024.3403804},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8912419,
  author={Sowah, Robert and Friedman, Ryan and Ofoli, Abdul R. and Sarkodie-Mensah, Baffour},
  booktitle={2019 IEEE Industry Applications Society Annual Meeting}, 
  title={Think to Speak - A Piezoelectric-EEG system for Augmentative and Alternative Communication (AAC) using Recurrent Neural Networks}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={The collection of individuals with severe speech and physical impairments (SSPI), is the target audience for the Think to Speak Augmentative and Alternative Communication (AAC) system. The slow communication rate of AACs accessible to the target audience renders them undesirable, exhausting to operate, and a barrier to social and economic inclusion. This research synergizes the use of Electroencephalography (EEG) and high-sensitivity piezoelectric sensor readings with a Long Short-Term Memory Recurrent Neural Network (LSTM RNN) to create a physically accessible AAC with performance comparable to 7.8 characters per minute communication rate. Since self-expression is inextricably linked with physical, mental, and emotional health, this research is of great significance to the estimated one percent of the global population with complex communication needs.},
  keywords={Electroencephalography;Brain modeling;Recurrent neural networks;Computer architecture;Headphones;Liquid crystal displays;Computational modeling;Piezoelectric sensor;Electroencephalography (EEG);Long Short-Term Memory;Recurrent Neural Network;Complex Communication Needs},
  doi={10.1109/IAS.2019.8912419},
  ISSN={2576-702X},
  month={Sep.},}@INPROCEEDINGS{9752645,
  author={Rappai, Sherin and Ramasamy, Gobi},
  booktitle={2022 International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI)}, 
  title={Computational Methods to Predict Suicide Ideation among Adolescents}, 
  year={2022},
  volume={},
  number={},
  pages={1-11},
  abstract={Suicide has been a prominent cause of death worldwide, regardless of age, sex, geography, and so on, and predominantly suicide among teens, increased as the years have passed. Suicide ideation, suicide risk, suicide attempts have been studied extensively, and the most common cause has been identified as depression, followed by familial concerns, hereditary factors, stress, avoidance fear, and a variety of other variables. When visited by a doctor, most adolescents are unaware of their mental state and hence do not take action on their own or are not assisted by family or peer members to overcome their fear of social stigma or the treatment they must undergo. According to popular belief, early treatment and detection are the most effective ways to reduce the risk of suicide. As a result, the focus of this study is to illustrate some of the computational strategies utilized in deep learning and machine learning fields to detect kids at risk of suicide},
  keywords={Deep learning;Geography;Sensitivity;Social networking (online);Magnetic resonance imaging;Medical services;Human factors;suicide prevention;suicide ideation;suicide risk;mental health;deep learning;neural network analysis;machine learning},
  doi={10.1109/ACCAI53970.2022.9752645},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10678083,
  author={Kim, Byoungjip and Hwang, Dasol and Cho, Sungjun and Jang, Youngsoo and Lee, Honglak and Lee, Moontae},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Show, Think, and Tell: Thought-Augmented Fine-Tuning of Large Language Models for Video Captioning}, 
  year={2024},
  volume={},
  number={},
  pages={1808-1817},
  abstract={Large language models (LLMs) have achieved a great success in natural language processing, and have a significant potential for multi-modal applications. Despite the surprising zero-shot or few-shot ability, it is also required to effectively fine-tune pre-trained language models for specific downstream tasks. In this paper, we introduce CaptionT5, a video captioning model that fine-tunes T5 towards understanding videos and generating descriptive captions. To generate a more corespondent caption, CaptionT5 introduces thought-augmented fine-tuning for video captioning, in which a pre-trained language model is fine-tuned on thought-augmented video inputs. This resembles the process that human see a video, think of visual concepts such as objects and actions, and then tell a correct and natural sentence based on the thoughts. To automatically generate thoughts, we propose (1) CLIP-guided thought sampling that samples thoughts based on the similarity in an image-text multimodal embedding space by leveraging CLIP. We also propose (2) CLIP-guided caption ranking during decoding for further performance gains. Through experimentation on VATEX, MSRVTT, and YC2 datasets, we empirically demonstrate that CaptionT5 performs competitively against prior-art video captioning approaches without using encoders specialized for video data. Further experiments show that CaptionT5 is especially effective under small number of sampled video frames.},
  keywords={Visualization;Computer vision;Large language models;Computational modeling;Conferences;Performance gain;Data models;Large Language Models;Thought-Augmented Fine-Tuning;Video Captioning},
  doi={10.1109/CVPRW63382.2024.00187},
  ISSN={2160-7516},
  month={June},}@INPROCEEDINGS{10654818,
  author={Cheng, Sijie and Guo, Zhicheng and Wu, Jinawen and Fang, Kechen and Li, Peng and Liu, Huaping and Liu, Yang},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={EgoThink: Evaluating First-Person Perspective Thinking Capability of Vision-Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={14291-14302},
  abstract={Vision-language models (VLMs) have recently shown promising results in traditional downstream tasks. Evaluation studies have emerged to assess their abilities, with the majority focusing on the third-person perspective, and only a few addressing specific tasks from the first-person per-spective. However, the capability of VLMs to “think” from a first-person perspective, a crucial attribute for advancing autonomous agents and robotics, remains largely unexplored. To bridge this research gap, we introduce EgoThink, a novel visual question-answering benchmark that encompasses six core capabilities with twelve detailed dimensions. The benchmark is constructed using selected clips from ego-centric videos, with manually annotated question-answer pairs containing first-person information. To comprehensively assess VLMs, we evaluate twenty-one popular VLMs on EgoThink. Moreover, given the open-ended format of the answers, we use GPT-4 as the automatic judge to compute single-answer grading. Experimental results indicate that although GPT-4V leads in numerous dimensions, all evaluated VLMs still possess considerable potential for improvement in first-person perspective tasks. Meanwhile, enlarging the number of trainable parameters has the most significant impact on model performance on EgoThink. In conclusion, EgoThink serves as a valuable addition to existing evaluation benchmarks for VLMs, providing an indispensable resource for future research in the realm of embodied artificial intelligence and robotics.},
  keywords={Bridges;Visualization;Computer vision;Computational modeling;Focusing;Benchmark testing;Planning;Egocentric;Vision-Language Models;Benchmark},
  doi={10.1109/CVPR52733.2024.01355},
  ISSN={2575-7075},
  month={June},}@INBOOK{9893006,
  author={Rubin, Olis Harold},
  booktitle={Computer Models of Process Dynamics: From Newton to Energy Fields}, 
  title={Creative thinking and scientific theories}, 
  year={2023},
  volume={},
  number={},
  pages={43-56},
  abstract={This chapter describes how the science of dynamics was created. It considers the study of electromagnetism, and focuses on the fluid dynamics. The chapter then focuses on many creative thinkers who formulated scientific models that described the behavior of the real world. Astronomy has been one of the most persistent activities in science. Galileo Galilei's greatest contribution was to combine experimental methods with creative thinking and mathematical analysis. Isaac Newton extended the work of Galileo to replace Kepler's empirical model of the solar system by mathematical equations. In 1864 Clerk Maxwell used an equation to show that an electromagnetic wave would be propagated through space at the speed of light. The chapter considers the efforts to create a mathematical model of aerodynamics.},
  keywords={Moon;Sun;Earth;Planetary orbits;Computational modeling;Extraterrestrial measurements;Analytical models},
  doi={10.1002/9781119885689.ch3},
  ISSN={},
  publisher={IEEE},
  isbn={9781119885665},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9893006},}@INPROCEEDINGS{8725190,
  author={Jaeger, Martin and Adair, Desmond},
  booktitle={2019 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Process Teaching Simulator: Trial and Error, Thinking, Learning Effectiveness}, 
  year={2019},
  volume={},
  number={},
  pages={160-165},
  abstract={The importance of feedback on students' learning activities, so as to facilitate high learning effectiveness, has been shown before. However, the effectiveness of feedback on students' learning activities, when students learn engineering processes based on computer based simulations, is much less well known. The purpose of this study is to analyze the impact of “correcting feedback” (i.e. the feedback indicates only students' mistakes) and “reflective feedback” (i.e. the feedback includes a hint to encourage the student to re-think a specific answer) on learning effectiveness of engineering students, when using computer based simulation in order to enhance the learning of engineering processes. The impact of “reflective feedback” is analyzed by carrying out semi-quasi experiments using experimental and control groups of students. It is found that “reflective feedback” does not result in higher learning effectiveness and that the students of this study prefer to correct their mistakes by focusing on “correcting feedback” and previously learned content, while using a “trial and error mentality”. The results provide evidence, first, about the impact of students' learning background when using teaching simulators, and, secondly, that simulators showing both, “correcting feedback” and “reflective feedback”, may reduce the stimulating effect of “reflective feedback” because of the presence of “correcting feedback”. Consideration of these findings will contribute to further improvement of process teaching simulators. This study is part of an ongoing research effort related to computer simulation based learning in engineering education.},
  keywords={Computational modeling;Engineering students;Games;Companies;Conferences;process simulation;learning effectiveness;computer-based learning;feedback methods},
  doi={10.1109/EDUCON.2019.8725190},
  ISSN={2165-9567},
  month={April},}@ARTICLE{9389764,
  author={Riekki, Jukka and Mämmelä, Aarne},
  journal={IEEE Access}, 
  title={Research and Education Towards Smart and Sustainable World}, 
  year={2021},
  volume={9},
  number={},
  pages={53156-53177},
  abstract={We propose a vision for directing research and education in the field of information and communications technology (ICT). Our Smart and Sustainable World vision targets prosperity for the people and the planet through better awareness and control of both human-made and natural environments. The needs of society, individuals, and industries are fulfilled with intelligent systems that sense their environment, make proactive decisions on actions advancing their goals, and perform the actions on the environment. We emphasize artificial intelligence, feedback loops, human acceptance and control, intelligent use of basic resources, performance parameters, mission-oriented interdisciplinary research, and a holistic systems view complementing the conventional analytical reductive view as a research paradigm, especially for complex problems. To serve a broad audience, we explain these concepts and list the essential literature. We suggest planning research and education by specifying, in a step-wise manner, scenarios, performance criteria, system models, research problems, and education content, resulting in common goals and a coherent project portfolio as well as education curricula. Research and education produce feedback to support evolutionary development and encourage creativity in research. Finally, we propose concrete actions for realizing this approach.},
  keywords={Education;Sustainable development;Systems thinking;Pattern recognition;Intelligent systems;Europe;Complex systems;Smart world vision;sustainable development goals;Internet of Things (IoT);artificial intelligence (AI);computational intelligence (CI);reductive view;systems view;emergence;experimental-inductive method;hypothetico-deductive method;functionality;basic resources;performance;energy efficiency;dependability;availability;reliability;safety;security;constraints;optimization;decision making;hierarchy;open-loop control;closed-loop feedback control;degree of centralization;distributed systems;education;integrative learning;research;innovation;history},
  doi={10.1109/ACCESS.2021.3069902},
  ISSN={2169-3536},
  month={},}@ARTICLE{7475484,
  author={},
  journal={IEEE Smart Grid Vision for Computing: 2030 and Beyond Reference Model}, 
  title={IEEE Smart Grid Vision for Computing: 2030 and Beyond Reference Model}, 
  year={2016},
  volume={},
  number={},
  pages={1-18},
  abstract={This document, IEEE Smart Grid Vision for Computing: 2030 and Beyond Reference Model introduces the concepts and structure of the more detailed IEEE Smart Grid Vision for Computing: 2030 and Beyond and IEEE Smart Grid Vision for Computing: 2030 and Beyond Roadmap that together provide Smart Grid architectural concepts, functional concepts, and technological concepts that describe the time-phased role of computing that enable Smart Grid functions. The content and examples in this reference model ultimately provide energy systems professionals and computing technologists assistance in the use of the Vision documents, facilitating investment decisions, and fostering advancements in the Smart Grid. For Corporate or Institutional Access, request a custom quote for your organization at www.ieee.org/smartgridresearch},
  keywords={Smart grids;Trademarks;Computational modeling;IEEE Standards;Standards organizations;Organizations;Computational intelligence;Cyber security and resilience;Data analytics (and databases);Distributed multi-agent architecture;High-performance computing;Messaging-oriented middleware;Modeling and simulation;Self-integrating systems;Software verification and validation;Virtual comput},
  doi={},
  ISSN={},
  month={May},}@INPROCEEDINGS{10189158,
  author={Ammermann, Joshua and Bittner, Tim and Eichhorn, Domenik and Schaefer, Ina and Seidl, Christoph},
  booktitle={2023 IEEE/ACM 4th International Workshop on Quantum Software Engineering (Q-SE)}, 
  title={Can Quantum Computing Improve Uniform Random Sampling of Large Configuration Spaces?}, 
  year={2023},
  volume={},
  number={},
  pages={34-41},
  abstract={A software product line models the variability of highly configurable systems. Complete exploration of all valid configurations (the configuration space) is infeasible as it grows exponentially with the number of features in the worst case. In practice, few representative configurations are sampled instead, which may be used for software testing or hardware verification. Pseudo-randomness of modern computers introduces statistical bias into these samples. Quantum computing enables truly random, uniform configuration sampling based on inherently random quantum physical effects. We propose a method to encode the entire configuration space in a superposition and then measure one random sample. We show the method's uniformity over multiple samples and investigate its scale for different feature models. We discuss the possibilities and limitations of quantum computing for uniform random sampling regarding current and future quantum hardware.},
  keywords={Computers;Software testing;Quantum computing;Quantum algorithm;Computational modeling;Scalability;Quantum mechanics;Uniform sampling;Software product lines;Quantum computing},
  doi={10.1109/Q-SE59154.2023.00012},
  ISSN={},
  month={May},}@ARTICLE{6519937,
  author={Wang, Song and Li, Ling and Jones, James D.},
  journal={IEEE Systems Journal}, 
  title={Systemic Thinking on Services Science, Management and Engineering: Applications and Challenges in Services Systems Research}, 
  year={2014},
  volume={8},
  number={3},
  pages={803-820},
  abstract={As the world increasingly becomes characterized by the provision of services to customers, service research faces many challenges and needs a new vision. Many of these challenges stem from the fact that technologies are continually experiencing dramatic change, and savvy customers are increasingly demanding more qualified services. Although research and experiential findings on services in many disciplines have achieved impressive results, systematic research on modern services systems is rarely considered. Aiming at services systems (not only services themselves), this paper discusses the contributions and the potentials for the field of systems theory for Services Science, Management and Engineering (SSME). Thus, SSME can provide suitable referential clues for discussing impacts of systems theory on services research, and systemic thinking can be applied to discuss key issues in SSME. Providing basic definitions of services and services systems, this paper elaborates on the research objects and methodologies of SSME from systems perspective, and proposes that systems theory can be applied as the foundations of services engineering. This paper further sheds light on systemic issues in services science and engineering, services operations, and services systems management. It also provides a summary of relevant theories and tools applied to services systems at the systems level. Finally, some potential prospects in SSME research are presented to meet research demands and practical challenges.},
  keywords={Production;Manufacturing;Industries;Economics;Standards organizations;Organizations;Services engineering;services management;services science;services system;SSME;systems theory;Services engineering;services management;services science;services system;SSME;systems theory},
  doi={10.1109/JSYST.2013.2260622},
  ISSN={1937-9234},
  month={Sep.},}@INPROCEEDINGS{974419,
  author={Brandt, M.E.},
  booktitle={Proceedings 2nd Annual IEEE International Symposium on Bioinformatics and Bioengineering (BIBE 2001)}, 
  title={Thinking nonlinearly about brain dynamics: a neurocommentary}, 
  year={2001},
  volume={},
  number={},
  pages={112-118},
  abstract={Despite significant progress over the past several decades in neural research there still remains an ingrained tendency to approach the field using overly reductionistic as well as linear theories and methods. We are just beginning to appreciate the complexity of the brain. A further shift in our "consciousness" about neural dynamics is needed to take the next steps in brain research. We need to use more reflexively what we have learned about the nonlinear dynamical and complex nature of the brain to attempt to "bootstrap" our own thinking processes about neural science itself.},
  keywords={Brain},
  doi={10.1109/BIBE.2001.974419},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8491714,
  author={Sabin, Mihaela and Smith, Adrienne and DuBow, Wendy and Deloge, Rosabel},
  booktitle={2018 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT)}, 
  title={Creative computing challenge: teacher professional learning to enhance non-computing career and technical education curricula with engaging computational practices for all students}, 
  year={2018},
  volume={},
  number={},
  pages={i-i},
  abstract={The Creative Computing Challenge (CCC) project (2014-2018) is funded by the National Science Foundation and is designed to broaden participation in computing by providing professional development (PD) for high school teachers at Career & Technical Education (CTE) programs throughout the state of New Hampshire. Teachers receive a stipend and tablets for their classrooms; they attend several in-person PD sessions through the year, where master teachers and PD facilitators introduce modeling of inquiry and equity-based practices, as well as teach the App Inventor tool and how to inculcate computational thinking in students. Project evaluation has included teacher interviews, classroom and PD observations, as well as student and teacher surveys. External evaluation of this project has been an integral part of the project from the beginning and, along with the project team’s observations and input, has significantly reshaped the project activities. It became clear after the first year that a central challenge of this project would be working with a mix of teachers across multiple domains – from teachers who had little experience even using computers to teachers who had computer science degrees; from teachers who came to teaching from professional backgrounds to those who had education degrees; and from beginning teachers to those who had been teaching the same courses for twenty years. Through evaluation data and really listening to teacher feedback, we not only tailored the PD content and structure, but also refined the data collection instruments and evaluation design to bridge the gap between different teacher experiences and levels of preparation. As a result, we have been able to bring computing into non-technical content areas such as Hospitality and non-programming classes such as Photography, as well as support computing educations in New Hampshire CTE programs. In Year 4, we now better understand the range of benefits and challenges involved in working with CTE programs and inserting CCC-inspired curricular modules in non-computing courses.},
  keywords={Education;Handheld computers;Engineering profession;Programming profession;Photography;Interviews;Instruments;teacher professional learning;career and technocal edcuation;inquiry and equity-based teaching professional development evaluation},
  doi={10.1109/RESPECT.2018.8491714},
  ISSN={},
  month={Feb},}@ARTICLE{9454259,
  author={Zhang, Tielin and Jia, Shuncheng and Cheng, Xiang and Xu, Bo},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Tuning Convolutional Spiking Neural Network With Biologically Plausible Reward Propagation}, 
  year={2022},
  volume={33},
  number={12},
  pages={7621-7631},
  abstract={Spiking neural networks (SNNs) contain more biologically realistic structures and biologically inspired learning principles than those in standard artificial neural networks (ANNs). SNNs are considered the third generation of ANNs, powerful on the robust computation with a low computational cost. The neurons in SNNs are nondifferential, containing decayed historical states and generating event-based spikes after their states reaching the firing threshold. These dynamic characteristics of SNNs make it difficult to be directly trained with the standard backpropagation (BP), which is also considered not biologically plausible. In this article, a biologically plausible reward propagation (BRP) algorithm is proposed and applied to the SNN architecture with both spiking-convolution (with both 1-D and 2-D convolutional kernels) and full-connection layers. Unlike the standard BP that propagates error signals from postsynaptic to presynaptic neurons layer by layer, the BRP propagates target labels instead of errors directly from the output layer to all prehidden layers. This effort is more consistent with the top-down reward-guiding learning in cortical columns of the neocortex. Synaptic modifications with only local gradient differences are induced with pseudo-BP that might also be replaced with the spike-timing-dependent plasticity (STDP). The performance of the proposed BRP-SNN is further verified on the spatial (including MNIST and Cifar-10) and temporal (including TIDigits and DvsGesture) tasks, where the SNN using BRP has reached a similar accuracy compared to other state-of-the-art (SOTA) BP-based SNNs and saved 50% more computational cost than ANNs. We think that the introduction of biologically plausible learning rules to the training procedure of biologically realistic SNNs will give us more hints and inspiration toward a better understanding of the biological system’s intelligent nature.},
  keywords={Neurons;Biology;Convolutional neural networks;Biological neural networks;Tuning;Membrane potentials;Neural networks;Biologically plausible computing;neuronal dynamics;reward propagation;spiking neural network (SNN)},
  doi={10.1109/TNNLS.2021.3085966},
  ISSN={2162-2388},
  month={Dec},}@ARTICLE{10355908,
  author={Mittal, Shweta and Saharia, Ankur and Ismail, Yaseera and Petruccione, Francesco and Bourdine, Anton V. and Morozov, Oleg G. and Demidov, Vladimir V. and Yin, Juan and Singh, Ghanshyam and Tiwari, Manish and Kumar, Santosh},
  journal={IEEE Sensors Journal}, 
  title={Design and Performance Analysis of a Novel Hoop-Cut SPR-PCF Sensor for High Sensitivity and Broad Range Sensing Applications}, 
  year={2024},
  volume={24},
  number={3},
  pages={2697-2704},
  abstract={This article presents a systematic numerical investigation of a surface plasmon resonance (SPR) sensor based on photonic crystal fiber (PCF). The proposed design is modeled and simulated using the full-vectorial finite-element (FV-FEM) technique and sensing characteristics, such as confinement loss (CL) behaviors, phase matching, and sensitivity, which are investigated and presented. The plasmonic layer is made up of TiO2 and gold for improved sensitivity. The reported sensor exhibits an amplitude sensitivity of −374.062 RIU−1 and a wavelength sensitivity of 2000 nm/RIU for the refractive index (RI) sensing range of (1.39–1.44), according to the loss spectrum shift. The reported hoop-cut PCF-based SPR (HPCF-SPR) sensor is suitable for biosensing and chemical sensing applications because of its broad range (1.39–1.44) of analyte detection.},
  keywords={Sensors;Sensitivity;Gold;Refractive index;Optical fiber sensors;Surface plasmons;Photonics;Biosensors;fiber-optic sensor;photonic crystal fiber (PCF);sensitivity;surface plasmon resonance (SPR)},
  doi={10.1109/JSEN.2023.3339813},
  ISSN={1558-1748},
  month={Feb},}@ARTICLE{10138574,
  author={Dyavangoudar, Amogh A. and Chhipa, Mayur Kumar and Saharia, Ankur and Ismail, Yaseera and Petruccione, Francesco and Bourdine, Anton V. and Morozov, Oleg G. and Demidov, Vladimir V. and Yin, Juan and Singh, Ghanshyam and Tiwari, Manish},
  journal={IEEE Access}, 
  title={Orbital Angular Momentum Mode Propagation and Supercontinuum Generation in a Soft Glass Bragg Fiber}, 
  year={2023},
  volume={11},
  number={},
  pages={56891-56899},
  abstract={This manuscript presents a ring-core Bragg Fiber (RC-BF) for orbital angular momentum (OAM) modes propagation and supercontinuum generation. The proposed RC-BF is composed of alternating layers of soft glasses SF57 and LLF1 to render high nonlinearity to the fiber. Mode analysis using full-vectorial finite element method resulted in obtaining HE/EH modes to support vector modes as well as orbital angular momentum modes. The optimized fiber supports 22 OAM modes and exhibits a zero-dispersion wavelength (ZDW). The small effective area of Fiber 3 aided in achieving the highest nonlinearity,  $\gamma $  = 91.51  $\text{W}^{-1}$ km $^{-1}$ . A near-infrared supercontinuum is generated with a 35 dB flatness over a bandwidth of  $\sim $ 1087 - 2024 nm in a 20 cm long RC-BF using a chirp-free hyperbolic secant pulse of width 200 fs and peak power of 5 kW.},
  keywords={Optical fiber dispersion;Finite element methods;Optical fibers;Supercontinuum generation;Refractive index;Dispersion;Optical fiber networks;Bragg gratings;Bragg fiber;finite element method;OAM modes;zero-dispersion wavelength;supercontinuum generation},
  doi={10.1109/ACCESS.2023.3281370},
  ISSN={2169-3536},
  month={},}@ARTICLE{6418003,
  author={Leeb, Robert and Lancelle, Marcel and Kaiser, Vera and Fellner, Dieter W. and Pfurtscheller, Gert},
  journal={IEEE Transactions on Computational Intelligence and AI in Games}, 
  title={Thinking Penguin: Multimodal Brain–Computer Interface Control of a VR Game}, 
  year={2013},
  volume={5},
  number={2},
  pages={117-128},
  abstract={In this paper, we describe a multimodal brain-computer interface (BCI) experiment, situated in a highly immersive CAVE. A subject sitting in the virtual environment controls the main character of a virtual reality game: a penguin that slides down a snowy mountain slope. While the subject can trigger a jump action via the BCI, additional steering with a game controller as a secondary task was tested. Our experiment profits from the game as an attractive task where the subject is motivated to get a higher score with a better BCI performance. A BCI based on the so-called brain switch was applied, which allows discrete asynchronous actions. Fourteen subjects participated, of which 50% achieved the required performance to test the penguin game. Comparing the BCI performance during the training and the game showed that a transfer of skills is possible, in spite of the changes in visual complexity and task demand. Finally and most importantly, our results showed that the use of a secondary motor task, in our case the joystick control, did not deteriorate the BCI performance during the game. Through these findings, we conclude that our chosen approach is a suitable multimodal or hybrid BCI implementation, in which the user can even perform other tasks in parallel.},
  keywords={Games;Electroencephalography;Electrodes;Training;Brain computer interfaces;Educational institutions;Feature extraction;Brain–computer interfaces (BCI);brain switch;game;hybrid BCI;multimodal;multitasking;virtual reality (VR)},
  doi={10.1109/TCIAIG.2013.2242072},
  ISSN={1943-0698},
  month={June},}@ARTICLE{9677010,
  author={Kartal, Yavuz Selim and Kutlu, Mucahid},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Re-Think Before You Share: A Comprehensive Study on Prioritizing Check-Worthy Claims}, 
  year={2023},
  volume={10},
  number={1},
  pages={362-375},
  abstract={The massive amount of misinformation spreading on the internet on a daily basis has enormous negative impacts on societies. Therefore, we need systems to help fact-checkers to combat misinformation and to raise public awareness of this important problem. In this article, we propose a hybrid model which combines bidirectional encoder representations from transformer (BERT) model with various features to prioritize claims based on their check-worthiness. Features we use include domain-specific controversial topics (CT), word embeddings (WE), part-of-speech (POS) tags, and others. In addition, we explore various ways of increasing labeled data size to effectively train the models, such as increasing positive (IncPos) samples, active learning (AL), and utilizing labeled data in other languages. In our extensive experiments, we show that our model outperforms all state-of-the-art models in test collections of Conference and Labs of Evaluation Forum (CLEF) CheckThat! Lab (CTL) 2018 and 2019. In addition, when positive samples are increased in the training set, our model achieves the best mean average precision (MAP) score reported so far for the test collection of CTL 2020. Furthermore, we show that cross-lingual training is effective for prioritizing Arabic and Turkish claims, but not for English.},
  keywords={Task analysis;Fake news;Data models;Training;Bit error rate;Training data;Predictive models;Check-worthy claims;fact-checking;misinformation},
  doi={10.1109/TCSS.2021.3138642},
  ISSN={2329-924X},
  month={Feb},}@INPROCEEDINGS{10552015,
  author={Dudysheva, Elena V. and Shiling, Galina S. and Zakharov, Pavel V.},
  booktitle={2024 7th International Conference on Information Technologies in Engineering Education (Inforino)}, 
  title={University Students Interdisciplinary Training of Educational Resources Design for Computer Modeling in School Engineering Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={School graduates of technology profiles classes are often seen as the most prepared potential applicants for engineering universities. Future engineers will need to apply modeling to solve problems that emerge in professional activities building on the school primary engineering learning. The construction of physical processes 3D models in computer environments can aid in the development of engineering thinking and digital training. This requires the electronic educational resources design and the development of suitable methods. The collaboration between pedagogical and engineering universities can facilitate the accomplishment of these tasks provided with methodical basis and a consolidation of the universities scientific and practical developments in the network interaction. One of the popular areas for training future engineers is distance project design where tasks are distributed among several performers. The issue of interdisciplinary design of electronic educational resources to ensure the quality of engineering training in technological profiles in schools is significant for the theory and practice of innovation in engineering education, pedagogical methodology and technology, and digital didactics. The proposed methods include computer modeling of physical processes in engineering (using materials science example), pedagogical design, and educational outcomes analysis. The paper describes the results of experimental work on organizing interdisciplinary projects for the development of electronic educational resources for school engineering learning by student teams. These teams consist of pedagogical university students, future teachers, and polytechnic university students, future engineers. It concludes that interdisciplinary training of students from pedagogical and engineering universities in the electronic educational resources design on computer modeling for school primary engineering learning is effectively feasible using distributed educational technologies. The outcome may be useful for early schoolchildren involvement in innovative engineering initiatives through participation in research projects and STEM Olympiads including multi-language educational events.},
  keywords={Training;Solid modeling;Materials science and technology;Three-dimensional displays;Computational modeling;Biological system modeling;Educational technology;interdisciplinary design;electronic educational resources;school education;primary engineering learning;computer modeling;pedagogical universities;engineering universities;distance technologies;student teams projects},
  doi={10.1109/Inforino60363.2024.10552015},
  ISSN={},
  month={April},}@INPROCEEDINGS{8405151,
  author={Cornejo, Maria Eda and Sommer, Sonia and Rodríguez, Jorge},
  booktitle={2017 36th International Conference of the Chilean Computer Science Society (SCCC)}, 
  title={An approach based on Embodied Programming to teach computer science at a Secondary School}, 
  year={2017},
  volume={},
  number={},
  pages={1-9},
  abstract={In this article a didactic approach is introduced which seeks to integrate the progress made in the context of Block-Based Programming and other didactic approaches developed in the area of computer teaching. The prospects developed in the area of Project Based Learning Approach, Collaborative Learning and Embodied Programming are taken into account. Surrogate Embodiment, in the Embodied Programming context, is a kind of interaction where the movements performed by a person on a stage are directed by students. Furthermore, it is used as a structuring resource in the teaching process, the development of computational devices, paying special attention to skills development in the area of Computational Thinking. This paper presents a Video Game Development Workshop based on this approach with first year students from a state technical school. The experience has shown satisfactory results in connection to the acquisition of concepts and fundamental practices in the area of Algorithms and Programming.},
  keywords={Programming;Education;Software;Cognition;Collaborative work;Performance evaluation;Secondary School;Computing Science;Computational Thinking;Teaching Programming;Embodied Programming;Blocks-based Programming},
  doi={10.1109/SCCC.2017.8405151},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9962388,
  author={Aulicino, Alexa and Bakrania, Smitesh},
  booktitle={2022 IEEE Frontiers in Education Conference (FIE)}, 
  title={A Python-based lab module to conduct thermodynamic cycle analysis}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={A Python-based lab activity was developed for a remote Thermodynamics course to add computational thinking to traditional analytical problem solving. Python was selected to conduct the analysis because of its popularity and utility in the broader engineering field. Early exposure to this highly desired engineering skill can provide added benefits to students. Combining Python with an engaging lab experience can have a compounding effect on student learning outcomes. A five-week Python-based lab module was developed for an introductory thermal-fluid science class. The module reinforced fundamental concepts learned in lecture, while expanding on design-related analysis which is often left for advanced courses. The lab module began with an introduction to Python programming and quickly transitioned to the parametric analysis of standard Rankine, Gas Turbine, and Vapor Compression cycles. The lab module was designed to be self-guided with step-by-step instructions presented using Google Colab. This paper details the implementation and the student outcomes. Both direct and indirect assessments were conducted over two semesters of the course. Results indicate a strong positive impact on Python programming learning outcomes. Students acquired a working knowledge of Python programming and experienced how computational tools can be used to solve advanced engineering problems. At the same time, the student feedback indicated students' resistance to open-ended projects and independent learning; even if they are aware of their relevance and benefits to their future careers. Nevertheless, the positive learning outcomes were encouraging. Whether students pursue a career in thermodynamics or in a broader engineering field, this lab experience equipped them with tools that can augment their engineering skills.},
  keywords={Resistance;Knowledge engineering;Thermodynamics;Engineering profession;Internet;Problem-solving;Programming profession;Thermodynamics;Python;Computational Thinking;Open-ended;Online Learning},
  doi={10.1109/FIE56618.2022.9962388},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{1342537,
  author={Bastoul, C.},
  booktitle={Proceedings. 13th International Conference on Parallel Architecture and Compilation Techniques, 2004. PACT 2004.}, 
  title={Code generation in the polyhedral model is easier than you think}, 
  year={2004},
  volume={},
  number={},
  pages={7-16},
  abstract={Many advances in automatic parallelization and optimization have been achieved through the polyhedral model. It has been extensively shown that this computational model provides convenient abstractions to reason about and apply program transformations. Nevertheless, the complexity of code generation has long been a deterrent for using polyhedral representation in optimizing compilers. First, code generators have a hard time coping with generated code size and control overhead that may spoil theoretical benefits achieved by the transformations. Second, this step is usually time consuming, hampering the integration of the polyhedral framework in production compilers or feedback-directed, iterative optimization schemes. Moreover, current code generation algorithms only cover a restrictive set of possible transformation functions. This paper discusses a general transformation framework able to deal with nonunimodular, noninvertible, nonintegral or even nonuniform functions. It presents several improvements to a state-of-the-art code generation algorithm. Two directions are explored: generated code size and code generator efficiency. Experimental evidence proves the ability of the improved method to handle real-life problems.},
  keywords={Iterative algorithms;Optimizing compilers;Production;Computational modeling;Size control;Program processors;Data structures;Solid modeling;Mathematical model;Scheduling},
  doi={10.1109/PACT.2004.1342537},
  ISSN={1089-795X},
  month={Oct},}@ARTICLE{7997798,
  author={Papyan, Vardan and Sulam, Jeremias and Elad, Michael},
  journal={IEEE Transactions on Signal Processing}, 
  title={Working Locally Thinking Globally: Theoretical Guarantees for Convolutional Sparse Coding}, 
  year={2017},
  volume={65},
  number={21},
  pages={5687-5701},
  abstract={The celebrated sparse representation model has led to remarkable results in various signal processing tasks in the last decade. However, despite its initial purpose of serving as a global prior for entire signals, it has been commonly used for modeling low dimensional patches due to the computational constraints it entails when deployed with learned dictionaries. A way around this problem has been recently proposed, adopting a convolutional sparse representation model. This approach assumes that the global dictionary is a concatenation of banded circulant matrices. While several works have presented algorithmic solutions to the global pursuit problem under this new model, very few truly effective guarantees are known for the success of such methods. In this paper, we address the theoretical aspects of the convolutional sparse model providing the first meaningful answers to questions of uniqueness of solutions and success of pursuit algorithms, both greedy and convex relaxations, in ideal and noisy regimes. To this end, we generalize mathematical quantities, such as the l0 norm, mutual coherence, Spark and restricted isometry property to their counterparts in the convolutional setting, intrinsically capturing local measures of the global model. On the algorithmic side, we demonstrate how to solve the global pursuit problem by using simple local processing, thus offering a first of its kind bridge between global modeling of signals and their patch-based local treatment.},
  keywords={Dictionaries;Convolution;Convolutional codes;Computational modeling;Sparse matrices;Mathematical model;Matching pursuit algorithms;Sparse representations;convolutional sparse coding;uniqueness guarantees;stability guarantees;orthogonal matching pursuit;basis pursuit;global modeling;local processing},
  doi={10.1109/TSP.2017.2733447},
  ISSN={1941-0476},
  month={Nov},}@INPROCEEDINGS{8443741,
  author={Gupta, Gaurav and Pequito, Sergio and Bogdan, Paul},
  booktitle={2018 ACM/IEEE 9th International Conference on Cyber-Physical Systems (ICCPS)}, 
  title={Re-Thinking EEG-Based Non-Invasive Brain Interfaces: Modeling and Analysis}, 
  year={2018},
  volume={},
  number={},
  pages={275-286},
  abstract={Brain interfaces are cyber-physical systems that aim to harvest information from the (physical) brain through sensing mechanisms, extract information about the underlying processes, and decide/actuate accordingly. Nonetheless, the brain interfaces are still in their infancy, but reaching to their maturity quickly as several initiatives are released to push forward their development (e.g., NeuraLink by Elon Musk and `typing-by-brain' by Facebook). This has motivated us to revisit the design of EEG-based non-invasive brain interfaces. Specifically, current methodologies entail a highly skilled neuro-functional approach and evidence-based a priori knowledge about specific signal features and their interpretation from a neuro-physiological point of view. Hereafter, we propose to demystify such approaches, as we propose to leverage new time-varying complex network models that equip us with a fractal dynamical characterization of the underlying processes. Subsequently, the parameters of the proposed complex network models can be explained from a system's perspective, and, consecutively, used for classification using machine learning algorithms and/or actuation laws determined using control system's theory. Besides, the proposed system identification methods and techniques have computational complexities comparable with those currently used in EEG-based brain interfaces, which enable comparable online performances. Furthermore, we foresee that the proposed models and approaches are also valid using other invasive and non-invasive technologies. Finally, we illustrate and experimentally evaluate this approach on real EEG-datasets to assess and validate the proposed methodology. The classification accuracies are high even on having less number of training samples.},
  keywords={Brain modeling;Brain-computer interfaces;Electroencephalography;Complex networks;Computational modeling;Feature extraction;Spatiotemporal phenomena;brain interfaces;spatiotemporal;fractional dynamics;unknown inputs;classification;motor prediction},
  doi={10.1109/ICCPS.2018.00034},
  ISSN={},
  month={April},}@INPROCEEDINGS{6142319,
  author={Carvalho, Jonata Tyska and Santos, Rafael A. Penna dos and Botelho, Silvia Silva da Costa and Filho, Nelson Duarte and Oliveira, Rodrigo Ruas and Santos, Edevaldo},
  booktitle={2011 International Conference on Internet of Things and 4th International Conference on Cyber, Physical and Social Computing}, 
  title={Hyper-Environments: A Different Way to Think about IoT}, 
  year={2011},
  volume={},
  number={},
  pages={25-32},
  abstract={The current technological scenario presents different mobile devices, which support wireless communication at an increasingly low cost. This all makes it possible to build systems thought to be impossible. The utilization of computational and natural elements, and the mixing of virtual and real elements, set up a complex relationship between elements. A good organization of these relations would enable the construction of complex systems that would bring countless benefits to users. This work presents an architecture to build hyper-environments, term proposed in this paper to define the interconnection between smart environments (which involve different elements, technological or not, real and/or virtual).The proposed architecture presents a taxonomy and a set of concepts for the organization of the hyper-environmental elements. It also offers directions to implement a middleware for building such systems. To validate the work, a hyper environment will be built using a middleware implemented based on the proposed architecture.},
  keywords={Computer architecture;Media;Organizations;Context;Middleware;Computational modeling;Architecture;smart environments;architecture;middleware;internet of things},
  doi={10.1109/iThings/CPSCom.2011.110},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9723201,
  author={Shahsavari, Sina and Sarangi, Pulak and Pal, Piya},
  booktitle={2021 55th Asilomar Conference on Signals, Systems, and Computers}, 
  title={KR-LISTA: Re-Thinking Unrolling for Covariance-Driven Sparse Inverse Problems}, 
  year={2021},
  volume={},
  number={},
  pages={1403-1408},
  abstract={This paper considers the problem of joint support recovery in Multiple Measurement Vector (MMV) models. We show that by exploiting correlation priors, one can boost the performance and computational cost of unrolled data-driven techniques for joint support recovery. We propose a novel unrolling of the Iterative Shrinkage Thresholding Algorithm (ISTA) for correlation-aware support recovery, which preserves the special "Khatri-Rao" structure that underlies the model. The proposed network, termed as "KR-LISTA", provides a parameter-efficient unrolling which enables training with limited data. Our numerical simulations demonstrate the effectiveness of KR-LISTA at test time for different values of SNR, and support sizes which were not provided to the network during training. In addition, KR-LISTA is also seen to be effective even in presence of model uncertainties. 1},
  keywords={Training;Uncertainty;Computational modeling;Training data;Network architecture;Numerical simulation;Time measurement;Joint Support Recovery;Multiple Measurement Vector;Correlation-awareness;Iterative Shrinkage Thresholding Algorithm (ISTA);Learned ISTA (LISTA);Khatri-Rao Product},
  doi={10.1109/IEEECONF53345.2021.9723201},
  ISSN={2576-2303},
  month={Oct},}@INPROCEEDINGS{10220748,
  author={Saranya, R. and Kalaivani, D.},
  booktitle={2023 5th International Conference on Inventive Research in Computing Applications (ICIRCA)}, 
  title={Manhattan Distance SMOTE Combined with Stacked Optimal Deep Learning Algorithms for the Efficient Heart Disease Prediction-Design Thinking Approach}, 
  year={2023},
  volume={},
  number={},
  pages={706-712},
  abstract={Advancements in technology and computational power have significantly diversified the field of medical sciences, especially in diagnosing human cardiac disorders, which is currently one of the most severe cardiac illnesses that drastically shortens human lives. Early detection of heart failure is critical to prevent it and improve patients' survival rates. However, traditional manual methods are subject to inter examiner variability and bias, making them unreliable in diagnosing cardiac diseases. The study conducted aimed to evaluate the performance of machine learning algorithms in accurately identifying and classifying individuals with heart disease and those who are healthy. For this purpose, a heart disease dataset was utilized to assess the predictive capabilities of the machine learning models. The study employs nine classifiers, including Probabilistic Neural Network (PNN), Artificial Neural Networks (ANN), Linear Regression (Li-R), Logistic Regression (Lo-R), and Naive Bayes (NB), before and after hyper parameter tuning. This research work also assessed various metrics, such as classification accuracy, F-measure, sensitivity, and specificity. By conducting specific preprocessing, dataset standardization, and hyper parameter tuning, it is observed that data normalization and hyper parameter adjustment of the machine learning classifiers significantly improved their performance in predicting heart disease.},
  keywords={Heart;Machine learning algorithms;Computational modeling;Artificial neural networks;Standardization;Predictive models;Sensitivity and specificity;Machine learning algorithms;Heart disease diagnosis;Data normalization;Hyperparameter tuning},
  doi={10.1109/ICIRCA57980.2023.10220748},
  ISSN={},
  month={Aug},}@ARTICLE{9475486,
  author={Qi, Shanshan and Yang, Luxi and Li, Chunguo and Huang, Yongming},
  journal={IEEE Access}, 
  title={Coarse-to-Fine Spatial-Temporal Relationship Inference for Temporal Sentence Grounding}, 
  year={2021},
  volume={9},
  number={},
  pages={97430-97443},
  abstract={Temporal sentence grounding aims to ground a query sentence into a specific segment of the video. Previous methods follow the common equally-spaced frame selection mechanism for appearance and motion modeling, which fails to consider redundant and distracting visual information. There is also no guarantee that all meaningful frames can be obtained. Moreover, this task needs to detect the location clues precisely from both spatial and temporal dimensions, but the relationship between spatial-temporal semantic information and query sentence is still unexplored in existing methods. Inspired by human thinking patterns, we propose a Coarse-to-Fine Spatial-Temporal Relationship Inference (CFSTRI) network to progressively localize fine-grained activity segments. Firstly, we present a coarse-grained crucial frame selection module, where the query-guided local difference context modeling from adjacent frames helps discriminate all the coarse boundary locations relevant to the sentence semantics, and the soft assignment vector of locally aggregated descriptors are employed to enhance the representation of selected frames. Then, we develop a fine-grained spatial-temporal relationship matching module to refine the coarse boundaries, which disentangles the spatial and temporal semantic information from query sentence to guide the excavation of visual grounding clues of corresponding dimensions. Furthermore, we devise a gated graph convolution network to incorporate the spatial-temporal semantic information by leveraging a gate operation to highlight frames referred to by the query sentence from spatial and temporal dimensions, and propagate fused information on the graph. Extensive experiments on two benchmark datasets demonstrate that our CFSTRI significantly outperforms most state-of-the-art methods.},
  keywords={Semantics;Grounding;Visualization;Task analysis;Logic gates;Proposals;Convolution;Temporal sentence grounding;coarse-grained crucial frame selection;fine-grained spatial-temporal relationship matching;gated graph convolution network},
  doi={10.1109/ACCESS.2021.3095229},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9718393,
  author={Adhikari, Janak and Mathrani, Anuradha and Scogings, Chris},
  booktitle={2021 IEEE Asia-Pacific Conference on Computer Science and Data Engineering (CSDE)}, 
  title={Analysis of technology-mediated pedagogies: Experiences from a BYOD initiative in New Zealand}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={A longitudinal study was conducted in a New Zealand secondary school to investigate the immediate and longer-term challenges and opportunities of a technology-supported learning initiative. A ‘bring your own device’ (BYOD) initiative called for a stronger connect with digital technology in formal educational settings in 2012. This was indeed much ahead of its time, as now evident from worldwide move towards digital education in the aftermath of the COVID-19 pandemic. In this study, we tracked transformations within learning and teaching for over five years. At the inception of the idea, there was much resistance from parents and other stakeholders; however, the BYOD initiative ultimately showcased a very successful example of technology-supported teaching and learning initiative for other New Zealand schools. Our investigation primarily focused on one of the critical indicators for the success of such an initiative, the digital divide. The digital divide is particularly important because of the level of attention and dialogue this BYOD topic gathered across New Zealand. Initial discourses (over newspapers, radio and television) suggested that this initiative would be damaging in view of existing digital divides across societies and the overall public opinion outweighed the potential positives from such an initiative. As part of our five-year study, we investigated some of the key concerns around the digital divide issue in the context of such a technology-supported learning initiative. One of the key enablers of this study was integration of two frameworks, to enable the cross-examination of relationships between various sources of social cognitive abilities related to an individual’s information literacy, motivational and behavioral aspects. That is, how skill development, knowledge acquisition, and changes in personal and behavioral aspects impact self-efficacy levels as a consequence of BYOD strategies. The resulting framework is especially relevant in post-COVID-19 times, since technology-driven remote education delivery formats are now being touted as the new norm. Our framework will therefore provide much value to policy-makers in establishing inclusive educational policies.},
  keywords={Resistance;TV;Tracking;Pandemics;Knowledge acquisition;Education;Data engineering;BYOD;digital divide;three-level digital divide framework;socio-cultural framework for mobile learning},
  doi={10.1109/CSDE53843.2021.9718393},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6900484,
  author={Biswas, Subhodip and Eita, Mohammad A. and Das, Swagatam and Vasilakos, Athanasios V.},
  booktitle={2014 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Evaluating the performance of Group Counseling Optimizer on CEC 2014 problems for Computational Expensive Optimization}, 
  year={2014},
  volume={},
  number={},
  pages={1076-1083},
  abstract={Group Counseling Optimizer (GCO) is a recently proposed population-based metaheuristics that simulates the ability of human beings to solve problems through counseling within a group. It is motivated by the fact that the human thinking ability is often predicted to be the most rational. This research article examines the performance of GCO on the benchmark test suite designed for the CEC 2014 Competition for Computational Expensive Optimization. Experimental results on 24 black-box optimization problems (8 test problems with 10, 20 and 30 dimensions) have been tabulated along with the algorithm complexity metrics. Additionally we investigate the parametric behavior of GCO based on these test instances.},
  keywords={Employee welfare;Vectors;Optimization;Sociology;Statistics;Linear programming;Problem-solving},
  doi={10.1109/CEC.2014.6900484},
  ISSN={1941-0026},
  month={July},}@INPROCEEDINGS{8769513,
  author={Almutairi, Mona M. and Alhamad, Nada and Alyami, Albandari and Alshobbar, Zainab and Alfayez, Heela and Al-Akkas, Noor and Alhiyafi, Jamal A. and Olatunji, Sunday O.},
  booktitle={2019 2nd International Conference on Computer Applications & Information Security (ICCAIS)}, 
  title={Preemptive Diagnosis of Schizophrenia Disease Using Computational Intelligence Techniques}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Schizophrenia is a severe chronic mental disorder, which affects the behavior, the perception and the thinking of the patient. The purpose of this research is to develop a predictive system to preemptively diagnose Schizophrenia Disease using computational intelligence-based techniques. The system will show the possibilities of getting the disease at an early stage, which will improve the health state of the patients. This will be done using machine learning techniques. The used dataset has 86 records, which was obtained from the Machine Learning for Signal Processing (MLSP) 2014 Schizophrenia Classification Kaggle Challenge. The used techniques in this paper are Support Vector Machine (SVM), Random Forest (RF), Artificial Neural Network (ANN), and Naive Bayesian (NB). The highest accuracy was 90.6977% reached by using SVM, RF, and NB techniques while ANN technique reached 88.3721% accuracy. The obtained accuracies are reached by using 204 features. Therefore, we conclude that using SVM, RF, and NB techniques are better in this particular problem.},
  keywords={Support vector machines;Radio frequency;Diseases;Computer science;Artificial neural networks;Information technology;Machine learning;Schizophrenia Disease;Diagnose;Machine Learning;Artificial Neural Network;Random Forest;Naive Bayesian;Support Vector Machine;Functional Network Connectivity;Source-Based Morphometry},
  doi={10.1109/CAIS.2019.8769513},
  ISSN={},
  month={May},}@INPROCEEDINGS{9659152,
  author={Li, Bin and He, Yuqing and Li, Wenfeng},
  booktitle={2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Neural-Physical Fusion Computation for Container Terminal Handling Systems by Computational Logistics and Deep Learning}, 
  year={2021},
  volume={},
  number={},
  pages={2828-2833},
  abstract={The emerging information technology and the rising computational thinking make it possible to establish new theoretical methods and engineering practices for planning, scheduling, control and decision-making of complex logistics systems. Consequently, the complex logistics systems oriented neural-physical fusion computation (CLSO-NPFC) is proposed initially to discuss and explore the decision issues of complex logistics systems at all the strategic, tactical and operational levels. By CLSO-NPFC, the container terminal oriented logistics generalized computing mechanization, automation and intelligence are constructed uniformly and tentatively, and the typical deep learning model neural computing architecture (DLM-NCA) in CLSO-NPFC is designed for the prediction of calling liner handling volume that is measured by container units rather than twenty-feet equivalent unit. A typical regional container terminal along the coast of China is selected to implement, execute and evaluate the DLM-NCA, and the DLM-NCA shows the agile, efficient and robust performance for forecasting with the low and stable computation consumption. It demonstrates the feasibility, credibility and practicality of the abstract principles, design paradigms and computing architecture in CLSO-NPFC preliminarily.},
  keywords={Deep learning;Solid modeling;Automation;Processor scheduling;Volume measurement;Computer architecture;Containers},
  doi={10.1109/SMC52423.2021.9659152},
  ISSN={2577-1655},
  month={Oct},}@INPROCEEDINGS{234877,
  author={Palmer, J. and Steele, G.L.},
  booktitle={[Proceedings 1992] The Fourth Symposium on the Frontiers of Massively Parallel Computation}, 
  title={Connection Machine model CM-5 system overview}, 
  year={1992},
  volume={},
  number={},
  pages={474-483},
  abstract={The Connection Machine model CM-5 provides high performance and ease of use for large data-intensive applications. The CM-5 architecture is designed to scale to teraflops performance on terabyte-sized problems. SPARC-based processing nodes, each with four vector pipes, are connected by two communications networks, the Data Network and the Control Network. The system combines the best features of SIMD (single-instruction multiple-data) and MIMD (multiple-instruction multiple-data) designs, integrating them into a single 'universal' parallel architecture. The processor nodes may be divided into independent computational partitions; each partition may be independently timeshared or devoted to batch processing. Programming languages include Fortran (with Fortran 90 array constructs) and C*, a parallel dialect of C. The PRISM programming environment supports source-level debugging, tracing, and profiling through a graphical interface based on X Windows.<>},
  keywords={Process control;Control systems;Bandwidth;Communication system control;Computer architecture;Weight control;Concurrent computing;Communication networks;Computer languages;Programming environments},
  doi={10.1109/FMPC.1992.234877},
  ISSN={},
  month={Oct},}@ARTICLE{8047430,
  author={Gaither, Kelly},
  journal={IEEE Computer Graphics and Applications}, 
  title={How Visualization Can Foster Diversity and Inclusion in Next-Generation Science}, 
  year={2017},
  volume={37},
  number={5},
  pages={106-112},
  abstract={Visualization researchers, developers, practitioners, and educators routinely work across traditional discipline boundaries, oftentimes in teams of people that come from a diverse blend of backgrounds, using visualizations as a common language for collaboration. There is a looming global workforce shortage in the computational science and high-tech space, primarily due to a disconnect between population demographics and the demographics of those educated to fill these jobs. The visualization community is uniquely positioned to bring a fresh approach to making diversity and inclusion fundamental tenets that are necessary rather than desirable.},
  keywords={Visualization;Computer graphics;Globalization;Employment;Research and development;computer graphics;visualization;global workforce;cross-disciplinary research;interdisciplinary skills},
  doi={10.1109/MCG.2017.3621230},
  ISSN={1558-1756},
  month={},}@INPROCEEDINGS{6402119,
  author={Hoji, Eduardo S. and Vianna, William B. and De A. Félix, Taísa},
  booktitle={2012 15th International Conference on Interactive Collaborative Learning (ICL)}, 
  title={A computer-aided math teaching approach for students in a technical institute: The experience with the Octave in the electro-mechanical technical course}, 
  year={2012},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper describes the experience to teach mathematics in the electro-mechanical technical course applying a computer-aided approach. Instead of give a bunch of equations and a calculator to the students, as it is usual in technical courses, we offer them the Octave, which is a numerical computational tool, and the mathematical concepts involved, in order to them find the solution of applied problems. Despite the deficiencies the students in technical courses have in their formation, we could notice that their vision regarding mathematics has changed after discover that there is more than calculators to help them finding the solution. The approach was initially applied with a group of 25 mature students, which passed by a flawed basic educational system and stayed away from school for a long time.},
  keywords={Educational institutions;Calculators;Software;Mathematical model;technical education;mathematics teaching;numerical computation;mature students},
  doi={10.1109/ICL.2012.6402119},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8947750,
  author={Horner, Jack K.},
  booktitle={2018 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={A Mathematica-Based Automated Deduction of the Marsden-Herman Theorem in Quantum Logic}, 
  year={2018},
  volume={},
  number={},
  pages={1199-1203},
  abstract={We can think of the set of propositions describing the outcome of measurements of physical systems as a set of propositions of the form “Measurand X had (didn't have) value V at time t”. In classical physics, this system of propositions has a Boolean logic (BL). In quantum mechanics, this system is isomorphic to the algebra, C(H), of closed linear subspaces of (equivalently, the system of linear operators on (observables in)) in a Hilbert space and is isomorphic to an ortholattice (OL). A consequence of the existence of non-commuting observables in quantum mechanics is that QL does not satisfy the BL distribution law. Quantum logicians have thus paid much attention to "quasi"- distributive theorems, one of the better known of which is the Marsden-Herman theorem (MHT). Informally, the MHT states that if there is a four-element cyclic chain of commuting elements in an orthomodular lattice, the distributive law holds for those elements. Here I provide a Mathematica-based automated deduction of the MHT.},
  keywords={Lattices;Quantum mechanics;Algebra;Hilbert space;Finite element analysis;Presses;Time measurement;automated deduction;quantum logic;orthomodular lattice;Hilbert space},
  doi={10.1109/CSCI46756.2018.00230},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9668455,
  author={Mason, A. and Esper, I. and Korostynska, O. and Haiddegger, T. and Popov, A. and Christensen, L. B. and Alvseike, O.},
  booktitle={2021 IEEE 21st International Symposium on Computational Intelligence and Informatics (CINTI)}, 
  title={The Meat Factory Cell: A new way of thinking for meat producers}, 
  year={2021},
  volume={},
  number={},
  pages={000091-000096},
  abstract={This paper presents the novel Meat Factory Cell (MFC) concept which is being developed in both semi- and fully-automated forms. The MFC provides several important opportunities for the red meat sector, including enhanced robustness, scalability and flexibility. Moreover, it is mindful of the need for small-medium meat processors requiring access to automation, which has proven uneconomical until now. The industry has renewed interest in such automation initiatives, particularly considering its need to improve resilience in the face of future global pandemics. The paper describes the progress of the MFC, as well as a rudimentary framework for realising the implementation. Finally, the paper discusses some of the major hurdles faced in the future.},
  keywords={Technological innovation;Automation;Program processors;Scalability;Robustness;Production facilities;Safety;automation;meat;pork;robotics;butchering},
  doi={10.1109/CINTI53070.2021.9668455},
  ISSN={2471-9269},
  month={Nov},}@INPROCEEDINGS{6417279,
  author={Khouri, Selma and Bellatreche, Ladjel and Boukhari, Ilyes and Bouarar, Selma},
  booktitle={2012 IEEE 15th International Conference on Computational Science and Engineering}, 
  title={More Investment in Conceptual Designers: Think about it!}, 
  year={2012},
  volume={},
  number={},
  pages={88-93},
  abstract={Developing database (DB) and data warehouse (DW) applications passes through three main modeling phases imposed by the ANSI/SPARC architecture: conceptual, logical and physical. This architecture creates two different actors: (i) conceptual designers and Database Administrators (DBA). The first actor collects user requirements, chooses the relevant diagrams for designing the conceptual model (or the logical model). The DBA ensures the performance, the maintenance and the tuning of the final application. Most of the tasks performed by these two actors are complex and time consuming for a majority of companies. Recently, some academic and industry research efforts are moving towards truly zero-administration of DW by proposing tools (advisors) substituting some tasks of DBA. One of the functionalities of these tools is to propose recommendations in choosing optimization structures such as indexing, materialized views, etc. They do not guarantee robust solutions. In this paper, we propose a revolutionary economical model for DB /DW application. Instead of substituting the DBA by advisors, we propose to delegate some DBA tasks to conceptual designers like selecting optimization structures. First, we propose to connect user requirements to the conceptual model of the target application. Secondly, based on the analysis of requirements, SQL queries are identified and then used to select optimization structures. Finally, a feasibility of our approach is tested through the selection of bitmap join indexes based on user requirements.},
  keywords={Optimization;Indexes;Unified modeling language;Data models;Benchmark testing;Amplitude modulation;Requirements Engineering;ANSI/SPARC Ar-chitecture;Designer;Administrator;Data Warehouse;Optimization;Experiments},
  doi={10.1109/ICCSE.2012.22},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{5952118,
  author={Levine, Daniel S.},
  booktitle={2011 IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain (CCMB)}, 
  title={Modeling decisions by brains that think, feel, and vegetate}, 
  year={2011},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper summarizes three interrelated neural network models of data on emotionally influenced decision making: the first on a gambling task, the second on probability judgment, and the third on probability weighting. The networks incorporate data on executive regions of the brain and organizing principles such as adaptive resonance and fuzzy traces that have been utilized to model other cognitive data.},
  keywords={Encoding;Brain models;Data models;Steady-state;Basal ganglia;Neurons},
  doi={10.1109/CCMB.2011.5952118},
  ISSN={},
  month={April},}@INPROCEEDINGS{8253363,
  author={Ahmad, Adang Suwandi},
  booktitle={2017 International Symposium on Electronics and Smart Devices (ISESD)}, 
  title={Brain inspired cognitive artificial intelligence for knowledge extraction and intelligent instrumentation system}, 
  year={2017},
  volume={},
  number={},
  pages={352-356},
  abstract={Artificial intelligence evolves with the development of computers even rely on computational development. The ways and processes of human thinking developed by Psychologists and welcomed by computational experts produce the science of Artificial Intelligence. This continues with the development of cognitive science that encourages the development of Artificial Intelligence to Cognitive Thinking Intelligence, a new pathway to the science of Artificial Intelligence that can emulate human cognitive abilities even if not 100%. Emulation of human cognitive abilities is developed based on the modeling of system interaction with the environment and information fusion, which can be used to conduct Inferencing, so when this occurs repeatedly it will produce knowledge that grows. This process is called Knowledge Growing System which is Brain Inspired Cognitive Artificial Intelligence and can be used for information extraction and when applied to instrumentation system will realize Intelligent Instrumentation System.},
  keywords={Artificial intelligence;Heart;Data mining;Software;Instruments;Electrocardiography;Smart devices;Artificial Intelligence;Cognitive Artificial Intelligece;Knowledge Extraction},
  doi={10.1109/ISESD.2017.8253363},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8511891,
  author={Li, Yue and Pan, Yiqing and Liu, Wensheng and Zhang, Xingming},
  booktitle={2018 IEEE 16th Intl Conf on Dependable, Autonomic and Secure Computing, 16th Intl Conf on Pervasive Intelligence and Computing, 4th Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)}, 
  title={An Automated Evaluation System for App Inventor Apps}, 
  year={2018},
  volume={},
  number={},
  pages={230-235},
  abstract={More and more K-12 schools are paying attention to the training of Computational Thinking. A considerable amount of K-12 use blocked-based visual programming platforms such as Scratch, App Inventor, Alice and etc. MIT App Inventor is one of the more popular mobile application visualization programming platforms. Visual programming is based on the 'You see what you get' doctrine. Its simplicity and ease of use coheres with K-12 teaching principles and allows students to access to computational thinking without the burden of learning Coding grammar. Recently App Inventor is gaining momentum and traction in China at a very high speed and is expected to grow even faster in the future. Teachers using App Inventor for teaching face the problem of having to go through a very high number of App Inventor apps without any way to catalogue them. The 2017 Google App Inventor Competition alone received over 1300 entries. This article aims to devise an automated scoring method based on TF-IDF and clustering to help teachers evaluate App Inventor apps, thus greatly reducing their workload. Evaluating the method gives us an 75.42% with space for further improvement in the future.},
  keywords={Clustering algorithms;Programming;Visualization;Mobile applications;Creativity;Education;App Inventor;automated evaluation system},
  doi={10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00048},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8985981,
  author={Lee, Sarah and Ivy, Jessica and Stamps, Andrew},
  booktitle={2019 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT)}, 
  title={Providing Equitable Access to Computing Education in Mississippi}, 
  year={2019},
  volume={},
  number={},
  pages={1-4},
  abstract={To maintain competitiveness as a nation, the United States must broaden participation in computing education and career pathways. Integrating computational thinking and computer science in K-12 classrooms is becoming increasingly essential to the development of a responsible and innovative workforce. Further, with increased recognition of the need for computing competency, workforce development programs that target the emerging workforce that may not be on a college pathway and those citizens who want to retool for the digital economy are also essential. This study examines work by researchers and practitioners in Mississippi to engage all public school students and the workforce with computational thinking, computer science concepts, and cybersecurity, providing pathways for learning that make computing education accessible for all citizens. The state of Mississippi has the lowest median wage in the nation, and one of the lowest rates of STEM employment. With half of the public school children identified as African American, and half of them female, there is much opportunity for broadening participation in computing. Assessments from a K-12 teacher professional development programs will be discussed, in addition to outcomes from one year of a workforce development program.},
  keywords={computer science;K-12;workforce development},
  doi={10.1109/RESPECT46404.2019.8985981},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9570851,
  author={Su, Karen and Bonnet, Evgeniia and Mondada, Francesco},
  booktitle={2021 IEEE AFRICON}, 
  title={Developing STEM and Team-working Skills Through Collaborative Space Robotics Missions}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Building on the success of the first North-South cross-continental collaborative educational robotics mission held in November 2015 [1], this paper presents a practical model for scaling the event up into a program for developing countries, particularly those of Africa, where the first edition took place. Past participants in Remote Rescue Thymio II (R2T2) missions, students and educators alike, have shared qualitative observations about its positive educational impact, notably in the areas of Collaboration, Communication, Critical thinking, Creative problem solving, Computational thinking, and Cross-cultural exchange. The proposed framework for delivering R2T2 missions has been adapted to Africa, being specifically designed to tackle the critical challenges of internet connectivity, teacher training and program costs. In so doing, it strives to pave the way for collaboration with partners in African educational ecosystems and North-South funding bodies that share the vision of making collaborative STEM education more accessible and attractive to teachers and schoolchildren around the world.},
  keywords={Training;Computational modeling;Space missions;Ecosystems;Collaboration;Africa;Tools;educational robotics;telerobotics;space robotics;Thymio robot;STEM education;21st century skills;North-South collaboration;local education networks},
  doi={10.1109/AFRICON51333.2021.9570851},
  ISSN={2153-0033},
  month={Sep.},}@INPROCEEDINGS{1419802,
  author={Miyake, Y.},
  booktitle={Third International Conference on Creating, Connecting and Collaborating through Computing (C5'05)}, 
  title={Co-creation system and human-computer interaction}, 
  year={2005},
  volume={},
  number={},
  pages={169-172},
  abstract={The purpose of this research is to realize a "co-creation system". Co-creation means co-emergence of real-time coordination by sharing subjective space and time between different persons. Human communication with emergent reality like this is essential to improve communicability in social systems, and we assume such communication needs two kinds of information process at the same time. One is explicit communication such as the transmission of messages and the other is implicit embodied interaction such as the sympathy and direct experience. The conventional IT system mainly covers the former process but we have been pointing out the importance of the latter process. Especially, this implicit process is related with rhythmic interaction between humans, such as entrainment of body motion. From this background, using these implicit and explicit processing complementarily, we are developing co-creative man-machine interfaces and communication media. We think this dual-processing based new technology will be effective for recovering human linkage and mutual-reliability that has been weakened in modern IT society.},
  keywords={Humans;Artificial intelligence;Competitive intelligence;Real time systems;Computational intelligence;Space technology;Couplings;Machine intelligence;Application software;Joining processes},
  doi={10.1109/C5.2005.8},
  ISSN={1556-0090},
  month={Jan},}@INPROCEEDINGS{5211102,
  author={Du, Cai-Feng},
  booktitle={2009 WASE International Conference on Information Engineering}, 
  title={High Clustering Coefficient of Computer Networks}, 
  year={2009},
  volume={1},
  number={},
  pages={371-374},
  abstract={Due to the rapid development of network technology, the structure of computer network is increasingly complicated.The traditional random network model is difficult to characterize the topology of current computer network.Complex network theory provides new view and thinking to study in this field. In this paper, we give a probabilistic model to examine the evolution of computer networks by random duplication processes of node degree as well as the preferential choice mechanisms. The model is solved exactly for large network. We demonstrate that both the degree distribution and the triangle distribution have stationary properties. When the size of the network tends to infinity,the degree distribution behaves as P(k) prop k-3 and the average clustering coefficient C is independent of the network size N.},
  keywords={Computer networks;Complex networks;H infinity control;Predictive models;Educational institutions;Mathematics;Petroleum;Network topology;Numerical simulation;Computational modeling},
  doi={10.1109/ICIE.2009.276},
  ISSN={},
  month={July},}@INPROCEEDINGS{10544496,
  author={Venkateshwarlu, M. and Javeed, Sk. and Shreya, S. and Muthukumaran, N. and Vilas, B. Pranay},
  booktitle={2024 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Handwritten Paragraph Text Recognition using OCR}, 
  year={2024},
  volume={},
  number={},
  pages={1243-1246},
  abstract={The recognition of unlimited signatures is an ongoing challenge for computer vision systems. Traditionally, in paragraph text recognition, two separate models are used for character splitting and text character recognition. In this regard, this study proposes an integrated end-to-end framework and a new hybrid thinking approach to address the existing challenge. The prototype is specifically intended to handle a splitting picture per align iteratively, with three different modules. Initially, the encoder creates maps of features derived from the whole passage picture. Then, a concept module produces typically a mask with weights, which enables focused analysis of current text line features, especially implicit line splitting Finally, the decoder module is used for performing spectrum detection in each text line feature, ending with comprehensive detection of the entire paragraph offers a new solution.},
  keywords={Computer vision;Text recognition;Computational modeling;Optical character recognition;Prototypes;Feature extraction;Decoding;Implicit line splitting;Attention Module;Encoder;Decoder Module},
  doi={10.1109/ICICT60155.2024.10544496},
  ISSN={2767-7788},
  month={April},}@ARTICLE{10320320,
  author={Maulidevi, Nur Ulfa and Aji, Byan Sakura Kireyna and Hikmawati, Erna and Surendro, Kridanto},
  journal={IEEE Access}, 
  title={Modeling Integrated Sustainability Monitoring System for Carbon Footprint in Higher Education Buildings}, 
  year={2023},
  volume={11},
  number={},
  pages={135365-135376},
  abstract={Recent research has shed light on integrating cutting-edge technologies in various organisations to support daily operations in the digital age. However, this implementation has resulted in undesirable consequences, notably contributing to global warming and climate change, primarily due to unchecked carbon emissions. Higher Educational Institutions are expected to lead by example in reducing global carbon emissions. Despite some institutions’ efforts in this regard, multiple studies suggest that progress could be expedited through digital technology, leaving room for improvement. Numerous Higher Educational Institutions still need sustainable practices within their building infrastructure. Hence, this research project was developed to create an intelligent model for monitoring the carbon footprint of buildings within Higher Educational Institutions. The study focused on the Bandung Institute of Technology facilities, which encountered similar challenges stemming from various aspects contributing to the overall carbon footprint. This research effectively managed energy consumption by implementing design thinking, encompassing electricity and water usage, and reducing emissions. Furthermore, the application of this model provided valuable insights into both current and projected energy consumption and emission production. It also assessed the sustainability status of these buildings and enhanced the efficiency of information dissemination in energy reporting processes. This, in turn, facilitated the implementation of proactive measures for emission management not only at the Bandung Institute of Technology but also in other Higher Educational Institution buildings sharing similar characteristics.},
  keywords={Carbon footprint;Climate change;Lifetime estimation;Product lifecycle management;Energy management;Design engineering;Predictive models;Education;Buildings;Sustainable development;Building materials;Construction industry;Carbon footprint;life cycle assessment;energy management;monitoring systems;prediction model;design thinking},
  doi={10.1109/ACCESS.2023.3333890},
  ISSN={2169-3536},
  month={},}@ARTICLE{9917300,
  author={García-Zamora, Diego and Labella, Álvaro and Rodríguez, Rosa M. and Martínez, Luis},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={A Linguistic Metric for Consensus Reaching Processes Based on ELICIT Comprehensive Minimum Cost Consensus Models}, 
  year={2023},
  volume={31},
  number={5},
  pages={1676-1688},
  abstract={Linguistic group decision making (LiGDM) aims at solving decision situations involving human decision makers (DMs) whose opinions are modeled by using linguistic information. To achieve agreed solutions that increase DMs' satisfaction toward the collective solution, linguistic consensus reaching processes (LiCRPs) have been developed. These LiCRPs aim at suggesting DMs to change their original opinions to increase the group consensus degree, computed by a certain consensus measure. In recent years, these LiCRPs have been a prolific research line, and consequently, numerous proposals have been introduced in the specialized literature. However, we have pointed out the nonexistence of objective metrics to compare these models and decide which one presents the best performance for each LiGDM problem. Therefore, this article aims at introducing a metric to evaluate the performance of LiCRPs that takes into account the resulting consensus degree and the cost of modifying DMs' initial opinions. Such a metric is based on a linguistic comprehensive minimum cost consensus (CMCC) model based on Extended Comparative Linguistic Expressions with Symbolic Translation information that models DMs' hesitancy and provides accurate Computing with Words processes. In addition, the linguistic CMCC optimization model is linearized to speed up the computational model and improve its accuracy.},
  keywords={Linguistics;Computational modeling;Proposals;Measurement;Numerical models;Costs;Analytical models;Computing with Words (CW);extended comparative linguistic expressions with symbolic translation (ELICIT) information;fuzzy linguistic approach;linguistic cost metric;minimum cost consensus},
  doi={10.1109/TFUZZ.2022.3213943},
  ISSN={1941-0034},
  month={May},}@INPROCEEDINGS{9832076,
  author={Zhu, Ping and Lv, Pohua and Shi, Jin and Jiang, Xuetao and Zou, Weiming and Ma, Yirong},
  booktitle={2022 IEEE 2nd International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={Semantic Inheritance and Overloading}, 
  year={2022},
  volume={},
  number={},
  pages={01-09},
  abstract={Humanoid reasoning and computing are the crucial research objectives of computing thinking, so semantic understanding and explicit representation are the basis steps for computing thinking. However, at present, there is no mature and systematic theory and engineering technology to fully describe massive multi-dimensional semantic expressions of natural language. Then the semantic inheritance and overloading theory was proposed to describe the semantic superposition and synthesis processing of the input vocabularies in this paper. Taking the clause as the basic semantic unit, the semantics were integrated by the local semantics of the clause itself and the global semantics of the cross clauses. The semantic frameworks were represented by the core vocabulary sequence of the clause, and the unified semantic representation grammar of the semantic frameworks to explicitly describe the local semantics and global semantics was studied; From the perspective of big data engineering, according to the unified grammar, the semantic annotation was chose as the initial step, the semantic scene based on the pattern matching of semantic frameworks was divided, the implementation technologies of semantic inheritance and overloading theory between scenes on the base of the observed language representation phenomenon were put forward, and the core algorithms of machine humanoid resolving primary mathematics application problems were realized, the effectiveness of semantic inheritance and overloading theory was preliminarily verified. The advantage was that the implementation could make full use of the power of the cloud computing to do semantic annotation and semantic framework pattern matching in parallel, and explore the engineering way to achieve natural language semantic understanding and computing thinking.},
  keywords={Vocabulary;Systematics;Annotations;Semantics;Natural languages;Humanoid robots;Grammar;computing thinking;semantic understanding;semantic inheritance;semantic overloading;humanoid resolving},
  doi={10.1109/SEAI55746.2022.9832076},
  ISSN={},
  month={June},}@INPROCEEDINGS{8247835,
  author={Balci, Osman and Fujimoto, Richard M. and Goldsman, David and Nance, Richard E. and Zeigler, Bernard P.},
  booktitle={2017 Winter Simulation Conference (WSC)}, 
  title={The state of innovation in modeling and simulation: The last 50 years}, 
  year={2017},
  volume={},
  number={},
  pages={821-836},
  abstract={Innovation in Modeling and Simulation (M&S) refers to exploiting new ideas, exploiting new technology, and employing out-of-the-box thinking, which lead to the creation of new methodologies, techniques, concepts, frameworks, and software. This paper addresses the following questions: (a) what was the state of the art in M&S 50 years ago, what is it today, how much progress has been made? (b) how much innovation in M&S has been accomplished over the last half a century? (c) what were the obstacles to innovation in M&S? (d) what are some recommendations to promote innovation in M&S? (e) what message should be sent to the funding agencies to encourage innovation in M&S?},
  keywords={Handheld computers;Data models;Computational modeling;Computer simulation;Cloud computing;Conferences;Technological innovation},
  doi={10.1109/WSC.2017.8247835},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{7509810,
  author={Chen, Jinhua and Jiang, Qin and Wang, Yuxin and Tang, Jing},
  booktitle={2016 IEEE International Conference on Big Data Analysis (ICBDA)}, 
  title={Study of data analysis model based on big data technology}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={The traditional data analysis are based on the cause and effect relationship, formed a sample microscopic analysis, qualitative and quantitative analysis, the thinking mode of trend extrapolation analysis. Big data has a fundamental impact on the traditional data analysis. Big data analysis based on correlation, formed global macro analysis, data and technical analysis, correlation analysis and new thinking mode of correlation analysis. Namely, from causal analysis to correlation analysis and knowledge discovery, from model fitting to data mining, from logical reasoning to association rules. Data analysis in the era of big data have taken great changes, Namely, Big data analysis, from the analysis of objects, the mode of data processing, analytical methods and tools, analytical thinking.},
  keywords={Data analysis;Big data;Statistical analysis;Data models;Correlation;Analytical models;Computational modeling;big data;data analysis;qualitative and quantitative analysis},
  doi={10.1109/ICBDA.2016.7509810},
  ISSN={},
  month={March},}@INPROCEEDINGS{5522827,
  author={Chakradhar, Srimat T. and Raghunathan, Anand},
  booktitle={Design Automation Conference}, 
  title={Best-effort computing: Re-thinking parallel software and hardware}, 
  year={2010},
  volume={},
  number={},
  pages={865-870},
  abstract={With the advent of mainstream parallel computing, applications can obtain better performance only by scaling to platforms with larger numbers of cores. This is widely considered to be a very challenging problem due to the difficulty of parallel programming and the bottlenecks to efficient parallel execution. Inspired by how networking and storage systems have scaled to handle very large volumes of packet traffic and persistent data, we propose a new approach to the design of scalable, parallel computing platforms. For decades, computing platforms have gone to great lengths to ensure that every computation specified by applications is faithfully executed. While this design philosophy has remained largely unchanged, applications and the basic characteristics of their workloads have changed considerably. A wide range of existing and emerging computing workloads have an inherent forgiving nature. We therefore argue that adopting a best-effort service model for various software and hardware components of the computing platform stack can lead to drastic improvements in scalability. Applications are cognizant of the best-effort model, and separate their computations into those that may be executed on a best-effort basis and those that require the traditional execution guarantees. Best-effort computations may be exploited to simply reduce the computing workload, shape it to be more suitable for parallel execution, or execute it on unreliable hardware components. Guaranteed computations are realized either through an overlay software layer on top of the best-effort substrate, or through the use of application-specific strategies. We describe a system architecture for a best-effort computing platform, provide examples of parallel software and hardware that embody the best-effort model, and show that large improvements in performance and energy efficiency are possible through the adoption of this approach.},
  keywords={Concurrent computing;Hardware;Application software;Parallel processing;Parallel programming;Telecommunication traffic;Computer applications;Scalability;Shape;Computer architecture;Best effort systems;parallel computing;multi core;performance;scalability},
  doi={10.1145/1837274.1837492},
  ISSN={0738-100X},
  month={June},}@INPROCEEDINGS{4736743,
  author={Demchenko, Yuri and de Laat, Cees and Koeroo, Oscar and Groep, David},
  booktitle={2008 IEEE Fourth International Conference on eScience}, 
  title={Re-thinking Grid Security Architecture}, 
  year={2008},
  volume={},
  number={},
  pages={79-86},
  abstract={The security models used in Grid systems today strongly bear the marks of their diverse origin. Historically retrofitted to the distributed systems they are designed to protect and control, the security model is usually limited in scope and applicability, and its implementation tailored towards a few specific deployment scenarios. A common approach towards even the "basic" elements such as authentication to resources is only now emerging, whereas for more complex issues such as community organization, integration of site access control with operating systems, cross-domain resource provisioning, or overlay community Grids ("late authentication" for pilot job frameworks or community-based virtual machines) there is no single coherent and consistent "security" view. Via this paper we aim to share some observations on current security models and solutions found in Grid architectures and deployments today and identify architectural limitations in solving complex access control and policy enforcement scenarios in distributed resource management. The paper provides a short overview of the OGSA security services and other security solutions used in Grid middleware and operations practice. However, it is becoming clear that further development in Grid requires a fresh look at the concepts, both operationally and security-wise. This paper analyses the security aspects of different types of Grids and a set of use cases that may require extended security functionality, such as dynamic security context management, and management of stateful services. Recent developments in open systems security, and revisiting basic security concepts in networking and computing including the OSI security architecture and the concepts used in the trusted computing base provide interesting examples on how some of the conceptual security problems in Grid can be addressed, and on how the shortcomings of current systems and the frequently proposed "ad-hoc" stop-gaps for what are in fact complex security manageability problems may be avoided. This paper is thus intended to initiate and stimulate the wider discussion on the concepts of Grid security, thereby setting the scene for and providing input to a Grid security taxonomy leading to a more consistent Grid security architecture.},
  keywords={Security;Authentication;Access control;Open systems;Computer networks;Grid computing;Protection;Operating systems;Virtual machining;Resource management;Grids;Open Grid Security Architecture;Trusted Computing Base;Reference Monitor;Security models;Security Context;Authentication;Authorisation session},
  doi={10.1109/eScience.2008.53},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{5981083,
  author={Yang, Chaowei},
  booktitle={2011 19th International Conference on Geoinformatics}, 
  title={Thinking and computing spatiotemporally to enable cloud computing and science discoveries}, 
  year={2011},
  volume={},
  number={},
  pages={1-6},
  abstract={We live in space time dimensions and all physical and social sciences are based on the dimensions. The representation and digitization of scientific phenomena into data and computation of the digitized data greatly depends on the spatiotemporal principles that govern the relationships of phenomena. The latest advancement of cloud computing is not an exception. Conducting cloud computing in a spatiotemporal fashion will help use spatiotemporal principles, which exist in all physical and social sciences, to optimize cloud computing and science discoveries. This paper 1) introduces the latest advancement of distributed computing; 2) analyzes the impact cloud computing has on GIS science, application, and education; 3) illustrates how spatiotemporal principles exist and can be utilized to enable cloud computing and science discoveries; and 4) discusses research directions and agenda for GIScience professionals in the 21st centuries.},
  keywords={Cloud computing;Spatiotemporal phenomena;Earth;Education;Humans;GIS;Geodynamics;CyberGIS Spatial Computing;Geospatial Cyberinfrastructure},
  doi={10.1109/GeoInformatics.2011.5981083},
  ISSN={2161-0258},
  month={June},}@INBOOK{9986161,
  author={Lee, Clifford and Soep, Elisabeth and Kyles, Kyra and Emdin, Christopher},
  booktitle={Code for What?: Computer Science for Storytelling and Social Justice}, 
  title={2 A Framework: Critical Computational Expression}, 
  year={2022},
  volume={},
  number={},
  pages={37-52},
  abstract={To gain clarity on how we think about our world, first we have to understand how our experiences and underlying ideologies shape the way we see it. In academic discourse, conceptual frameworks provide us with the language and a lens to understand our research. They supply mental maps or visual organizers for ideas. And they orient our present and future selves: how to think, what to say, how to act, and how to make sense of whatever we encounter.},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262371841},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9986161},}@INPROCEEDINGS{9039963,
  author={Geselowitz, Michael},
  booktitle={2019 6th IEEE History of Electrotechnology Conference (HISTELCON)}, 
  title={Tinkerers Ever to Chance: Engineers, Computers, and the Rise of Probablistic Thinking}, 
  year={2019},
  volume={},
  number={},
  pages={52-60},
  abstract={Historians of scientific thought and philosophy have emphasized during the Enlightenment a shift from chance-based medieval thought to probability-based modern thought. They have not, however, focused on the technology that makes the implementation of such thought possible. At the same time, historians of computing have emphasized the rise of mechanical calculators—predecessors of modern computers—in this same period, but only in reference to solving practical problems arising from increasingly complex societies. This paper will draw on the two different streams of historical thought to show how the rise of probability and statistics and the rise of mechanical calculating devices were inextricably linked in complex ways.},
  keywords={Computers;Probability;Meteorology;Probabilistic logic;Computer crime;History;history;computing;probability},
  doi={10.1109/HISTELCON47851.2019.9039963},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10341425,
  author={Ivolga, Dmitriy V. and Borisov, Ivan I. and Nasonov, Kirill V. and Kolyubin, Sergey A.},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Computational Design of Closed-Chain Linkages: Respawn Algorithm for Generative Design}, 
  year={2023},
  volume={},
  number={},
  pages={481-486},
  abstract={Designing robots is a multiphase process aimed at solving a multi-criteria optimization problem to find the best possible detailed design. Generative design (GD) aims to accelerate the design process compared to manual design, since GD allows exploring and exploiting the vast design space more efficiently. In the field of robotics, however, relevant research focuses mostly on the generation of fully-actuated open chain kinematics, which is trivial in mechanical engineering perspective. Within this paper, we address the problem of generative design of closed-chain linkage mechanisms. A GD algorithm has to be able to generate meaningful mechanisms which satisfy conditions of existence. We propose an optimization-driven algorithm for generation of planar closed-chain linkages to follow a predefined trajectory. The algorithm creates an unlimited range of physically reproducible design alternatives that can be further tested in simulation. These tests could be done in order to find solutions that satisfy extra criteria, e.g., desired dynamic behavior or low energy consumption. The proposed algorithm is called “respawn” since it builds a new linkage after the ancestor has been tested in a virtual environment in pursuit for the optimal solution. To show that the algorithm is general enough, we show a set of generated linkages that can be used for a wide class of robots.},
  keywords={Couplings;Heuristic algorithms;Software algorithms;Virtual environments;Transforms;Software;Trajectory},
  doi={10.1109/IROS55552.2023.10341425},
  ISSN={2153-0866},
  month={Oct},}@INPROCEEDINGS{4127430,
  author={Majumder, D. Dutta and Ulrichs, Christian and Majumder, Debosmita and Mewis, Inga and Thakur, Ashoke Ranjan and Brahmachary, R.L. and Banerjee, Rajat and Rahman, Ayesha and Debnath, Nitai and Seth, Dipankar and Das, Sumistha and Roy, Indrani and Ghosh, Amrita and Sagar, Prity and Schulz, Carsten and Linh, Nguyen Quang and Goswami, Arunava},
  booktitle={2007 International Conference on Computing: Theory and Applications (ICCTA'07)}, 
  title={Current Status and Future Trends of Nanoscale Technology and Its Impact on Modern Computing, Biology, Medicine and Agricultural Biotechnology}, 
  year={2007},
  volume={},
  number={},
  pages={563-573},
  abstract={Nanoscale technologies have gone from being just an ambitious concept to being a rapidly advancing area of interdisciplinary science with immense practical importance. Feynman's vision on nanoscience provided great impetus to the development of nanophysics, nanochemistry, nanoelectronics and nanotechnology in general. High resolution microscopic devices such as scanning tunneling microscope, transmission electron microscope and atomic force microscope etc. in mid 1980s allowed researchers to see individual atoms on surfaces and arrange them. The authors (nanobiologists, computer scientists, biotechnologists and material scientists) attempt to provide a review of the state of the art in the field of nanoscale technologies and its impact on various fields of research like computation, basic biology, medicine and agricultural biotechnology. Imprints of memory mechanisms in living systems operating at different levels (e.g. biochemical, immunological and neuronal) have provided inputs to design and fabricate 'bio-inspired' nanoelectronic devices suitable for various applications. Several examples of such nanoscale technology based frameworks and devices are presented in the scenario of their potential role in the development of future nanoscale technologies. Nanoscale technologies might finally revolutionize computational intelligence and thinking. The power and limits of computing processes govern the intelligence, knowledge acquisition and thinking process of human and machine. Present computational methods and models provide us courage to study the problem, but these tools are not yet sufficient to answer the following riddles of machine intelligence - what can computers do better than humans? What can humans do better than computers? And the most important one - what is computable? The authors try to present evidences that show bio-inspired nanoscale technologies might gain the power in helping us to go deeper into these challenges of research in future},
  keywords={Biology computing;Nanobioscience;Biotechnology;Atomic force microscopy;Scanning electron microscopy;Transmission electron microscopy;Humans;Nanoelectronics;Nanoscale devices;Computational intelligence;Agriculture;Alzheimer's disease;biotechnology;cancer;computational biology;consciousness;cybernetics;genomics;HIV;hydrophobic nanosilica;lipophilic nanosilica;machine learning;malaria;metabolomics;Nanoscience;nanosilica;neuronal network;pervasive computing;quantum mechanics;reversible computing.},
  doi={10.1109/ICCTA.2007.46},
  ISSN={},
  month={March},}@INPROCEEDINGS{9071173,
  author={Inoue, Hiroaki and Hori, Masaya and Yu, Kikuti and Maeda, Mayu and Kobayashi, Yusuke and Kiryu, Takuya and Tsubota, Toshiya and Shimizu, Shunji},
  booktitle={2019 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Basic Study on Measuring Brain Activity during Exercise for Evaluation of Welfare Device}, 
  year={2019},
  volume={},
  number={},
  pages={1007-1011},
  abstract={Recently, Japan (also world-wide countries) has become aged society, and a wide variety welfare device and system have been developed. But evaluation of welfare system and device are limited only stability, intensity and partial operability. Thus, evaluation of usefulness is insufficient. Evaluation of usefulness is necessity to consider about interaction of human and welfare device. In this paper, we measure load of sitting and standing movement to use EMG (Electromyogram) and 3D Motion Capture and set a goal to establish objective evaluation method. We think that establishing objective evaluation method is necessity to develop useful welfare device. We examined possibility of assessing load and fatigue from measuring brain activity to use NIRS (Near Infra-Red Spectroscopy). We think that measuring load and fatigue is very important for developing user-friendly welfare device. Idea of universal design is widespread in welfare device and system. Measuring require verification of all generations. However, we performed to measure younger subjects as a first step. We think that younger subjects were observed the significant difference, because they had enough physical function. Considering younger subjects as a benchmark is appropriate for creating evaluation method.},
  keywords={Brain;Electromyography;Fatigue;Motion measurement;Psychology;Physiology;Brain activity;Near Infra-Red Spectroscopy},
  doi={10.1109/CSCI49370.2019.00192},
  ISSN={},
  month={Dec},}
