@INPROCEEDINGS{8969049,
  author={Hitesh, MSR and Vaibhav, Vedhosi and Kalki, Y.J Abhishek and Kamtam, Suraj Harsha and Kumari, Santoshi},
  booktitle={2019 2nd International Conference on Intelligent Communication and Computational Techniques (ICCT)}, 
  title={Real-Time Sentiment Analysis of 2019 Election Tweets using Word2vec and Random Forest Model}, 
  year={2019},
  volume={},
  number={},
  pages={146-151},
  abstract={Sentiment analysis of social media data consists of attitudes, assessments, and emotions which can be considered a way human think. Understanding and classifying the large collection of documents into positive and negative aspects are a very difficult task. Social networks such as Twitter, Facebook, and Instagram provide a platform in order to gather information about people's sentiments and opinions. Considering the fact that people spend hours daily on social media and share their opinion on various different topics helps us analyze sentiments better. More and more companies are using social media tools to provide various services and interact with customers. Sentiment Analysis (SA) classifies the polarity of given tweets to positive and negative tweets in order to understand the sentiments of the public. This paper aims to perform sentiment analysis of real-time 2019 election twitter data using the feature selection model word2vec and the machine learning algorithm random forest for sentiment classification. Word2vec with Random Forest improves the accuracy of sentiment analysis significantly compared to traditional methods such as BOW and TF-IDF. Word2vec improves the quality of features by considering contextual semantics of words in a text hence improving the accuracy of machine learning and sentiment analysis.},
  keywords={Sentiment Analysis;Word2Vec;Random Forest;Twitter data analysis;TF-IDF;BOW},
  doi={10.1109/ICCT46177.2019.8969049},
  ISSN={},
  month={Sep.},}@ARTICLE{9547207,
  author={Vyas, Jayant and Das, Debasis and Chaudhury, Santanu},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={DriveBFR: Driver Behavior and Fuel-Efficiency-Based Recommendation System}, 
  year={2022},
  volume={9},
  number={5},
  pages={1446-1455},
  abstract={Despite the tremendous growth of the transportation sector, the availability of systems that ensure safe, efficient, sustainable transportation reduces traffic congestion, maintenance costs, the off-road time of the vehicle, enhances driver’s experiences, and ensures a more reliable journey are very limited. The fast evolution of our economy, lack of driver training, and the grown affordability of our society are reasons for this mismatch in developing economies. We think that the inconsistency will increase and unfavorably affect our traffic structure unless intelligent algorithm-based solutions are developed and deployed. This article presents a system for providing safe, accurate, comfortable, reliable, fuel-efficient, and economical driving behavior using Machine Learning techniques like the hidden Markov model (HMM). Our proposed system recommends subsequent trips using a multi-objective optimization (MOO) technique for the driver. It provides suggestions concerning speed limits and alerts based on the driver’s behavior score and fuel efficiency. We used a publicly available UAH-DriveSet dataset captured by the driving monitoring app DriveSafe for all of our experiments. The results reveal that the proposed model predicts behavior with 95% accuracy and calculates fuel efficiency to improve driving quality and experience. This system recommends safer, more comfortable, more reliable, more efficient, and economical rides, beneficial for everyone in our society.},
  keywords={Vehicles;Fuels;Hidden Markov models;Global Positioning System;Reliability;Monitoring;Costs;Driver behavior analysis;fuel-efficient driving;trip recommendation system},
  doi={10.1109/TCSS.2021.3112076},
  ISSN={2329-924X},
  month={Oct},}@INPROCEEDINGS{9177719,
  author={Yu, Lin and Deng, Ting and Zhang, Wenxiang and Zeng, Zhigang},
  booktitle={2020 12th International Conference on Advanced Computational Intelligence (ICACI)}, 
  title={Stronger Adversarial Attack: Using Mini-batch Gradient}, 
  year={2020},
  volume={},
  number={},
  pages={364-370},
  abstract={Recent years, convolutional neural network (CNN) has achieved excellent performance in computer vision, but recent researches show that they're very vulnerable to adversarial examples, which results security risks to practical applications of CNN. Research on the generation algorithm of adversarial examples is conducive to evaluate the robustness of CNNs and promotes the study of defense algorithm. Although existing attack algorithms have achieved good performance in white-box manner, they behave unsatisfactorily in black-box manner. In this paper, we propose the mini-batch gradient based iterative method which could dramatically improve the attack ability in black-box manner. The previous iterative methods such as Iterative Fast Gradient Sign Method (I-FGSM) always make the generated adversarial examples fall into over-fitting, however we use minibatch gradient information to help them jump out of the local minimum. Moreover, the proposed method can also be considered as self-ensemble or implicit ensemble attack thus have a stronger attack power. The parallel randomization layer plays core role for providing the mini-batch gradient and the implement of it is very simple since there are no trainable variables. In order to further improve the attack success rate, we combined the momentum and the proposed method. We conducted several experiments on seven networks and the highest success rate of black-box attack has reached 94.1%, which is close to the whitebox manner. Since the proposed method greatly improve the transferability of adversarial examples, we think it could help evaluate the robustness of various deep networks.},
  keywords={Iterative methods;Robustness;Neural networks;Training;Data models;Computer vision;Security;adversarial example;adversariat attack;mini-batch gradient;parallel randomization;self-ensemble},
  doi={10.1109/ICACI49185.2020.9177719},
  ISSN={2573-3311},
  month={Aug},}@INPROCEEDINGS{990497,
  author={Bertalmio, M. and Bertozzi, A.L. and Sapiro, G.},
  booktitle={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001}, 
  title={Navier-stokes, fluid dynamics, and image and video inpainting}, 
  year={2001},
  volume={1},
  number={},
  pages={I-I},
  abstract={Image inpainting involves filling in part of an image or video using information from the surrounding area. Applications include the restoration of damaged photographs and movies and the removal of selected objects. We introduce a class of automated methods for digital inpainting. The approach uses ideas from classical fluid dynamics to propagate isophote lines continuously from the exterior into the region to be inpainted. The main idea is to think of the image intensity as a 'stream function for a two-dimensional incompressible flow. The Laplacian of the image intensity plays the role of the vorticity of the fluid; it is transported into the region to be inpainted by a vector field defined by the stream function. The resulting algorithm is designed to continue isophotes while matching gradient vectors at the boundary of the inpainting region. The method is directly based on the Navier-Stokes equations for fluid dynamics, which has the immediate advantage of well-developed theoretical and numerical results. This is a new approach for introducing ideas from computational fluid dynamics into problems in computer vision and image analysis.},
  keywords={Fluid dynamics;Streaming media;Filling;Image restoration;Motion pictures;Laplace equations;Algorithm design and analysis;Navier-Stokes equations;Computational fluid dynamics;Computer vision},
  doi={10.1109/CVPR.2001.990497},
  ISSN={1063-6919},
  month={Dec},}@ARTICLE{5737846,
  author={Bogdan, Paul and Marculescu, Radu},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
  title={Non-Stationary Traffic Analysis and Its Implications on Multicore Platform Design}, 
  year={2011},
  volume={30},
  number={4},
  pages={508-519},
  abstract={Networks-on-chip (NoCs) have been proposed as a viable solution to solving the communication problem in multicore systems. In this new setup, mapping multiple applications on available computational resources leads to interaction and contention at various network resources. Consequently, taking into account the traffic characteristics becomes of crucial importance for performance analysis and optimization of the communication infrastructure, as well as proper resource management. Although queuing-based approaches have been traditionally used for performance analysis purposes, they cannot properly account for many of the traffic characteristics (e.g., non-stationarity, self-similarity) that are crucial for multicore platform design. To overcome these limitations, we propose a statistical physics inspired approach to capture the traffic dynamics in multicore systems. As shown later in this paper, this is of fundamental significance for re-thinking the very basis of multicore systems design; it also opens up new research directions into NoC optimization which require accurate models of time-dependent and space-dependent traffic behavior.},
  keywords={Fractals;Multicore processing;Analytical models;Stochastic processes;Optimization;Equations;Computational modeling;Multicore systems;networks-on-chip;non-stationary traffic;self-similar behavior;systems-on-chip},
  doi={10.1109/TCAD.2011.2111270},
  ISSN={1937-4151},
  month={April},}@ARTICLE{7765145,
  author={Brady, Corey and Orton, Kai and Weintrop, David and Anton, Gabriella and Rodriguez, Sebastian and Wilensky, Uri},
  journal={IEEE Transactions on Education}, 
  title={All Roads Lead to Computing: Making, Participatory Simulations, and Social Computing as Pathways to Computer Science}, 
  year={2017},
  volume={60},
  number={1},
  pages={59-66},
  abstract={Computer science (CS) is becoming an increasingly diverse domain. This paper reports on an initiative designed to introduce underrepresented populations to computing using an eclectic, multifaceted approach. As part of a yearlong computing course, students engage in Maker activities, participatory simulations, and computing projects that foreground the social and collaborative aspects of CS. Collectively, these activities are designed to introduce learners to the growing diversity of what CS looks like in the 21st century. This paper lays out the practical and theoretical motivations for the Computational Thinking for Girls (CT4G) project, specifically highlighting the use of Making through physical and social computing as ways to engage students in CS. A snapshot of one activity from the program is provided-Wearing the Web-in which students use open-hardware programmable badges to explore the underlying structure and technology that enables the Internet. Data from the first year of the CT4G program are presented to show the positive effects that this diverse introduction to CS is having on the students with respect to their attitudes toward CS.},
  keywords={Computational modeling;Social computing;Collaboration;Context;Programming profession;Sociology;Collaborative learning;computer science (CS);gender diversity;high school;making;participatory simulations;underrepresented students;wearable technology},
  doi={10.1109/TE.2016.2622680},
  ISSN={1557-9638},
  month={Feb},}@ARTICLE{9465680,
  author={López-Espejo, Iván and Tan, Zheng-Hua and Jensen, Jesper},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={A Novel Loss Function and Training Strategy for Noise-Robust Keyword Spotting}, 
  year={2021},
  volume={29},
  number={},
  pages={2254-2266},
  abstract={The development of keyword spotting (KWS) systems that are accurate in noisy conditions remains a challenge. Towards this goal, in this paper we propose a novel training strategy relying on multi-condition training for noise-robust KWS. By this strategy, we think of the state-of-the-art KWS models as the composition of a keyword embedding extractor and a linear classifier that are successively trained. To train the keyword embedding extractor, we also propose a new (CN,2+1)-pair loss function extending the concept behind related loss functions like triplet and N-pair losses to reach larger inter-class and smaller intra-class variation. Experimental results on a noisy version of the Google Speech Commands Dataset show that our proposal achieves around 12% KWS accuracy relative improvement with respect to standard end-to-end multi-condition training when speech is distorted by unseen noises. This performance improvement is achieved without increasing the computational complexity of the KWS model.},
  keywords={Training;Noise measurement;Noise robustness;Computational modeling;Deep learning;Proposals;Acoustic distortion;Keyword spotting;noise robustness;multi-condition training;deep metric learning;loss function;keyword embedding},
  doi={10.1109/TASLP.2021.3092567},
  ISSN={2329-9304},
  month={},}@INPROCEEDINGS{8215735,
  author={Al-Natsheh, Hussein T. and Martinet, Lucie and Muhlenbach, Fabrice and Rico, Fabien and Zighed, Djamel A.},
  booktitle={2017 IEEE International Conference on Data Mining Workshops (ICDMW)}, 
  title={Semantic Search-by-Examples for Scientific Topic Corpus Expansion in Digital Libraries}, 
  year={2017},
  volume={},
  number={},
  pages={747-756},
  abstract={In this article we address the problem of expanding the set of papers that researchers encounter when conducting bibliographic research on their scientific work. Using classical search engines or recommender systems in digital libraries, some interesting and relevant articles could be missed if they do not contain the same search key-phrases that the researcher is aware of. We propose a novel model that is based on a supervised active learning over a semantic features transformation of all articles of a given digital library. Our model, named Semantic Search-by-Examples (SSbE), shows better evaluation results over a similar purpose existing method, More-Like-This query, based on the feedback annotation of two domain experts in our experimented use-case. We also introduce a new semantic relatedness evaluation measure to avoid the need of human feedback annotation after the active learning process. The results also show higher diversity and overlapping with related scientific topics which we think can better foster transdisciplinary research.},
  keywords={Semantics;Libraries;Pipelines;Terminology;Training;Data mining;text mining;information retrieval;digital library;computational linguistics;research-paper recommender system;semantic representation},
  doi={10.1109/ICDMW.2017.103},
  ISSN={2375-9259},
  month={Nov},}@INPROCEEDINGS{9207148,
  author={Oki, Hideki and Abe, Motoshi and Miyao, Jyunichi and Kurita, Takio},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Triplet Loss for Knowledge Distillation}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={In recent years, deep learning has spread rapidly, and deeper, larger models have been proposed. However, the calculation cost becomes enormous as the size of the models becomes larger. Various techniques for compressing the size of the models have been proposed to improve performance while reducing computational costs. One of the methods to compress the size of the models is knowledge distillation (KD). Knowledge distillation is a technique for transferring knowledge of deep or ensemble models with many parameters (teacher model) to smaller shallow models (student model). Since the purpose of knowledge distillation is to increase the similarity between the teacher model and the student model, we propose to introduce the concept of metric learning into knowledge distillation to make the student model closer to the teacher model using pairs or triplets of the training samples. In metric learning, the researchers are developing the methods to build a model that can increase the similarity of outputs for similar samples. Metric learning aims at reducing the distance between similar and increasing the distance between dissimilar. The functionality of the metric learning to reduce the differences between similar outputs can be used for the knowledge distillation to reduce the differences between the outputs of the teacher model and the student model. Since the outputs of the teacher model for different objects are usually different, the student model needs to distinguish them. We think that metric learning can clarify the difference between the different outputs, and the performance of the student model could be improved. We have performed experiments to compare the proposed method with state-of-the-art knowledge distillation methods. The results show that the student model obtained by the proposed method gives higher performance than the conventional knowledge distillation methods.},
  keywords={Computational modeling;Mathematical model;Training;Convolution;Euclidean distance;Feature extraction;Convolutional Neural Network;Metric Learning;triplet loss;knowledge distillation},
  doi={10.1109/IJCNN48605.2020.9207148},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{8005358,
  author={Landauer, Christopher and Bellman, Kirstie L.},
  booktitle={2017 IEEE International Conference on Autonomic Computing (ICAC)}, 
  title={An Architecture for Self-Awareness Experiments}, 
  year={2017},
  volume={},
  number={},
  pages={255-262},
  abstract={There are many open challenges and current / future research directions for self-aware systems. We have shown that self-modeling systems address many of them, but we have not yet seen many replicable experiments that allow methods and results to be shared. In this paper, we describe an architecture for self-modeling systems, and how we expect to use it for experiments in self-awareness. These experiments support a system development and verification process that extends from system conception / definition time through run time operation.Self-Modeling, like Self-Awareness, is an approach to reach a goal, not an end in itself. The goal is survivability in difficult environments, and as much operational competence as possible. We think that run-time models are a minimum necessity for significant self-awareness, and our architecture makes significant use of them throughout.The theme for this paper: this is a beginning description of a reference architecture for a software controlled system that allows / encourages infrastructure analysis and performance prediction. It facilitates the evaluation of design choices at system definition time, so we can then specialize it to the expected run-time environment and specified run-time behavior constraints without losing the capability to "re-specialize" the architecture when the environmental conditions change.},
  keywords={Computer architecture;Wrapping;Adaptation models;Software;Electronic mail;Control systems;Buildings;Self-Aware Systems;Self-Adaptive Systems;Self-Modeling Systems;Reference Architecture;Computational Reflection;Wrapping Integration Infrastructure},
  doi={10.1109/ICAC.2017.33},
  ISSN={2474-0756},
  month={July},}@INPROCEEDINGS{9274172,
  author={Demarle-Meusel, Heike and Rottenhofer, Marina and Albaner, Birgit and Sabitzer, Barbara},
  booktitle={2020 IEEE Frontiers in Education Conference (FIE)}, 
  title={Educational Pyramid Scheme – A Sustainable Way Of Bringing Innovations To School}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={Full paper. One of the biggest challenges in education is the transfer of innovations and new didactic approaches into the school system. To ensure a high standard of teaching, it is essential that the teachers' expertise, pedagogical content knowledge as well as digital competences are continuously improved by further training. In-service training for teachers is offered in different settings (short-, middle- and long term), with advantages and disadvantages. Two aspects that correlate positively are the costs and the sustainable outcome of these trainings. With these aspects in mind the Educational Pyramid Scheme (EPS) is currently being developed and implemented as part of an Erasmus Plus project. It is an innovative concept that aims at spreading new learning contents and methods in a relatively short time within the school system, with low costs and high effect. It is inspired by the economical pyramid scheme, which is designed to create value through the exploitation of business opportunities. The transaction content of the Educational Pyramid Scheme refers to methods or strategies that are being exchanged, and to the resources and capabilities that are required to enable the exchange. According to a train-the-trainer principle, teachers and pupils will be qualified to be trainers, who then spread their knowledge and skills to people in their school and beyond. The EPS contains three different functions or roles: multipliers (teachers and scientists), mentors (teachers) and tutors (pupils). The motivation to participate is maintained with a benefit system adapted for each target group. The training of target groups follows high qualitative standards and therefore presents different phases: input, practical phase and reflection. This paper describes the development of the EPS and its first implementation in the framework of the Austrian mandatory curriculum "Basic Digital Education" including computational thinking and programming. It presents some qualitative results gained so far from interviews and observation, which are satisfactory and deliver good arguments for the further implementation of the EPS.},
  keywords={Training;Technological innovation;Stakeholders;Pupils;Computational modeling;Task analysis;Organizations;teacher training;pyramid scheme;train the trainer;professional development;modeling},
  doi={10.1109/FIE44824.2020.9274172},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{7573160,
  author={Landauer, Christopher and Bellman, Kirstie L.},
  booktitle={2016 IEEE International Conference on Autonomic Computing (ICAC)}, 
  title={Model-Based Cooperative System Engineering and Integration}, 
  year={2016},
  volume={},
  number={},
  pages={334-341},
  abstract={This paper is about some difficult issues in systems of systems engineering, especially when the systems are self-modeling. The questions are about which of the available participant systems have the collection of capabilities desired, how to use them to provide those capabilities, and how to avoid introducing new error modes that emerge from the interaction. In this paper, we describe the process of designing and constructing a system of systems, starting with a provided mapping from the perceived need to a coordinated set of system capabilities that can address that need, some of which are missing capabilities for which new systems are needed. The system engineering aspects of this problem are difficult: the available information about the component system capabilities is always incomplete and often inconsistent, and there can be only approximations of the range of environmental behaviors. For these applications, the design will have to change as the environmental conditions change. These systems are in “continual dynamic development”, which is why we think the systems should manage and perform the integration tasks themselves. This paper shows one way to do that.},
  keywords={Wrapping;Context;Knowledge based systems;Information services;System of systems;Analytical models;Computational Reflection;Wrapping Infrastructure;Self-Monitoring;Self-Improvement;Self-Integration;Cooperative System Engineering;Model Deficiency Analysis},
  doi={10.1109/ICAC.2016.30},
  ISSN={},
  month={July},}@INPROCEEDINGS{9275915,
  author={Demir, Mehmet and Turetken, Ozgur and Ferworn, Alexander},
  booktitle={2020 IEEE International Systems Conference (SysCon)}, 
  title={Blockchain-Based Transparent Disaster Relief Delivery Assurance}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Blockchain technology presents benefits that change the way business partners interact. This new way of establishing democratic trust encourages business owners to think differently. Disaster relief and aid industries are built on the power of collaborating participants. A very high number of participants in different hierarchies, including donors, charities, disaster victims, insurance companies and government agencies interact under extraordinary circumstances of a disaster and hard times. Establishing a new way of trust brings forward a better disaster recovery. In this paper, we propose a blockchain-based ecosystem. The blockchain-based disaster recovery not only would enhance the basic processes around disaster relief, but also promote the willingness of help by transparency and potential fraud prevention. This new blockchain system introduces an opportunity to be more resilient, to react rapidly, to communicate transparently, and to include new contributors such as IoT.},
  keywords={Blockchain;Drones;Supply chains;Smart contracts;Production;Meteorology;Economics;Blockchain;computational public safety;humanitarian aid;disaster relief;IoT;artificial intelligence},
  doi={10.1109/SysCon47679.2020.9275915},
  ISSN={2472-9647},
  month={Aug},}@INPROCEEDINGS{7408367,
  author={Davis, Paul K. and Manheim, David and Perry, Walter L. and Hollywood, John},
  booktitle={2015 Winter Simulation Conference (WSC)}, 
  title={Using causal models in heterogeneous information fusion to detect terrorists}, 
  year={2015},
  volume={},
  number={},
  pages={2586-2597},
  abstract={We describe basic research that uses a causal, uncertainty-sensitive computational model rooted in qualitative social science to fuse disparate pieces of threat information. It is a cognitive model going beyond rational-actor methods. Having such a model has proven useful when information is uncertain, fragmentary, indirect, soft, conflicting, and even deceptive. Inferences from fusion must then account for uncertainties about the model, the credibility of information, and the fusion methods - i.e. we must consider both structural and parametric uncertainties, including uncertainties about the uncertainties. We use a novel combination of (1) probabilistic and parametric methods, (2) alternative models and model structures, and (3) alternative fusion methods that include nonlinear algebraic combination, variants of Bayesian inference, and a new entropy-maximizing approach. Initial results are encouraging and suggest that such an analytically flexible and model-based approach to fusion can simultaneously enrich thinking, enhance threat detection, and reduce harmful false alarms.},
  keywords={Uncertainty;Terrorism;Computational modeling;Probabilistic logic;Mathematical model;Bayes methods;Analytical models},
  doi={10.1109/WSC.2015.7408367},
  ISSN={1558-4305},
  month={Dec},}@ARTICLE{9722569,
  author={Fotiadis, Filippos and Vamvoudakis, Kyriakos G.},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Recursive Reasoning With Reduced Complexity and Intermittency for Nonequilibrium Learning in Stochastic Games}, 
  year={2023},
  volume={34},
  number={11},
  pages={8467-8481},
  abstract={In this article, we propose a computationally and communicationally efficient approach for decision-making in nonequilibrium stochastic games. In particular, due to the inherent complexity of computing Nash equilibria, as well as the innate tendency of agents to choose nonequilibrium strategies, we construct two models of bounded rationality based on recursive reasoning. In the first model, named level- $k$  thinking, each agent assumes that everyone else has a cognitive level immediately lower than theirs and—given such an assumption—chooses their policy to be a best response to them. In the second model, named cognitive hierarchy, each agent conjectures that the rest of the agents have a cognitive level that is lower than theirs, but follows a distribution instead of being deterministic. To explicitly compute the boundedly rational policies, a level-recursive algorithm and a level-paralleled algorithm are constructed, where the latter one can have an overall reduced computational complexity. To further reduce the complexity in the communication layer, modifications of the proposed nonequilibrium strategies are presented, which do not require the action of a boundedly rational agent to be updated at each step of the stochastic game. Simulations are performed that demonstrate our results.},
  keywords={Games;Stochastic processes;Computational modeling;Cognition;Nash equilibrium;Learning systems;Decision making;Bounded rationality;communication efficiency;recursive reasoning;stochastic games},
  doi={10.1109/TNNLS.2022.3151250},
  ISSN={2162-2388},
  month={Nov},}@INPROCEEDINGS{10184757,
  author={Ahmad, Akhlaque and Yuan, Lyuheng and Yan, Da and Guo, Guimu and Chen, Jieyang and Zhang, Chengcui},
  booktitle={2023 IEEE 39th International Conference on Data Engineering (ICDE)}, 
  title={Accelerating k-Core Decomposition by a GPU}, 
  year={2023},
  volume={},
  number={},
  pages={1818-1831},
  abstract={The k-core of a graph is the largest induced sub-graph with minimum degree k. The problem of k-core decomposition finds the k-cores of a graph for all valid values of k, and it has many applications such as network analysis, computational biology and graph visualization. Currently, there are two types of parallel algorithms for k-core decomposition: (1) degree-based vertex peeling, and (2) iterative h-index refinement. There is, however, few studies on accelerating k-core decomposition using GPU. In this paper, we propose a highly optimized peeling algorithm on a GPU, and compare it with possible implementations on top of think-like-a-vertex graph-parallel GPU systems as well as existing serial and parallel k-core decomposition algorithms on CPUs. Extensive experiments show that our GPU algorithm is the overall winner in both time and space. Our source code is released at https://github.com/akhlaqueak/KCoreGPU.},
  keywords={Source coding;Graphics processing units;Network analyzers;Data engineering;Iterative algorithms;Parallel algorithms;Computational biology;GPU;k-core;graph;h-index},
  doi={10.1109/ICDE55515.2023.00142},
  ISSN={2375-026X},
  month={April},}@ARTICLE{475593,
  author={Killingsworth, M.J. and Rosenberg, M.E.},
  journal={IEEE Transactions on Professional Communication}, 
  title={The icon as a problem in cognition and social construction: complexity and consensual domains in technical rhetoric}, 
  year={1995},
  volume={38},
  number={4},
  pages={216-227},
  abstract={Suggests that current theories about how even the simplest elements of graphical design function in professional communication do not adequately convey the complexity of the element's actual role in communication. By showing how producers of computer interfaces rely on the possibility of multiple interpretive trajectories in the use of any sign and how users of such signs respond in ways that are far from being totally predictable, we argue that it is best to think of the communication act not as a simple exchange of information between two minds (producer and user) but rather as a field of possibilities that requires flexibility and an experimental attitude from both the producer and the user. Examining theoretical developments in the history of physics and cognitive science, we contend that the dominant paradigms of understanding communication-the old cognitive (or computational) model and the social constructionist model as currently employed in the fields of composition and technical communication-fall short of accounting for even fairly straightforward exchanges of information. In place of the communication triangle that both of the old models rely upon, we offer a new model that uses the concept of "consensual domains" as the basis for a general theory of rhetoric. As a starting point for our investigation, we present the history of a still evolving sign-the trash-can icon in the user interface of the Macintosh operating system-from the perspective of a single (also still evolving) human user.},
  keywords={Cognition;History;Professional communication;Computer interfaces;Trajectory;Cognitive science;Physics computing;Computational modeling;Rhetoric;User interfaces},
  doi={10.1109/47.475593},
  ISSN={1558-1500},
  month={Dec},}@INPROCEEDINGS{9953889,
  author={Chatziagapi, Aggelina and Sgouropoulos, Dimitris and Karouzos, Constantinos and Melistas, Thomas and Giannakopoulos, Theodoros and Katsamanis, Athanasios and Narayanan, Shrikanth},
  booktitle={2022 10th International Conference on Affective Computing and Intelligent Interaction (ACII)}, 
  title={Audio and ASR-based Filled Pause Detection}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Filled pauses (or fillers) are the most common form of speech disfluencies and they can be recognized as hesitation markers (“um”, “uh” and “er”) made by speakers, usually to gain extra time while thinking their next words. Filled pauses are very frequent in spontaneous speech. Their detection is therefore rather important for two basic reasons: (a) their existence influences the performance of individual components, like Automatic Speech Recognition system (ASR), in human-machine interaction and (b) their frequency can characterize the overall speech quality of a particular speaker, as it can be strongly associated with the speaker's confidence. Despite that, only limited work has been published for the detection of filled pauses in speech, especially through audio. In this work, we propose a framework for filled pause detection using both audio and textual information. For the audio modality, we transfer knowledge from a plethora of supervised tasks, such as emotion or speaking rate, using Convolutional Neural Networks (CNNs). For the text modality, we develop a temporal Recurrent Neural Network (RNN) method that takes into account textual information derived from an ASR system. In addition, the proposed transfer learning approach for the audio classifier leads to better results when benchmarked on our internal dataset for which the text is not transcribed but estimated by an ASR system. In this case, a simple late fusion approach boosts the performance even further. This proves that the audio approach is suitable for real-world applications where the transcribed text is not available and has to leverage imperfect ASR results, or even the absence of textual information (to reduce computational cost).},
  keywords={Knowledge engineering;Affective computing;Recurrent neural networks;Transfer learning;Benchmark testing;Computational efficiency;Convolutional neural networks;Filled Pauses;Hesitation;Disfluency Detection;Audio Classification;Text Classification;Multimodal Learning;Automatic Speech Recognition;Convolutional Neural Networks;Recurrent Neural Networks;Deep Learning},
  doi={10.1109/ACII55700.2022.9953889},
  ISSN={2156-8111},
  month={Oct},}@INPROCEEDINGS{6422038,
  author={Abuczki, Ágnes},
  booktitle={2012 IEEE 3rd International Conference on Cognitive Infocommunications (CogInfoCom)}, 
  title={The role of discourse markers in the generation and interpretation of discourse structure and coherence}, 
  year={2012},
  volume={},
  number={},
  pages={531-536},
  abstract={The present paper studies the notions of turn management and topic orientation, and more specifically, a group of pragmatic elements, so-called discourse markers (DMs) which indicate the act of next speaker selection, turn-keeping, topic elaboration and digression. After definitions of discourse marker, turn, floor control types/turn segments, topical units and actions are provided, a list of verbal and nonverbal discourse markers will be given, and they will be grouped into subclasses on the basis of the meaning relations between the linked discourse segments and the type of floor control and thematic control affected. The fundamental question is if discourse markers are key indicators of discourse structure and can be used in the automatic interpretation of utterance meaning and rhetoric relations. The goal of the paper is twofold: firstly, to identify how nonverbal behavior (gestures, posture, gaze) may help disambiguate the actual function(s) of a discourse marker in a given context; secondly, to make explicit how different modalities work together in a synchronized manner in turn regulation and topic control during cooperative interaction. It is examined in twenty spontaneous dialogues of the Hungarian HuComTech multimodal corpus what roles and functions verbal and nonverbal discourse markers play in indicating discourse structure and coherence relations. Concordances and corpus queries presented address both the verbal and nonverbal features of different turn management behavior and topical actions accompanied or supported by discourse markers. Taking a semasiological approach, some of the controversial defining features of discourse markers generally listed in the literature will be tested on a few Hungarian discourse markers: hát (‘well’), tehát (‘so’), mondjuk (‘say’), amúgy (‘otherwise’), egyébként (‘by the way’), szerintem (‘I think’). The features in question regard their position (turn-initiality, topic unit-initiality) as well as the genre-specificity and gender-specificity of their use.},
  keywords={Floors;Manuals;Pragmatics;Coherence;Human computer interaction;Context;Interviews;computational pragmatics;discourse analysis;turn management;topic orientation;discourse structure markers},
  doi={10.1109/CogInfoCom.2012.6422038},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10385599,
  author={Liu, Yuhang and Li, Tianhao and Wang, Zixuan and Zhu, Guiquan and Zhang, Yongqing and Zou, Quan},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Exploring Parameter-Efficient Fine-Tuning of a Large-Scale Pre-Trained Model for scRNA-seq Cell Type Annotation}, 
  year={2023},
  volume={},
  number={},
  pages={580-585},
  abstract={Accurate identification of cell types is a pivotal and intricate task in scRNA-seq data analysis. Recently, significant strides have been made in cell type annotation of scRNA-seq data using pre-trained language models (PLMs). This method has surmounted the constraints of conventional approaches regarding precision, robustness, and generalization. However, the fine-tuning process of large-scale pre-trained models incurs substantial computational expenses. To tackle this issue, a promising avenue of research has emerged, proposing parameter-efficient fine-tuning techniques for PLMs. These techniques concentrate on fine-tuning only a small portion of the model parameters while attaining comparable performance. In this study, we extensively research parameter-efficient fine-tuning methods for scRNA-seq cell type annotation, employing scBERT as the backbone. We scrutinize the performance and compatibility of various parameter-efficient fine-tuning methodologies across multiple datasets. Through comprehensive analysis, we demonstrate the remarkable performance of parameter-efficient fine-tuning methods in cell type annotation. Hopefully, this study can inspire new thinking in analyzing scRNA-seq data.},
  keywords={Data analysis;Annotations;Computational modeling;Biological system modeling;Robustness;Data models;Task analysis;Single-cell RNA-seq;Cell type annotation;Parameter-efficient fine-tuning;Pre-trained language model},
  doi={10.1109/BIBM58861.2023.10385599},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{5599732,
  author={Shi, Zhongzhi and Wang, Xiaofeng and Shi, Zhiping and Chen, Limin and Wang, Zhuxiao},
  booktitle={9th IEEE International Conference on Cognitive Informatics (ICCI'10)}, 
  title={A mind model for brain-like computer}, 
  year={2010},
  volume={},
  number={},
  pages={257-264},
  abstract={Mind is all mankind's spiritual activities, including emotion, will, perception, consciousness, representation, learning, memory, thinking, intuition, etc. Mind model is for explaining what individuals operate in the cognitive process for something in the real world. It is the internal sign or representation for external realistic world. If the neural network is a hardware of the brain system, then the mind model is the software of the brain system. The key issue in intelligence science is to construct the mind model of the brain system, which will guide the development of brain-like computer in engineering through structure, dynamics, function and behavioral reverse engineering of the brain. This paper will discuss the computational model of memory and consciousness in the mind model named Consciousness And Memory model(CAM).},
  keywords={Brain modeling;Computational modeling;Humans;Computer aided manufacturing;Biological system modeling;Computers;Computer architecture;mind model;CAM;brain-like computer;dynamic description logic;intelligence science},
  doi={10.1109/COGINF.2010.5599732},
  ISSN={},
  month={July},}@INPROCEEDINGS{5626848,
  author={Erson, E. Zeynep and Çavuşoğlu, M Çenk},
  booktitle={2010 Annual International Conference of the IEEE Engineering in Medicine and Biology}, 
  title={Design of a framework for modeling, integration and simulation of physiological models}, 
  year={2010},
  volume={},
  number={},
  pages={1485-1489},
  abstract={Modeling and simulation of physiological processes deal with the challenges of multiscale models in which coupling is very high within and among scales. Information technology approaches together with related analytical and computational tools will help to deal with these challenges. Physiological Model Simulation, Integration and Modeling Framework, Phy-SIM, provides the modeling environment which will help to cultivate various approaches to deal with the inherent problem of multiscale modeling of physiological systems. In this paper, we present the modular design of Phy-SIM. The proposed layered design of Phy-SIM, separates structure from function in physiological processes advocating modular thinking in developing and integrating physiological models. Moreover, the ontology based architecture will improve the modeling process by the mechanisms to attach anatomical and physiological ontological information to the models. The ultimate aim of the proposed approaches is to enhance the physiological model development and integration processes by providing the tools and mechanisms in Phy-SIM.},
  keywords={Computational modeling;Mathematical model;Biological system modeling;Load modeling;Atmospheric modeling;Ontologies;Analytical models},
  doi={10.1109/IEMBS.2010.5626848},
  ISSN={1558-4615},
  month={Aug},}@INPROCEEDINGS{9040012,
  author={Kireš, M. and Šveda, D. and Ješková, Z. and Lukáč, S. and Ganajová, M. and Lešková, A. and Csachová, S.},
  booktitle={2019 17th International Conference on Emerging eLearning Technologies and Applications (ICETA)}, 
  title={Key innovation concepts of STEM education driven by IT Academy project}, 
  year={2019},
  volume={},
  number={},
  pages={378-382},
  abstract={The information society places requirements on the profile of graduates, what is unreachable in the inertial education system. We aim for key changes in STEM education at primary and secondary schools through a national wide-impact project IT Academy. Active learning focusing on conceptual understanding and development of selected inquiry skills, together with formative assessment, form our didactic basis for innovation. The development of scientific literacy and computational thinking are also stimulated by changes in the content of science and mathematics curricula. We create a strong link to informatics concepts and practical use of informatics in everyday life, study, work and research. We expect the interest of young people to study computer science and STEM will increase. In this paper, we introduce key concepts of STEM education innovation, with examples of educational activities. The results of the pilot verification are formulated in recommendations to the educational professionals.},
  keywords={Education;Pupils;Mathematics;Technological innovation;Informatics;Computational modeling;Geography},
  doi={10.1109/ICETA48886.2019.9040012},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8229646,
  author={Malagon, Edwin and Rojas, Alexis},
  booktitle={2017 CHILEAN Conference on Electrical, Electronics Engineering, Information and Communication Technologies (CHILECON)}, 
  title={Analysis and simulation of graphs applied to learning with parallel programming in HPC}, 
  year={2017},
  volume={},
  number={},
  pages={1-7},
  abstract={Large-scale graph analysis or also called network analysis of networks is supported by different algorithms, among the most relevant are PageRank (Web page ranking), Betweenness centrality (centrality in a graph) and Community Detection, these by of their complexity and the large amount of data that process diverse applications, increasingly need to use computational resources such as processor, memory and storage, for these reasons, it is necessary to apply high performance computing or HPC (High Performance Computing) but it would not be useful to apply HPC without having designed these algorithms in parallel programming, in this part there have been many studies on its application and methodologies to do it. The purpose of this work is to create a framework that allows computer science students to abstract a computer system based on the parallel programming paradigm, which implies that students to get acquainted with the resolution of algorithmic problems in a more natural way and away from the typical sequential thinking., The development of a graph analysis design pattern oriented to parallel programming in HPC, complemented with the design of didactic learning techniques in the network such as laboratories and/or simulators are key in the development of this framework.},
  keywords={Parallel programming;High performance computing;Algorithm design and analysis;Computational modeling;Hardware;Handheld computers;Analytical models;Analysis;graphs;parallel programing;high performance computing;learning},
  doi={10.1109/CHILECON.2017.8229646},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10097957,
  author={Bistarelli, Stefano and Mancinelli, Alessio and Santini, Francesco and Taticchi, Carlo},
  booktitle={2022 IEEE 34th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Arg-XAI: a Tool for Explaining Machine Learning Results}, 
  year={2022},
  volume={},
  number={},
  pages={205-212},
  abstract={The requirement of explainability is gaining more and more importance in Artificial Intelligence applications based on Machine Learning techniques, especially in those contexts where critical decisions are entrusted to software systems (think, for example, of financial and medical consultancy). In this paper, we propose an Argumentation-based methodology for explaining the results predicted by Machine Learning models. Argumentation provides frameworks that can be used to represent and analyse logical relations between pieces of information, serving as a basis for constructing human tailored rational explanations to a given problem. In particular, we use extension-based semantics to find the rationale behind a class prediction.},
  keywords={Semantics;Machine learning;Predictive models;Software systems;Computational Argumentation;Machine Learning;Explainability},
  doi={10.1109/ICTAI56018.2022.00037},
  ISSN={2375-0197},
  month={Oct},}@INPROCEEDINGS{508194,
  author={Saini, S.},
  booktitle={Proceedings of International Conference on Parallel Processing}, 
  title={NAS experiences of porting CM Fortran codes to HPF on IBM SP2 and SGI Power Challenge}, 
  year={1996},
  volume={},
  number={},
  pages={873-880},
  abstract={Current Connection Machine (CM) Fortran codes developed for the CM-2 and the CM-5 represent an important class of parallel applications. Several users have employed CM Fortran codes in the production mode on the CM-2 and the CM-5 for the last five to six years, constituting a heavy investment in terms of cost and time. With Thinking Machines Corporation's decision to withdraw from the hardware business and with the decommissioning of many CM-2 and CM-5 machines, the best way to protect the substantial investment in CM Fortran codes is to port the codes to High Performance Fortran (HPF) on highly parallel systems. HPF is very similar to CM Fortran and thus represents a natural transition. The Numerical Aerodynamic Simulation (NAS) Program, located at NASA Ames Research Center, is a pathfinder in high-performance computing for NASA and is dedicated to advancing the science of computational aerodynamics. Their experiences with the conversion issues involved in porting CM Fortran codes on the CM-5 to HPF are presented. Several CM Fortran codes have been ported to Subset HPF on the IBM SP2 and the SGI Power Challenge. Speedup ratios versus number of processors for the linear solver and DSMC (direct simulation Monte Carlo) code are presented.},
  keywords={Investments;Aerodynamics;NASA;Production;Costs;Hardware;Protection;Computational modeling;Numerical simulation;Monte Carlo methods},
  doi={10.1109/IPPS.1996.508194},
  ISSN={},
  month={April},}@INPROCEEDINGS{1244258,
  author={Marginean, F.A.},
  booktitle={SMC'03 Conference Proceedings. 2003 IEEE International Conference on Systems, Man and Cybernetics. Conference Theme - System Security and Assurance (Cat. No.03CH37483)}, 
  title={The cybernetics of the concept}, 
  year={2003},
  volume={3},
  number={},
  pages={2495-2500 vol.3},
  abstract={The concept of concept is central to several mathematical fields dealing with the processing and interpretation of knowledge, such as Computational Learning Theory in Machine Learning or Formal Concept Analysis in Artificial Intelligence. It has however had much less of an impact on other related mathematical fields, amongst which Data Mining and Knowledge Discovery in Databases, for which the pattern rather than the concept seems to play the role of the basic unit of knowledge. In this paper we examine the potential role of cybernetical thinking in the formal analysis of concepts with relevance to learning and performance.},
  keywords={Cybernetics;Data mining;Logic;Computational intelligence;Modems;History;Computer science;Artificial intelligence;Databases;Knowledge management},
  doi={10.1109/ICSMC.2003.1244258},
  ISSN={1062-922X},
  month={Oct},}@INPROCEEDINGS{10412418,
  author={Raeisi, Arash and Aghanasiri, Pouria and Etezadi, Hamed and Zarafshan, Payam and Dehghani, Mohammad},
  booktitle={2023 11th RSI International Conference on Robotics and Mechatronics (ICRoM)}, 
  title={Design and Analysis of a Fiber Laser Flying Robot for Cleaning Power Line Insulators}, 
  year={2023},
  volume={},
  number={},
  pages={402-407},
  abstract={It is one of humanity’s greatest needs today to be able to transmit electric current using power lines from power plants to cities, Therefore, power generation companies are always thinking about improving power transmission lines. As a result of pollution sitting on electrical insulators and making them conductive, power lines lose most of their power. Therefore, we need more effective and newer methods to wash these pollutions from electrical insulators. In this article, the cleaning of electrical insulators using a fiber laser by a hexarotor has been investigated. The control of these systems is done either by a pilot at the ground station or by an autopilot. The steps involved in construction and the parts described. Solidworks flow simulatin was used to simulate the effect of wind at a height of 50 meters near the power tower using computational fluid dynamics (CFD).},
  keywords={Computational fluid dynamics;Power lasers;Insulators;Laser modes;Cleaning;Robots;Fiber lasers;Electrical Insulator;Fiber Laser;Flying Robot;Cleaning Insulator;Hexarotor},
  doi={10.1109/ICRoM60803.2023.10412418},
  ISSN={2572-6889},
  month={Dec},}@INPROCEEDINGS{9622815,
  author={Milechin, Lauren and Lopez-Contreras, Javier and Alet, Ferran},
  booktitle={2021 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={Efficiently Building a Large Scale Dataset for Program Induction}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={One of the applications of machine learning with the most potential is speeding up expensive computational processes, i.e. learning to think. To do so, one first generates a large-scale dataset by a compute-intensive process and then trains a model to approximate the distribution. High performance computing (HPC) is a perfect fit for these processes, as one may efficiently deploy large amounts of computation to generate a dataset in a reasonable amount of time, to then learn a computationally-efficient solution. Here, we focus on generating a program synthesis dataset. Finding the program that fits a given input-output specification is very expensive, but generating the input-output pairs for a given program is a well-defined process. In this work, we show how we efficiently ran hundreds of thousands of C++ codes line-by-line and used intermediate variable states to generate a large-scale program synthesis dataset.},
  keywords={Training;Computational modeling;High performance computing;Pipelines;Distributed databases;Machine learning;Tools;AI / Machine Learning;Big Data and Distributed Computing;High Throughput Computing},
  doi={10.1109/HPEC49654.2021.9622815},
  ISSN={2643-1971},
  month={Sep.},}@INPROCEEDINGS{5334409,
  author={Kimura, Hidenori and Shimoda, Shingo and Lu Gaohua and Tanaka, Reiko J.},
  booktitle={2009 ICCAS-SICE}, 
  title={Towards a common principle of biological control — How control weaves the string of life}, 
  year={2009},
  volume={},
  number={},
  pages={5111-5116},
  abstract={This paper reviews the interplay between biology and control theory as a typical example of transdisciplinary knowledge integration. Control is a fundamental function of the living organism that works in all aspects of the life. Various control mechanisms are ubiquitously built-in at all levels of body structures of living organisms and work all the time to support the life. They are diversely different from one to another with different material bases and structures, but there are many reasons to think that have some common ground and design principles. It is argued that a unified approach is exploited by focusing on a biological way of dealing with environmental changes to investigate various control mechanisms of living organisms.The notion of compound control is proposed as a common principle of biological control based on the transdisciplinary nature of control theory.},
  keywords={Biological control systems;Organisms;Control engineering;Biology;Humans;Reliability engineering;Power engineering and energy;Control theory;Design engineering;Systems engineering and theory;biological control;feedback;transdisciplinary science;compound control;computational media},
  doi={},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9962408,
  author={Fonseca Silveira, Rodrigo and Holanda, Maristela and Ramos, Guilherme N. and Victorino, Marcio and Da Silva, Dilma},
  booktitle={2022 IEEE Frontiers in Education Conference (FIE)}, 
  title={Analysis of Student Performance and Social-economic Data in Introductory Computer Science Courses at the University of Brasília}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Computer Science 1 (CS1) courses introduce undergraduate students to computational thinking and their first programming language. As in most institutions, CS1 is a challenge for students at the University of Brasilia, one of the top 10 universities in Brazil. In 2012, the Brazilian higher education system changed with an affirmative-action policy to admit more students from the public K-12 system: the “Quota” Law was implemented at all federal public universities. This paper aims to answer two research questions: 1) What knowledge about the positive/negative impact of certain features on the success of a CS1 course can be discovered from mining educational data augmented by social-economic information? 2) Are these features different between quota and non-quota students? The analysis uses social-economic and academic performance data of undergraduate students from 2012 to 2019. Data mining algorithms such as generalized linear model, gradient boosting machine, and random forest were applied to the data. The findings include: (1) the relevance of indicators such as the consumption rate of university-subsidized meals, (2) that gender is not a determining factor in failure/success, and (3) a higher failure rate for quota students in the Computer Engineering and Mechatronics Engineering majors.},
  keywords={Computer languages;Mechatronics;Databases;Computational modeling;Education;Data models;Trajectory;Educational Data Mining;CS1;Introduction to Computer Science course;Machine Learning},
  doi={10.1109/FIE56618.2022.9962408},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10198449,
  author={Zeng, Shaoting and Lyu, Xin and Kang, Jingfan},
  journal={IEEE Access}, 
  title={Research on Innovative Method of Human–Computer Collaborative Aesthetic Education Based on Hybrid of Neuroaesthetics and Shape Grammar}, 
  year={2023},
  volume={11},
  number={},
  pages={82728-82737},
  abstract={This paper proposed an innovative method for aesthetic education by integrating shape grammar and neuroaesthetics. Aesthetic education can be divided into bottom-up aesthetic cultivation and top-down knowledge education, which correspond to the characteristics of shape grammar and neuroaesthetics, respectively. In this study, we redefined the state space of traditional shape grammar by replacing the computer-dominated label set with the affective-dominated emotion set of neuroaesthetics. This resulted in a neuroaesthetic shape grammar that is led by the designer and complementary to human intuition and algorithmic logic. We validated this method through practical design cases in the field of aesthetic education.},
  keywords={Grammar;Education;Visualization;Iterative algorithms;Transforms;Image color analysis;Design methodology;Man-machine systems;Neuroscience;Human computer interaction;Aesthetic education;design thinking;human-machine collaboration;neuroaesthetics;shape grammar},
  doi={10.1109/ACCESS.2023.3300800},
  ISSN={2169-3536},
  month={},}@ARTICLE{6843352,
  author={Fatemi, Mehdi and Haykin, Simon},
  journal={IEEE Access}, 
  title={Cognitive Control: Theory and Application}, 
  year={2014},
  volume={2},
  number={},
  pages={698-710},
  abstract={From an engineering point-of-view, cognitive control is inspired by the prefrontal cortex of the human brain; cognitive control may therefore be viewed as the overarching function of a cognitive dynamic system. In this paper, we describe a new way of thinking about cognitive control that embodies two basic components: learning and planning, both of which are based on two notions: 1) two-state model of the environment and the perceptor and 2) perception-action cycle, which is a distinctive characteristic of the cognitive dynamic system. Most importantly, it is shown that the cognitive control learning algorithm is a special form of Bellman's dynamic programming. Distinctive properties of the new algorithm include the following: 1) optimality of performance; 2) algorithmic convergence to optimal policy; and 3) linear law of complexity measured in terms of the number of actions taken by the cognitive controller on the environment. To validate these intrinsic properties of the algorithm, a computational experiment is presented, which involves a cognitive tracking radar that is known to closely mimic the visual brain. The experiment illustrates two different scenarios: 1) the impact of planning on learning curves of the new cognitive controller and 2) comparison of the learning curves of three different controllers, based on dynamic optimization, traditional  \(Q\) -learning, and the new algorithm. The latter two algorithms are based on the two-state model, and they both involve the use of planning.},
  keywords={Cognition;Heuristic algorithms;Brain modeling;Radar tracking;Dynamic programming;Complexity theory;Perception;Control systems;Cognitive dyanamic systems;cognitive control;dynamic programming;two-state model;entropic state;Shannon's entropy;explore/exploit tradeoff;learning;planning;Bayesian filtering},
  doi={10.1109/ACCESS.2014.2332333},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{5555103,
  author={Reyss, Alexandra and Balandin, Sergey},
  booktitle={2010 IEEE Region 8 International Conference on Computational Technologies in Electrical and Electronics Engineering (SIBIRCON)}, 
  title={Healthcare, medical support and consultancy applications and services for mobile devices}, 
  year={2010},
  volume={},
  number={},
  pages={300-305},
  abstract={While thinking about potential new user groups for mobile devices one can notice that the world largest clusters with low penetration of devices are people from developing countries. In the developed countries the largest groups are children and older generation people. Driven by different factors the healthcare and medical applications might create real breakthrough in demand for the new mobile devices and services, and actively involve the above mentioned user groups. The paper describes ideas of the new applications, services and mobile device extension modules which provide the user with medical support and consultancy everywhere at anytime. The paper cannot be seen as a real scientific study, instead it is the first exploration of this field, which in particular is focused on proposing and arguing healthcare and medical solutions for mobile devices targeted to fulfill needs of the above mentioned user groups.},
  keywords={Mobile handsets;Pediatrics;Monitoring;Sensors;Diseases;Mobile communication},
  doi={10.1109/SIBIRCON.2010.5555103},
  ISSN={},
  month={July},}@INPROCEEDINGS{6417292,
  author={Bouaziz, Rahma and Coulette, Bernard},
  booktitle={2012 IEEE 15th International Conference on Computational Science and Engineering}, 
  title={Applying Security Patterns for Component Based Applications Using UML Profile}, 
  year={2012},
  volume={},
  number={},
  pages={186-193},
  abstract={Today's systems require a higher consideration for the non functional requirement as security and dependability. Developers have to handle these requirements during software development lifecycle. To provide developers with security guidelines, security patterns were proposed. These patterns are a collection of expert's security knowledge and a good solution to convey security concepts. In order to encourage developers to take advantage from security solutions proposed by security patterns, we think that it is necessary to provide an appropriate mechanism to implement those patterns using UML profiles. In this paper, we propose structured UML profiles construction process based on security patterns. An illustration of the proposed profile construction process is provided using the active replication pattern. A case study of GPS system is also provided to demonstrate the application of generated UML profile using the proposed process.},
  keywords={Security;Unified modeling language;Object oriented modeling;Program processors;Context;Connectors;based approach;Security pattern;UML profile;Model Driven Development},
  doi={10.1109/ICCSE.2012.104},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6993108,
  author={Anshad, P Y Muhammed and Kumar, S. S.},
  booktitle={2014 International Conference on Control, Instrumentation, Communication and Computational Technologies (ICCICCT)}, 
  title={Recent methods for the detection of tumor using computer aided diagnosis — A review}, 
  year={2014},
  volume={},
  number={},
  pages={1014-1019},
  abstract={Computer Aided Diagnosis (CAD) is one of the trusted methods in the field of medicine. CAD system assists the doctors for the diagnosis of diseases in higher degree of perfection within a short period of time. Now CAD is the most preferable method for the initial diagnosis of cancer using X-ray, CT, mammogram or MRI images. CAD works as an intermediate in between the radiologist and the input images. The output from CAD doesn't think about as a final result however used as a reference for more tests in the relevant field. In fact CAD helps the doctors for detection of cancer more precisely and early. The combination of artificial intelligence, digital image processing technique and radiological image processing etc makes the CAD system more reliable and efficient. Sensitivity, specificity, absolute detection rate etc are the important parameters of the CAD system. Now CAD system is mostly used for breast cancer detection, lung cancer detection, colon cancer, coronary artery disease, congenital heart defect, lung cancer, bone cancer, brain tumor etc. Any part of body can affect cancer and very high possibility to spread other parts. These days CAD system developed to a great extends, however it's not reached to 100% accuracy. In this article that discusses the necessary options, motivation, findings from the early developments and future expansions of CAD systems.},
  keywords={Feature extraction;Design automation;Tumors;Cancer;Computers;Lungs;Classification algorithms;Computer Aided Diagnosis;Artificial intelligence;digital image processing technique;radiological image processing},
  doi={10.1109/ICCICCT.2014.6993108},
  ISSN={},
  month={July},}@INPROCEEDINGS{9004238,
  author={Velliangiri, S. and Karthikeyan, P. and Joseph, Iwin Thanakumar and Kumar, Satish A. P.},
  booktitle={2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)}, 
  title={Investigation of Deep Learning Schemes in Medical Application}, 
  year={2019},
  volume={},
  number={},
  pages={87-92},
  abstract={Deep learning models are equipped for thinking out how to concentrate on the correct features without anyone else's input, requiring a little direction from the software engineer. Essentially, deep learning mirrors how our brain is functioning to take decisions. Deep learning techniques are highly applied in medical imaging diagnosis. Deep learning techniques are used in medical applications in four different areas i. Detections ii. Classifications iii. Segmentations iv. Registrations. In this paper we have discussed deep learn scheme advantage, dataset, software and hardware used in medical applications. Further, we discussed the comparative analysis of medical application using deep learning techniques.},
  keywords={},
  doi={10.1109/ICCIKE47802.2019.9004238},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6799500,
  author={Chattaraj, Ritwik and Bhattacharya, Srijan and Roy, Ankur and Mazumdar, Abhra and Bepari, Bikash and Bhaumik, Subhasis},
  booktitle={2014 Recent Advances in Engineering and Computational Sciences (RAECS)}, 
  title={Gesture based control of IPMC actuated gripper}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={Robotic grippers and its control is always a challenging and an interesting topic for the researcher. In the present scenario the most advanced gripping devices which are commercially available are of macro size. But the real challenge comes when we think for micro gripping or micro assembly. This paper represents a novel technique of gripping with Ionic Polymer Metal Composite (IPMC) actuated finger and advance communication process with the help of joystick and data glove. This technique gives an advantage to control a micro gripping device from a remote location. End effectors are made of IPMC. IPMC is one of the Electro Active Polymer (EAPs) which holds an excellent bending property at low actuation voltage resulting in high force output, thus it is capable of doing work as good as human finger tip when the same is employed as an actuator for micromanipulation. This device can manipulate micro object less than 1 mm in diameter as well as macro sized object within 10 mm diameter. This finger design is compliant in nature. In this article the underlying principle based on which the gripper operates and its fabrication process are explained in detail. It involves miniature part handling, integration and assembly operation.},
  keywords={Grippers;Data gloves;Thumb;Polymers;Actuators;Power supplies;Ionic Polymer Metal Composite;Electro Active Polymer;Data Glove;Joystick;Micro Gripper},
  doi={10.1109/RAECS.2014.6799500},
  ISSN={},
  month={March},}@INPROCEEDINGS{4937501,
  author={Collingsworth, Ben and Menezes, Ronaldo and Martins, Paulo},
  booktitle={2009 IEEE Symposium on Computational Intelligence for Financial Engineering}, 
  title={Assessing organizational stability via network analysis}, 
  year={2009},
  volume={},
  number={},
  pages={43-50},
  abstract={It is widely known that the email system forms a social network. Analysis of email networks reveals properties similar to classic social networks such as friendship or academic collaboration networks. Like other social networks, the properties observed in email networks are the result of patterns of human social behavior rather than the underlying technology. Hence, email social network properties correlate to the social environment in which they are generated. The overall social behavior observed in an organization may be attributed directly to organizational stability and robustness. As a result, organizational health and robustness may be discerned by examining the social network properties of the network formed by the email interaction of its employees because they certainly reflect changes in organizational mood. The fears, worries, gossips, the good and the bad, are reflected in the email activity of individuals in the organization; the challenge though is to extract his information from the network itself. In this paper we provide a first step in the process of demonstrating that email social network analysis can tell us more about the organization than we may think; we show using a case study based on the Enron corporation that problems in the organization were apparent as an emergent characteristic of social network formed by email exchange in the organization.},
  keywords={Stability analysis},
  doi={10.1109/CIFER.2009.4937501},
  ISSN={2380-8454},
  month={March},}@INPROCEEDINGS{4631237,
  author={Sheri, Guleng and Corne, David W.},
  booktitle={2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)}, 
  title={The simplest evolution/learning hybrid: LEM with KNN}, 
  year={2008},
  volume={},
  number={},
  pages={3244-3251},
  abstract={The learnable evolution model (LEM) was introduced by Michalski in 2000, and involves interleaved bouts of evolution and learning. Here we investigate LEM in (we think) its simplest form, using k-nearest neighbour as the dasialearningpsila mechanism. The essence of the hybridisation is that candidate children are filtered, before evaluation, based on predictions from the learning mechanism (which learns based on previous populations). We test the resulting dasiaKNNGApsila on the same set of problems that were used in the original LEM paper. We find that KNNGA provides very significant advantages in both solution speed and quality over the unadorned GA. This is in keeping with the original LEM paperpsilas results, in which the learning mechanism was AQ and the evolution/learning interface was more sophisticated. It is surprising and interesting to see such beneficial improvement in the GA after such a simple learning-based intervention. Since the only application-specific demand of KNN is a suitable distance measure (in that way it is more generally applicable than many other learning mechanisms), LEM methods using KNN are clearly recommended to explore for large-scale optimization tasks in which savings in evaluation time are necessary.},
  keywords={Gallium;Pediatrics;Evolution (biology);Next generation networking;Learning systems;Evolutionary computation;Prediction algorithms},
  doi={10.1109/CEC.2008.4631237},
  ISSN={1941-0026},
  month={June},}@INPROCEEDINGS{6724340,
  author={Gupta, Sonali and Bhatia, Komal Kumar},
  booktitle={2013 International Symposium on Computational and Business Intelligence}, 
  title={CrawlPart: Creating Crawl Partitions in Parallel Crawlers}, 
  year={2013},
  volume={},
  number={},
  pages={137-142},
  abstract={With the ever proliferating size and scale of the WWW [1], efficient ways of exploring content are of increasing importance. How can we efficiently retrieve information from it through crawling? And in this "era of tera" and multi-core processors, we ought to think of multi-threaded processes as a serving solution. So, even better how can we improve the crawling performance by using parallel crawlers that work independently? The paper devotes to the fundamental advantages and challenges arising from the design of parallel crawlers [4]. The paper mainly focuses on the aspect of URL distribution among the various parallel crawling processes. How to distribute URLs from the URL frontier to the various concurrently executing crawling process threads is an orthogonal problem. The paper provides a solution to the problem by designing a framework that partitions the URL frontier into a several URL queues by ordering the URLs within each of the distributed set of URLs.},
  keywords={Crawlers;Web pages;Databases;World Wide Web;Search engines;Servers;HTML;WWW;search engine;parallel crawler;Web-Partitioning;URL distribution;Scalability},
  doi={10.1109/ISCBI.2013.36},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{612297,
  author={Beigel, R. and Bin Fu},
  booktitle={Proceedings of Computational Complexity. Twelfth Annual IEEE Conference}, 
  title={Circuits over PP and PL}, 
  year={1997},
  volume={},
  number={},
  pages={24-35},
  abstract={C.B. Wilson's (1985) model of oracle gates provides a framework for considering reductions whose strength is intermediate between truth-table and Turing. Improving on a stream of results by previous authors, we prove that PL and PP are closed under NC/sub 1/ reductions. This answers an open problem of M. Ogihara (1996). More generally, we show that NC/sub k+1//sup PP/=AC/sub k//sup PP/ and NC/sub k+1//sup PL/=AC/sub k//sup PL/ for all k/spl ges/0. On the other hand, we construct an oracle A such that NC/sub k/(PP/sup A/)/spl ne/NC/sub k+1/(PP/sup A/) for all integers k/spl ges/1. Slightly weaker than NC/sub 1/ reductions are Boolean formula reductions. We ask whether PL and PP are closed under Boolean formula reductions. This is a nontrivial question despite NC/sub 1/=BF, because that equality is easily seen not to relativize. We prove that P/sub log2n/loglogn-T//sup PP//spl sube/BF/sup PP//spl sube/PrTIME(n/sup O(logn)/). Because P/sub log2n/loglogn-T//sup PP//spl nsub/PP relative to an oracle, we think it is unlikely that PP is closed under Boolean formula reductions. We also show that PL is unlikely to be closed under BF reductions.},
  keywords={Circuits;Computer science;Polynomials;NASA;Complexity theory;Upper bound},
  doi={10.1109/CCC.1997.612297},
  ISSN={1093-0159},
  month={June},}@ARTICLE{9935325,
  author={Razzak, Imran and Naz, Saeeda and Alinejad-Rokny, Hamid and Nguyen, Tu N. and Khalifa, Fahmi},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={A Cascaded Mutliresolution Ensemble Deep Learning Framework for Large Scale Alzheimer's Disease Detection Using Brain MRIs}, 
  year={2024},
  volume={21},
  number={4},
  pages={573-581},
  abstract={Alzheimer's is progressive and irreversible type of dementia, which causes degeneration and death of cells and their connections in the brain. AD worsens over time and greatly impacts patients’ life and affects their important mental functions, including thinking, the ability to carry on a conversation, and judgment and response to environment. Clinically, there is no single test to effectively diagnose Alzheimer disease. However, computed tomography (CT) and magnetic resonance imaging (MRI) scans can be used to help in AD diagnosis by observing critical changes in the size of different brain areas, typically parietal and temporal lobes areas. In this work, an integrative mulitresolutional ensemble deep learning-based framework is proposed to achieve better predictive performance for the diagnosis of Alzheimer disease. Unlike ResNet, DenseNet and their variants proposed pipeline utilizes PartialNet in a hierarchical design tailored to AD detection using brain MRIs. The advantage of the proposed analysis system is that PartialNet diversified the depth and deep supervision. Additionally, it also incorporates the properties of identity mappings which makes it powerful in better learning due to feature reuse. Besides, the proposed ensemble PartialNet is better in vanishing gradient, diminishing forward-flow with low number of parameters and better training time in comparison to its counter network. The proposed analysis pipeline has been tested and evaluated on benchmark ADNI dataset collected from 379 subjects patients. Quantitative validation of the obtained results documented our framework's capability, outperforming state-of-the-art learning approaches for both multi-and binary-class AD detection.},
  keywords={Alzheimer's disease;Diseases;Magnetic resonance imaging;Brain;Convolutional neural networks;Task analysis;Neuroimaging;Ensemble PartialNet;alzheimer disorder;dementia;early diagnosis},
  doi={10.1109/TCBB.2022.3219032},
  ISSN={1557-9964},
  month={July},}@INPROCEEDINGS{6597226,
  author={Weber, Philip and Bordbar, Behzad and Tin̂o, Peter},
  booktitle={2013 IEEE Symposium on Computational Intelligence and Data Mining (CIDM)}, 
  title={A principled approach to mining from noisy logs using Heuristics Miner}, 
  year={2013},
  volume={},
  number={},
  pages={119-126},
  abstract={Noise is a challenge for process mining algorithms, but there is no standard definition of noise nor accepted way to quantify it. This means it is not possible to mine with confidence from event logs which may not record the underlying process correctly. We discuss one way of thinking about noise in process mining. We consider mining from a `noisy log' as learning a probability distribution over traces, representing the true process, from a log which is a sample from multiple distributions: the `true' process model and one or more `noise' models. We apply this using a probabilistic analysis of the Heuristics Miner algorithm, and demonstrate on a simple example. We show that for a given model it is possible to predict how much data is needed to mine the underlying model without the noise, and identify differences in the the robustness of Heuristics Miner to different types of noise.},
  keywords={Noise;Data mining;Noise measurement;Probabilistic logic;Business;Algorithm design and analysis;Joints},
  doi={10.1109/CIDM.2013.6597226},
  ISSN={},
  month={April},}@ARTICLE{9779869,
  author={Stafford, Thomas F. and Duong, Bao Q.},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Social Media in Emerging Economies: A Cross-Cultural Comparison}, 
  year={2023},
  volume={10},
  number={3},
  pages={1160-1178},
  abstract={Social media are increasingly popular, worldwide, and when social media technologies extend from the Western markets in which they were developed into the Eastern markets where they are now used, marketing strategies that support technology uses in new cultural contexts must be developed. To inform this process achieve this, social media researchers must learn new ways of thinking about technology in its cultural context. In a comparative study of the Southeast Asian social media markets of Vietnam and Singapore, we induce a grounded theory perspective of social media cultures, comparing across instances of both an emerging market and an advanced market in the hemispheric region. We find the Vietnamese culture of social media use orients around economic productivity, Social Commerce, leveraging social connections to generate consumer-to-consumer commerce largely outside of government notice and taxation. The Singaporean culture of social media revolves around the important and highly implicit notion of Influence Commerce. Singaporeans are experts in their application of social media presence to monetize the process of exerting social influence on networks of information and opinion. The Singaporean media use culture takes place with full knowledge and support of the relevant government Bureaus since most internally produced social media influence is political in nature and friendly to the ruling powers.},
  keywords={Social networking (online);Media;Encoding;Cultural differences;Business;Asia;Interviews;Facebook;information and communication technology;Internet social computing},
  doi={10.1109/TCSS.2022.3169412},
  ISSN={2329-924X},
  month={June},}@INPROCEEDINGS{9751832,
  author={Rathod, Nishit A and Gupta, Tanuj and Sharma, Neha V and Sharma, Saurabh},
  booktitle={2021 International Conference on Computational Performance Evaluation (ComPE)}, 
  title={Model Comparison and Multiclass Implementation Analysis on the UNSW NB15 Dataset}, 
  year={2021},
  volume={},
  number={},
  pages={549-555},
  abstract={As the world has seen a dramatic ascent in the utilization of innovation in recent many years, the field of network safety has gotten always significant. Because of this, it has seen numerous advancements with the field of AI assuming a gigantic part in it. As AI or profound learning is additionally turning out to be further developed every day, use its advantages. Over, the most recent couple of years we have likewise seen a significant ascent in information significance which has made information assortment and development essential. This paper centers around the advancement of Network Intrusion Detection Systems (NIDS) utilizing Deep Learning. NIDS or IDS are utilized to identify any organizations which might act as an assault on any framework. We have utilized the UNSW NB15 dataset for our methodology as it is the latest and is enhanced different variables from its archetype and generally chipped away at the dataset – KDD CUP 99. We have utilized different normalizing instruments and extra trees classifier to set up the dataset for proper profound learning models and highlight determination. The executions utilized here are – Convolutional Neural Network, Recurrent Neural Network, and Long Recurrent Convolutional - Network to think about the outcomes. The arrangements carried out in this paper are both in double and multiclass with the significant center in regard to greatest full- scale accuracy, review, and f-score for the multiclass approach utilizing a connection of proper assault types and a way for additional exploration},
  keywords={Performance evaluation;Analytical models;Technological innovation;Recurrent neural networks;Reconnaissance;Turning;Safety;Convolutional Neural Network;Recurrent Neural Network;Long Recurrent Convolutional Neural Network;UNSW NB15;Network Intrusion Detection System;Cyber Security},
  doi={10.1109/ComPE53109.2021.9751832},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6633624,
  author={Maggiore, Giuseppe and Santos, Carlos and Dini, Dino and Peters, Frank and Bouwknegt, Hans and Spronck, Pieter},
  booktitle={2013 IEEE Conference on Computational Inteligence in Games (CIG)}, 
  title={LGOAP: Adaptive layered planning for real-time videogames}, 
  year={2013},
  volume={},
  number={},
  pages={1-8},
  abstract={One of the main aims of game AI research is the building of challenging and believable artificial opponents that act as if capable of strategic thinking. In this paper we describe a novel mechanism that successfully endows NPCs in real-time games with strategic planning capabilities. Our approach creates adaptive behaviours that take into account long-term and short term consequences. Our approach is unique in that: (i) it is sufficiently fast to be used for hundreds of agents in real time; (ii) it is flexible in that it requires no previous knowledge of the playing field; and (iii) it allows customization of the agents in order to generate differentiated behaviours that derive from virtual personalities.},
  keywords={Games;Planning;Real-time systems;Artificial intelligence;Complexity theory;Logic programming;Cities and towns;Games AI;planning},
  doi={10.1109/CIG.2013.6633624},
  ISSN={2325-4289},
  month={Aug},}@ARTICLE{10057228,
  author={Wang, Tan and Ye, Peijun and Lv, Hongqiang and Gong, Weichao and Lu, Hao and Wang, Fei-Yue},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Modeling Digital Personality: A Fuzzy-Logic-Based Myers–Briggs Type Indicator for Fine-Grained Analytics of Digital Human}, 
  year={2024},
  volume={11},
  number={1},
  pages={1096-1107},
  abstract={Digital human in cyberspace can help provide humanized services in specific applications, such as question & answer systems, recommender systems, chatter robots, and intelligent assistants. While most researches focus on behavior analytics, few of them integrate the personality that is also a closely related factor. As a classic indicator for personality representation, Myers–Briggs type indicator (MBTI) categorizes an individual into mutually exclusive types from four dichotomous axes (extraversion versus introversion, sensing versus intuition, thinking versus feeling, judging versus perceiving). Traditional recognition method using MBTI simply measures the user’s preference frequency in each axis through questionnaires, treating the dominant value as the identified result. Such a paradigm, however, represents all the people with only 16 types and cannot distinguish heterogeneous users clearly. This article proposes a novel personality recognition method using fuzzy logic. Different from previous classifications, our new method categorizes the individual in a continuous space and represents one’s personality in a more fine-grained level. We have designed comparative psychological tests for 77 people. The validation experiments on such tests indicate that the fuzzy-logic-based method is not only consistent with the classic MBTI tests (in the sense of defuzzification) but also provides the uncertainty for each personality type. Therefore, it can be viewed as a generalization of the classic MBTI tests and promotes the representation of individual’s heterogeneity for fine-grained analytics of digital human.},
  keywords={Psychology;Fuzzy logic;Automation;Technological innovation;Uncertainty;Soft sensors;Social networking (online);Digital human;digital personality;fuzzy logic reasoning;fuzzy personality recognition;Myers-Briggs type indicator (MBTI)},
  doi={10.1109/TCSS.2023.3245127},
  ISSN={2329-924X},
  month={Feb},}@INPROCEEDINGS{9459223,
  author={Yi, XingCheng and Zhang, Yan and Xu, Tong and Su, Xiaoyun and Fu, Cong},
  booktitle={2021 IEEE 9th International Conference on Bioinformatics and Computational Biology (ICBCB)}, 
  title={Study on Pathological Mechanism of Pneumonia Infected by Coronavirus Based on Time-Series Gene Co-expression Network Analysis}, 
  year={2021},
  volume={},
  number={},
  pages={168-173},
  abstract={Recently, the epidemic of COVID-19 infection broke out in Wuhan, China. To explore the pathological mechanism of pneumonia infected by coronavirus, we built a bioinformatics pipeline based on time-series gene co-expression network analysis to analyze the gene expression profile of lung cells in mice infected by SARS-Cov (GSE19137). In this study, Pearson correlation analysis was performed to construct a gene co-expression network. Time-ordered gene network modules were digged out by BFS algorithm. PageRank algorithm was used to explore HUB genes related to pneumonia infected by coronavirus. Based on the information we got, we think that cell lines infected by coronavirus might go through 5 stages, and 10 HUB genes(AKT1, CD68, CTSS, FCGR3A, HSPA8, PTPRC, UBC, VCP, PRPF31, ITPKB) might play a key role in coronavirus infection. This might provide some hints for coronavirus related research.},
  keywords={COVID-19;Pathology;Epidemics;Correlation;Pulmonary diseases;Pipelines;Lung;coronavirus;time-series gene co-expression network;PageRank algorithm;BFS algorithm},
  doi={10.1109/ICBCB52223.2021.9459223},
  ISSN={},
  month={May},}@INPROCEEDINGS{5284095,
  author={Diehl, Christopher P. and Montemayor, Jaime and Pekala, Mike},
  booktitle={2009 International Conference on Computational Science and Engineering}, 
  title={Social Relationship Identification: An Example of Social Query}, 
  year={2009},
  volume={4},
  number={},
  pages={381-388},
  abstract={Every moment, millions of people worldwide are communicating and sharing content online. We express ourselves online to enrich existing relationships and establish new relationships that would otherwise be difficult or impossible to develop offline. Such actions are reflected in a corresponding set of digital social artifacts, such as blog posts, emails and status updates. We are accustomed to thinking of collections of digital artifacts online as repositories of information. What if we are now searching collections of digital social artifacts that reflect people's online relationships with one another and aspects of their lives? Are standard search methods sufficient? How do we want to query such data? We contend that general queries may have both informational and social components to them. We define social queries as queries about social attributes and behaviors that identify individuals, relationships or groups exhibiting such characteristics. To develop a deeper understanding of social query, we focus on the specific task of social relationship identification. In the context of two scenarios, we examine the challenges posed by the task, review an initial realization of social relationship identification and present a way forward to address the general task.},
  keywords={Information services;Web sites;Internet;Search engines;Search methods;Blogs;Physics computing;Laboratories;Fellows;Social network services;social query;social relationship identification;preference learning},
  doi={10.1109/CSE.2009.211},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8902352,
  author={Willcox, Gregg and Rosenberg, Louis and Donovan, Rory and Schumann, Hans},
  booktitle={2019 11th International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={Dense Neural Network used to Amplify the Forecasting Accuracy of real-time Human Swarms}, 
  year={2019},
  volume={},
  number={},
  pages={69-74},
  abstract={Artificial Swarm Intelligence (ASI) is a hybrid AI technology that enables distributed human groups to "think together" in real-time systems modeled on natural swarms. Prior research has shown that by forming "human swarms," networked groups can substantially amplify their combined intelligence and produce significantly more accurate forecasts than traditional methods. The present study explores whether the rich behavioral data collected during "swarming" can be used to further increase the accuracy of swarm-based forecasts. To do this, a dense neural network was used to process the data collected during a set of swarm-based forecasts and generate a Conviction Index (CI) for each forecast that estimates its expected accuracy. This method was then tested in an authentic forecasting task – wagering on sporting events against the Vegas odds. Specifically, groups of sports fans, working as real-time swarms, were tasked with predicting the outcome of 238 NBA games over 25 consecutive weeks. As a baseline, the swarms achieved an impressive 25% net return on investment (ROI) against the Vegas Odds. This was compared to an enhanced method that used Conviction Index to (a) estimate the strength of each forecast and then (b) wager only on forecasts of sufficient strength. The CI-selected wagers yielded a 57% net ROI against Vegas Odds. This is a significant gain, equivalent to more than doubling the ROI of the naïve swarm betting strategy.},
  keywords={Swarm Intelligence;Artificial Swarm Intelligence;Collective Intelligence;Human Swarming;Artificial Intelligence;Collaborative Intelligence;Machine Learning;Sports Forecasting;Wisdom of Crowds},
  doi={10.1109/CICN.2019.8902352},
  ISSN={2472-7555},
  month={Jan},}@INPROCEEDINGS{7449861,
  author={Gao, Jinsheng and Zhou, Changle},
  booktitle={2016 Eighth International Conference on Advanced Computational Intelligence (ICACI)}, 
  title={A reasoning system about knowledge acquisition in bi-agent interaction}, 
  year={2016},
  volume={},
  number={},
  pages={412-417},
  abstract={In artificial intelligence, knowledge acquisition and reasoning are the most basic key elements for intelligent agent to obtain the ability of the simulation thinking which capacitate intelligent agent to carry out a series of actions. At present, Dynamic Epistemic Logic (DEL) has been a primary technique for modelling knowledge acquisition and reasoning. This is mainly due to the dynamic epistemic logic has a stronger expression ability to deal with many problems about agent's cognitive reasoning in computer science. In this paper, we distinguish the major sorts of knowledge that the cognitive agent will hold in their interaction in the beginning, and then establish a Knowledge Acquisition System (KAS) which is added a new operator of `knowledge acquisition' to extend the basic epistemic language for bi-agent interaction. Other than that, we prove the soundness and completeness of this system, and analyze some properties about it. By this system, it is clear to explain how the agent acquires knowledge that will be transformed into common knowledge by observing the other agent's speech act. The acquired knowledge is further transformed into new private knowledge that provides the strategy options in agent's mind in interaction.},
  keywords={Cognition;Knowledge acquisition;Intelligent agents;Speech;Semantics;Electronic mail;artificial intelligence;bi-agent interaction;knowledge acquisition;private knowledge;common knowledge},
  doi={10.1109/ICACI.2016.7449861},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{4631011,
  author={Mason, Jonathan and Menezes, Ronaldo},
  booktitle={2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)}, 
  title={Autonomous algorithms for terrain coverage metrics, classification and evaluation}, 
  year={2008},
  volume={},
  number={},
  pages={1641-1648},
  abstract={Terrain coverage algorithms are quite common in the computer science literature and for a good reason: they are able to deal with a diverse set of problems we face. From Web crawling to automated harvesting, from spell checking to area reconnaissance by unmanned aerial vehicles (UAVs), a good terrain coverage algorithm lies at the core of a successful approach to these and other problems. Despite the popularity of terrain coverage, none of the works in the field addresses the important issue of classification and evaluation of these algorithms. It is easy to think that all algorithms (since they are all called terrain coverage) deal with the same problem but this is a fallacy that this paper tries to correct. This paper presents a summary of many algorithms in the field, classifies them based on their goals, introduces metrics to evaluate them, and finally performs the evaluation.},
  keywords={Classification algorithms;Algorithm design and analysis;Time measurement;Lattices;Evolutionary computation;Redundancy;Area measurement},
  doi={10.1109/CEC.2008.4631011},
  ISSN={1941-0026},
  month={June},}@INPROCEEDINGS{6085916,
  author={Jeckmans, Arjan and Tang, Qiang and Hartel, Pieter},
  booktitle={2011 International Conference on Computational Aspects of Social Networks (CASoN)}, 
  title={Privacy-preserving profile matching using the social graph}, 
  year={2011},
  volume={},
  number={},
  pages={42-47},
  abstract={We present a privacy-preserving protocol for users to test a match with potential new friends in an environment where all users cryptographically encrypt their private information. The following scenario is considered. Suppose that user Alice thinks that Bob might be a good new friend. So, Alice and the Online Social Network (representing Bob) engage in a two-party matching protocol. In this protocol no work from Bob is required, Bob can be offline. The matching protocol is designed to give Alice an indication if Bob is similar to her based on their profiles. We show that the process does so without revealing the private information of Alice and Bob to one another and to the Online Social Network.},
  keywords={Public key;Protocols;Polynomials;Encryption;Social network services;Online Social Network;profile privacy;profile matching;secret distribution},
  doi={10.1109/CASON.2011.6085916},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9930608,
  author={Mustaffa, Zuriani and Zaidi, Nur Alia Shahira Mohd and Ernawan, Ferda and Elhadi, Haithm and Hakim, Muhammad Malik},
  booktitle={2022 6th International Conference on Informatics and Computational Sciences (ICICoS)}, 
  title={Personality Predictive Analysis Based on Artificial Neural Network}, 
  year={2022},
  volume={},
  number={},
  pages={105-110},
  abstract={Individual personality is a vital criterion in a human life as well as in a development of an organization. Every individual holds a different personality type with various characteristics in terms of thinking, feeling, and behaving. Due to that matter, analyzing human personality should be done carefully which can be challenging and time consuming. Therefore, this study presents a personality prediction model based on Artificial Neural Network (ANN). The prediction was realized on the Big Five personality model. The dataset consists of 709 rows and retrieved from open-source website called Kaggle. For training, validation and testing phases, the dataset was divided into 70:15:15 respectively. Findings of the study demonstrated the capability of ANN in producing better accuracy compared to three identified algorithms which includes Naïve Bayes, ZeroR and Random Forest.},
  keywords={Training;Artificial neural networks;Organizations;Predictive models;Prediction algorithms;Data models;Task analysis;Artificial Neural Network;Big Five Personality;Personality prediction},
  doi={10.1109/ICICoS56336.2022.9930608},
  ISSN={2767-7087},
  month={Sep.},}@ARTICLE{10379489,
  author={Ibrahim, Hazem and Debicki, Mikolaj and Rahwan, Talal and Zaki, Yasir},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Big Tech Dominance Despite Global Mistrust}, 
  year={2024},
  volume={11},
  number={3},
  pages={3741-3752},
  abstract={The technological and online experiences of billions worldwide are dominated by a handful of companies known as “Big Tech.” Despite this being a cause for concern in governmental, economic, and ethical spheres, the literature lacks a study exploring the impact of public scandals on, and the global sentiment toward, Big Tech. Here, we quantify the power of Big Tech by analyzing their acquisitions, market capitalization, and number of monthly active users. Moreover, we utilize the synthetic control method to estimate the effect of public scandals on the stock price of two Big Tech companies, and find that they had no lasting effect. We also analyze the number of tweets mentioning these scandals, and find that they quickly fade from the spotlight. To explore public sentiment, we survey 5300 participants across 25 countries, and find that those from countries with lower digital literacy and more authoritarian regimes are more trusting of Big Tech. Furthermore, we find that one in three feels they lack control over the data collected about them, and one in four feels that Big Tech knows what they are thinking, knows more about them than their best friend, and may even be secretly listening to their conversations. Additionally, one in four feels addicted to Big Tech products, have no choice but to use them, and wishes there were more companies to choose from. These findings highlight the adverse effect of the oligopolistic nature of Big Tech on consumer choice and help inform policy-makers aiming to curb their dominance.},
  keywords={Companies;Internet;Surveys;Privacy;Social networking (online);Regulation;Indexes;Policy;technology;trust},
  doi={10.1109/TCSS.2023.3339183},
  ISSN={2329-924X},
  month={June},}@INPROCEEDINGS{10193910,
  author={Harb, Atef and Trad, Mony and Harb, John and Kassem, Abdallah},
  booktitle={2023 Fifth International Conference on Advances in Computational Tools for Engineering Applications (ACTEA)}, 
  title={Analysis and Evaluation of the Behavior and Awareness of the Lebanese Society Regarding Electronic Waste Management}, 
  year={2023},
  volume={},
  number={},
  pages={173-177},
  abstract={This paper presents a part of research into e-waste and e-cycling in Lebanon; it describes the status quo of today's governmental and NGO's actions, tools, and intentions about e-waste. The research questions answered throughout this paper are two: the first one wonders if the Lebanese society and government are aware of the e-waste hazards and whether there is any action taken, on the governmental level, to avert an environmental catastrophe. Whereas the second one is concerned with finding out, what Lebanese think about e-waste and whether they are willing to fight against it? Answers to the first question resulted from interviews. The authors have visited Company A and NGO B, the first is concerned with collecting waste in greater Beirut while the second aims at spreading awareness to e-waste's dangers on governmental and social levels alike. Question two was discussed throughout surveys filled by random individuals from Lebanese society. The answers to both research questions came in a way that proves both hypotheses assumed at the beginning of the research, namely that e-waste poses a great threat to the Lebanese environment and that laws must be implemented to regulate collection and disposal of electronic appliances; also, e-cycling initiatives must be encouraged to reduce the quantities of generated e-waste. Hypothesis two if environment friendliness and affinity to right e-waste disposal depend on the educational level of any given citizen has been proven to be true while analyzing the answers in the survey.},
  keywords={Surveys;Government;Companies;Electronic waste;Question answering (information retrieval);Hazards;Behavioral sciences;e-waste;e-cycling;WEEE;waste management;pollution;electrical appliances;electronic devices;environmental awareness;refurbished products;recycled materials;Engineering process},
  doi={10.1109/ACTEA58025.2023.10193910},
  ISSN={},
  month={July},}@INPROCEEDINGS{8883022,
  author={Kollipara, Praneetha Bose and Regalla, Lokesh and Ghosh, Goldina and Kasturi, Nivedita},
  booktitle={2019 Second International Conference on Advanced Computational and Communication Paradigms (ICACCP)}, 
  title={Selecting Project Team Members through MBTI Method: An Investigation with Homophily and Behavioural Analysis}, 
  year={2019},
  volume={},
  number={},
  pages={1-9},
  abstract={Myers Briggs Type Indicator (MBTI) is the method through which test is done to measure the psychological condition of a person in viewing the world and making the decision. It is generally divided into 4 preference sets namely,' Extraversion - Introversion,' `Sensing - Intuition',' Thinking - Feeling',' Judgment - Perception'. This test is applied in many areas like, for recruitment of people into jobs, to choose career depending on one's personality, to estimate a person himself/herself, selecting optional subjects in universities. Here, the aim of the research work was to propose an optimized prediction analysis for allotting members to a project by the Project Manager by testing the members' ability through MBTI testing method and further analyzing and justifying that the person selected was most suitable for the project or required some advice for their improvement in the work. By using MBTI assessment the dataset for the proposed work has been created. For developing the experimental work, collection of answers for the predesigned questionnaire available in MBTI site from our college students were taken. Based on these data a novel method was developed to select a group of members who are fit to be in that project according to the requirements of the project manager. This is done through Homophily affect and thus study the behavior of each member within the group to test the rate of appropriate members selected by the project manager. Simulation was done by using R-studio and MATLAB thereby identifying the weak and strong bond among the members of the project.},
  keywords={Leadership;Computer science;Sensors;Testing;Social networking (online);Engineering profession;Data visualization;Homophily;MBTI;Behavioral Analysis;Random Sampling Method;Data Visualization},
  doi={10.1109/ICACCP.2019.8883022},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{4052678,
  author={Poli, Jean-philippe and Carrive, Jean},
  booktitle={2006 International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce (CIMCA'06)}, 
  title={Improving Program Guides for Reducing TV Stream Structuring Problem to a Simple Alignment Problem}, 
  year={2006},
  volume={},
  number={},
  pages={31-31},
  abstract={TV stream structuring is the first step in the description process of telecasts for TV archives holders like the French National Audiovisual Institute. It consists in breaking down automatically the stream into telecasts and advertisings. One can think TV stream structuring consists in a simple alignment of the TV guide (for example electronic program guide or TV magazines) on the stream. But our study shows that only 34% of telecasts appear in program guides. In average, 2 hours per day, composed of short telecasts and advertisings, are missing. We propose in this article a way to model and predict TV schedules (one day or one week of telecasts on a channel) by using a new extension of Markov models and regression trees. The goal is that the improved schedules obtained by the prediction can be aligned on the stream.},
  keywords={Streaming media;Hidden Markov models;Context modeling;Advertising;Regression tree analysis;Processor scheduling;Layout;TV broadcasting;Predictive models;Indexing},
  doi={10.1109/CIMCA.2006.124},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{6571360,
  author={Stirparo, Pasquale},
  booktitle={2013 Fifth International Conference on Computational Intelligence, Communication Systems and Networks}, 
  title={A Fuzzing Framework for the Security Evaluation of NDEF Message Format}, 
  year={2013},
  volume={},
  number={},
  pages={165-170},
  abstract={In the very near future, the vast majority of mobile phones will be NFC-enabled. The NFC technology, other than adding extra features to mobile devices, adds a new way for attackers to break into these. To be sure that attackers will go after this technology, it is enough to think that the killer feature foreseen for this technology it will be the possibility for the user to pay on the fly with his phone, by simply putting the smartphone in close proximity to the payment device. The aim of this paper is to draw the attention to one aspect related to the security of NFC devices, the NFC Data Exchange Format (NDEF). In this paper will be introduced techniques for testing NDEF, as well as to propose a new solution for fuzz testing NDEF on smart phones.},
  keywords={Smart phones;Security;Testing;Payloads;Mobile communication;Protocols;Android;NFC;mobile security;fuzzing},
  doi={10.1109/CICSYN.2013.58},
  ISSN={},
  month={June},}@INPROCEEDINGS{10582950,
  author={Varga, János and Kahler-Korcsmáros, Enikő and Csiszárik-Kocsir, Ágnes},
  booktitle={2024 IEEE 11th International Conference on Computational Cybernetics and Cyber-Medical Systems (ICCC)}, 
  title={Perceptions of Local Macroeconomic Challenges Faced by Hungarian Enterprises and How to Meet Them Along Competitiveness Dimensions}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The 2000s held many challenges for humanity. The 2008 mortgage crisis significantly redrawn our financial thinking and changed our attitudes towards financial products. The effects that thousands of people have suffered as a result of poorly made financial decisions have contributed to all these processes. The same characteristics could be said for businesses. Following the mortgage crisis, we became acquainted with a number of other financial crises during the 2000s, but a new level after all this was still the coronavirus epidemic escalated in 2020 and the ensuing crisis. The growing digitalisation challenge, the advancement of artificial intelligence, and the automation of processes are causing headaches for many small and medium-sized enterprises. Businesses around the world face these challenges, sometimes stronger and weaker. The aim of our study is to present the local, macroeconomic challenges and the assessment of those whose competitiveness is affected and influenced by the results of a questionnaire research conducted in Hungary. The research is part of an international survey, in our present study we want to present the effects in Hungary.},
  keywords={Surveys;Loans and mortgages;Humanities;Companies;Environmental factors;Regulation;Macroeconomics;competitiveness;local challenges;macroeconomic factors;Hungary},
  doi={10.1109/ICCC62278.2024.10582950},
  ISSN={},
  month={April},}@ARTICLE{10689567,
  author={Shen, Qiqi and Ma, Miao and Li, Mengge},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={An Extensible Bounded Rationality-Based Task Recommendation Scheme for From-Scratch Mobile Crowdsensing}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Mobile crowdsensing (MCS) has recently shown good performance in solving large-scale sensing tasks. As an essential topic in MCS, recommending tasks to participants has received extensive attention from researchers. Most studies assume that participants are absolutely rational, which is unrealistic because it is difficult for participants to know all the information about the transaction. Furthermore, most of them do not consider how to learn the preferences of new participants. In addition, their works are difficult to extend to different MCS scenarios. Considering the above problems, we propose an extensible bounded rationality-based task recommendation scheme (EBRTR), which contains a task recommendation framework and a bounded rationality decision-making model. First, a task recommendation framework that can be easily extended to various MCS scenarios is designed. Second, in our bounded rationality decision-making model, for participants with historical task information, according to the implicit information in their historical tasks, the human thinking mode with bounded rationality is simulated, and the improved classification and regression tree (ICART) algorithm is designed to construct the decision tree. For participants who newly join the platform, social information is introduced to construct an initial decision tree. Finally, extensive experimental evaluations demonstrate the effectiveness of the proposed scheme.},
  keywords={Decision making;Sensors;Crowdsensing;Mobile computing;Tensors;Symbols;Costs;Bounded rationality;decision-making model;mobile crowdsensing (MCS);task recommendation},
  doi={10.1109/TCSS.2024.3452099},
  ISSN={2329-924X},
  month={},}@INPROCEEDINGS{10666582,
  author={Contreras, Mauricio Rojas and Jaimes, Jorge Omar Portilla},
  booktitle={2024 IEEE Colombian Conference on Applications of Computational Intelligence (ColCACI)}, 
  title={Artificial Intelligence Literacy in Research}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This research article examines the use of artificial intelligence (AI) literacy in the field of research. Employing a multi-method methodological approach, it integrates narrative review, a quasi-experiment of an AI literacy course, and methodological triangulation. As a result, it describes a comprehensive content construct to develop AI literacy processes aimed at researchers. This construct encompasses generic competencies, generative AI, search engines, document interaction, document analysis by characteristics, generation of co-citation maps, literature reviews, database integration, data analysis, research tools, ethics in AI literacy, development of critical thinking through AI, and evaluation of AI literacy. The proposal provides a solid guide to strengthen the understanding and application of AI in research.},
  keywords={Ethics;Text analysis;Data analysis;Reviews;Generative AI;Databases;Search engines;AI Literacy;Research;AI Ethics;AI Literacy Frameworks;AI Literacy Assessment},
  doi={10.1109/ColCACI63187.2024.10666582},
  ISSN={2769-3643},
  month={July},}@INPROCEEDINGS{637497,
  author={Hutchins, S.G. and Kemple, W.G. and Entin, E.E. and Kleinman, D.L.},
  booktitle={1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation}, 
  title={Measures of effectiveness under different command and control organizational architectures}, 
  year={1997},
  volume={5},
  number={},
  pages={4342-4347 vol.5},
  abstract={Today's military faces enormous pressure to downsize and restructure. In addition, operations-other-than-war, such as humanitarian assistance and peace-keeping, differ significantly from traditional combat missions. The unique characteristics of peace-keeping missions involve inherently more complex command arrangements. Moreover, the increased political sensitivity associated with these missions further exacerbates the stress on command and control (C2) arrangements. Thus, Joint and Coalition doctrine is more complex and reliant on the synchronized employment of combined arms. The process of organizing for Joint and Coalition operations must be driven by the disparate missions and the requisite tasks involved. Depending on the specific mission, the diverse range of future anticipated operations can require a wide variety of service capabilities under a Joint Force Coalition. It follows that the C2 organization should be flexible in order to allow commanders to meet the many and diverse operations that are expected to continue to undertaken. This paper reports on the use of measurement instruments developed for the initial experiment conducted under the Adaptive Architectures for Command and Control (A2C2) program. The goal of the A2C2 research effort is to provide insights based on exploring innovative thinking and empirical research on organizational design that can assist in positioning the Joint community to face the diverse challenges and dynamic changes that are projected for the future.},
  keywords={Command and control systems;Organizing;Personnel;Pressure control;Stress;Employment;Arm;Instruments;Programmable control;Adaptive control},
  doi={10.1109/ICSMC.1997.637497},
  ISSN={1062-922X},
  month={Oct},}@INPROCEEDINGS{1006638,
  author={Gomez-Skarmeta, A.F. and Jimenez, F. and Valdes, M. and Botia, J.A. and Padilla, A.M.},
  booktitle={2002 IEEE World Congress on Computational Intelligence. 2002 IEEE International Conference on Fuzzy Systems. FUZZ-IEEE'02. Proceedings (Cat. No.02CH37291)}, 
  title={Towards a modeling framework for integrating hybrid techniques}, 
  year={2002},
  volume={2},
  number={},
  pages={985-990 vol.2},
  abstract={Nowadays, it is easy to find a number of different hybrid approaches for fuzzy modeling. All these approaches were built in a very ad-hoc manner, and did not follow a systematic approach. However, we think that some kind of information system which helps in the study of how algorithms can combine to model systems in a fuzzy fashion should be very helpful. In this article, we propose METALA (META-Learning Architecture), an architecture to study the typical processes of machine learning, to study the particular issue of fuzzy modeling.},
  keywords={Fuzzy systems;Fuzzy sets;Context modeling;Machine learning;Parameter estimation;Input variables;Information systems;Machine learning algorithms;Merging;Learning systems},
  doi={10.1109/FUZZ.2002.1006638},
  ISSN={},
  month={May},}@INPROCEEDINGS{7008676,
  author={ElGibreen, Hebah and Aksoy, Mehmet Sabih},
  booktitle={2014 IEEE Symposium on Computational Intelligence and Data Mining (CIDM)}, 
  title={Incremental transfer RULES with incomplete data}, 
  year={2014},
  volume={},
  number={},
  pages={257-264},
  abstract={Recently strong AI emerged from artificial intelligence due to need for a thinking machine. In this domain, it is necessary to deal with dynamic incomplete data and understanding of how machines make their decision is also important, especially in information system domain. One type of learning called Covering Algorithms (CA) can be used instead of the difficult statistical machine learning methods to produce simple rule with powerful prediction ability. However, although using CA as the base of strong AI is a novel idea, doing so with the current methods available is not possible. Thus, this paper presents a novel CA (RULES-IT) and tests its performance over incomplete data. This algorithm is the first incremental algorithm in its family, and CA as a whole, that transfer rules from different domains and introduce intelligent aspects using simple representation. The performance of RULES-IT will be tested over incomplete and complete data along with other algorithms in the literature. It will be validated using 5-fold cross validation in addition to Friedman with Nemenyi post hoc tests to measure the significance and rank the algorithms.},
  keywords={Training;Complexity theory;Artificial intelligence;Classification algorithms;Accuracy;Measurement uncertainty;Error analysis;Incremental Learning;Incomplete Data;Transfer Learning;Covering Algorithms;Rules Family},
  doi={10.1109/CIDM.2014.7008676},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9865351,
  author={Privodnova, Evgeniya Yu. and Volf, Nina V.},
  booktitle={2022 Ural-Siberian Conference on Computational Technologies in Cognitive Science, Genomics and Biomedicine (CSGB)}, 
  title={Effect of Cognitive Stimulation with Creativity Tasks on Resting-State EEG Alpha Power Depends on BDNF Val66Met Polymorphism}, 
  year={2022},
  volume={},
  number={},
  pages={200-204},
  abstract={Main functions of brain-derived neurotrophic factor (BDNF) are neuroprotection and synaptic plasticity. A common single nucleotide polymorphism in the human BDNF gene (Val66Met) impairs activity-dependent secretion of the BDNF, and carrying Met allele is associated with poorer learning. We explored the role of BDNF polymorphism in short-term plasticity induced by complex cognitive stimulation with creativity thinking tasks in Caucasian adults from younger (22.7±3.7 years old, N = 63) and older (63.5±5.2 years old, N = 49) age groups. Resting-state EEG with eyes open was recorded prior to and immediately after forty-minute verbal and figural creative task performance. The EEG spectral density in individual alpha frequency band was calculated using FFT in pre-task and post-task intervals. All subjects were genotyped for BDNF status. ANOVA revealed more left-sided (left>right) changes from pre-task to post-task intervals in Val/Val homozygotes in comparison with Met carriers. BDNF-associated alpha power asymmetry indicator in frontal region, which is well-known manifestation of motivational withdrawal/approach, was strongly correlated with interest in tasks (not with originality, amount of ideas, or task difficulty). Mediation analysis confirmed that attenuated frontal asymmetry (left-right) of pre/post task changes in Met carriers in comparison to Val/Val was associated with lower interest in tasks - component of internal motivation for creative problem solving. These findings suggest that complex cognitive stimulation with creativity tasks induced tendency towards withdrawal motivation in Met carriers in comparison to Val/Val at the level of brain activity.},
  keywords={Brain;Genomics;Electroencephalography;Task analysis;Mediation;Bioinformatics;Creativity;brain-derived neurotrophic factor (BDNF);BDNF Val66Met polymorphism;short-term plasticity;alpha power;hemispheric asymmetry;withdrawal/approach},
  doi={10.1109/CSGB56354.2022.9865351},
  ISSN={},
  month={July},}@INPROCEEDINGS{10433950,
  author={G, Abirami and Poornima, D. and Premalatha, J. Sarojini and Mayura Shivani R, Ridhi and Shree, T. Bhanu},
  booktitle={2023 International Conference on Emerging Research in Computational Science (ICERCS)}, 
  title={Implementation of smart sensors with Swarm Intelligence for Disease Diagnosis in Smart Environments}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Disease diagnosis in smart settings has been transformed by the fast development of technology, especially the Internet of Things (IoT) and Swarm Intelligence. Various health-related data may be continually monitored and collected in smart environments due to the abundance of sensors. However, this data's vast quantity and complexity complicates accurate illness diagnosis and early management. Inspired by the coordinated actions of flocks of birds and swarms of insects, Swarm Intelligence provides a novel paradigm for analyzing and understanding this mountain of data. Hence, this paper proposes a Swarm Intelligence-enabled Disease Diagnosis (SI-DD) in smart environments using IoT-based sensors. Smart systems use algorithms motivated by swarm behaviour to assess data from several sensors in concert, allowing for faster, more accurate illness diagnosis. As a shape of collective swarm intelligence, Ant Colony Optimization (ACO) enables make healthcare treatments more effective. As a result, sufferers get care tailor-made to their unique desires, thinking about their scientific history and the kingdom of the healthcare machine. This article examines the most distinguished makes use of the Internet of Things and Swarm Intelligence in healthcare. It highlights how those techniques have already shown their promise for higher contamination detection. With this in thoughts, it's clear that the usage of clever sensors prepared with Swarm Intelligence for infection detection in clever settings is a viable path toward enhancing healthcare results and the first-rate of existence for sufferers. This novel approach has the capability to revolutionize contamination surveillance, prognosis, and control, leading to greater cost-effective scientific services and higher results for sufferers.},
  keywords={Shape;Surveillance;Medical diagnosis;Internet of Things;Particle swarm optimization;Intelligent sensors;Contamination;Disease diagnosis;Smart Sensor;Internet of Things;Swarm Intelligence;Smart environment},
  doi={10.1109/ICERCS57948.2023.10433950},
  ISSN={},
  month={Dec},}@ARTICLE{10597373,
  author={Sánchez-Corcuera, Rubén and Zubiaga, Arkaitz and Almeida, Aitor},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Early Detection and Prevention of Malicious User Behavior on Twitter Using Deep Learning Techniques}, 
  year={2024},
  volume={11},
  number={5},
  pages={6649-6661},
  abstract={Organized misinformation campaigns on Twitter continue to proliferate, even as the platform acknowledges such activities through its transparency center. These deceptive initiatives significantly impact vital societal issues, including climate change, thus spurring research aimed at pinpointing and intercepting these malicious actors. Present-day algorithms for detecting bots harness an array of data drawn from user profiles, tweets, and network configurations, delivering commendable outcomes. Yet, these strategies mainly concentrate on postincident identification of malevolent users, hinging on static training datasets that categorize individuals based on historical activities. Diverging from this approach, we advocate for a forward-thinking methodology, which utilizes user data to foresee and mitigate potential threats before their realization, thereby cultivating more secure, equitable, and unbiased online communities. To this end, our proposed technique forecasts malevolent activities by tracing the projected trajectories of user embeddings before any malevolent action materializes. For validation, we employed a dynamic directed multigraph paradigm to chronicle the evolving engagements between Twitter users. When juxtaposed against the identical dataset, our technique eclipses contemporary methodologies by an impressive 40.66% in F score (F1 score) in the anticipatory identification of harmful users. Furthermore, we undertook a model evaluation exercise to gauge the efficiency of distinct system elements.},
  keywords={Social networking (online);Blogs;Fake news;Climate change;Chatbots;Social factors;Detection algorithms;Crowdsourcing;Malware;Data integrity;Information integrity;Foreseeing;malicious users;social networks;Twitter},
  doi={10.1109/TCSS.2024.3419171},
  ISSN={2329-924X},
  month={Oct},}@INPROCEEDINGS{4631323,
  author={Shuai Jin and Zhaohan Sheng},
  booktitle={2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)}, 
  title={Modeling and simulation research on diffusion of the public voice}, 
  year={2008},
  volume={},
  number={},
  pages={3866-3873},
  abstract={The public opinion formation is becoming of a strategic importance at all levels of society. Public voice, a consequence of an asymmetrical informational structure, is interwoven by viewpoints of many individuals involved in the issue. The control and possible handling to manipulate information are now major issues in social organizations, including economy, politics, fashion, and even personal affairs. This paper focuses on simulation of the public voice diffusing based on the social mechanisms at individual level. At first, an analysis was performed to establish a multi-agent-based model analogous to a cellular automata model; it incorporated the variables of individual characters and other individualspsila impact to describe the thinking process of individuals, when they were confronted with the public voice. The attributes and hypothesizes referred in the model would be detailed in this section. Then another analyses followed further examine the functions of some parameters and mechanisms in the public voice forming, based on simulation experiments and sensitivity analysis. Finally, exploratory discussions and limitations on the model were presented.},
  keywords={Evolutionary computation},
  doi={10.1109/CEC.2008.4631323},
  ISSN={1941-0026},
  month={June},}@INPROCEEDINGS{7916986,
  author={Matsuo, Tokuro and Otsuka, Takanobu and Oishi, Tetsuya and Fujita, Rieko and Ito, Takayuki and Sengoku, Akihisa and Shiramatsu, Shun and Fukuta, Naoki and Fujita, Katsuhide and Iwamoto, Hidekazu},
  booktitle={2016 4th Intl Conf on Applied Computing and Information Technology/3rd Intl Conf on Computational Science/Intelligence and Applied Informatics/1st Intl Conf on Big Data, Cloud Computing, Data Science & Engineering (ACIT-CSII-BCD)}, 
  title={A Novel Model of Convention Management Research and Business Process}, 
  year={2016},
  volume={},
  number={},
  pages={224-229},
  abstract={A lot of data are collected through various kind of sensors and devices and can be used to make business strategy. These are sometimes used in business and marketing. In existing convention management research and its business research, most of contributions provide the result of analyses of surveys using answer of questionnaire or interviews from convention attendees, event planners and several other stakeholders. If we can know attendees' behavior, perception, and thinking by collecting data from sensors, digital voice recorders and cameras, the management and business design can be designed based on the analysis in order to improve the quality of service and attendee's satisfaction. In this paper, we explain what convention attendees expect to attend the conventions. We show our preliminary experiments to collect attendees' behavior data in a convention. Then, we propose an improved design on experiment environment to acquire attendees' data in convention. We propose a refined model of convention management research and business process in the end of this paper. In our proposed research and business process on convention management, a lot of types acquired data from sensors set in convention facility and can promise to design an improved service to enhance attendees' satisfaction in convention.},
  keywords={Cameras;Sensors;Career development;Stakeholders;Engineering profession;Layout;Convention business research;business process;data-oriented research scheme;IoT;and business model},
  doi={10.1109/ACIT-CSII-BCD.2016.051},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9988578,
  author={Dev, Mrinal and Kumar, Abhishek and Kumar, Gautam and Singh, Gambhir},
  booktitle={2022 2nd International Conference on Technological Advancements in Computational Sciences (ICTACS)}, 
  title={Data Science related to Big Data, Data-Driven Decision Making and its Application}, 
  year={2022},
  volume={},
  number={},
  pages={221-227},
  abstract={In today's time data scientist is needed in every sector. As today's era is going on, we are seeing that anyone go to buy even a small thing, then first do a research on the internet, then we go to buy it. Consider that we have to go to purchase a mobile phone, now we search on the internet, according to our budget, so we get many search results, which we can say that the result is the Big Data. Now we are according to our specifications, we choose 10 phones, which is called data mining, now we shortlist the mobile phone according to the specifications, need and budget, in the end, we think to purchase a mobile phone which is called decision making. In the above example I am trying to explain the need of Data Science in today's time. Our objective in this research paper is that using data science, how can we tell a relationship with big data. Which helps us in decision making.},
  keywords={Decision making;Machine learning;Companies;Big Data;Data science;Market research;Mobile handsets;data science;big data;data driven decision making},
  doi={10.1109/ICTACS56270.2022.9988578},
  ISSN={},
  month={Oct},}@INBOOK{6278407,
  author={Agre, Philip E. and Rosenschein, Stanley J.},
  booktitle={Computational Theories of Interaction and Agency}, 
  title={The intelligent use of space}, 
  year={1996},
  volume={},
  number={},
  pages={397-434},
  abstract={The objective of this essay is to provide the beginning of a principled classification of some of the ways space is intelligently used. Studies of planning have typically focused on the temporal ordering of action, leaving as unaddressed, questions of where to lay down instruments, ingredients, work-in-progress, and the like. But, in having a body, we are spatially located creatures: we must always he facing some direction, have only certain objects in view, be within reach of certain others. How we manage the spatial arrangement of items around us, is not an afterthought; it is an integral part of the way we think, plan and behave. The proposed classification has three main categories: spatial arrangements that simplify choice; spatial arrangements that simplify perception; and spatial dynamics that simplify internal computation. The data for such a classification is drawn from videos of cooking, assembly and packing, everyday observations in supermarkets, workshops and playrooms, and experimental studies of subjects playing Tetris, the computer game. This study, therefore, focusses on interactive processes in the medium and short term: on how agents set up their workplace for particular tasks, and how they continuously manage that workplace.},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262291040},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/6278407},}@INPROCEEDINGS{6748491,
  author={Jiang, Bing and Song, Yan and Dai, Li-Rong},
  booktitle={2013 Sixth International Conference on Advanced Computational Intelligence (ICACI)}, 
  title={Image classification using mixed-order structural representation based on mid-level feature}, 
  year={2013},
  volume={},
  number={},
  pages={144-149},
  abstract={Many successful methods for image classification transform low-level descriptors into mid-level features, and obtain a compact and discriminative representation. However, these approaches rarely think about the spatial context information between mid-level features. In this paper, we present a new mixed-order structural (MOS) representation which may generalize the widely used method spatial pyramid representation (SPR) with correlation modeling method. We first partition the image following SP and extract the mid-level feature for each spatial region. Then our MOS consists of 0th and 1st - order correlation model based on mid-level features. The 0th- order correlation can answer what the mid-level feature represents, and the 1-th order corresponds to spatial contextual information in ambient neighbors. In addition, we apply principal component analysis to reduce the dimension of mid-level features which makes our MOS can be a relatively low dimensionality. Our experiments demonstrate that the proposed MOS representation achieves a better performance compared with spatial pyramid matching (SPM) and other state-of-the-art algorithms.},
  keywords={Semantics;Principal component analysis;Face;Subspace constraints;Training;Vectors},
  doi={10.1109/ICACI.2013.6748491},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10382029,
  author={Benczúr, András},
  booktitle={2023 IEEE 23rd International Symposium on Computational Intelligence and Informatics (CINTI)}, 
  title={From the appearance of “The Computer and the Brain” to the revolution of the infosphere}, 
  year={2023},
  volume={},
  number={},
  pages={000159-000164},
  abstract={This Neumann’s last publication marks the beginning of a comparison between artificial and natural information processing machines that has continued ever since, that is, the comparison of “The Computer and the Brain”. With a brief description of the book, we prepare the formulation of the new tasks of the comparison. In doing so, the revolutionary change that took place in the infosphere of humanity with the co-evolution of computing, networking and representing information, and which is still in intensive development, must be taken into account. The book contrasts the stored program architecture based on Neumann’s principle with the neural network architecture of the brain. The numerical comparison is based on differences in the performance, number, and density of the active elements. The comparison cannot be continued in this way, because we are not dealing with individual computers, but with a system of cooperating machines organized in the Internet. The worlds of the two kinds of machines jointly use the latest collection of artificially created information carriers, the Data Sphere, and together they form the active information processing component of the Humanity’s infosphere. The carriers of information provide the common, materially existing object of computation and thinking, which I call formation in the paper. The information event, introduced in the paper, associate formation with information. Formation means information when the observation or creation of the formation in an information event is connected to the meaning for its owner. While the information processing of computers is only the transformation of formations, the assignment of meaning is carried on in an information event both before and after the transformation. In the most important information event, the owner is the human mind. The separating barrier between the two worlds is the information event. Within the computer systems, there are no more information events, only formations are transformed, in which the activation of program formations enables the automatic execution of the computation.},
  keywords={Humanities;Semantics;Computer architecture;Biosphere;Mathematics;Internet;Task analysis;computers;brain;mind;computing;information;infosphere;data sphere},
  doi={10.1109/CINTI59972.2023.10382029},
  ISSN={2471-9269},
  month={Nov},}@INPROCEEDINGS{5491256,
  author={Hurjui, Cristina and Graur, Adrian},
  booktitle={2010 International Joint Conference on Computational Cybernetics and Technical Informatics}, 
  title={Analysis of RFID security and privacy by means of identification and authentication protocols}, 
  year={2010},
  volume={},
  number={},
  pages={315-320},
  abstract={When analyzing the Radio Frequency Identification applications, one might think of two essential hierarchies: the structures aiming to offer security to an RFID system and the structures aiming to offer functionality means, with no security issues. One should know precisely the significance of these notions. Radio Frequency Identification represents an advanced wireless technology, which integrates an essential solution within the fields of intelligent chips and automation technologies. In this paper, four protocols based on updating the tags' identifiers by means of RFID readers will be compared, in order to carry out an analysis over the jeopardizing points that threaten the security and privacy of RFID systems. Cryptography signifies a way of creating RFID systems more secure. A chaotic matter is brought into discussion, by the following situations: to find out if it is a protocol of identification or authentication that is necessary, depending on various RFID applications or systems. Such analysis over RFID security has carried out wide thoughts.},
  keywords={Radiofrequency identification;Privacy;Authentication;Data security;Computer security;Automation;Application software;Cryptographic protocols;Cryptography;Databases},
  doi={10.1109/ICCCYB.2010.5491256},
  ISSN={},
  month={May},}@INPROCEEDINGS{10351292,
  author={Batghare, Kalpana and Dixit, Anil Kumar and Memoria, Minakshi and Saxena, Sager and Bilgaye, Manish},
  booktitle={2023 3rd International Conference on Innovative Sustainable Computational Technologies (CISCT)}, 
  title={State of Art of School Education in Rural Areas of Yavatmal District in the State of Maharashtra in India Based on a Real Survey}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The paper aims to present the real current situation of the state of education being provided by various schools in rural areas of the central Indian district of Yavatmal in the state of Maharashtra situated in India. Also, the paper is an attempt to analyze the data using simple analytical tools from an artificial intelligence perspective to predict various parameters indicating the future shape and direction of education is going to in these rural parts of mainland India. The study is based on real survey data collected by visiting numerous schools after receiving written permission from the Block Development Officer of Tehsil Yavatmal. The initial emphasis was on girl education but has been generalized to boys as well because of the coeducation system. The process involved talks on the state of the art of education and collection of data from respective heads of the school followed by interviews with schoolteachers, nonteaching staff, and students. The study is represented in the form of graphs, inferences, and observations on the complicated way ahead, for education to reach these deprived large chunks of people, who think that their future is their children and education is the only key responsible for new light to come to their lives. The paper includes the developmental stages Indian education passed through from pre-independence to recent times.},
  keywords={Surveys;Pediatrics;Art;Shape;Education;Atmosphere;Market research;Article 21;21A;41;45;46;47;15(3);Girl Education;Rural India;Artificial Intelligence;Original Survey},
  doi={10.1109/CISCT57197.2023.10351292},
  ISSN={},
  month={Sep.},}@ARTICLE{1255422,
  author={Cordon, O. and Herrera, F.},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Author's reply [to Comments on 'A proposal to improve the accuracy of linguistic modelling']}, 
  year={2003},
  volume={11},
  number={6},
  pages={866-869},
  abstract={In our opinion, there are two main concerns in Roubos and Babugka's note, that are summarized as follows. 1) The kinds of problems used in our paper to test the algorithm proposed in "A proposal to improve the accuracy of linguistic modeling" and other studies. The authors claim that they are very simple to be considered as benchmarks for nonlinear modeling techniques. 2) The interpretability of the different kinds of models considered. Roubos and Babuska think that there is no difference between the interpretability of fuzzy linguistic models, Takagi-Sugeno-Kang (TSK) fuzzy models, and mathematical formulations (linear models, in this case). We agree with some of the opinions of the authors of the note but not with some others.},
  keywords={Benchmark testing;Mathematical model;Fuzzy systems;Fuzzy neural networks;Databases;Nonlinear dynamical systems;Humans;Modeling;Neural networks;Computer science},
  doi={10.1109/TFUZZ.2003.819820},
  ISSN={1941-0034},
  month={Dec},}@ARTICLE{8158793,
  author={Santos-Trigo, Manuel and Reyes-Rodríguez, Aarón and Espinosa-Pérez, Hugo},
  journal={Teaching Mathematics and Its Applications: International Journal of the IMA}, 
  title={Musing on the use of dynamic software and mathematics epistemology}, 
  year={2007},
  volume={26},
  number={4},
  pages={167-178},
  abstract={Different computational tools may offer teachers and students distinct opportunities in representing, exploring and solving mathematical tasks. In this context, we illustrate that the use of dynamic software (Cabri Geometry) helped high school teachers to think of and represent a particular task dynamically. In this process, the teachers had the opportunity of identifying, exploring and supporting mathematical relations that emerged during the solution of the task. We distinguish problem-solving episodes that teachers exhibited while understanding and representing the task, thinking of a solution plan, searching and presenting mathematical arguments and looking for connections.},
  keywords={},
  doi={10.1093/teamat/hrl019},
  ISSN={1471-6976},
  month={Dec},}@INPROCEEDINGS{701334,
  author={Tan, J.K.},
  booktitle={Proceedings. 11th IEEE Symposium on Computer-Based Medical Systems (Cat. No.98CB36237)}, 
  title={Total quality in the management of information technology (TQMIT): the case of tele-radiology and imaging technologies}, 
  year={1998},
  volume={},
  number={},
  pages={164-169},
  abstract={Addresses the management of health care information technology (HCIT) from a total quality perspective with a focus on associated technologies in radiology and imaging. The aim is to chart a course for the application of these advancing technologies within the context of an integrated delivery system (IDS) to prepare radiologists and other medical technologists facing a rapidly changing health service delivery system. In this context, a critical step is the task of strategic HCIT planning, design and implementation to realize an efficient, appropriate and effective HCIT infrastructure for developing seamless, integrated radiological services. The key factors underlying this challenge in face of rapid advances in radiological and imaging technology are often poorly understood. The concept of a total quality management information technology (TQMIT) model is explored and illustrated. The central theme is to demonstrate how this sort of thinking can be applied philosophically, logically and physically to guide management and radiologists in strategy formulation and in taking critical steps to plan, design and develop high-quality services that will facilitate distributed image processing, information exchange and sharing among multiple health care providers within an IDS.},
  keywords={Information management;Quality management;Technology management;Information technology;Radio spectrum management;Medical services;Context-aware services;Intrusion detection;Radiology;Biomedical imaging},
  doi={10.1109/CBMS.1998.701334},
  ISSN={1063-7125},
  month={June},}@INBOOK{9933661,
  author={},
  booktitle={Selected Topics in Intelligent Chips with Emerging Devices, Circuits and Systems}, 
  title={Selected Topics in Intelligent Chips with Emerging Devices, Circuits and Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-3},
  abstract={Memristors have provided a new direction of thinking for circuit designers to overcome the limits of scalability and for thinking of building systems beyond Moore&#x2019;s law. Over the last decade, there has been a significant number of innovations in using memristors for building neural networks through analog computing, in-memory computing, and stochastic computing approaches. The emergence of intelligent integrated circuits is inevitable for the future of integrated circuit applications. This book provides a collection of talks conducted as part of the IEEE Seasonal School on Circuits and System, having a focus on Intelligence in Chip: Tomorrow of Integrated Circuits. Technical topics discussed in the book include: &#x2022; Edge of Chaos Theory Explains Complex Phenomena in Memristor Circuits &#x2022; Analog Memristive Computing &#x2022; Designing energy efficient neo-cortex system with on-device learning &#x2022; Integrated sensors &#x2022; Challenges and recent advances in NVM based Neuromorphic Computing ICs &#x2022; In-memory Computing (for deep learning) &#x2022; Deep learning with Spiking Neural Networks &#x2022; Computational Intelligence for Designing Integrated Circuits and Systems &#x2022; Neurochip Design, Modeling, and Applications},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770227643},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9933661},}@INBOOK{9933673,
  author={},
  booktitle={Selected Topics in Intelligent Chips with Emerging Devices, Circuits and Systems}, 
  title={About the Editors}, 
  year={2022},
  volume={},
  number={},
  pages={235-237},
  abstract={Memristors have provided a new direction of thinking for circuit designers to overcome the limits of scalability and for thinking of building systems beyond Moore&#x2019;s law. Over the last decade, there has been a significant number of innovations in using memristors for building neural networks through analog computing, in-memory computing, and stochastic computing approaches. The emergence of intelligent integrated circuits is inevitable for the future of integrated circuit applications. This book provides a collection of talks conducted as part of the IEEE Seasonal School on Circuits and System, having a focus on Intelligence in Chip: Tomorrow of Integrated Circuits. Technical topics discussed in the book include: &#x2022; Edge of Chaos Theory Explains Complex Phenomena in Memristor Circuits &#x2022; Analog Memristive Computing &#x2022; Designing energy efficient neo-cortex system with on-device learning &#x2022; Integrated sensors &#x2022; Challenges and recent advances in NVM based Neuromorphic Computing ICs &#x2022; In-memory Computing (for deep learning) &#x2022; Deep learning with Spiking Neural Networks &#x2022; Computational Intelligence for Designing Integrated Circuits and Systems &#x2022; Neurochip Design, Modeling, and Applications},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770227643},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9933673},}@INPROCEEDINGS{7738674,
  author={Agrawal, Ankur and Choi, Jungwook and Gopalakrishnan, Kailash and Gupta, Suyog and Nair, Ravi and Oh, Jinwook and Prener, Daniel A. and Shukla, Sunil and Srinivasan, Vijayalakshmi and Sura, Zehra},
  booktitle={2016 IEEE International Conference on Rebooting Computing (ICRC)}, 
  title={Approximate computing: Challenges and opportunities}, 
  year={2016},
  volume={},
  number={},
  pages={1-8},
  abstract={Approximate computing is gaining traction as a computing paradigm for data analytics and cognitive applications that aim to extract deep insight from vast quantities of data. In this paper, we demonstrate that multiple approximation techniques can be applied to applications in these domains and can be further combined together to compound their benefits. In assessing the potential of approximation in these applications, we took the liberty of changing multiple layers of the system stack: architecture, programming model, and algorithms. Across a set of applications spanning the domains of DSP, robotics, and machine learning, we show that hot loops in the applications can be perforated by an average of 50% with proportional reduction in execution time, while still producing acceptable quality of results. In addition, the width of the data used in the computation can be reduced to 10-16 bits from the currently common 32/64 bits with potential for significant performance and energy benefits. For parallel applications we reduced execution time by 50% using relaxed synchronization mechanisms. Finally, our results also demonstrate that benefits compounded when these techniques are applied concurrently. Our results across different applications demonstrate that approximate computing is a widely applicable paradigm with potential for compounded benefits from applying multiple techniques across the system stack. In order to exploit these benefits it is essential to re-think multiple layers of the system stack to embrace approximations ground-up and to design tightly integrated approximate accelerators. Doing so will enable moving the applications into a world in which the architecture, programming model, and even the algorithms used to implement the application are all fundamentally designed for approximate computing.},
  keywords={Approximate computing;Synchronization;Hardware;Computer architecture;Synthetic aperture radar;Training;Approximation algorithms;Approximate computing;perforation;reduced precision;relaxed synchronization},
  doi={10.1109/ICRC.2016.7738674},
  ISSN={},
  month={Oct},}@ARTICLE{1011207,
  author={Soo-Chang Pei and Jian-Jiun Ding},
  journal={IEEE Transactions on Signal Processing}, 
  title={Fractional cosine, sine, and Hartley transforms}, 
  year={2002},
  volume={50},
  number={7},
  pages={1661-1680},
  abstract={In previous papers, the Fourier transform (FT) has been generalized into the fractional Fourier transform (FRFT), the linear canonical transform (LCT), and the simplified fractional Fourier transform (SFRFT). Because the cosine, sine, and Hartley transforms are very similar to the FT, it is reasonable to think they can also be generalized by the similar way. We introduce several new transforms. They are all the generalization of the cosine, sine, or Hartley transform. We first derive the fractional cosine, sine, and Hartley transforms (FRCT/FRST/FRHT). They are analogous to the FRFT. Then, we derive the canonical cosine and sine transforms (CCT/CST). They are analogous to the LCT. We also derive the simplified fractional cosine, sine, and Hartley transforms (SFRCT/SFRST/SFRHT). They are analogous to the SFRFT and have the advantage of real-input-real-output. We also discuss the properties, digital implementation, and applications (e.g., the applications for filter design and space-variant pattern recognition) of these transforms. The transforms introduced in this paper are very efficient for digital implementation. We can just use one half or one fourth of the real multiplications required for the FRFT and LCT to implement them. When we want to process even, odd, or pure real/imaginary functions, we can use these transforms instead of the FRFT and LCT. Besides, we also show that the FRCT/FRST, CCT/CST, and SFRCT/SFRST are also useful for the one-sided (t /spl isin/ [0, /spl infin/]) signal processing.},
  keywords={Fourier transforms;Digital filters;Signal processing;Councils},
  doi={10.1109/TSP.2002.1011207},
  ISSN={1941-0476},
  month={July},}@INPROCEEDINGS{6803230,
  author={Mukherjee, Arijit and Paul, Himadri Sekhar and Dey, Swarnava and Banerjee, Ansuman},
  booktitle={2014 IEEE World Forum on Internet of Things (WF-IoT)}, 
  title={ANGELS for distributed analytics in IoT}, 
  year={2014},
  volume={},
  number={},
  pages={565-570},
  abstract={The current global emphasis on “Internet of Things (IoT)” have highlighted the extreme importance of sensor-based intelligent and ubiquitous systems which are more commonly known as “cyber-physical systems.” The technology has the potential to create a network of smart devices and things to an extent that has never been envisaged before, far outnumbering the number of devices connected in the Internet as we know today. The sheer number of such connected ubiquitous devices is likely to give rise to a hitherto unforeseen volume of data of different types with a demand for execution of analytical algorithms over the data. On the success of these analytic processes will depend the actual “smartness” of the “Intelligent Infrastructures” which now form the crux of the IoT paradigm. We have seen the advent of cloud-based paradigms to analyse the data in a data-parallel fashion within large data centres which now form the basis of the “big-data” problem. But apart from the servers in the data centres, we potentially have a huge pool of compute resources if we think about the smart devices in and around our homes collectively, which remain relatively idle. In this paper, we present a proposal with some emulated experimental results where we claim that in an IoT framework, the smart devices such as mobile phones, home gateways etc. can be utilised for execution of dataparallel analytic jobs. This is effectively a work-in-progress and it is acknowledged that there will be further challenges for real devices. Future research will attempt to consider these challenges.},
  keywords={Internet;Smart phones;Logic gates;Mobile communication;Computer architecture;Servers;cyber-physical;ubiquitous systems;analytics;parallel execution;black-box;mobile grid},
  doi={10.1109/WF-IoT.2014.6803230},
  ISSN={},
  month={March},}@INPROCEEDINGS{8715004,
  author={Fadiheh, Mohammad Rahmani and Stoffel, Dominik and Barrett, Clark and Mitra, Subhasish and Kunz, Wolfgang},
  booktitle={2019 Design, Automation & Test in Europe Conference & Exhibition (DATE)}, 
  title={Processor Hardware Security Vulnerabilities and their Detection by Unique Program Execution Checking}, 
  year={2019},
  volume={},
  number={},
  pages={994-999},
  abstract={Recent discovery of security attacks in advanced processors, known as Spectre and Meltdown, has resulted in high public alertness about security of hardware. The root cause of these attacks is information leakage across covert channels that reveal secret data without any explicit information flow between the secret and the attacker. Many sources believe that such covert channels are intrinsic to highly advanced processor architectures based on speculation and out-of-order execution, suggesting that such security risks can be avoided by staying away from high-end processors. This paper, however, shows that the problem is of wider scope: we present new classes of covert channel attacks which are possible in average-complexity processors with in-order pipelining, as they are mainstream in applications ranging from Internet-of-Things to Autonomous Systems. We present a new approach as a foundation for remedy against covert channels: while all previous attacks were found by clever thinking of human attackers, this paper presents a formal method called Unique Program Execution Checking which detects and locates vulnerabilities to covert channels systematically, including those to covert channels unknown so far.},
  keywords={Security;Hardware;Microarchitecture;Hazards;Software;Pipelines;Timing},
  doi={10.23919/DATE.2019.8715004},
  ISSN={1558-1101},
  month={March},}@INPROCEEDINGS{5175828,
  author={Baresi, Luciano and Guinea, Sam and Pistore, Marco and Trainotti, Michele},
  booktitle={2009 IEEE International Conference on Web Services}, 
  title={Dynamo + Astro: An Integrated Approach for BPEL Monitoring}, 
  year={2009},
  volume={},
  number={},
  pages={230-237},
  abstract={In the literature, there exist several approaches for monitoring the execution of BPEL processes. They concentrate on different properties, adopt different languages, work at different levels of abstraction, and assume different perspectives. Even if the field is rather new, we do not think that this diversity is a limitation of current solutions; rather it is intrinsic in the problem itself. We claim that, instead of working on the definition of the ultimate approach for BPEL monitoring, we should push a cooperative approach based on the integration of different solutions.In this paper, we present a first step in this direction, and describe a monitoring framework which is obtained by integrating two well-known approaches, namely Dynamo and Astro. This integration, which happens both for the language used for expressing the properties to be monitored, and for the architecture of the monitoring framework, allows to combine the advantages of the two approaches and to obtain a general, comprehensive solutions for BPEL monitoring.},
  keywords={Magnetohydrodynamic power generation;Monitoring;Proposals;Web services;Computer architecture;Software systems;Assembly;Distributed computing;Quality of service;Probes},
  doi={10.1109/ICWS.2009.67},
  ISSN={},
  month={July},}@ARTICLE{9079596,
  author={Wang, Ziye and Zuo, Renguang and Dong, Yanni},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Mapping of Himalaya Leucogranites Based on ASTER and Sentinel-2A Datasets Using a Hybrid Method of Metric Learning and Random Forest}, 
  year={2020},
  volume={13},
  number={},
  pages={1925-1936},
  abstract={The widely distributed leucogranite belt in the Himalayan orogeny is expected to have excellent potential for developing rare metal mineralization. Finding a way to effectively map the spatial distribution of leucogranites would be a significant contribution to rare metal exploration. Research shows remote sensing technology has long been recognized the significance in geological works, which greatly promoted mineral exploration in a cost-effective manner, especially in the Himalayan orogenic belt with poor natural environment. However, several challenges still exist in relation to the limited spectral band and spatial resolution of remote sensing images, as well as the onerous data processing. In this context, this study sought to resolve these two issues by applying a hybrid approach that comprises image fusion, metric learning, and random forest methods. For the first challenge, multisource and multisensor remote sensing data were integrated to provide more comprehensive spatial texture characteristics and spectral information. To address the second challenge, this study used a hybrid method of metric learning and random forest to promote computing efficiency and classification accuracy. This process is illustrated through a case study of lithological mapping in Cuonadong dome, the northern part of the Himalayan orogeny belt. Seven target lithological units were effectively discriminated with an 85.75% overall accuracy. This provides an important scientific basis for further exploration for rare metal deposits in the Himalayan orogeny belt, and a way of thinking for detecting geological features under harsh natural conditions.},
  keywords={Measurement;Remote sensing;Geology;Random forests;Belts;Spatial resolution;Metals;Himalaya leucogranites;lithological mapping;metric learning;random forest;remote sensing},
  doi={10.1109/JSTARS.2020.2989509},
  ISSN={2151-1535},
  month={},}@ARTICLE{8884236,
  author={Hamdaoui, Bechir and Alkalbani, Mohamed and Znati, Taieb and Rayes, Ammar},
  journal={IEEE Network}, 
  title={Unleashing the Power of Participatory IoT with Blockchains for Increased Safety and Situation Awareness of Smart Cities}, 
  year={2020},
  volume={34},
  number={2},
  pages={202-209},
  abstract={IoT has emerged as an unprecedented paradigm with great potential for changing how people interact, think and live. It is making existing Internet services feasible in ways that were previously impossible, as well as paving the way for new situation- awareness applications suitable for smart cities, such as realtime video surveillance, traffic control, and emergency management. These applications will typically rely on large numbers of IoT devices to collect and collaboratively process streamed data to enable real-time decision making. In this article, we introduce the concept of Semantic Virtual Space (SVS), an abstraction for virtualized cloud-enabled IoT infrastructure that is commensurate with the goals and needs of these emerging smart city applications, and propose and discuss scalable architectures and mechanisms that enable and automate the deployment and management of multiple SVS instances on top of the cloud-enabled IoT infrastructure.},
  keywords={Cloud computing;Internet of Things;Smart cities;Computer architecture;Blockchain;Real-time systems},
  doi={10.1109/MNET.001.1900253},
  ISSN={1558-156X},
  month={March},}@INPROCEEDINGS{6687429,
  author={Eicker, Norbert and Lippert, Thomas and Moschny, Thomas and Suarez, Estela},
  booktitle={2013 42nd International Conference on Parallel Processing}, 
  title={The DEEP Project - Pursuing Cluster-Computing in the Many-Core Era}, 
  year={2013},
  volume={},
  number={},
  pages={885-892},
  abstract={Homogeneous cluster architectures dominating high-performance computing (HPC) today are challenged, in particular when thinking about reaching Exascale by the end of the decade, by heterogeneous approaches utilizing accelerator elements. The DEEP (Dynamical Exascale Entry Platform) project aims for implementing a novel architecture for high-performance computing consisting of two components - a standard HPC Cluster and a cluster of many-core processors called Booster. In order to make the adaptation of application codes to this Cluster-Booster architecture as seamless as possible, DEEP provides a complete programming environment. It integrates the offloading functionality given by the MPI standard with an abstraction layer based on the task-based OmpSs programming paradigm. This paper presents the DEEP project with an emphasis on the DEEP programming environment.},
  keywords={Computer architecture;Program processors;Scalability;Hardware;Fabrics;Parallel processing;Programming;HPC;Computer Architecture;Exascale},
  doi={10.1109/ICPP.2013.105},
  ISSN={2332-5690},
  month={Oct},}@INPROCEEDINGS{4341867,
  author={Wang, Yingxu},
  booktitle={6th IEEE International Conference on Cognitive Informatics}, 
  title={Cognitive Informatics Foundations of Nature and Machine Intelligence}, 
  year={2007},
  volume={},
  number={},
  pages={3-12},
  abstract={Intelligence is a driving force or an ability to acquire and use knowledge and skills, or to inference in problem solving. This keynote lecture describes the taxonomy and nature of intelligence. It analyzes roles of information in the evolution of human intelligence, and the needs for logical abstraction in modeling the brain and natural intelligence. A formal model of intelligence is developed known as the generic intelligence mode (GIM), which provides a foundation to explain the mechanisms of advanced natural intelligence such as thinking, learning, and inferences. A measurement framework of intelligent capability of humans and systems is presented in the forms of intelligent quotient, intelligent equivalence, and intelligent metrics. On the basis of GIM model and theories, the compatibility of nature and machine intelligence is revealed, which forms a theoretical foundation for rigorous study in machine intelligence, AI, and intelligent systems.},
  keywords={Cognitive informatics;Machine intelligence;Learning systems;Humans;Problem-solving;Taxonomy;Information analysis;Brain modeling;Artificial intelligence;Intelligent systems;Cognitive informatics;brain science;intelligence science;denotational mathematics;cognitive models;cognitive processes;mathematical models;concept algebra;RTPA;intelligent measurement;intelligent quotient;intelligent metrics;LRMB;OAR;GIM;AI},
  doi={10.1109/COGINF.2007.4341867},
  ISSN={},
  month={Aug},}@ARTICLE{9034161,
  author={Roppert, K. and Schoder, S. and Toth, F. and Kaltenbacher, M.},
  journal={IEEE Transactions on Magnetics}, 
  title={Non-Conforming Nitsche Interfaces for Edge Elements in Curl–Curl-Type Problems}, 
  year={2020},
  volume={56},
  number={5},
  pages={1-7},
  abstract={In this article, a methodology to incorporate non-conforming interfaces between several conforming mesh regions is presented for Maxwell's curl-curl problem. The derivation starts from a general interior penalty discontinuous Galerkin formulation of the curl-curl problem and eliminates all interior jumps in the conforming parts but retains them across non-conforming interfaces. Therefore, it is possible to think of this Nitsche approach for interfaces as a specialization of discontinuous Galerkin on meshes, which are conforming nearly everywhere. The applicability of this approach is demonstrated in two numerical examples, including parameter jumps at the interface. A convergence study is performed for h-refinement, including the investigation of the penalization- (Nitsche-) parameter.},
  keywords={Convergence;Approximation error;Method of moments;Magnetostatics;Eddy currents;Three-dimensional displays;Magnetic domains;Eddy current problem;magnetostatic;Nédélec elements;Nitsche method;non-conforming interface},
  doi={10.1109/TMAG.2020.2980477},
  ISSN={1941-0069},
  month={May},}@INPROCEEDINGS{4371296,
  author={Doboli, Simona and Minai, Ali A. and Brown, Vincent R.},
  booktitle={2007 International Joint Conference on Neural Networks}, 
  title={Adaptive Dynamic Modularity in a Connectionist Model of Context-Dependent Idea Generation}, 
  year={2007},
  volume={},
  number={},
  pages={2183-2188},
  abstract={Cognitive control -the ability to produce appropriate behavior in complex situations -is a fundamental aspect of intelligence. It is increasingly evident that this control arises from the interaction of dynamics in several brain regions, and depends significantly on processes of modulation and dynamical biasing. While most research has focused on explanations of behavioral responses seen in experiments and pathologies, it is reasonable to expect that internal functions such as planning and thinking would also use similar control mechanisms. In this paper, we present a connectionist model for an idea generation process that can rapidly retrieve old ideas in familiar contexts and search for novel ideas in unfamiliar ones. Based on a simple reinforcement signal, the system learns context-dependent biases that represent effective internal "response systems" for generating ideas from conceptual elements. A broad goal of the research is to show that preconfigured structural modularity, limited real-time selectivity, and adaptive modulation can interact to produce the flexible functionality necessary for cognition and intelligent behavior.},
  keywords={Context modeling;Brain modeling;Biological system modeling;Biological neural networks;Cognition;Programmable control;Adaptive control;Intelligent networks;Pathology;Path planning},
  doi={10.1109/IJCNN.2007.4371296},
  ISSN={2161-4407},
  month={Aug},}@ARTICLE{1514661,
  author={Ovaska, S.J. and Bose, T. and Vainio, O.},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Genetic algorithm-assisted design of adaptive predictive filters for 50/60 Hz power systems instrumentation}, 
  year={2005},
  volume={54},
  number={5},
  pages={2041-2048},
  abstract={We introduce a genetic algorithm-based method for structural optimization of multiplicative general parameter (MGP) finite impulse response (FIR) filters. These computationally efficient reduced-rank adaptive filters are robust, suitable for predictive configurations, and they have numerous applications in 50/60 Hz power systems instrumentation. The design process of such filters has three independent stages: Lagrange multipliers-based optimization of the sinusoid-predictive basis filter, genetic algorithm-based search of optimal FIR tap cross-connections and, finally, the online MGP-adaptation phase guided by variations in signal statistics. Thus, our multistage design procedure is a complementary fusion of hard computing (HC) and soft computing (SC) methodologies. Such advantageous fusion (or symbiosis) thinking is emerging among researchers and practicing engineers, and it can potentially lead to competitive combinations of individual HC and SC methods.},
  keywords={Genetics;Algorithm design and analysis;Adaptive filters;Power systems;Instruments;Finite impulse response filter;Optimization methods;Robustness;Process design;Signal design;Adaptive filtering;control instrumentation;electric power systems;genetic algorithms;predictive filtering},
  doi={10.1109/TIM.2005.853230},
  ISSN={1557-9662},
  month={Oct},}@INPROCEEDINGS{937966,
  author={Haddow, P.C. and van Remortel, P.},
  booktitle={Proceedings Third NASA/DoD Workshop on Evolvable Hardware. EH-2001}, 
  title={From here to there : future robust EHW technologies for large digital designs}, 
  year={2001},
  volume={},
  number={},
  pages={232-239},
  abstract={Fault-tolerance may be expected to gain more and more importance in the future. Extremely harsh and changing environments, like outer space, already force us to think about this issue today, but issues like production of large-scale devices might put the same requirements on the devices of tomorrow. Imagine a mixture of chemical substances in a reservoir, together with a circuit-implementing shell that has self-repairing properties based on the maintenance of the chemical equilibrium. Could this type of solution be the basis for a robust future technology for evolvable hardware? A long term goal of evolvable hardware is to evolve large complex designs for large devices. However, both evolving large complex designs and manufacturing large reliable devices is technologically out of reach due to the resource greedy nature of GAs and low device yield rates. In this article we explore the technological requirements of digital design, design by evolution and development and the reliability issue in the light of today's digital evolvable hardware technology, FPGA and a proposed fault tolerant technology, Amorphous Computers. Considering the limitation of these platforms, we project these findings towards possible future technology platforms.},
  keywords={Robustness;Hardware;Space technology;Fault tolerance;Chemical technology;Production;Large-scale systems;Reservoirs;Circuits;Maintenance},
  doi={10.1109/EH.2001.937966},
  ISSN={},
  month={July},}@INPROCEEDINGS{6912676,
  author={Mohebbi, Abolfazl and Baron, Luc and Achiche, Sofiane and Birglen, Lionel},
  booktitle={Proceedings of the 2014 International Conference on Innovative Design and Manufacturing (ICIDM)}, 
  title={Trends in concurrent, multi-criteria and optimal design of mechatronic systems: A review}, 
  year={2014},
  volume={},
  number={},
  pages={88-93},
  abstract={Due to the inherent complexity and the dynamic coupling between subsystems of mechatronic systems, a systematic and multicriteria design thinking methodology is crucial to replace the traditionally used sequential design approach. In this paper we discuss the various aspects of current approaches within mechatronic system design to point out the most important challenges. Accordingly, a review on the most recent work on design and optimization methods and tools is presented and briefly discussed. A framework for concurrent and integrated design of mechatronic system based on separation of realtime and non-realtime system behaviours is also introduced and developed methods based on this model are presented.},
  keywords={Mechatronics;Design methodology;Software;System analysis and design;Mathematical model;Solid modeling;Systematics;KEYWORDS;Mechatronics;Multicriteria;Multi-disciplinary;Concurrent Design;Integration;Optimization},
  doi={10.1109/IDAM.2014.6912676},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9426783,
  author={Sodhi, Balwinder and Kapur, Ritu},
  booktitle={2021 IEEE 18th International Conference on Software Architecture (ICSA)}, 
  title={Quantum Computing Platforms: Assessing the Impact on Quality Attributes and SDLC Activities}, 
  year={2021},
  volume={},
  number={},
  pages={80-91},
  abstract={Practical quantum computing is rapidly becoming a reality. To harness quantum computers’ real potential in software applications, one needs to have an in-depth understanding of all such characteristics of quantum computing platforms (QCPs), relevant from the Software Engineering (SE) perspective. Restrictions on copying, deletion, the transmission of qubit states, a hard dependency on quantum algorithms are few, out of many, examples of QCP characteristics that have significant implications for building quantum software.Thus, developing quantum software requires a paradigm shift in thinking by software engineers. This paper presents the key findings from the SE perspective, resulting from an in-depth examination of state-of-the-art QCPs available today. The main contributions that we present include i) Proposing a general architecture of the QCPs, ii) Proposing a programming model for developing quantum software, iii) Determining architecturally significant characteristics of QCPs, and iv) Determining the impact of these characteristics on various Quality Attributes (QAs) and Software Development Life Cycle (SDLC) activities.We show that the nature of QCPs makes them useful mainly in specialized application areas such as scientific computing. Except for performance and scalability, most of the other QAs (e.g., maintainability, testability, and reliability) are adversely affected by different characteristics of a QCP.},
  keywords={Quantum algorithm;Software architecture;Scalability;Qubit;Buildings;Software algorithms;Computer architecture;Quantum Computing;Quantum Software Engineering;Software Development Life Cycle;Computing Platforms},
  doi={10.1109/ICSA51549.2021.00016},
  ISSN={},
  month={March},}@INPROCEEDINGS{6133162,
  author={Charalabidis, Yannis and Koussouris, Sotirios and Ramfos, Antonis},
  booktitle={2011 IEEE Third International Conference on Cloud Computing Technology and Science}, 
  title={A Cloud Infrastructure for Collaborative Digital Public Services}, 
  year={2011},
  volume={},
  number={},
  pages={340-347},
  abstract={Looking back at the major developments of the previous years in the Internet and IT industry, it is more than certain that two of the most important innovations are cloud computing, which evidently takes processing power and IT provision to a whole new level, and Web2.0 service applications, that reveal the innovative thinking and development power of users, who in many cases are the architects of these applications. Despite this progress, focusing on the provision of public services reveals that until today little has been done in order to expose the real power of those two concepts. Cloud computing is in most cases regarded just as an alternative to having in premise infrastructures, while Web2.0 applications designed by third parties cannot be integrated in the public sector and are characterised as "promising initiatives that cannot go further". This paper targets the constantly increasing need for having more efficient and effective public sector services by trying to combine the benefits that derive by both the cloud computing and the open innovation concepts, and proposes a platform that could actually assist stakeholders to deploy their services towards meeting their needs, whether this refers to the exposure of public services over cloud infrastructures or to the creation of personalised composite public services.},
  keywords={Technological innovation;Cloud computing;Service oriented architecture;Europe;Collaboration;Government;Cloud Computing;Public Services;Collaboration;Open Innovation;eGovernance},
  doi={10.1109/CloudCom.2011.53},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9101636,
  author={Zhao, Cheng and Zhang, Zhibin and Xu, Peng and Zheng, Tianqi and Guo, Jiafeng},
  booktitle={2020 IEEE 36th International Conference on Data Engineering (ICDE)}, 
  title={Kaleido: An Efficient Out-of-core Graph Mining System on A Single Machine}, 
  year={2020},
  volume={},
  number={},
  pages={673-684},
  abstract={Graph mining is one of the most important categories of graph algorithms. However, exploring the subgraphs of an input graph produces a huge amount of intermediate data. The "think like a vertex" programming paradigm, pioneered by Pregel, cannot readily formulate mining problems, which is designed to produce graph computation problems like PageRank. Existing mining systems like Arabesque and RStream need large amounts of computing and memory resources. In this paper, we present Kaleido, an efficient single machine, out-of-core graph mining system which treats disks as an extension of memory. Kaleido treats intermediate data in graph mining tasks as a tensor and adopts a succinct data structure for the intermediate data. Kaleido implements half-memory-half-disk storage for storing large intermediate data, which treats the disk as an extension of the memory. Kaleido adopts a lightweight isomorphism checking strategy which uses an eigenvalue-based algorithm for small graphs and solves tree isomorphism for the other graphs. Comparing with two state-of-the-art mining systems, Arabesque and RStream, Kaleido outperforms them by a GeoMean 13.2× and 64.8× respectively.},
  keywords={Data mining;Programming;Memory management;Patents;Arrays;Tensile stress;graph mining;exploration;isomorphism;out-of-core},
  doi={10.1109/ICDE48307.2020.00064},
  ISSN={2375-026X},
  month={April},}@ARTICLE{9750858,
  author={Baccour, Emna and Erbad, Aiman and Mohamed, Amr and Hamdi, Mounir and Guizani, Mohsen},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={RL-DistPrivacy: Privacy-Aware Distributed Deep Inference for Low Latency IoT Systems}, 
  year={2022},
  volume={9},
  number={4},
  pages={2066-2083},
  abstract={Although Deep Neural Networks (DNN) have become the backbone technology of several ubiquitous applications, their deployment in resource-constrained machines, e.g., Internet of Things (IoT) devices, is still challenging. To satisfy the resource requirements of such a paradigm, collaborative deep inference with IoT synergy was introduced. However, the distribution of DNN networks suffers from severe data leakage. Various threats have been presented, including black-box attacks, where malicious participants can recover arbitrary inputs fed into their devices. Although many countermeasures were designed to achieve privacy-preserving DNN, most of them result in additional computation and lower accuracy. In this paper, we present an approach that targets the security of collaborative deep inference via re-thinking the distribution strategy, without sacrificing the model performance. Particularly, we examine different DNN partitions that make the model susceptible to black-box threats and we derive the amount of data that should be allocated per device to hide proprieties of the original input. We formulate this methodology, as an optimization, where we establish a trade-off between the latency of co-inference and the privacy-level of data. Next, to relax the optimal solution, we shape our approach as a Reinforcement Learning (RL) design that supports heterogeneous devices as well as multiple DNNs/datasets.},
  keywords={Task analysis;Collaboration;Deep learning;Servers;Privacy;Neural networks;Data models;IoT devices;resource constraints;sensitive data;black-box;distributed DNN;reinforcement learning},
  doi={10.1109/TNSE.2022.3165472},
  ISSN={2327-4697},
  month={July},}
