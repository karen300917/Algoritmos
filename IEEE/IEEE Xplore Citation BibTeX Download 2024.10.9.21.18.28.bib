@INPROCEEDINGS{9274155,
  author={Conte, Davi Jose and de Souza, Paulo Sergio Lopes and Martins, Guilherme and Bruschi, Sarita Mazzini},
  booktitle={2020 IEEE Frontiers in Education Conference (FIE)}, 
  title={Teaching Parallel Programming for Beginners in Computer Science}, 
  year={2020},
  volume={},
  number={},
  pages={1-9},
  abstract={This research full paper describes our experience in teaching parallel programming for students without previous knowledge of basic concepts of computing, comparing their levels of learning. The use of parallel software grew considerably in recent years due to the increasing availability of multi and many-core devices. The evolution of hardware and software resources collaborated for a remarkable computational processing power offered by parallel programs. However, parallel programming is taught usually in more advanced years of the undergraduate computer courses, due to its supposed prerequisites as sequential programming, operating systems, computer architectures and others. Postponing parallel programming teaching hinder students to apply parallelism other subjects, reducing the probability of these future professionals think on parallel solutions naturally. We executed 05 experiments teaching parallel programming subjects for 252 students. We analyzed whether students without prerequisites could learn parallel programming in the same level verified with students with prior computing knowledge. We used three different teaching methodologies: traditional, Problem Based Learning (PBL), and Team-Based Learning (TBL). The teaching and learning evaluation took into account such metrics: parallelism thinking of students, use of programming-model, correct output of the program, source-code readability and satisfaction of the students. The paper shows that it is possible to teach parallel programming to students without previous knowledge of computing, obtaining high scores and interest in such learning. Our results contribute positively to disseminate parallel programming, which is vital to extract performance from nowadays computers.},
  keywords={Education;Parallel programming;Parallel processing;Programming profession;Software;Measurement;Computer architecture;Education;Teaching;Learning;Parallel Programming;Computer Science Teaching},
  doi={10.1109/FIE44824.2020.9274155},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10005170,
  author={Peterson, Tina L. and Ferreira, Rodrigo and Vardi, Moshe Y.},
  journal={IEEE Transactions on Technology and Society}, 
  title={Abstracted Power and Responsibility in Computer Science Ethics Education}, 
  year={2023},
  volume={4},
  number={1},
  pages={96-102},
  abstract={As computing becomes more powerful and extends the reach of those who wield it, the imperative grows for computing professionals to make ethical decisions regarding the use of that power. We propose the concept of abstracted power to help computer science students understand how technology may distance them perceptually from consequences of their actions. Specifically, we identify technological intermediation and computational thinking as two factors in computer science that contribute to this distancing. To counter the abstraction of power, we argue for increased emotional engagement in computer science ethics education, to encourage students to feel as well as think regarding the potential impacts of their power on others. We suggest four concrete pedagogical approaches to enable this emotional engagement in computer science ethics curriculum, and we share highlights of student reactions to the material.},
  keywords={Ethics;Computer science education;Writing;Cognition;Codes;Philosophical considerations;Social implications of technology;Curriculum development;Social factors;Power;abstraction;responsibility;social impact;emotional engagement;ethics},
  doi={10.1109/TTS.2022.3233776},
  ISSN={2637-6415},
  month={March},}@INPROCEEDINGS{6113219,
  author={Nagar, Yiftach},
  booktitle={2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing}, 
  title={Beyond the Human-Computation Metaphor}, 
  year={2011},
  volume={},
  number={},
  pages={800-805},
  abstract={Two assumptions have become dominant in the field of social computing and crowd sourcing - the computational view, and the assumption of a human-only crowd. In this paper, I address those assumptions. I trace their origin in the human-computation metaphor, and argue that while this metaphor is instrumental in facilitating novel developments, it also constrains the thinking of designers. I discuss some of the limitations this metaphor might impose, and offer that additional perspectives, such as an organizational design perspective and the distributed cognition perspective can help us think of novel possibilities of organizing work with crowd sourcing. I call for extending the conversation among computer-scientists and organizational researchers, and propose that the metaphor of 'information processing' might serve as a 'boundary-object' around which the dialogue among these communities can thrive.},
  keywords={Humans;Computers;Cognition;Games;Organizing;Encyclopedias;human-computation;crowdsourcing;collective-intelligence;human-computer interaction;computer-supported-collaborative-work},
  doi={10.1109/PASSAT/SocialCom.2011.205},
  ISSN={},
  month={Oct},}@ARTICLE{7302530,
  author={Ning, Huansheng and Liu, Hong and Ma, Jianhua and Yang, Laurence T. and Wan, Yueliang and Ye, Xiaozhen and Huang, Runhe},
  journal={IEEE Access}, 
  title={From Internet to Smart World}, 
  year={2015},
  volume={3},
  number={},
  pages={1994-1999},
  abstract={The development of informationization and intelligentization prompts Internet developing toward a new era. A deep fusion among cyber space, physical space, social space, and thinking space brings a quaternionic cyber-physical-social-thinking hyperspace, based on which an embryo of smart world is being established through heterogeneous spaces. The smart world is expected to be an attractive perspective involving ubiquitous sensing, computing, and communication to achieve comprehensive interconnections of physical perception, cyber interaction, social correlation, and cognitive thinking. In this paper, evolution of the smart world is briefly introduced, and physical-based coordination, social-inspired interactivity, brain-abstracted cooperativity, and cyber-enabled homogeneity are, respectively, discussed as the main characteristics of the smart world.},
  keywords={Cyber-physical systems;Internet of things;Social factors;Smart world;Internet of Things;cyber-physicalsocial system;hyperspace;Smart world;Internet of Things;cyber-physical-social system;hyperspace},
  doi={10.1109/ACCESS.2015.2493890},
  ISSN={2169-3536},
  month={},}@ARTICLE{9425540,
  author={Metcalfe, Jason S. and Perelman, Brandon S. and Boothe, David L. and Mcdowell, Kaleb},
  journal={IEEE Access}, 
  title={Systemic Oversimplification Limits the Potential for Human-AI Partnership}, 
  year={2021},
  volume={9},
  number={},
  pages={70242-70260},
  abstract={The modern world is evolving rapidly, especially with respect to the development and proliferation of increasingly intelligent, artificial intelligence (AI) and AI-related technologies. Nevertheless, in many ways, what this class of technologies has offered as return on investment remains less impressive than what has been promised. In the present paper, we argue that the continued failure to realize the potential in modern AI and AI-related technologies is largely attributable to the oversimplified, yet pervasive ways that our global society treats the relationship between these technologies and humans. Oversimplified concepts, once conveyed, tend to perpetuate myths that in turn limit the impact of such technologies in human society. To counter these oversimplifications, we offer a theoretical construct, which we call the landscape of human-AI partnership. This construct characterizes individual capability for real-world task performance as a dynamic function of information certainty, available time to respond, and task complexity. With this, our goal is to encourage more nuanced discourse about novel ways to solve challenges to modern and future sociotechnical societies, but without defaulting to notions that remain rooted in today's technologies-as-tools ways of thinking. The core of our argument is that society at large must recognize that intelligent technologies are evolving well beyond being mere tools for human use and are instead becoming capable of operating as interdependent teammates. This means that how we think about interactions between humans and AI needs to go beyond a “Human-or-AI” conversation about task assignments to more contextualized “Human-and-AI” way of thinking about how best to capitalize on the strengths hidden within emergent capabilities of unique human-AI partnerships that have yet to be fully realized.},
  keywords={Artificial intelligence;Task analysis;Complexity theory;Tools;Robot sensing systems;Ecosystems;Aging;Human-AI partnership;human-autonomy teaming;sociotechnical systems;AI ecosystems;function allocation;task complexity;capability;use cases;implementation},
  doi={10.1109/ACCESS.2021.3078298},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7546203,
  author={Manekar, Amit Kumar and Pradeepini, G.},
  booktitle={2015 International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={Cloud Based Big Data Analytics a Review}, 
  year={2015},
  volume={},
  number={},
  pages={785-788},
  abstract={Today's computing world is facing tsunami and driving without riding on this tsunami towards next generation computing is no choice. So many IT companies decided to grow up with this tsunami like technology. One of these is cloud computing and another is Big data. Currently more than 5 billion mobile users and nearly same facebook and other social media user generate this tsunami of data. On another side to deliver this services of big data a model called as cloud computing is spreading everywhere as next generations IT Service model. Both technologies continue to evolve. Ultimately as a cloud computing development matures, every top mind of organizations will think for development of efficient and agile cloud environment. At the other side every cloud provider offers the services to the huge number data processing companies that generate data process data and make decision on cloud infrastructure. Ultimately its today's need to think on futures efficient cloud based Big data analytics In this review paper we are focusing on, how we can club Big data and cloud Computing in one frame of development.},
  keywords={Cloud computing;Big data;Distributed databases;Security;Next generation networking;Tsunami;Market research;Big Data;Cloud Computing;Data Management;Distributed Computing},
  doi={10.1109/CICN.2015.160},
  ISSN={2472-7555},
  month={Dec},}@INPROCEEDINGS{8311704,
  author={Subekti, Mohammad and Junaidi and Warnars, Harco Leslie Hendric Spits and Heryadi, Yaya},
  booktitle={2017 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom)}, 
  title={The 3 steps of best data warehouse model design with leaning implementation for sales transaction in franchise restaurant}, 
  year={2017},
  volume={},
  number={},
  pages={170-174},
  abstract={Doing Data Warehouse (DW) to your business or system is not only think about the trend only, but how to understand the DW knowledge itself and how to implement it. DW as a real technology of Artificial Intelligent (AI) which show up as how to think like a human, inevitably help the human particularly in making quick decision reports. Doing DW to your systems should apply to the mother knowledge of AI which we recognized as Software Engineering (SE) where we should apply best software application in more importantly we should satisfy the user. In order to make a good DW model design as user expectation then we should apply 3 steps such as collect all the needed reporting, order all the reports start from the most needed reports and mapping all the ordered reports into fact constellation schema. In this paper the 3 steps to model DW schema is applied in sale transaction in franchise restaurant as an example data. Building franchise restaurant must supported by information technology such as Data Warehouse (DW) in order to manage and control the business process, the branch, the sale, the staff and so on.},
  keywords={Data warehouses;Databases;Data models;Computer science;Finance;Software;Star Schema;Snowflake;Fact Constellation;Data Warehouse;OLAP},
  doi={10.1109/CYBERNETICSCOM.2017.8311704},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{713830,
  author={Perlovsky, L.I.},
  booktitle={Proceedings of the 1998 IEEE International Symposium on Intelligent Control (ISIC) held jointly with IEEE International Symposium on Computational Intelligence in Robotics and Automation (CIRA) Intell}, 
  title={Cyberaesthetics: aesthetics, symbols and control}, 
  year={1998},
  volume={},
  number={},
  pages={857-862},
  abstract={The notions of concepts and emotions are mathematically described, and an "elementary" perception-cognition process is discussed inherently involving both aspects of the psyche. The mathematical nature of perception and cognition turn out to be very similar. The developed mathematical technique is practically useful for engineering designs and also corresponds to our intuition about our psyche. The paper establishes relationships between the developed mathematical techniques, classical semiotic concepts of sign and symbol, and more general notions of symbol in culture and psychology. An important and psychologically loaded notion of symbol refers to psychic processes connecting conscious and unconscious representations (concepts and archetypes). I analyze the elementary thinking process and discuss which aspects of this process are available to consciousness. This leads to a suggestion that the mathematical nature of the symbol process is similar to the perception-cognition process. Thus, thinking-process and symbol-process are same: a vortex of emotions, models-archetypes, and sensory data. This vortex brings forth into consciousness the previously unconscious contents of mind, which improve our understanding of the world.},
  keywords={Psychology;Artificial intelligence;Intelligent systems;Cognition;Design engineering;Joining processes;Cultural differences;Adaptive systems;Potential well;Intelligent networks},
  doi={10.1109/ISIC.1998.713830},
  ISSN={2158-9860},
  month={Sep.},}@INPROCEEDINGS{6643413,
  author={Jiang, Zuowen and Zhao, Yiming and Qin, Zhiping and Lin, Xueming},
  booktitle={2013 International Conference on Computational and Information Sciences}, 
  title={Coding Standard Based Object Oriented Programming Course Teaching Reform}, 
  year={2013},
  volume={},
  number={},
  pages={1890-1892},
  abstract={Object Oriented Programming is an important subject for computer major students, this course not only delivers the expertise on how to write program in an OOP language, but also guides students to think in object oriented paradigm. Teachers always found themselves in confusion on which language should be used as the teaching tool. In this paper we present some reform measures took based on our own teaching experiences, by introducing the thinking in object oriented paradigm. We use C#, C++ and Java in parallel to deliver the course. By emphasizing the programming standard in coding, the students acquired the knowledge to distinguish the 3 languages in practice as well as the OOP itself.},
  keywords={Educational institutions;Programming profession;Computers;Standards;Object oriented programming;Object Oriented Programming;coding standard},
  doi={10.1109/ICCIS.2013.494},
  ISSN={},
  month={June},}@INPROCEEDINGS{9988214,
  author={Ramesh, T. and Madhubala, E and Rani, N Sandhya and Roshini, K T},
  booktitle={2022 2nd International Conference on Technological Advancements in Computational Sciences (ICTACS)}, 
  title={A Novel Approach for Alzheimer Detection Using SMLT}, 
  year={2022},
  volume={},
  number={},
  pages={380-385},
  abstract={The absence of the brain chemical acetylcholine is the characteristic of Alzheimer's disease. In the early stages, this condition is thought to cause minimal memory loss, but as the disease progresses, it causes some loss of ability during discussion. It is a brain illness in which memory is progressively lost along with the capacity to think and carry out some daily duties. Some areas of the brain are also involved, including those that regulate the ability to think, remember, and use language. Alzheimer's treatment choices vary depending on whether or not the Alzheimer's is present. An Alzheimer's disease biopsy is required prior to final brain surgery in order to confirm the diagnosis. There are an estimated 6 million persons in the United States who suffer from Alzheimer's disease, and the majority of them are over the age of 65. Memory and other essential internal processes are lost as brain cell connections and cells themselves degrade and die. The most common signs and symptoms are disorientation and loss of memory. There is no cure, however medications and surgical procedures can alleviate symptoms for a while. For example, there are various hazard features to an Alzheimer's complaint, as well as a requirement for time to gather correct and accepted procedures in order to form an early assessment and resolve the complaint as quickly as possible. Data mining is a common practice in the healthcare industry for reusing large amounts of data. To better understand Alzheimer's disease, researchers use data mining and machine learning approaches to evaluate large volumes of medical information. Machine learning is being used to develop a model for diagnosing Alzheimer's disease at this time. In order to estimate the rise, various algorithms are examined and a current model is employed.},
  keywords={Training;Surgery;Machine learning;Medical services;Predictive models;Prediction algorithms;Data models;Alzheimer's disease Prediction;Machine Learning;SMLT},
  doi={10.1109/ICTACS56270.2022.9988214},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{6381625,
  author={Mandaleeka, Narayana GPL},
  booktitle={2012 IEEE International Conference on Computational Intelligence and Cybernetics (CyberneticsCom)}, 
  title={Organization-wide innovation management, a cybernetics approach}, 
  year={2012},
  volume={},
  number={},
  pages={98-102},
  abstract={Firms are recognizing the need to distinguish between R&D and Innovation. Innovation is becoming a distinct management function in the lines of marketing, HR, etc. Businesses need to be ambidextrous in their thinking taking into account capabilities of both right (creative) and left (analytical) side of the brain as challenges faced today requires integral solutions. The need is to work in cross functional teams, develop deep understanding of customer role, collaborate and more importantly address customer needs that may even not known to them; rather than just apply branding or fancy design styling. Fundamentals to integral approach are collaboration, embracing multidimensionality, systems thinking and applying cybernetics principles. The integral approach should involve users, designers, customers and suppliers. One need to understand the user based on fieldwork study, reach insights into user role and discover unarticulated needs. We normally measure innovation in terms of its technical strength and its utility value. In many cases this may not be enough. Innovation is a renewal process in that it prepares one for the future. It involves investing in the development of competence of the people, developing capabilities in them, nurturing customer relationships, and organizing knowledge bases. The point where technical innovation gets done is at the core of all these activities. The Balanced Score Card (BSC) has aroused considerable interest in the last two decades in business performance measurement. The reason could be that the managers are finding something more than the short term revenue reports that are prevalent. In the similar way the innovation can be looked not just at the point of idea creation but should be viewed as a staged process in the organization for the innovation to see the light of the market in a concerted way. This paper explains a cybernetics approach of modeling the innovation activities along the lines of Balanced Score Card (BSC).The principles of cybernetics may considered to be useful in `how we design” innovations as much as in “what innovations we design”.},
  keywords={Technological innovation;Companies;Cybernetics;Innovation management;Couplings;Innovation;key processes;cybernetics;balanced score card (BSC)},
  doi={10.1109/CyberneticsCom.2012.6381625},
  ISSN={},
  month={July},}@INPROCEEDINGS{638185,
  author={Eisner, H.},
  booktitle={1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation}, 
  title={Some lateral conjectures in science and psychology}, 
  year={1997},
  volume={2},
  number={},
  pages={1451-1456 vol.2},
  abstract={This paper uses aspects of lateral thinking traceable to de Bono (1970) to offer several conjectures relating to selected domains of science and psychology. In one instance, the former domain is that of thermodynamics and information theory and the latter involves mental health. The lateral conjecture takes the form of drawing an analogy between notions of entropy and the ability of the human to construct choices. In another case, a law of thermodynamics is viewed in terms of organizational behavior. In a third instance, a Prigogine idea (Prigogine, 1980) is briefly explored from the perspective of a lateral conjecture. These and other notions are introduced to encourage other researchers interested in the heuristics of lateral thinking within the context of interdisciplinary research.},
  keywords={Psychology;Cybernetics;Polarization;Thermodynamics;Fractionation;Information theory;Entropy;Humans;Communication system control;Control systems},
  doi={10.1109/ICSMC.1997.638185},
  ISSN={1062-922X},
  month={Oct},}@ARTICLE{9319727,
  author={Chen, Xing and Liu, Guizhong},
  journal={IEEE Internet of Things Journal}, 
  title={Energy-Efficient Task Offloading and Resource Allocation via Deep Reinforcement Learning for Augmented Reality in Mobile Edge Networks}, 
  year={2021},
  volume={8},
  number={13},
  pages={10843-10856},
  abstract={The augmented reality (AR) applications have been widely used in the field of Internet of Things (IoT) because of good immersion experience for users, but their ultralow delay demand and high energy consumption bring a huge challenge to the current communication system and terminal power. The emergence of mobile-edge computing (MEC) provides a good thinking to solve this challenge. In this article, we study an energy-efficient task offloading and resource allocation scheme for AR in both the single-MEC and multi-MEC systems. First, a more specific and detailed AR application model is established as a directed acyclic graph according to its internal functionality. Second, based on this AR model, a joint optimization problem of task offloading and resource allocation is formulated to minimize the energy consumption of each user subject to the latency requirement and the limited resources. The problem is a mixed multiuser competition and cooperation problem, which involves the task offloading decision, uplink/downlink transmission resources allocation, and computing resources allocation of users and MEC server. Since it is an NP-hard problem and the communication environment is dynamic, it is difficult for genetic algorithms or heuristic algorithms to solve. Therefore, we propose an intelligent and efficient resource allocation and task offloading algorithm based on the deep reinforcement learning framework of multiagent deep deterministic policy gradient (MADDPG) in a dynamic communication environment. Finally, simulation results show that the proposed algorithm can greatly reduce the energy consumption of each user terminal.},
  keywords={Task analysis;Servers;Optimization;Resource management;Energy consumption;Computational modeling;Heuristic algorithms;Augmented reality (AR);deep reinforcement learning;Internet of Things (IoT);mobile-edge computing (MEC);multiagent deep deterministic policy gradient (MADDPG);resource allocation;task offloading},
  doi={10.1109/JIOT.2021.3050804},
  ISSN={2327-4662},
  month={July},}@ARTICLE{6185551,
  author={Avraham, Guy and Nisky, Ilana and Fernandes, Hugo L. and Acuna, Daniel E. and Kording, Konrad P. and Loeb, Gerald E. and Karniel, Amir},
  journal={IEEE Transactions on Haptics}, 
  title={Toward Perceiving Robots as Humans: Three Handshake Models Face the Turing-Like Handshake Test}, 
  year={2012},
  volume={5},
  number={3},
  pages={196-207},
  abstract={In the Turing test a computer model is deemed to “think intelligently” if it can generate answers that are indistinguishable from those of a human. We developed an analogous Turing-like handshake test to determine if a machine can produce similarly indistinguishable movements. The test is administered through a telerobotic system in which an interrogator holds a robotic stylus and interacts with another party - artificial or human with varying levels of noise. The interrogator is asked which party seems to be more human. Here, we compare the human-likeness levels of three different models for handshake: (1) Tit-for-Tat model, (2) λ model, and (3) Machine Learning model. The Tit-for-Tat and the Machine Learning models generated handshakes that were perceived as the most human-like among the three models that were tested. Combining the best aspects of each of the three models into a single robotic handshake algorithm might allow us to advance our understanding of the way the nervous system controls sensorimotor interactions and further improve the human-likeness of robotic handshakes.},
  keywords={Humans;Muscles;Force;Computational modeling;Haptic interfaces;Robot sensing systems;Noise;Handshake;sensorimotor control;psychophysics;teleoperation;turing test.},
  doi={10.1109/TOH.2012.16},
  ISSN={2329-4051},
  month={Third},}@INPROCEEDINGS{8252094,
  author={Ahmad, Adang Suwandi and Sumari, Arwin Datumaya Wahyudi},
  booktitle={2017 Computing Conference}, 
  title={Cognitive artificial intelligence: Brain-inspired intelligent computation in artificial intelligence}, 
  year={2017},
  volume={},
  number={},
  pages={135-141},
  abstract={Computation occurred within human brain is very much awesome and is not possible to be emulated 100% exactly in Artificial Intelligence (AI) method-based machines. What scientists did and have been done so far up to now are to try to model it as close as to what exactly occurs within the brain. Human brain has an awesome mechanism in performing computation with the end result is new knowledge and human uses the knowledge to actuate his organs. In this paper we will show a new approach for emulating the computation occured within human brain to obtain new knowledge based on the inputs sensed by the system's sensory system taken from the environment. When this process is carried out recursively, the system's knowledge becomes newer and newer, and it is called as knowledge growing. This approach is designed for an agent that has ability to think and act rationally like human. Our cognitive modelling approach is resulted in a model of human information processing and a technique to obtain the most maximum performance should be taken by the cognitive agent. This method is called as A3S (Arwin-Adang-Aciek-Sembiring), the agent is called as Knowledge-Growing System (KGS) and this brain-inspired method opens a new perspective in AI that we call as Cognitive Artificial Intelligence (CAI).},
  keywords={Brain modeling;Information processing;Artificial intelligence;Mathematical model;Psychology;Computational modeling;A3S;Cognitive Artificial Intelligence;intelligent computation;knowledge extraction;Knowledge-Growing System},
  doi={10.1109/SAI.2017.8252094},
  ISSN={},
  month={July},}@INPROCEEDINGS{8819498,
  author={Haque, Md Ariful and Shetty, Sachin and Krishnappa, Bheshaj},
  booktitle={2019 IEEE 5th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)}, 
  title={ICS-CRAT: A Cyber Resilience Assessment Tool for Industrial Control Systems}, 
  year={2019},
  volume={},
  number={},
  pages={273-281},
  abstract={In this work, we use a subjective approach to compute cyber resilience metrics for industrial control systems. We utilize the extended form of the R4 resilience framework and span the metrics over physical, technical, and organizational domains of resilience. We develop a qualitative cyber resilience assessment tool using the framework and a subjective questionnaire method. We make sure the questionnaires are realistic, balanced, and pertinent to ICS by involving subject matter experts into the process and following security guidelines and standards practices. We provide detail mathematical explanation of the resilience computation procedure. We discuss several usages of the qualitative tool by generating simulation results. We provide a system architecture of the simulation engine and the validation of the tool. We think the qualitative simulation tool would give useful insights for industrial control systems' overall resilience assessment and security analysis.},
  keywords={Resilience;Measurement;Integrated circuits;Tools;Security;Robustness;Computational modeling;Cyber Resilience;Industrial Control Systems;Qualitative Tool;Resilience Metrics;Critical Service Functionality},
  doi={10.1109/BigDataSecurity-HPSC-IDS.2019.00058},
  ISSN={},
  month={May},}@INPROCEEDINGS{9322470,
  author={Baccour, Emna and Erbad, Aiman and Mohamed, Amr and Hamdi, Mounir and Guizani, Mohsen},
  booktitle={GLOBECOM 2020 - 2020 IEEE Global Communications Conference}, 
  title={DistPrivacy: Privacy-Aware Distributed Deep Neural Networks in IoT surveillance systems}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={With the emergence of smart cities, Internet of Things (IoT) devices as well as deep learning technologies have witnessed an increasing adoption. To support the requirements of such paradigm in terms of memory and computation, joint and real-time deep co-inference framework with IoT synergy was introduced. However, the distribution of Deep Neural Networks (DNN) has drawn attention to the privacy protection of sensitive data. In this context, various threats have been presented, including black-box attacks, where a malicious participant can accurately recover an arbitrary input fed into his device. In this paper, we introduce a methodology aiming to secure the sensitive data through re-thinking the distribution strategy, without adding any computation overhead. First, we examine the characteristics of the model structure that make it susceptible to privacy threats. We found that the more we divide the model feature maps into a high number of devices, the better we hide proprieties of the original image. We formulate such a methodology, namely DistPrivacy, as an optimization problem, where we establish a trade-off between the latency of co-inference, the privacy level of the data, and the limited-resources of IoT participants. Due to the NP-hardness of the problem, we introduce an online heuristic that supports heterogeneous IoT devices as well as multiple DNNs and datasets, making the pervasive system a general-purpose platform for privacy-aware and low decision-latency applications.},
  keywords={Privacy;Image segmentation;Task analysis;Computational modeling;Automobiles;Surveillance;Servers;IoT devices;distributed DNN;privacy;sensitive data;black-box;resource constraints},
  doi={10.1109/GLOBECOM42002.2020.9322470},
  ISSN={2576-6813},
  month={Dec},}@INPROCEEDINGS{8790188,
  author={Heintz, Benjamin and Hong, Rankyung and Singh, Shivangi and Khandelwal, Gaurav and Tesdahl, Corey and Chandra, Abhishek},
  booktitle={2019 IEEE International Conference on Cloud Engineering (IC2E)}, 
  title={MESH: A Flexible Distributed Hypergraph Processing System}, 
  year={2019},
  volume={},
  number={},
  pages={12-22},
  abstract={With the rapid growth of large online social networks, the ability to analyze large-scale social structure and behavior has become critically important, and this has led to the development of several scalable graph processing systems. In reality, however, social interaction takes place not only between pairs of individuals as in the graph model, but rather in the context of multi-user groups. Research has shown that such group dynamics can be better modeled through a more general hypergraph model, resulting in the need to build scalable hypergraph processing systems. In this paper, we present MESH, a flexible distributed framework for scalable hypergraph processing. MESH provides an easy-to-use and expressive application programming interface that naturally extends the "think like a vertex" model common to many popular graph processing systems. Our framework provides a flexible implementation based on an underlying graph processing system, and enables different design choices for the key implementation issues of partitioning a hypergraph representation. We implement MESH on top of the popular GraphX graph processing framework in Apache Spark. Using a variety of real datasets and experiments conducted on a local 8-node cluster as well as a 65-node Amazon AWS testbed, we demonstrate that MESH provides flexibility based on data and application characteristics, as well as scalability with cluster size. We further show that it is competitive in performance to HyperX, another hypergraph processing system based on Spark, while providing a much simpler implementation (requiring about 5X fewer lines of code), thus showing that simplicity and flexibility need not come at the cost of performance.},
  keywords={Computational modeling;Manganese;Cluster computing;Scalability;Partitioning algorithms;Sparks;Social networking (online);Hypergraph Processing System;Distributed Processing System},
  doi={10.1109/IC2E.2019.00-11},
  ISSN={},
  month={June},}@INPROCEEDINGS{7827611,
  author={Chang, Wanli and Roy, Debayan and Zhang, Licong and Chakraborty, Samarjit},
  booktitle={2016 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)}, 
  title={Model-based design of resource-efficient automotive control software}, 
  year={2016},
  volume={},
  number={},
  pages={1-8},
  abstract={Automotive platforms today run hundreds of millions of lines of software code implementing a large number of different control applications spanning across safety-critical functionality to driver assistance and comfort-related functions. While such control software today is largely designed following model-based approaches, the underlying models do not take into account the details of the implementation platforms, on which the software would eventually run. Following the state-of-the-art in control theory, the focus in such design is restricted to ensuring the stability of the designed controllers and meeting control performance objectives, such as settling time or peak overshoot. However, automotive platforms are highly cost-sensitive and the issue of designing “resource-efficient” controllers has largely been ignored so far and is addressed using very ad hoc techniques. In this paper, we will illustrate how, following traditional embedded systems design oriented thinking, computation, communication and memory issues can be incorporated in the controller design stage, thereby resulting in control software not only satisfying the usual control performance metrics but also making efficient utilization of the resources on distributed automotive architectures.},
  keywords={Automotive engineering;Actuators;Computer architecture;Measurement;Computational modeling;Embedded systems},
  doi={10.1145/2966986.2980075},
  ISSN={1558-2434},
  month={Nov},}@INPROCEEDINGS{1582903,
  author={Sprinkle, J. and Ames, A.D. and Pinto, A. and Haiyang Zheng and Sastry, S.S.},
  booktitle={Proceedings of the 44th IEEE Conference on Decision and Control}, 
  title={On the Partitioning of Syntax and Semantics For Hybrid Systems Tools}, 
  year={2005},
  volume={},
  number={},
  pages={4694-4699},
  abstract={Interchange formats are notoriously difficult to finish. That is, once one is developed, it is highly nontrivial to prove (or disprove) generality, and difficult at best to gain acceptance from all major players in the application domain. This paper addresses such a problem for hybrid systems, but not from the perspective of a tool interchange format, but rather that of tool availability in a toolbox. Through the paper we explain why we think this is a good approach for hybrid systems, and we also analyze the domain of hybrid systems to discern the semantic partitions that can be formed to yield a classification of tools based on their semantics. These discoveries give us the foundation upon which to build semantic capabilities, and to guarantee operational interaction between tools based on matched operational semantics.},
  keywords={Computational modeling;Embedded computing;Control system synthesis;Process control;Control systems;Hardware;Resistors;Capacitors;Inductors;Design engineering},
  doi={10.1109/CDC.2005.1582903},
  ISSN={0191-2216},
  month={Dec},}@INPROCEEDINGS{9643932,
  author={Imanaga, Tomohiro and Nakano, Koji and Yasudo, Ryota and Ito, Yasuaki and Kawamata, Yuya and Katsuki, Ryota and Ozaki, Shiro and Yazane, Takashi and Hamano, Kenichiro},
  booktitle={2021 Ninth International Symposium on Computing and Networking (CANDAR)}, 
  title={Solving the sparse QUBO on multiple GPUs for Simulating a Quantum Annealer}, 
  year={2021},
  volume={},
  number={},
  pages={19-28},
  abstract={Quadratic Unconstraint Binary Optimization (QUBO) is a combinatorial optimization problem such that an $n\times n$ upper triangle matrix $W$ is given and the objective is to find an n-bit vector $X$ that minimizes the energy value $E(X)=X^{T}WX$. A QUBO instance $W$ is sparse if instance $W$ has few non-zero elements. The D-Wave 2000$Q$ is a quantum annealer that can solve 2048-bit sparse QUBO instances represented as a Chimera graph topology. We present a sparse QUBO solver running on GPUs for 2048-bit sparse QUBO with a Chimera graph topology. We have evaluated the performance of our sparse QUBO solver and the D-Wave 2000Q for solving 2048-bit QUBO instances with various resolutions. The experimental results show that our sparse QUBO solver running on a GPU cloud server with 8 NVIDIA A100 GPUs can find optimal solutions in less than 3ms for all instances while the D-Wave 2000$Q$ cannot find them in 996.7ms. Hence, our QUBO solver can find better solutions than the D-Wave 2000Q in less than 1/300 running time. We can think that our QUBO solver is a quantum annealer simulator with better performance in terms of the accuracy of solutions and the running time. Our result implies that quantum annealer D-Wave 2000$Q$ does not achieve quantum supremacy yet.},
  keywords={Annealing;Shape;Computational modeling;Graphics processing units;Simulated annealing;Quantum annealing;Topology;Ising model;quantum computing;quantum supremacy;GPGPU},
  doi={10.1109/CANDAR53791.2021.00011},
  ISSN={2379-1896},
  month={Nov},}@INPROCEEDINGS{9776343,
  author={Rathore, Abhiraj Singh and Sharma, Adarsh and Massoudi, Massoud},
  booktitle={2021 6th International Conference on Computing, Communication and Security (ICCCS)}, 
  title={Personalized Engineering Education Model Based on Artificial Intelligence for Learning Programming}, 
  year={2021},
  volume={},
  number={},
  pages={1-10},
  abstract={Background: Personalisation is a critical element in the learning environment of students. This is one area that our educational system falls short. Students study at varying rates and in varying contexts, and this should be considered, which most institutions do not. We need a structure that enables students of diverse background to research and learn in their own unique manner, at their own speed, in order to grasp concepts and solve problems. Today, there is something that is gaining a lot of popularity. The future is artificial intelligence, and we agree that science holds the secret to resolving the majority of the world's problems. Result: This article provides a novel model of a system that utilizes artificial intelligence and machine learning algorithms to assist students in learning to program and creates a customized system for them. The model classifies students into beginner, intermediate, and proficient ranks using Bayesian networks. Students are helped to understand ideas by the use of tools such as flowcharts. Each level of students is provided with unique instruments and materials, and the goal is to raise the comprehension level of beginner and intermediate students to a point that they can compete with proficient students, who are provided with practice questions to further their learning. Additionally, skilled students have the ability to work in industry through the model's industry-academia partnership module. Conclusion: This paper proposes a technique that helps students in customized learning as well as in improving their critical thinking capacities using a multi-agent-based flowchart development tool. It serves as an absolute and a complete tutoring aid for students learning programming.},
  keywords={Industries;Flowcharts;Machine learning algorithms;Instruments;Computational modeling;Learning (artificial intelligence);Bayes methods;Personalized learning;Engineering education;Artificial intelligence;Learning outcome},
  doi={10.1109/ICCCS51487.2021.9776343},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8603189,
  author={Audrito, Giorgio and Damiani, Ferruccio and Viroli, Mirko and Bini, Enrico},
  booktitle={2018 IEEE Real-Time Systems Symposium (RTSS)}, 
  title={Distributed Real-Time Shortest-Paths Computations with the Field Calculus}, 
  year={2018},
  volume={},
  number={},
  pages={23-34},
  abstract={As the density of sensing/computation/actuation nodes is increasing, it becomes more and more feasible and useful to think at an entire network of physical devices as a single, continuous space-time computing machine. The emergent behaviour of the whole software system is then induced by local computations deployed within each node and by the dynamics of the information diffusion. A relevant example of this distribution model is given by aggregate computing and its companion language field calculus, a minimal set of purely functional constructs used to manipulate distributed data structures evolving over space and time, and resulting in robustness to changes. In this paper, we study the convergence time of an archetypal and widely used component of distributed computations expressed in field calculus, called gradient: a fully-distributed estimation of distances over a metric space by a spanning tree. We provide an analytic result linking the quality of the output of a gradient to the amount of computing resources dedicated. The resulting error bounds are then exploited for network design, suggesting an optimal density value taking broadcast interferences into account. Finally, an empirical evaluation is performed validating the theoretical results.},
  keywords={Calculus;Aggregates;Programming;Computational modeling;Real-time systems;Sensors;Wireless sensor networks;aggregate computing;field calculus;shortest path;IoT;distributed systems},
  doi={10.1109/RTSS.2018.00013},
  ISSN={2576-3172},
  month={Dec},}@INPROCEEDINGS{10254740,
  author={Pujol, Victor Casamayor and Morichetta, Andrea and Nastic, Stefan},
  booktitle={2023 IEEE International Conference on Service-Oriented System Engineering (SOSE)}, 
  title={Intelligent Sampling: A Novel Approach to Optimize Workload Scheduling in Large-Scale Heterogeneous Computing Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={140-149},
  abstract={Scheduling workloads on large-scale infrastructures, such as in the Edge-Cloud continuum is a challenging task. Usually, the scheduling algorithm considers only a limited sample of the infrastructure nodes, typically obtained through random sampling. The sampling reduces the number of nodes, which need to be evaluated in the scheduling pipeline, making the scheduling process more saleable. Unfortunately, current sampling approaches become largely inefficient when the infrastructure is heterogeneous and specific, scarce node characteristics are required to successfully execute a workload. Computing continuum infrastructures are heterogeneous, hence, we need to re-think the sampling process to keep it viable at scale while also being able to identify and leverage the heterogeneity of the Edge-Cloud continuum resources. In this article, we present Intelligent Sampling - a novel technique for improving sampling in large-scale and heterogeneous infrastructures. We develop a model for any heterogeneous infrastructure. Based on this model, we provide a method to sample the infrastructure nodes more accurately, considering the specific task at hand. Finally, we leverage the Alibaba PAI dataset to show that our approach is 2.5x times more accurate compared with other state-of-the-art sampling mechanisms while retaining comparable performance and scalability.},
  keywords={Service-oriented systems engineering;Scheduling algorithms;Computational modeling;Scalability;Pipelines;Heterogeneous networks;Complexity theory;Computing continuum;Intelligent sampling;Workloads scheduling;Heterogeneous infrastructure model},
  doi={10.1109/SOSE58276.2023.00024},
  ISSN={2642-6587},
  month={July},}@INPROCEEDINGS{6779199,
  author={Bai, Liming},
  booktitle={16th International Conference on Advanced Communication Technology}, 
  title={Techniques for system of systems engineering in construction of a smart tourism industry information system}, 
  year={2014},
  volume={},
  number={},
  pages={402-408},
  abstract={Currently, as many disciplines begin to cultivate a set of core methodologies, system of systems engineering (SoSE), which has its root in context of military programming, becomes a significant research focus and provides a new perspective to solve the emerging "system of systems" challenges in industrial analysis. Meanwhile, modern communication and information technologies have provided greater possibilities for socio-economic sectors to execute smarter decisions, and these technologies may advance the industrial application of SoSE. Therefore, targeting the rareness of government-oriented intelligent decision support system (DSS), and guided by the underlying system of systems thinking, this paper proposes a technical framework for designing a policy maker-responsive smart information system which focuses: (1) system of systems structural architecting; (2) geographical simulation using time-series remotely sensed data, GIS instrument and simulation bodies such as cellular automata (CA) and multi-agent systems (MAS); (3) SoS evolution description through network analysis and intelligent computing; (4) measurement of SoS effectiveness with two-tier and four-grade method; and (5) SoSE program for industrial optimization. Its application in tourism analysis will provide a smarter base for industrial policy-making, planning and forecasting, and will help reduce risk and cost in industrial restructuring. For this relatively new field of SoSE application, tools and methods are not perfect, so it is important to draw together academia, government, industrial organizations and enterprises to collaborate for further valuable achievement.},
  keywords={Information systems;Computational modeling;Artificial intelligence;Industries;Biological system modeling;System of systems engineering (SoSE);geographical simulation;tourism;smart industry information system;intelligent computing},
  doi={10.1109/ICACT.2014.6779199},
  ISSN={1738-9445},
  month={Feb},}@INPROCEEDINGS{6143085,
  author={Neri, Luis and Noguez, Julieta and Pérez, Iván and Aguilar, Gerardo},
  booktitle={2011 Frontiers in Education Conference (FIE)}, 
  title={Facilitating the design of physics active learning problems through authoring simulation tools: Authorphysics}, 
  year={2011},
  volume={},
  number={},
  pages={S3C-1-S3C-6},
  abstract={Active learning is an educational strategy that promotes the development of the student's critical and creative thinking through carefully designed activities. The teacher often faces challenges to design adequate physics problems because it demands a high effort to have enough variety of exercises for several students' levels. In addition, it is important to display exercises in an attractive visual and interactive environment, but this requires deep computer knowledge. Most common simulators in the literature are visually attractive, but are often designed to solve a particular or limited problem. Authoring tools have the advantage to allow building several learning environments, involving professors without computer expertise. Therefore, teachers require less effort and time to develop simulation problems. In this work we present an on line authoring simulation tool, called AuthorPhysics, aimed to facilitate the design of physics active learning problems, reducing instructors' time and effort. An initial evaluation of the usability and benefits of the system for the instructors was carried on. The results are encouraging in the sense that teachers are able to create a great variety of physical scenarios and problems, appropriate for introductory undergraduate and high-school physics courses. An evaluation with students is currently running.},
  keywords={Computational modeling;Pulleys;Mathematical model;Education;Friction;Java;Active Learning;Authoring Tools;eLearning Tools;Introductory Classical Mechanics;On line Tools;Physics Simulations},
  doi={10.1109/FIE.2011.6143085},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{4531358,
  author={Buscema, Massimo},
  booktitle={NAFIPS 2008 - 2008 Annual Meeting of the North American Fuzzy Information Processing Society}, 
  title={The general philosophy of Artificial Adaptive Systems}, 
  year={2008},
  volume={},
  number={},
  pages={1-14},
  abstract={This paper has the objective of describing the structure and placing in a taxonomy the Artificial Adaptive Systems (AAS). These systems form part of the vast world of Artificial Intelligence (AI) nowadays called more properly Artificial Sciences (AS). Artificial Sciences means those sciences for which an understanding of natural and/or cultural processes is achieved by the recreation of those processes through automatic models. In particular, Natural Computation tries to construct automatic models of complex processes, using the local interaction of elementary micro-processes, simulating the original process functioning. Such models organize themselves in space and time and connect in a non-linear way to the global process they are part of, trying to reproduce the complexity through the dynamic creation of specific and independent local rules that transform themselves in relation to the dynamics of the process. Natural Computation constitutes the alternative to Classical Computation (CC). This one, in fact, has great difficulty in facing natural/cultural processes, especially when it tries to impose external rules to understand and reproduce them, trying to formalize these processes in an artificial model. In Natural Computation ambit, Artificial Adaptive Systems are theories which generative algebras are able to create artificial models simulating natural phenomenon. The learning and growing process of the models is isomorphic to the natural process evolution, that is, it's itself an artificial model comparable with the origin of the natural process. We are dealing with theories adopting the "time of development" of the model as a formal model of "time of process" itself. Artificial Adaptive Systems comprise Evolutive Systems and Learning Systems. Artificial Neural Networks are the more diffused and best-known Learning Systems models in Natural Computation. For this reason we present in this paper an application of new Artificial Adaptive Systems to a very hard and pragmatic topic: drug trafficking. That because we think that "real world" is often the best theory.},
  keywords={Adaptive systems;Computational modeling;Artificial intelligence;Cultural differences;Learning systems;Taxonomy;Algebra;Artificial neural networks;Computer networks;Drugs},
  doi={10.1109/NAFIPS.2008.4531358},
  ISSN={},
  month={May},}@INPROCEEDINGS{9658463,
  author={Liu, Jingyi and Yu, Lina and Wu, Min and Tong, Yuerong and Xu, Jian and Li, Zhiwei and Hu, Xuan and Li, Weijun},
  booktitle={2021 International Conference on High Performance Big Data and Intelligent Systems (HPBD&IS)}, 
  title={Producing Monomial Sets with Lower Calculation Complexity for Polynomial Fitting}, 
  year={2021},
  volume={},
  number={},
  pages={52-56},
  abstract={In the physic world, exploring and discovering the mechanism behind the various phenomenon is crucial for us to know the world better. However, it is hard to discover the principle in case of enormous data and the mechanism may be too hard for a human to figure out. Data science gives us a way of knowing the world and finding the mechanism hidden in the data. Automatic tool like polynomial fitting is a useful method to fit the data well. When the variable number and degree are relatively low, the computation amount of polynomial is small. However, the number of monomials grows exponentially with the increasing variable number and degree. Problems in the real world are always in a high-dimension, and the problem may be complex that needs to use a high degree to fit data well. Plus, with the huge data, the computation complexity is high. Therefore, we think it is necessary to find a way to reduce the computation amount of fitted polynomial. In this paper, we propose to use the PSO algorithm to find the monomial sets that have lower computation amounts. Experiments show the effectiveness of our method.},
  keywords={Fitting;Data science;Computational complexity;Physics;polynomial fitting;computation complexity;optimization problem;pattern recognition},
  doi={10.1109/HPBDIS53214.2021.9658463},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10633328,
  author={Zhang, Yifan and Towey, Dave and Pike, Matthew},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Enabling Effective Metamorphic- Relation Generation by Novice Testers: A Pilot Study}, 
  year={2024},
  volume={},
  number={},
  pages={2393-2398},
  abstract={This paper presents a pilot study that examines the capacity of novice testers to generate Metamorphic Relations (MRs) for autonomous driving systems (ADSs), specifically fo-cusing on parking functions. By comparing MRs generated by human participants with those generated by artificial intelligence (AI), we seek to understand the variances in quality, particularly in terms of correctness, applicability, novelty, and utility. Our findings indicate that despite receiving only minimal training, human participants were capable of producing MRs with a wide range of effectiveness. Notably, humans exhibited a potential for creative thinking, contrasting with AI's ability to generate MRs that adhere closely to technical and applicability standards. The study underscores the need for improved educational strategies aimed at enhancing the quality and confidence of MRs produced by humans. Future research directions will explore the optimization of training approaches, particularly within a constrained timeframe to create a positive learning experience and maintain participant engagement, to fully harness the creative capabilities of human learners in the context of ADS testing.},
  keywords={Training;Computational modeling;Software;Artificial intelligence;Standards;Optimization;Autonomous vehicles;Metamorphic testing;autonomous driving system;metamorphic relation;driving scenarios;large language models;artificial intelligence},
  doi={10.1109/COMPSAC61105.2024.00384},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{9443981,
  author={Li, Yang and Shi, Bing},
  booktitle={2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)}, 
  title={A Deep Reinforcement Learning based Mobile Device Task Offloading Algorithm in MEC}, 
  year={2020},
  volume={},
  number={},
  pages={200-207},
  abstract={Nowadays, more and more compute-intensive applications begin to appear on mobile devices. However, mobile devices may not be able to satisfy the computing requirements. Mobile Edge Computing (MEC) is proposed to address these issues. Mobile devices offload the computing tasks to the edge servers which accept tasks and handle them. And we think the edge servers should accomplish tasks as many as possible while minimizing total energy cost. However, users with mobile devices are usually keeping moving. In this situation, the energy consumption of tasks are constantly changing, and we need an efficient algorithm to dynamically determine how to offload tasks to a set of edge servers, to maximize the number of completed tasks while minimizing the energy consumption. The dynamic decision of task offloading is a multi-stage decision problem, and therefore we can model this problem as a Markov decision process (MDP). Because this problem involves a huge state space with high dimension, we propose a deep reinforcement learning (DRL) based mobile device task offloading algorithm to solve this problem. We also run extensive experiments to evaluate our task offloading approach against other typical task offloading approaches. The results of experiments show that our algorithm is superior to the baseline algorithms.},
  keywords={Energy consumption;Heuristic algorithms;Computational modeling;Reinforcement learning;Markov processes;Mobile handsets;Servers;Mobile Edge Computing;Task Offloading;Deep Reinforcement Learning},
  doi={10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00051},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10485136,
  author={Chen, Shiyang and Zheng, Da and Ding, Caiwen and Huan, Chengying and Ji, Yuede and Liu, Hang},
  booktitle={SC23: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Tango: Rethinking Quantization for Graph Neural Network Training on GPUs}, 
  year={2023},
  volume={},
  number={},
  pages={1-15},
  abstract={Graph learning is becoming increasingly popular due to its superior performance in tackling many grand challenges. While quantization is widely used to accelerate Graph Neural Network (GNN) computation, quantized training faces remarkable roadblocks. Current quantized GNN training systems often experience longer training time than their full-precision counterparts for two reasons: (i) addressing the quantization accuracy challenge leads to excessive overhead, and (ii) the optimization potential exposed by quanti-zation is not adequately leveraged. This paper introduces Tango which re-thinks quantization challenges and opportunities for graph neural network training on GPUs with three contributions: Firstly, we introduce efficient rules to maintain accuracy during quantized GNN training. Secondly, we design and implement quantization-aware primitives and inter-primitive optimizations to speed up GNN training. Finally, we integrate Tango with the popular Deep Graph Library (DGL) system and demonstrate its superior performance over the state-of-the-art approaches on various GNN models and datasets.},
  keywords={Training;Quantization (signal);High performance computing;Computational modeling;Graph neural networks;Libraries;Optimization},
  doi={10.1145/3581784.3607037},
  ISSN={2167-4337},
  month={Nov},}@INPROCEEDINGS{8802735,
  author={Di Pietro, Roberto and Jero, Leonardo and Lombardi, Flavio and Solanas, Agusti},
  booktitle={2019 IEEE Conference on Communications and Network Security (CNS)}, 
  title={GPU Algorithms for K-Anonymity in Microdata}, 
  year={2019},
  volume={},
  number={},
  pages={1-9},
  abstract={GPU computing, nowadays widely and readily available on the cloud, has opened up novel opportunities for the parallelization of computationally-intensive tasks, such as data anonymization. The development of effective techniques that help to guarantee data anonymity is a critical enabler for data sharing activities, as well as to enforce compliance-think about the European GDPR. In this scenario, we focus on personal data stored in microdata sets. Before releasing such microdata to the general public, statistical agencies and the like have to sanitize them by using a variety of Microdata Protection Techniques (MPTs)that aim at keeping data utility while preserving some kind of anonymity. In particular, microaggregation is a specific MPT arisen in the field of statistical disclosure control. We analyze the microaggregation anonymization issues and propose three GPU-based parallel approaches for a well-known microaggregation technique: the Maximum Distance to Average Vector (MDAV)algorithm. The experimental results demonstrate the feasibility of our proposal and emphasize the benefits of using GPUs to speed-up the execution of privacy preserving algorithms for microdata.},
  keywords={Graphics processing units;Security;Conferences;Privacy;Computational efficiency;Java;Communication networks;Privacy;Anonymization;Cloud;Microaggre-gation;GPU;Parallelization},
  doi={10.1109/CNS.2019.8802735},
  ISSN={},
  month={June},}@INPROCEEDINGS{4141731,
  author={Imai, Yoshiro and Kaneko, Keiichi and Nakagawa, Masaki},
  booktitle={2006 7th International Conference on Information Technology Based Higher Education and Training}, 
  title={A Visual Computer Simulator and its Applications to An ICT-based Higher Education}, 
  year={2006},
  volume={},
  number={},
  pages={nil13-nil20},
  abstract={A visual computer simulator, called "VisuSim", has been developed and applied to real education for Computer Science at Kagawa University. It is one of educational tools associated with lectures on computer architecture and assembly programming. The simulator is written in the pure Java programming language, executed in several kinds of environment (free for types of OS and CPU) and invoked in the applet mode as well as in the stand-alone one. Typical usages of our simulator are two-fold. Teachers employ our simulator, "VisuSim" to demonstrate visually how a computer processes its program. Students use the simulators in class or access our Website, download "VisuSim", and invoke applet-based "VisuSim" on their browsers. After receiving feedback from users, we have provided communication support facility as a new function of "VisuSim". With such a communication facility, can send their programs, ask questions on them to their classmates and the classmates can test received programs with their "VisuSim" to think together about the questions},
  keywords={Computational modeling;Computer simulation;Application software;Computer science education;Educational programs;Computer science;Computer architecture;Assembly;Programming profession;Java;Educational tool;Collaborative learning;Visual simulator;Java programming language;Computer literacy},
  doi={10.1109/ITHET.2006.339722},
  ISSN={},
  month={July},}@INPROCEEDINGS{882454,
  author={Principe, J.C. and Erdogmus, D.},
  booktitle={Proceedings of the IEEE 2000 Adaptive Systems for Signal Processing, Communications, and Control Symposium (Cat. No.00EX373)}, 
  title={From adaptive linear to information filtering}, 
  year={2000},
  volume={},
  number={},
  pages={99-104},
  abstract={Adaptive signal processing theory was born and has lived by exclusively exploiting the mean square error criterion. When we think of the goal of least squares without restrictions of Gaussianity, one has to wonder why an information theoretic error criterion is not utilized instead. After all, the goal of adaptive filtering should be to find the linear projection that best captures the information in the desired response. We summarize our efforts to extend adaptive linear filtering to information filtering. We review Renyi's (1987) entropy definition, Parzen (1967) windows and put them together in a framework to estimate entropy directly from samples (nonparametric). Once this criterion is developed we can train linear or nonlinear adaptive networks for entropy maximization or minimization. We present results on the properties of the Renyi's nonparametric entropy estimator, and show how it performs in chaotic time series prediction.},
  keywords={Information filtering;Entropy;Adaptive signal processing;Mean square error methods;Least squares methods;Gaussian processes;Adaptive filters;Maximum likelihood detection;Adaptive systems;Chaos},
  doi={10.1109/ASSPCC.2000.882454},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9381469,
  author={Michalski, Radoslaw and Pieczka, Marcin},
  booktitle={2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)}, 
  title={Dru: Studying Blockchain as a Complex Network}, 
  year={2020},
  volume={},
  number={},
  pages={929-932},
  abstract={Apart from many project design decisions that have to be made when incorporating blockchain as a trusted transactions register, it is also essential to gain a deeper understanding of the ecosystem when it already entered operational state. By looking at the way how nodes perform transactions, how they cluster, or what is the dynamics of the network, many valuable insights can be derived about the condition of the whole system. This leads to improving functionality, performance, scalability, and security. We propose a way of looking at the network of transactions as at a complex network and demonstrate that the methods and algorithms provided by network science can significantly increase our knowledge about the blockchain ecosystem. In this work, we introduce an open-source platform called Dru that is linked to this concept and simplifies performing analyses by providing a built-in storage of transactions and an API for research. We believe that the insights presented in this work will be helpful for studying blockchain-based systems. As a result, those systems supporting variety of processes will be able to move from reactive to proactive thinking and improve their functionality, availability and security.},
  keywords={Social networking (online);Scalability;Ecosystems;Blockchain;Complex networks;Cryptography;Open source software;blockchain;distributed ledger;network science;complex network;software platform},
  doi={10.1109/ASONAM49781.2020.9381469},
  ISSN={2473-991X},
  month={Dec},}@ARTICLE{9420690,
  author={Zahid, Amjad Hussain and Iliyasu, Abdullah M. and Ahmad, Musheer and Shaban, Mian Muhammad Umar and Arshad, Muhammad Junaid and Alhadawi, Hussam S. and El-Latif, Ahmed A. Abd},
  journal={IEEE Access}, 
  title={A Novel Construction of Dynamic S-Box With High Nonlinearity Using Heuristic Evolution}, 
  year={2021},
  volume={9},
  number={},
  pages={67797-67812},
  abstract={For decades, the security and privacy of data are among the major challenges faced by service providers dealing with public data. To cope with these challenges, most of the organizations rely on the adoption of cryptographic methods for protecting data against any illegitimate access and attacks. Modern day cryptographic ciphers utilize one or more substitution-boxes (S-boxes) that facilitate the realisation of strong security of plain data during encryption and legal decoding of it during decryption process. Security of ciphers is directly proportional to the cryptographic strength of S-boxes. This study proposes an efficient and simple method based on some modular operations for the construction of dynamic S-boxes with high nonlinearity using a heuristic evolution strategy. A large number of strong S-boxes can be easily constructed using slight variations in the parameters of the anticipated method. A specimen S-box is constructed and its critical performance analysis against standard security criteria including nonlinearity, strict avalanche criterion, bit independence criterion, differential uniformity, linear probability, and fixed points are reported as justification for the proposed technique's high cryptographic strength. Furthermore, the generated S-box is also applied to encrypt digital images to assess its cryptographic application performance. The performance and comparison study validates that the proposed S-box has better performance strength, which makes it a viable candidate for cryptographic applications in different areas of image security.},
  keywords={Ciphers;Security;Encryption;Matrix converters;Streaming media;Performance analysis;Computer science;Security and privacy;substitution-box;block ciphers;encryption;image security;cyber physical systems},
  doi={10.1109/ACCESS.2021.3077194},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{6728496,
  author={Shen, Z. and Wang, K. and Wang, F.-Y.},
  booktitle={16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013)}, 
  title={GPU based Non-dominated Sorting Genetic Algorithm-II for multi-objective traffic light signaling optimization with agent based modeling}, 
  year={2013},
  volume={},
  number={},
  pages={1840-1845},
  abstract={Micro-simulation becomes more and more important in the Intelligent Transportation Systems (ITS) research, because it can provide detailed descriptions of the system. For a multi-agent systems (MAS) modeling of an ITS, the computation burden is large, as it involves the computation of the state changing of all the agents. And, there are many multi-objective optimization problems in the ITS research. In this paper, we solve the traffic light signaling optimization problem and we take the average delay time and the average stop times as two objectives. We use a famous method of Non-dominated Sorting Genetic Algorithm II (NSGA-II). As NSGA-II can be viewed as an intelligent way of running a number of micro-simulations, usually the computation burden is huge. Graphics Processing Units (GPUs) have been a popular tool for parallel computing. The real transportation system runs in parallel and we think that a parallel tool is more suitable for the simulation and optimization of the system. We test GPU based NSGA-II method on a 4 intersection lattice road network, and on the 18 intersection road network of the Zhongguancun area of Beijing. Compared with the CPU version, the GPU version implementation achieves a speedup factor of 21.46 and 27.64 respectively.},
  keywords={Roads;Graphics processing units;Control systems;Topology;Time measurement;Convergence},
  doi={10.1109/ITSC.2013.6728496},
  ISSN={2153-0017},
  month={Oct},}@ARTICLE{486756,
  author={Beichl, I. and Sullivan, F.},
  journal={IEEE Computational Science and Engineering}, 
  title={Tree-lookup for partial sums or: how can I find this stuff quickly?}, 
  year={1996},
  volume={3},
  number={1},
  pages={13-15},
  abstract={Suppose that you need to maintain a large list of data that is to be searched and modified frequently in the course of a computation. You can almost always arrange for both operations to be done efficiently by storing the data in a structure other than a single array. Although there are several elegant ways to do this, we present just one: a simple tree that doesn't require a lot of thinking to implement. It can speed up execution tremendously because instead of searching through a list item after item for each update, possibly examining n items, you need only examine O(log n) items per operation. (More advanced methods can reduce this to log*n at the cost of more complex programming. Here, log*n is the number of iterations of log/sub 2/ that are required to get below 1. For numbers having less than 65K bits, log* is less than 5.).},
  keywords={Monte Carlo methods;Costs;Data structures;Molecular beam epitaxial growth;Epitaxial growth;Springs;Random number generation;Physics computing;Binary trees},
  doi={10.1109/99.486756},
  ISSN={1558-190X},
  month={Spring},}@INPROCEEDINGS{9111490,
  author={Tunstel, Edward},
  booktitle={2019 IEEE 13th International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
  title={Next-Level Robotic Intelligence : Plenary Talk}, 
  year={2019},
  volume={},
  number={},
  pages={000011-000012},
  abstract={Recent advances have been effective for progressing the state of robotics toward its next level of intelligence. At this stage, further advancement is needed with sharper focus on increased robustness, cognitive facilities, and more sophisticated behavior. Advances to date are impacting individual elements of what would become a robotic intelligence pipeline but the paths to effective integration of those elements that will realize practical intelligent robots and robotic systems are unclear. This talk offers thoughts and considerations for active researchers to ponder and appreciate in the context of their research programs. From a perspective on current stages of technology development, and looking toward the progress horizon from that vista, the talk discusses a number of topics within the SACI 2019 scope using examples from research projects and deployed systems. Aspects of intelligent robotics associated with different domains and applications are discussed such as planetary robotics, disaster response and wearable robotics. Also addressed are future considerations for the evolution of related technology toward increased robotic autonomy and advanced intelligence for robotic systems. Motivating this discourse are multiple considerations for next-level robotic intelligence such as enhancing perception capabilities beyond the visual modality, moving beyond object recognition and grasping to knowledge and reasoning about object properties, enabling smart human-collaborative robots that are responsive to intuitive, physical, and brain-interfaced interaction, advancing from robot learning for X (perception, control, etc.) to autonomous or developmental learning and knowledge or skill transfer, the need to realize smart behavior for not only singular robots but for multi-robot systems, and some of the related systems engineering considerations. The aim is to broaden the thinking of current researchers leading to the collective leverage that will boost robotic intelligence to the next level enabling robots that are multi-functional in the real-world.},
  keywords={},
  doi={10.1109/SACI46893.2019.9111490},
  ISSN={},
  month={May},}@INPROCEEDINGS{9098288,
  author={Wang, Ningqi and Niu, Chang and Li, Zizhong},
  booktitle={2019 12th International Symposium on Computational Intelligence and Design (ISCID)}, 
  title={RLayout: Interior Design System Based on Reinforcement Learning}, 
  year={2019},
  volume={1},
  number={},
  pages={117-120},
  abstract={The advanced artificial intelligence technologies have promoted the development of other industries. As a combination of AI technologies and art, intelligent design has become a research hotspot in recent years. Intelligent design uses computer to simulate human thinking activities with AI technologies, enabling the computers to undertake more complex design tasks in a better way. At the same time, reinforcement learning plays an increasingly important role in many fields, such as system control, game theory, computer network, decision making, etc. In this work, an intelligent design system based on the reinforcement learning algorithm was proposed, and corresponding reward rules were developed according to the design principles. The system can help the designer to generate the optimal scheme automatically, which can be extended and applied to find the best scheme in many problems, including interior design, daily schedule, resource arrangement, etc. Our demo shows that the system can offer excellent design scheme according to pre-set reward rules, and reduce workload of related designers.},
  keywords={Learning (artificial intelligence);Layout;Machine learning;Training;Intelligent systems;reinforcement learning;intelligent design;interior design},
  doi={10.1109/ISCID.2019.00033},
  ISSN={2473-3547},
  month={Dec},}@INPROCEEDINGS{5492514,
  author={Freudenthal, Eric and Ogrey, Alexandria N. and Roy, Mary K. and Siegel, Alan},
  booktitle={IEEE EDUCON 2010 Conference}, 
  title={A computational introduction to STEM studies}, 
  year={2010},
  volume={},
  number={},
  pages={663-672},
  abstract={We report on the content and early evaluation of a new introductory programming course “Media Propelled Computational Thinking,” (abbreviated MPCT and pronounced iMPaCT). MPCT is integrated into a freshman-level program designed for under-prepared students with interests in a STEM discipline. It is intended to reduce attrition rates by fostering student intuition in, appreciation of, and confidence about basic pre-calculus concepts. The MPCT curriculum is problem-driven, with analytical challenge exercises that are intended to motivate inquiry and to illustrate the reasoning used in the STEM professions Preliminary evaluation results are encouraging - students from a wide range of academic majors found MPCT engaging, and report that the course conveyed insight, and decreased anxiety about foundational mathematical concepts.},
  keywords={Programming profession;Computer science;Electrostatic precipitators;Mathematical programming;Algorithm design and analysis;Engineering profession;Propulsion;Calculus;Art;Mathematics;introductory computing curriculum;CS0;MPCT;entering students program;CCLI;CPATH},
  doi={10.1109/EDUCON.2010.5492514},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{9545008,
  author={Narayanan, S. Krishna and Dhanasekaran, S. and Vasudevan, V.},
  booktitle={2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA)}, 
  title={A shared computational model using distributed processing in a CPS enabled environment}, 
  year={2021},
  volume={},
  number={},
  pages={841-846},
  abstract={Cyber-Physical Systems (CPS) usually include a mix of movable things, embedded computers, and systems to keep track as well as actuate together with the encompassing real life. These computing components are generally wireless, interconnected to talk about interaction and data with one another, with the server component, and with cloud computing expertise. When it comes to such a heterogeneous atmosphere, brand new uses develop in order to meet ever-increasing requirements as well as these're a crucial problem on the processing features of products. For instance, instant traveling methods, producing locations, wise community managing, and so on. In order to fulfill the demands of stated application program contexts, the device is able to make computing procedures to disperse the work above the system and also a cloud computing server. Several choices develop within relation to what network nodes must support the delivery of all of the procedures. This particular paper concentrates on this issue by introducing a sent-out computational design and dynamically discuss the activities among the computing nodes as well as thinking about the natural variability on the context inside the locations. The approach of ours encourages the integration of the computing online resources, with externally provided cloud expertise, to satisfy contemporary program demands. The outcome of the Proposed design satisfies the shared computation level with energy efficient schemes and aslo achieved the response level in good level.},
  keywords={Wireless communication;Performance evaluation;Cloud computing;Power demand;Diversity reception;Atmosphere;Prototypes;CPS;Internet of things;Mobile computing (MC);Modeling;Distributed computation},
  doi={10.1109/ICIRCA51532.2021.9545008},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8914397,
  author={Dimirovski, Georgi and Warwick, Kevin and Stefanovski, Jovan},
  booktitle={2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)}, 
  title={Complexity Symbiosis of Glia-Neuron Cells and Computational Cybernetics of Hopfield Recurrent Network: Novel Neuron Model}, 
  year={2019},
  volume={},
  number={},
  pages={1396-1401},
  abstract={Science of artificial neural networks and relevant computing mechanisms since McCullock-Pitts artificial neuron (1943) up via neurons and networks of Anderson (1972), Barto et al (1983), Grosberg (1967, 1976), Hopfield (1982, 1984), Kohonen (1972) to Kasabov's evolving connectionist systems with spiking-neurons (2003) have undergone developments beyond any conceivable predictions. The computational efficiency and functionality of all kinds of neural network implies stable operating steady-state equilibrium is fast established and guaranteed. In parallel, Neurophysiology has yielded many insights Gayton-Hall (2006) converging to paradigm of systems biology. It appeared, on the crossroad of these findings with Hilbert's Thirteen problem and Kolmogorov's Superposition Representations in conjunction with Lyapunov foundations of stability and LaSalle invariance principle certain delicate subtle issues emerged Siljak (2008) and Sprecher (2017). This re-thinking the foundations of neural networks via the quest for parallels between artificial and living neurons is believed to open a new horizon. This belief follows obtained results on cultured-neuron controllers and recurrent neural networks with time-varying delays. A closer look into how animal and/or human brain cells can be cultivated as a controlling brain for a mobile robot (physical body) such that can move around and interact with the world. In turn, a new kind of artificial intelligence may be created, which is emulated by stabilized complex highly non-linear complex neural network system.},
  keywords={Neurons;Symbiosis;Artificial neural networks;Cybernetics;Biological neural networks;Hopfield neural networks;Artificial intelligence},
  doi={10.1109/SMC.2019.8914397},
  ISSN={2577-1655},
  month={Oct},}@INPROCEEDINGS{8190595,
  author={Nias, Jaye and Marshall, Brandeis and Thompson, Tayloir and Blunt, Takeria},
  booktitle={2017 IEEE Frontiers in Education Conference (FIE)}, 
  title={EvergreenLP: Using a social network as a learning platform}, 
  year={2017},
  volume={},
  number={},
  pages={1-7},
  abstract={We are living more of our lives situated within online networks and communities where digital artifacts can be collected and processed to showcase individual and group behavior representations. Growing data bandwidth coupled with amplified computational resources are aligning to allow for analysis of human behaviors at unprecedented scales. The proper data generation, collection, storage and analysis techniques are mostly untaught in the undergraduate experience. Pedagogical research shows that project based learning encourages and supports design thinking and collaborative work; skills that are important to practitioners in data science centric industries. To address these academic needs, we develop the Evergreen Learning Platform (EvergreenLP). EvergreenLP is an interdisciplinary project based learning framework that leverages pedagogy rooted in Critical Media Literacy. Students take advantage of design-learning principles on the front-end and computational discipline standards on the back end. Students are engaged in the design, development and use of this platform while simultaneously contributing data content on the chosen social media platform. Our data analysis and visualization environment allows the student coders and non-coders to explore data science principles in context of a current event or topic trending on twitter. In this paper, we experimentally assess and present the benefits of introducing culturally relevant data techniques to African-American female students in an interdisciplinary seminar on #BlackGirlMagic (#BGM).},
  keywords={Media;Twitter;Data science;Data visualization;Tagging;project-based learning;critical media literacy;social media},
  doi={10.1109/FIE.2017.8190595},
  ISSN={},
  month={Oct},}@ARTICLE{5406490,
  author={Kelly, Rory},
  journal={Computing in Science & Engineering}, 
  title={GPU Computing for Atmospheric Modeling}, 
  year={2010},
  volume={12},
  number={4},
  pages={26-33},
  abstract={Much success has been achieved using GPUs to accelerate existing applications that are highly data parallel, or that are dominated by small, intense computational kernels. What are the prospects for porting existing large scientific models that do not fit this mold? We take an expensive routine from the CAM atmosphere model, and port it to a GPU using CUDA. We use the experience gained as a guide in thinking about porting the full application to an accelerator based system. We consider the best path forward for getting large scientific models running on accelerator based systems, and identify cases where porting may be feasible, and where a complete redesign may be the best option.},
  keywords={Atmospheric modeling;Atmosphere;Computer aided manufacturing;CADCAM;Acceleration;Computational modeling;Land surface;Sea surface;Clouds;Kernel;emerging technologies;threads;graphics processors;computations on discrete structures},
  doi={10.1109/MCSE.2010.26},
  ISSN={1558-366X},
  month={July},}@INPROCEEDINGS{9445287,
  author={Brar, Dilpreet Singh and Kumar, Amit and Pallavi and Mittal, Usha and Rana, Pooja},
  booktitle={2021 2nd International Conference on Intelligent Engineering and Management (ICIEM)}, 
  title={Face Detection for Real World Application}, 
  year={2021},
  volume={},
  number={},
  pages={239-242},
  abstract={Face Detection has become a very prevalent issue in Machine Learning, not only in machine learning but in any field, one can think of. Due to this, it has gained a wide fan base and many people are working every day to improve the accuracy of object detection models using deep learning. But this improved performance comes at the price of increased computational overhead, which limits the ability of a machine learning model to be utilized on devices having small Graphical Processing Units. The core intent of this paper is to compare computation time for models such as Histogram of Oriented gradients (0.4 seconds) and ResNet (48.5 seconds) with BlazeFace (0.09 seconds), a model developed by google in the year 2020 and is a mobile device friendly model and fits well with real time application which need instant feedback and on top of that cannot handle bulky computations required for deep learning models.},
  keywords={Deep learning;Performance evaluation;Computational modeling;Face recognition;Predictive models;Real-time systems;Mobile handsets;BlazeFace;Blaze Block;CNN;Double Blaze Block;Face Detection;Object Detection},
  doi={10.1109/ICIEM51511.2021.9445287},
  ISSN={},
  month={April},}@INPROCEEDINGS{7344062,
  author={Sabitzer, Barbara and Pasterk, Stefan},
  booktitle={2015 IEEE Frontiers in Education Conference (FIE)}, 
  title={Modeling: A computer science concept for general education}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={For all computer scientists the term `modeling' is well known. It displays an often-used method, which is applied in each field of computer science to investigate, describe and plan problems or structures. With the help of models, large and complex structures are divided into smaller parts, which leads to a better understanding of the problem and often provides input for the solution. With the help of different types of models, different perspectives of one problem can be observed and discussed. These processes are not only part of computer science respectively computational thinking. Problem solving skills are needed in any domain and should be trained as well as possible in primary and secondary education. This could be supported by the computer science concept of modeling including processes like reduction, decomposition, abstraction, generalization etc. and appropriate techniques like UML Unified Modeling Language or the Entity-relationship model. We suppose that a consequent use of modeling beginning in different subjects during primary and secondary education can train and improve problem-solving skills. Before being able to verify this hypothesis, it is necessary to find a way to integrate modeling in schools despite of not being part of the curriculum. This is one aim of our project “Informatics - A Child's Play”, which tries to implement different computer science concepts in different subjects of primary and secondary education. To reach this goal we firstly have to convince and train teachers. In this paper some topics of modeling are presented as they were adapted for workshops in primary and early secondary education considering the age and interests of the students as well as topics taken from their surroundings. Furthermore, we present first evaluation results concerning its acceptance and usefulness for teachers and students as well as their performance in understanding and applying modeling in different lessons.},
  keywords={Computational modeling;Education;Mathematical model;Unified modeling language;Informatics;Conferences;models;diagrams;general education;Entity-Relationship-model},
  doi={10.1109/FIE.2015.7344062},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9138067,
  author={Bhuyan, M. P. and Sarma, S. K. and Rahman, M.},
  booktitle={2020 5th International Conference on Communication and Electronics Systems (ICCES)}, 
  title={Natural Language Processing based Stochastic Model for the Correctness of Assamese Sentences}, 
  year={2020},
  volume={},
  number={},
  pages={1179-1182},
  abstract={Increasing the number of social media users and the way these users write the regional languages have pushed the researchers to think about the originality of these languages. The native speakers are in fear that with time the regional languages may lose their originality. For such reason, the correctness checking at the time of writing is an important task in the field of natural language processing. The conventional methods for checking the correctness of a sentence are normally carried out by applying various syntactic and semantic rules and the rules are endless because of the free word order nature of the Assamese language. On the other hand, in the computational filed, the data-driven models are more appropriate than the rule-based system and the data-driven model is free from the rules. In this research work, a data-driven model is designed by using the different types of n-gram models like unigram, bigram, and trigram to check the correctness of the Assamese sentences along with the linear interpolation method. Assamese is one of the twenty-two official languages of India, predominantly spoken in Assam and its neighboring states. A corpus of the size of around 1 million words is used to train the system. During testing, four different levels of experiments are carried out one for the correct sentences and incorrect sentences. The F1-score of the system in correcting the users' sentences is above 60%.},
  keywords={Interpolation;Social networking (online);Computational modeling;Semantics;Stochastic processes;Writing;Syntactics;Assamese sentence;Assamese corpus;bigram;trigram;interpolation;sentence correctness},
  doi={10.1109/ICCES48766.2020.9138067},
  ISSN={},
  month={June},}@INPROCEEDINGS{6059211,
  author={Prego, Juan José Gude and Seisdedos, Luis Vázquez},
  booktitle={ETFA2011}, 
  title={Tailor-made small simulator for a drum boiler control based on linear techniques}, 
  year={2011},
  volume={},
  number={},
  pages={1-4},
  abstract={A computational thinking under simulated environment with amendable properties is promoted. It is exemplified on a real drum boiler multi-loop linear control. The model is based on the boiler-turbine plant P16/G16, which is oil-fired and the rated power is 160 MW, at the Sydvenska Kraft AB Plant in Malmö, Sweden. A proficient symbolic and numerical combination points out a fast and very efficient automatic engineering calculation. This contribution aims at tailor-made small simulators on Matlab for those industrial processes which are linked by heat energy. A first application at drum boiler with linear control meets a useful know-how to guide thoughts on how to translate physical fundamentals to Matlab codes for other industrial cases. Some comments relating to industrial practice are offered in this context.},
  keywords={Boilers;Process control;Mathematical model;Computational modeling;Educational institutions},
  doi={10.1109/ETFA.2011.6059211},
  ISSN={1946-0759},
  month={Sep.},}@INPROCEEDINGS{1357744,
  author={Cavallo, D. and Blikstein, P. and Sipitakiat, A. and Basu, A. and Camargo, A. and de Deus Lopes, R. and Cavallo, A.},
  booktitle={IEEE International Conference on Advanced Learning Technologies, 2004. Proceedings.}, 
  title={The City That We Want: generative themes, constructionist technologies and school/social change}, 
  year={2004},
  volume={},
  number={},
  pages={1034-1038},
  abstract={We describe a project, The City that We Want, which enabled the constructionist use of technology within a generative theme to enable students to design and construct their ideas about how to improve life in their communities. We used a variety of computational technologies combined with crafts and scrap materials. The goal was for children to learn in a more contextualized manner important ideas in the disciplines through their projects. We designed the overall project itself as an object to think with in order to facilitate a broader reform in the schools. The willing participation, inspired projects, and commitment and development of the teachers demonstrated significant value.},
  keywords={Cities and towns;Educational institutions;Educational technology;Environmental economics;Costs;Psychology;Meetings;Computational modeling},
  doi={10.1109/ICALT.2004.1357744},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9499781,
  author={Li, Hsuan},
  booktitle={2021 International Conference on Advanced Learning Technologies (ICALT)}, 
  title={The Designing of CSL Teacher Empowering Training Model of Robot-Assisted Language Learning based on the TPACK Framework}, 
  year={2021},
  volume={},
  number={},
  pages={276-278},
  abstract={This study provides the designing of the empowering training model of robot-assisted language learning (RALL) knowledge based on the framework of Technological Pedagogical Content Knowledge (TPACK) for Chinese as a Second Language (CSL) teacher. The model is a 10-hours program to enhance CSL teachers’ cognition of robot technology knowledge, and integrate Chinese pedagogical knowledge and Chinese phonetics knowledge. We analyzed what should be included in TK, PK, CK, TPK, TCK, PCK, TPACK when designing a robot assisted Chinese phonetics teaching. Also, computational thinking and Chinese teaching-oriented programming is been taught in order to let the CSL teachers have the ability to realize their design of RALL system.},
  keywords={Training;Computational modeling;Knowledge based systems;Phonetics;Data collection;Reflection;Planning;Robot-assisted language learning (RALL);Technological Pedagogical Content Knowledge (TPACK);Chinese as a second language (CSL);Language Teacher Empowering Training},
  doi={10.1109/ICALT52272.2021.00089},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{9209477,
  author={Chella, Antonio and Lanza, Francesco and Pipitone, Arianna and Seidita, Valeria},
  booktitle={2020 IEEE International Conference on Human-Machine Systems (ICHMS)}, 
  title={The Inner Life of a Robot in Human-Robot Teaming}, 
  year={2020},
  volume={},
  number={},
  pages={1-4},
  abstract={Giving the robot a “human” inner life, such as the capability to think about itself and to understand what the other team members are doing, would increase the efficiency of trustworthy interactions with the other members of the team. Our long-term research goal is to provide the robot with a computational model of inner life helping the robot to reason about itself, its capabilities, its environment and its teammates. Robot inner speech is a part of the research goal. In this paper, we summarize the results obtained in this direction.},
  keywords={Robot kinematics;Computer architecture;Computational modeling;Task analysis;Standards;Robot sensing systems;Human-Robot Teaming Interaction;Cognitive Architecture;Self-modeling;Introspection;Inner Speech;BDI agents.},
  doi={10.1109/ICHMS49158.2020.9209477},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{7346974,
  author={Siddiqui, M. Salman and Hasan, Syed Maaz},
  booktitle={2014 International Conference on Energy Systems and Policies (ICESP)}, 
  title={Optimized design of a straight blade urban roof top vertical axis wind turbine}, 
  year={2014},
  volume={},
  number={},
  pages={1-10},
  abstract={Depletion of fossil fuels and increasing concerns of global warming has forced the society to think about environmental friendly energy resources. Wind energy is a viable option in this regard. Vertical axis wind turbines offer promising solution and hence relieving the society from the integrated grid systems. Small scale urban roof top vertical axis wind turbine (VAWT) is one of the simplest forms with its wide spread applications necessitating its design and development in a cost-effective manner. A study is undertaken on a three straight bladed VAWT. The design is formulated using available empirical formulas and sophisticated software's leading to a fabricated scaled down prototype. A detailed CFD and stress analysis is done on multiple struts configurations, central column assemblies, blade profiles to optimize the performance of the turbine. A comparison is also made between the analytical, software based and experimental results.},
  keywords={Wind turbines;Blades;Wind energy;Renewable energy sources;Wind speed;Shafts;Wind power generation;Vertical Axis Wind Turbine;Computational Fluid Dynamics;Power Coefficient},
  doi={10.1109/ICESP.2014.7346974},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{5673203,
  author={Freudenthal, Eric and Ogrey, Alexandria and Gonzalez, Rebeca Q.},
  booktitle={2010 IEEE Frontiers in Education Conference (FIE)}, 
  title={Work in progress — Eliciting integrated understandings of high school STEM curricula through programming}, 
  year={2010},
  volume={},
  number={},
  pages={F2H-1-F2H-2},
  abstract={We describe our early investigation of the integration of educational modules originally developed for a college-level entering students program (ESP) titled “Media Propelled Computational Thinking” (MPCT) into high school science, math, and engineering/technology courses. Primary objectives of MPCT include introducing students to imperative programming and reinforcement of foundational mathematical concepts. This report describes this evolving integration including early informal experiments and potential extensions using programming functions of ubiquitous graphing calculators.},
  keywords={Educational institutions;Programming profession;Calculators;Context;Concrete;Computational modeling},
  doi={10.1109/FIE.2010.5673203},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10261563,
  author={Gao, Jie and Wei, Yantao and Wang, Kegang and Shi, Yafei},
  booktitle={2023 5th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Automatic Academic Emotion Recognition and Its Evolution Analysis in Classroom}, 
  year={2023},
  volume={},
  number={},
  pages={42-48},
  abstract={Students' emotional state plays a vital role in learning. In this study, we examined the emotional changes of 69 students during the lectures of the C Language Programming Foundation and Computational Thinking in central China. This paper presents a method using Yolov7 and the convolutional neural network CoAtNet to monitor students' emotional evolution by analyzing their facial expressions and recognizing academic affective states, including boring, confused, focus, happy, and neutral. The trained model has achieved a test accuracy of 76.0%. The results showed that focus increased at the beginning of the first 10 minutes of class and then began to decline. With the decline of focus emotion, students' neutral emotions increased. We found that when a new teaching session is performed, or the teaching method of naming questions is used, the students' emotion of focus increases briefly, lasting about 8–10 minutes. Subsequently, even if the varied teaching method was used to stimulate students' attention, their level of engagement did not increase significantly. It can be suggested that teachers can use teaching methods appropriately to promote students' attention. However, students' attention span is limited, and teachers should pay attention to methods and time to improve teaching quality effectively.},
  keywords={Emotion recognition;Face recognition;Computational modeling;Education;C languages;Convolutional neural networks;Programming profession;facial expression recognition;emotional evolution;improving classroom teaching},
  doi={10.1109/CSTE59648.2023.00015},
  ISSN={},
  month={April},}@INPROCEEDINGS{302309,
  author={Bringsjord, S. and Bringsjord, E.},
  booktitle={Proceedings of International Conference on Expert Systems for Development}, 
  title={Can AI accommodate imagistic expertise?}, 
  year={1994},
  volume={},
  number={},
  pages={36-41},
  abstract={After years of focussing almost exclusively on rather primitive symbolic forms of knowledge representation, AI has started a systematic attempt to design and implement a computational correlate to human diagrammatic representation and reasoning. However, a number of thinkers are on record as confidently claiming that such representation and reasoning is forever beyond a digital computer. Are such claims to be taken seriously? We think so/spl minus/when they are based on mental imagery more sophisticated than that which AI customarily concerns itself with. This "recalcitrant" imagery is the province of certain experts (e.g. authors and screenwriters).<>},
  keywords={Artificial intelligence;Humans;Knowledge representation;Robots;Turing machines;Logic;Heart;Expert systems;Computational modeling;Computer simulation},
  doi={10.1109/ICESD.1994.302309},
  ISSN={},
  month={March},}@INPROCEEDINGS{7740319,
  author={Tomasek, Martin and Cerny, Tomas},
  booktitle={2016 6th International Conference on IT Convergence and Security (ICITCS)}, 
  title={Context-Aware User Interface Field Classification}, 
  year={2016},
  volume={},
  number={},
  pages={1-5},
  abstract={Software applications are designed with a concrete purpose in mind, specified by business owners basing on the individual requirements. The user-system interaction is specified in the analysis phase. This phase specifies inputs, outputs, interaction etc. These elements could be specified separately based on the target platform. The designers know that the mobile clients could have a different application flow than desktop clients. However, this is not a rule and designers often times do not think about the user context nor do they consider the application context. This implies that outputs, inputs and interactions do not change automatically during the software life cycle. In this paper we present techniques that are able to determine whether the user, which is in a particular context, should be required to spend his/her time to fill in fields that are not needed for accomplishing a specific business task. Moreover, these techniques are able to determine whether the fields should display or are not necessary, as well as how the system might interact with the user. Finally, we present a computational architecture that is able to make these types of determinations.},
  keywords={Context;Business;Software;Computational modeling;Concrete;Security;User interfaces},
  doi={10.1109/ICITCS.2016.7740319},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{845692,
  author={Ariton, V. and Bumbaru, S.},
  booktitle={ICONIP'99. ANZIIS'99 & ANNES'99 & ACNN'99. 6th International Conference on Neural Information Processing. Proceedings (Cat. No.99EX378)}, 
  title={A fuzzy-neuro architecture for modular fault isolation in complex systems}, 
  year={1999},
  volume={2},
  number={},
  pages={765-770 vol.2},
  abstract={Faulty behavior of complex industrial systems is usually detected by deviations from expected values of performance parameters, regarding the system's utilities. When the isolation is performed by human diagnosticians, they use shallow knowledge on faulty cases, and deep knowledge on laws governing the installation running, both imprecise in variable values and in their relations. The paper presents a fuzzy-neuro architecture for a computational model, handling the imprecision of human-like thinking on faults and behavior of the conductive flow systems in industry. The primary effects isolation from the secondary effects proceeds in a modular fashion, based on four transport anomalies detected on the flow power disturbance in each (bond graph) junction of interconnected components. The manifestations take a fuzzy representation and the multiple links between manifestations and faults is represented and processed by productive neural networks. The modular structure of the diagnosis system reflects the modular structure of the target system, hence the faults-effects mapping is simpler and the isolation of faults is more precise.},
  keywords={Industrial relations;Fault detection;Humans;Computer architecture;Computational modeling;Power system modeling;Computer industry;Bonding;Power system interconnection;Fuzzy neural networks},
  doi={10.1109/ICONIP.1999.845692},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9936373,
  author={Li, Mingwei},
  booktitle={2022 International Conference on Edge Computing and Applications (ICECAA)}, 
  title={Quantum Dynamic Network Modeling Algorithm in Mathematical Modeling Training Combined with BOPPPS Comprehensive Networking System Construction}, 
  year={2022},
  volume={},
  number={},
  pages={379-382},
  abstract={A quantum self-organizing feature mapping network model and clustering algorithm are proposed. The inputs and weights of quantum neurons are quantum bits, and the output is real numbers. The characteristics and relationship of BOPPPS model and problem-driven teaching method are studied, BOPPPS model and teaching method The relationship between elements 5W, and taking the "Algorithm and Data Structure" course as an example, gives strategies and practices for cultivating computational thinking. The quantum self-organizing feature map network is composed of input layer and competition layer. The multi-objective programming model is established by mathematical methods such as linear weighting, objective programming and hierarchical sequence, and the solution to the dynamic allocation of resources in the logistics network is given by analyzing the model.},
  keywords={Training;Analytical models;Computational modeling;Heuristic algorithms;Neural networks;Clustering algorithms;Mathematical models;Quantum Dynamic Network;Mathematical Modeling Training;BOPPPS Comprehensive;Networking System Construction},
  doi={10.1109/ICECAA55415.2022.9936373},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9251295,
  author={Budiarto, Rahmat},
  booktitle={2020 7th International Conference on Electrical Engineering, Computer Sciences and Informatics (EECSI)}, 
  title={Memory Prediction on Real-Time User Behavior Traffic Detection}, 
  year={2020},
  volume={},
  number={},
  pages={4-4},
  abstract={Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Human brain is a learning system. Human have to learn by getting exposed to something. This capability of learning system to recognize new patterns is called generalization. The abilities of human brain to perform generalization are yet to be matched by neural network or even by any of artificial intelligence algorithm in general. Thus, the need for new machine intelligence approach is imperative. Neural network is designed to take advantages of the speed of computers to solve engineering and computational complex problems intelligently. On the other hand, human brain is somewhat not computationally powerful. Human brain is not even able to calculate quadratic problems within milliseconds. Instead, it uses its vast amounts of memory to store everything human know and have learned. According to a modern neuroscience theory named memory-prediction framework, introduced by Hawkins and Blakeslee in 2005, human brain uses this memory-based model to make continuous predictions of future events. Therefore, a hybrid approach that possesses the ability to compute like neural network and at the same time think like human brain will shed some light in the advancement of machine learning research as well as the development of a truly intelligent machine. This talk discusses the memory-prediction framework and proposes simplified single cell assembled sequential hierarchical memory (s-SCASHM) model instead of hierarchical temporal memory (HTM) in order to speed up the learning convergence. s-SCASHM consists of single neuronal cell (SNC) model and simplified sequential hierarchical superset (SHS) platform. The SHS platform is designed by simplifying to have a region with four rows columnar architecture instead of having six rows per region as in human neocortex. Then, the s-SCASHM is implemented as the prediction engine of user behavior analysis tool to detect insider attacks/anomalies. As nearly half of incidents in enterprise security triggered by the Insider, it is important to deploy more intelligent defense system to assist the enterprise be able to pinpoint and resolve any incidents caused by the Insider or malicious software (malware). The attacks evolve; however, current detection systems that use the deep learning techniques cannot perform online (on-the-fly) learning. Thus, an intelligent detection system with on-the-fly learning capability is required. Experimental results show that the proposed memory model is able to predict user behavior traffic with significant level of accuracy and performs on-the-fly learning.},
  keywords={Computer science;Computational modeling;Biological neural networks;Behavioral sciences;Predictive models;Microprocessors;Malware},
  doi={10.23919/EECSI50503.2020.9251295},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10315697,
  author={Martínez-Araneda, Claudia and Gutiérrez Valenzuela, Mariella and Gómez Meneses, Pedro and Maldonado Montiel, Diego and Segura Navarrete, Alejandra and Vidal-Castro, Christian},
  booktitle={2023 42nd IEEE International Conference of the Chilean Computer Science Society (SCCC)}, 
  title={How Useful TutorBot+ is for Teaching and Learning in Programming Courses: a Preliminary Study}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Objective: The objective of this paper is to present preliminary work on the development of an EduChatBot tool and the measurement of the effects of its use aimed at providing effective feedback to programming course students. This bot, hereinafter referred to as tutorBot+, was constructed based on chatGPT3.5 and is tasked with assisting and providing timely positive feedback to students in computer science programming courses at UCSC. Methods/Analysis: The proposed method consists of four stages: (1) Immersion in the feedback and Large Language Models (LLMs) topic; (2) Development of tutorBot+ prototypes in both non-conversational and conversational versions; (3) Experiment design; and (4) Intervention and evaluation. The first stage involves a literature review on feedback and learning, the use of intelligent tutors in the educational context, as well as the topics of LLMs and chatGPT. The second and third stages detail the development of tutorBot+ in its two versions, and the final stage lays the foundation for a quasi-experimental study involving students in the curriculum activities of Programming Workshop and Database Workshop, focusing on learning outcomes related to the development of computational thinking skills, and facilitating the use and measurement of the tool’s effects. Findings: The preliminary results of this work are promising, as two functional prototypes of tutorBot+ have been developed for both the non-conversational and conversational versions. Additionally, there is ongoing exploration into the possibility of creating a domain-specific model based on pretrained models for programming, integrating tutorBot+ with other platforms, and designing an experiment to measure student performance, motivation, and the tool’s effectiveness.},
  keywords={Databases;Computational modeling;Conferences;Bibliographies;Education;Prototypes;Focusing;retroalimentación efectiva;estrategias de aprendizaje;evaluación;chatGPT},
  doi={10.1109/SCCC59417.2023.10315697},
  ISSN={2691-0632},
  month={Oct},}@INPROCEEDINGS{10152154,
  author={Anu, Vaibhav and Hagiwara, Sumi and Herbert, Katherine and Sultana, Kazi Zakia and Shin, Minsun and Goldstein, Rebecca and Virella, Patricia},
  booktitle={2023 Intermountain Engineering, Technology and Computing (IETC)}, 
  title={Teachers' Perception and Experiences of Computer Science Education in K-8 Schools}, 
  year={2023},
  volume={},
  number={},
  pages={226-231},
  abstract={Supported by a state grant, our team of researchers (consisting of both Computer Science faculty and Teacher Education faculty) is offering a series of Professional Development sessions to K-8 teachers. These Professional Development (or PD) sessions are meant to help K-8 teachers develop their understanding of core computing concepts (such as algorithms, programming, data analysis, and networks) and thereby develop strong computer science programs for their students. In order to offer effective and meaningful Professional Development (PD) sessions, our research team first intended to understand the perceptions and experiences of K-8 teachers about Computer Science (CS) and Computational Thinking (CT) education. This paper presents the results of a K-8 teacher survey that we conducted as a pre-cursor to our PD series. The results of this survey provided valuable insights about elementary and middle-school teachers' perceptions of computer science education, self-perception of their ability to teach and learn CS, and understanding of CS discipline and those who typically engage in CS activities. The impact of teachers' perceptions impact how leaders in education and the CS industry can meet the needs of teachers, who in turn can meet the growing demand of CS education in K-8 schools.},
  keywords={Surveys;Seminars;Industries;Data analysis;Conferences;Computational modeling;Education;computer science education;K-8 teaching;professional development;survey},
  doi={10.1109/IETC57902.2023.10152154},
  ISSN={},
  month={May},}@ARTICLE{9267075,
  author={Zheng, Hong and Fan, Jianke and Zhao, Dapeng and Li, Cuilin and Dong, Dongdong and Zhang, Guangxu and Wang, Xiujuan},
  journal={Geophysical Journal International}, 
  title={A new method to estimate ocean-bottom-seismometer orientation using teleseismic receiver functions}, 
  year={2019},
  volume={221},
  number={1},
  pages={893-904},
  abstract={The orientation of an ocean-bottom-seismometer (OBS) is a critical parameter for analysing three-component seismograms, but it is difficult to estimate because of the uncontrollable OBS posture after its deployment. In this study, we develop a new and effective method to estimate the OBS orientation by fitting the amplitude of direct P wave of teleseismic receiver functions. The reliability of this method is verified using synthetic data and observed waveforms recorded at land seismic stations in Shandong Province, China. Our extensive synthetic tests show that our new method is little affected by a thin sedimentary layer that has a low S-wave velocity. The orientations of OBS stations that we deployed in the Yap subduction zone in the Western Pacific Ocean are estimated and corrected using our new method. After the correction, the direct P waves of teleseismic receiver functions show very good consistency. The effects of white and coloured noise in different levels, epicentral distance and backazimuth are also investigated, and the results show that these factors have small effects on the new method. We also examine the effect of sensor tilting on estimation of the OBS orientation, and find that a tilting correction should be made before the misorientation correction. We compare the OBS orientations determined with the new method and other methods and find that they are generally consistent with each other. We also discuss advantages and shortcomings of various methods, and think that our new method is more robust than the existing methods.},
  keywords={Time-series analysis;Body waves;Computational seismology;Seismic instruments},
  doi={10.1093/gji/ggaa041},
  ISSN={1365-246X},
  month={Dec},}@INPROCEEDINGS{10645894,
  author={de Almeida da Silva, Wildemarkes and Costa Fonseca, Luis Carlos and Labidi, Sofiane and Lima Pacheco, José Chrystian},
  booktitle={2024 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Mitigation of Hallucinations in Language Models in Education: A New Approach of Comparative and Cross-Verification}, 
  year={2024},
  volume={},
  number={},
  pages={207-209},
  abstract={The rapid growing application of language models (LLMs) in education offers exciting prospects for personalized learning and interactive experiences. However, a critical challenge emerges - the risk of "hallucinations," where LLMs generate factually incorrect or misleading information. This paper proposes Comparative and Cross-Verification Prompting (CCVP), a novel technique specifically designed to mitigate hallucinations in educational LLMs. CCVP leverages the strengths of multiple LLMs, a Principal Language Model (PLM) and Auxiliary Language Models (ALMs), to verify the accuracy and educational relevance of the PLM's response to a prompt. Through a series of prompts and assessments, CCVP harnesses the diverse perspectives of various LLMs and incorporates human expertise for intricate cases. This method addresses the limitations of relying on a single model and fosters critical thinking skills in learners within the educational context. We detail the CCVP approach with examples specifically applicable to educational settings, such as geography. We also discuss its strengths and limitations, including computational cost, data reliance, and ethical considerations. We highlight its potential applications in educational disciplines, including fact-checking content, detecting bias, and promoting responsible LLM use. CCVP presents a promising avenue for ensuring the accuracy and trustworthiness of LLM-generated educational content. Further research and development will refine its scalability, address potential biases, and solidify its position as a vital tool for harnessing the power of LLMs while fostering responsible knowledge dissemination in education.},
  keywords={Geography;Solid modeling;Accuracy;Scalability;Prevention and mitigation;Computational modeling;Education;Educational Language Models -LLMs;Hallucination Mitigation;Comparative and Cross-Verification Prompting -CCVP;Multi-model Approach;Responsible LLM Use},
  doi={10.1109/ICALT61570.2024.00066},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{301956,
  author={Kaehler, T. and Nash, H. and Miller, M.S.},
  booktitle={Digest of Papers. COMPCON Spring 89. Thirty-Fourth IEEE Computer Society International Conference: Intellectual Leverage}, 
  title={Betting, bribery, and bankruptcy - A simulated economy that learns to predict}, 
  year={1989},
  volume={},
  number={},
  pages={357-361},
  abstract={Derby is a collection of independent computational entities that exchange money for work and information in the course of solving some problem. The key to building an agoric system is to design a monetary incentive structure that forces the individual entities to cooperate and work on the user's problem. While building Derby the authors discovered that it is very useful to think of the entities as being opportunistic and uncooperative. In Derby, information is traded in marketplaces, with sellers issuing predictions and placing bets on their correctness at predicting incoming data streams. Buyers submit bids of how much they are willing to pay for each dollar of bet placed. A sealed-bid second-price double auction determines which bidders are accepted. Later, the buyers report how happy they were with the information they bought, and this determines each seller's winnings in the parimutuel betting pool.<>},
  keywords={Predictive models;Buildings;Computational modeling;System testing},
  doi={10.1109/CMPCON.1989.301956},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{8038113,
  author={Iwane, Toru.},
  booktitle={2017 16th Workshop on Information Optics (WIO)}, 
  title={Light-field optics as optical encoding and decoding system for 3-D scene}, 
  year={2017},
  volume={},
  number={},
  pages={1-3},
  abstract={Film-based cameras were replaced with digital cameras in a very short period. Saving film costs for each shot is not only of advantage of this transition. The more important advantage by this digitization is that forming optically a completed image on detector is not necessary and acquired data are processable by a computer. We can think that, with optional optical system-lens array-, acquired data can be nuggets of information which contains both image and its depth or bunch of incident rays which are equal value to actual 3-D scene. These data represent 3-D situations and by computing them, various optical effect, e.g. focusing and changing field of depth, can also be realized or simulated virtually. My issue is to clarify how 3-D scene is transformed and expressed on 2-D detector and how this 2-D information is retrieved back again into 3-D scene through lens array and other optical devices. Light-field optics or lens array is one of those exchangeable methods of the transformation between actual 3-D scene and information encoded on 2-D plane. Recently new method for lens array was introduced; a circular zone plate instead of lens array. As for a 3-D Display which consists of flat display and lens array, the encoded data shown on a flat display and they are retrieved into real 3-D image by a lens-array. I will mention not only its advantage but its limitation of ability for 3-D image reconstruction.},
  keywords={Lenses;Optical imaging;Three-dimensional displays;Image reconstruction;Holography;Cameras;Holographic optical components;computational imaging;three-dimensional image;displays;image reconstruction-restoration},
  doi={10.1109/WIO.2017.8038113},
  ISSN={},
  month={July},}@INPROCEEDINGS{9534503,
  author={Li, Jinli and Zhang, Xuebo and Wang, Lin and Sun, ChunJuan},
  booktitle={2021 2nd International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={Exploration of recursive algorithm teaching based on BOPPPS model}, 
  year={2021},
  volume={},
  number={},
  pages={728-731},
  abstract={Recursion is a typical algorithm design method, which plays an important role in training students to use computational thinking to analyze and solve problems. The BOPPPS model is a popular student-centered teaching mode at home and abroad in recent years, which emphasizes the participation of students and timely teaching feedback. In order to explore an effective teaching mode, this paper designs a recursive algorithm teaching design method combined with boppps model, which can effectively improve the participation of students and improve the quality of teaching.},
  keywords={Training;Computer aided instruction;Electronic learning;Design methodology;Computational modeling;Education;Online services;BOPPPS model;Recursion;Participation;Instructional Design},
  doi={10.1109/ICAIE53562.2021.00160},
  ISSN={},
  month={June},}@ARTICLE{9347437,
  author={Liu, Xiulei and Tong, Qiang and Liu, Xuhong and Qin, Zhihui},
  journal={IEEE Access}, 
  title={Ontology Matching: State of the Art, Future Challenges, and Thinking Based on Utilized Information}, 
  year={2021},
  volume={9},
  number={},
  pages={91235-91243},
  abstract={Information used in existing ontology matching solutions are usually grouped into four categories: lexical information, structural information, semantic information, and external information, respectively. By summarizing and analyzing the approaches for utilizing the same kind of information, this paper finds that lexical information is mainly analyzed based on text and dictionary similarity. Similarly, structural information and semantic information are mainly analyzed based on graph structure and reasoner, respectively. The approaches for aggregating information analysis results are discussed. Challenges in the analysis of various types of information for existing ontology matching solutions are also described, and insights into directions for future research are provided.},
  keywords={Ontologies;Semantics;Information analysis;Knowledge engineering;Information science;Dictionaries;Information classification;information analysis;ontology matching;semantic web},
  doi={10.1109/ACCESS.2021.3057081},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{6480966,
  author={Horváth, László and Rudas, Imre J.},
  booktitle={2013 IEEE 11th International Symposium on Applied Machine Intelligence and Informatics (SAMI)}, 
  title={Product definition on higher level in open PLM systems}, 
  year={2013},
  volume={},
  number={},
  pages={153-158},
  abstract={Product definition in space where objects are represented in a single contextual model brought a new thinking in work of engineers. This thinking is around the intended interaction with processes those are available for handling of objects in product modeling. Engineer defines a contribution to modify a product model development of which is result of contributions from various fields of engineering. Essential question is that what level results of human thinking process on objects can be applied as input at the model development. The answer depends on communication and representation capabilities of modeling procedures. This paper introduces a new definition of human interaction levels from the lowest to a proposed high level allowing input also on lower level if necessary. Increasing the level is the way towards intelligent product definition procedures. The proposed high level method realizes communication of awaited product characteristics and features together with methods those are assigned to fulfill these product characteristics and features. This paper is a new contribution to the earlier published coordinated request based product modeling (CRPM) methodology.},
  keywords={Object oriented modeling;Context modeling;Computational modeling;Knowledge engineering;Context;Informatics;Computers},
  doi={10.1109/SAMI.2013.6480966},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{7755520,
  author={Khatri, Saurabh and Tiwari, Sumit and Rizvi, Navaid Z.},
  booktitle={2016 International Conference on Electrical, Electronics, and Optimization Techniques (ICEEOT)}, 
  title={Electronic model of human brain using verilog}, 
  year={2016},
  volume={},
  number={},
  pages={4250-4254},
  abstract={Computers are man-made machines which work according to the given set of inputs and perform some operation on the input to generate a new set of outputs. They can be programmed to perform huge and complex task yet they lack imagination and ability to understand things. On the hand human brain is a machine which can learn new tasks by process of acquiring knowledge and understanding through thought, experience and the senses. To make computer work or think like human, human brain modeling of machine is necessary. We need to know how human brain works. The basic component of human brain is neuron, which make us think and do smart things. Brains have billions of neurons and they communicate with each other using electrical impulse. These impulses are responsible for making brain think and to have a consciousness. This paper proposes such a model of a part of the brain.},
  keywords={Neurons;Brain modeling;Artificial neural networks;Hardware;Computers;Computational modeling;Transfer functions;Neuron;layer;neural column;activation function},
  doi={10.1109/ICEEOT.2016.7755520},
  ISSN={},
  month={March},}@INPROCEEDINGS{4812710,
  author={Saurabh, Kumar and Krishnan, Balasubramanian},
  booktitle={2009 22nd Conference on Software Engineering Education and Training}, 
  title={Software Engineering: A System Dynamics Simulated Pedagogical Practice}, 
  year={2009},
  volume={},
  number={},
  pages={280-283},
  abstract={System Theories, analysis and design have been deployed within every corporate function and within a broad section of businesses and markets. Systems thinking involve changing paradigms about the way the world works, the way corporations function, and the human role in each. In systems thinking, analysis and design we look for interrelationships among the elements of a system. System engineering technology involves the interactions of science, an organization, and its environment as well as the information and knowledge bases that support each. The purpose of systems engineering is to support organizations that desire improved performance. Software Process Simulation is directly linked to software process improvement. Organizations can use software process simulation at all levels of maturity to obtain significant benefits. The aim is to determine how to usefully model a teaching-learning system for a specific course taught to a fresh graduate, and use simulation and modeling to predict consequences of changes to the process.},
  keywords={Software engineering;Predictive models;Software performance;Systems engineering and theory;Costs;Systems engineering education;Computational modeling;Analytical models;Computer simulation;Educational technology},
  doi={10.1109/CSEET.2009.59},
  ISSN={2377-570X},
  month={Feb},}@INPROCEEDINGS{6921307,
  author={Sadia, Rina},
  booktitle={Proceedings of PICMET '14 Conference: Portland International Center for Management of Engineering and Technology; Infrastructure and Service Integration}, 
  title={The impact of culture on group model-building process}, 
  year={2014},
  volume={},
  number={},
  pages={1585-1590},
  abstract={System thinking refers to the interrelationship between the parts of the organization that intend to design, produce and distribute products or services. System thinking is actually a conceptual language that encourages professionals into using “feedback loop" thinking rather than mere linear thinking. To solve a problem, systems thinking requires the building of a model by a diverse group with a varied input. The group modeling process which is an important process of system dynamics intervention in organizations is mainly developed by researchers from similar backgrounds and cultures. A research conducted in Israel, a country with a mixture of cultures and social backgrounds, evokes a different experience and approach to the more known group model building techniques. Since the participants in the group were from diverse backgrounds in terms of their culture, economic situation and their work position, they could easily be led by their social condition in their thinking and opinions. Therefore, knowledge elicitation through the group model building process during the group sessions and on the other hand, knowledge elicitation through personal conversation brought up contradictory information and called for constantly improving the elicitation process.},
  keywords={Feedback loop;Buildings;Organizations;Computational modeling;Mathematical model;Production;Maintenance engineering},
  doi={},
  ISSN={2159-5100},
  month={July},}@INPROCEEDINGS{8862433,
  author={Kumar, Sanjay and Gupta, Priyanka and Lakra, Sachin and Sharma, Lavanya and Chatterjee, Ram},
  booktitle={2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)}, 
  title={The Zeitgeist Juncture of “Big Data” and its Future Trends}, 
  year={2019},
  volume={},
  number={},
  pages={465-469},
  abstract={With the prime objective of understanding the direction in which the field of big data is heading, this paper emphasizes on the recent and upcoming trends in big data. The human brain handles big data in all its forms very efficiently and almost instantaneously, no matter what is the granularity of the data. The idea behind the field of processing big data is to mimic the manner in which the natural brain works and handles big data. All the fields and subfields of machine intelligence are based on identifying and mimicking the natural methods which are used by mother nature to handle big data. The current trends are mainly moving towards processing big data using the cloud infrastructure and machine learning techniques. By and large the intention of artificial intelligence lies in developing a humanoid robot which can work, talk and think like a human being. The future trends of big data are being applied to such techniques as microprocessors processing big data in a robot’s-brain to plan its actions, express emotions and ultimately to think like a human being.},
  keywords={Big Data;Market research;Real-time systems;Companies;Machine learning;Cloud computing;Data Analytics;MapReduce;Big Data;Artificial Intelligence;Cloud Computing;Cyber Security;IoT},
  doi={10.1109/COMITCon.2019.8862433},
  ISSN={},
  month={Feb},}@ARTICLE{9819884,
  author={Calaiaro, Jason},
  journal={IEEE Spectrum}, 
  title={AI Takes a Dumpster Dive: Computer-vision systems sort your recyclables at superhuman speed}, 
  year={2022},
  volume={59},
  number={7},
  pages={22-27},
  abstract={It's Tuesday night. In front of your house sits a large blue bin, full of newspaper, cardboard, bottles, cans, foil take-out trays, and empty yogurt containers. You may feel virtuous, thinking you're doing your part to reduce waste. But after you rinse out that yogurt container and toss it into the bin, you probably don't think much about it ever again.},
  keywords={Computer vision;Recycling;Environmental management;Pollution control;Sorting;Industries;Financial management;Market research;Neural networks;Training data},
  doi={10.1109/MSPEC.2022.9819884},
  ISSN={1939-9340},
  month={July},}@INPROCEEDINGS{1437155,
  author={Chockler, G. and Demirbas, M. and Gilbert, S. and Lynch, N. and Newport, C. and Nolte, T.},
  booktitle={25th IEEE International Conference on Distributed Computing Systems Workshops}, 
  title={Reconciling the theory and practice of (un)reliable wireless broadcast}, 
  year={2005},
  volume={},
  number={},
  pages={42-48},
  abstract={Theorists and practitioners have fairly different perspectives on how wireless broadcast works. Theorists think about synchrony; practitioners think about backoff. Theorists assume reliable communication; practitioners worry about collisions. The examples are endless. Our goal is to begin to reconcile the theory and practice of wireless broadcast, in the presence of failures. We propose new models for wireless broadcast and use them to examine what makes a broadcast model good. In the process, we pose some interesting questions that help to bridge the gap.},
  keywords={Broadcasting;Algorithm design and analysis;Reliability theory;Wireless sensor networks;Wireless communication;Usability;Computer science;Artificial intelligence;Bridges;Sensor phenomena and characterization},
  doi={10.1109/ICDCSW.2005.120},
  ISSN={2332-5666},
  month={June},}@INPROCEEDINGS{9913127,
  author={Jelínek, Jiří},
  booktitle={2022 12th International Conference on Advanced Computer Information Technologies (ACIT)}, 
  title={Data Structure and Simulation Model for Associative Reasoning}, 
  year={2022},
  volume={},
  number={},
  pages={525-529},
  abstract={Implementing the human way of thinking in different systems is still an open issue in artificial intelligence. Part of this thinking is also the so-called associative reasoning, which is based on associations arising mainly from the simultaneous observations of individual concepts representing our world. These observations can take both the form of images and simultaneous perceptions through other human senses (e.g., sound perceptions). This paper focuses on how to represent these perceptions and their sequence and ways to implement associative reasoning based on them. A data model enabling this functionality on large volumes of data will be presented, as well as the results of experiments on it.},
  keywords={Knowledge based systems;Decision making;Data structures;Data processing;Cognition;Data models;Sparse matrices;associative reasoning;human perception;concept representation;data structures},
  doi={10.1109/ACIT54803.2022.9913127},
  ISSN={2770-5226},
  month={Sep.},}@INPROCEEDINGS{10503402,
  author={Kadyan, Laksh and Neerugatti, Vikram and Taranum, Ayesha and Rani, Geetha and Somasekar, J},
  booktitle={2024 4th International Conference on Data Engineering and Communication Systems (ICDECS)}, 
  title={Machine Learning and Clinical Insights Analysis of BMI Dataset Predictive Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Machine learning (ML) has developed at a superlative rate, accompanying requests spanning various fields. This research investigates the experience of strength data, exceptionally the request of machine learning (ML) algorithms to a Body Mass Index (BMI) dataset. The basic aim of searching out unwinds the dossier’s many linkages and patterns, eventually chief to more thorough information of the variables deciding BMI. The study starts accompanying an initiation to the subject within reach, understood by a thorough study of appropriate work, a complex mechanics division, and an itemized reason of the reached results. However, because of advances in Machine Learning, we immediately have the talent to handle this issue in a more excellent manner. We’ve built an advance dossier-study system that can think a patient has diabetes, a suggestion of correction, admitting for early mediation. This predicting plan uses dossier analysis methods to extractable intuitions from a big number of diabetes-accompanying facts. Its basic aim is to correctly determine a patient’s risk of diabetes. We’ve working categorization plans to a degree Decision Tree, Artificial Neural Networks (ANN), Naive Bayes, and Support Vector Machine (SVM) algorithms to cultivate the model. These outcomes show the influence of the subsystems in thinking diabetes risk admit a large size of veracity. This predictive finish can create a meaningful dissimilarity in labeling at-risk things early and providing bureaucracy with essential care and counseling before the ailment progresses. In summary, our machine intelligence-located scheme offers a natural still strong solution to call the risk of diabetes in subjects. By controlling the wherewithal of dossier reasoning and categorization algorithms, we can enhance early discovery and deterrent measures for this weighty affliction, eventually reconstructing patient consequences and reducing the burden of BMI-related complications.},
  keywords={Support vector machines;Weight measurement;Machine learning algorithms;Machine learning;Medical services;Artificial neural networks;Prediction algorithms;Diabetes;Bayes methods;Wearable devices;BMI;Machine Learning;Algorithm;Health and Comparative Analysis},
  doi={10.1109/ICDECS59733.2023.10503402},
  ISSN={},
  month={March},}@INPROCEEDINGS{10293079,
  author={Jin, Xin and Wang, Yu and Wu, Wei and Li, Xiaodong},
  booktitle={2023 IEEE 14th International Conference on Software Engineering and Service Science (ICSESS)}, 
  title={Research on The Architecture of an Intelligent Assistant System for Commanders}, 
  year={2023},
  volume={},
  number={},
  pages={122-125},
  abstract={Battle commanders in modern war are facing new challenges such as massive information and short time windows. There is an urgent demand of intelligent assistant system to communicate with the commanders and staff officers, think about what they think, answer their questions, offer advises to their decision making, learn their experiences, and significantly improve their performance. Based on capability requirements analysis of such system, its system architecture was proposed, which shares data, knowledge, functions and computing power with the command information system currently in use. An AI framework based technical architecture was proposed, which has five characteristics: natural human-computer interaction, flexible function integration, knowledge system driven, continues ability evolution, and powerful computing support.},
  keywords={Human computer interaction;Integrated circuits;Knowledge based systems;Decision making;Systems architecture;Information sharing;Computer architecture;commanders and staff officers;intelligent assistant system;command information system;system architecture;technical architecture},
  doi={10.1109/ICSESS58500.2023.10293079},
  ISSN={2327-0594},
  month={Oct},}@INPROCEEDINGS{6488351,
  author={Liming Bai},
  booktitle={2013 15th International Conference on Advanced Communications Technology (ICACT)}, 
  title={System of systems engineering and geographical simulation: Towards a smart tourism industry information system}, 
  year={2013},
  volume={},
  number={},
  pages={1015-1018},
  abstract={The last few decades proves to be an era of booming communication and information disciplines, bringing about profound influence on people's life and every socio-economic sector. In this dramatically changed world, it is being found that many of the systems engineering principles and business practices that some industries have purposely pursued no longer function effectively in a System of Systems environment. This paper is inspired by the embedded, “system of systems (SoS) thinking” in the context of military programming. The purpose of this paper is to draw a conceptual framework for a smart tourism industry information system in responding to competitive challenges. The approach here is to illustrate how this SoS thinking and corresponding SoS engineering (SoSE) may be applied through the top-level design for the smart system. For designing a policy maker-responsive, informative system, an emerging complex spatial information approach, geographical simulation, is introduced. This holistic means includes: 1) simulation of the tourism SoS' architecture and evolution process through cellular automata (CA) and multi-agent systems (MAS) techniques, based on remote sensing data and GIS instrument; 2) illustration of the mechanism of industrial evolution by scale-free network analysis and social influence network with dynamic Bayesian network theory. This paper calls for a particular attention of communication specialists to concern the forefront of information (esp. spatial information) and systems engineering disciplines.},
  keywords={Business;Geographic information systems;Industries;Information systems;Optimization;System of systems (SoS);System of systems engineering (SoSE);geographical simulation;tourism;smart industry information system},
  doi={},
  ISSN={1738-9445},
  month={Jan},}@INPROCEEDINGS{5614536,
  author={Murat, Zunairah Hj and Taib, Mohd Nasir and Lias, Sahrim and Kadir, Ros Shilawani S. Abdul and Sulaiman, Norizam and Mustafa, Mahfuzah},
  booktitle={2010 2nd International Conference on Computational Intelligence, Communication Systems and Networks}, 
  title={EEG Analysis for Brainwave Balancing Index (BBI)}, 
  year={2010},
  volume={},
  number={},
  pages={389-393},
  abstract={The purpose of this research is to establish the fundamental brainwave balancing index (BBI) using EEG signals. Brainwave signals from EEG were measured and analyzed using intelligent signal processing techniques and specific algorithm. Consequently, the signals were statistically correlated with established psychoanalysis techniques to produce BBI system. The result shows that the PSD analysis provides reliable BBI with 80% conformity. The fundamental findings (brainwave balancing index and brain dominance) from this research can be served as a simple indicator of one's thinking leading to great opportunity for positive human potential development.},
  keywords={Electroencephalography;Indexes;Humans;Electrical engineering;Electrodes;Electric potential;Signal processing;brainwave;brainwave balancing index;EEG},
  doi={10.1109/CICSyN.2010.62},
  ISSN={},
  month={July},}@INPROCEEDINGS{9410715,
  author={Merencilla, Nino E. and Sarraga Alon, Alvin and Fernando, Glenn John O. and Cepe, Elaine M. and Malunao, Dennis C.},
  booktitle={2021 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)}, 
  title={Shark-EYE: A Deep Inference Convolutional Neural Network of Shark Detection for Underwater Diving Surveillance}, 
  year={2021},
  volume={},
  number={},
  pages={384-388},
  abstract={People are anxious about the potential dangers of scuba diving and like in all sports, there are dangers involved in it. Typically, people think sharks and shark attacks are the dangers of scuba diving, as sharks are one of the ocean's biggest predators, and the great white shark, in particular, is one of the primary threats to divers. The study proposes a deep learning approach to shark detection for underwater diving surveillance. A large collection of great white sharks' datasets underwater is used by the system for training as sharks are hard to differentiate from other sharks like animals in an underwater environment. A YOLOv3 algorithm that uses convolutional neural networks for object detection, multiscale prediction, and bounding box prediction through the use of logistic regression is used in the study. And with this approach, the testing of the shark detection system generates a good result.},
  keywords={Training;Knowledge engineering;Surveillance;Oceans;Object detection;Prediction algorithms;Convolutional neural networks;shark detection;underwater surveillance;deep learning;object detection;yolov3},
  doi={10.1109/ICCIKE51210.2021.9410715},
  ISSN={},
  month={March},}@INPROCEEDINGS{7546191,
  author={Jadon, Kuldeep Singh and Bhadoria, Robin Singh and Tomar, Geetam Singh},
  booktitle={2015 International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={A Review on Costing Issues in Big Data Analytics}, 
  year={2015},
  volume={},
  number={},
  pages={727-730},
  abstract={In 2004, Wall Mart guaranteed to have the biggest information stockroom with 500 terabytes stockpiling (identical to 50 printed accumulations of the US Library of Congress). In 2009, eBay stockpiling added up to eight petabytes (think about 104 years of HD-TV feature). After two years, the Yahoo distribution center totalled 170 petabytes1 (8.5 seasons of all hard circle drives made in 1995)2. Since the ascent of digitisation, undertakings from different verticals have amassed thriving measures of advanced information, catching trillions of bytes of data about their clients, suppliers and operations. Information volume is likewise developing exponentially because of the blast of machine-created (information records, web-log documents, sensor information) and from developing human engagement inside of the interpersonal organizations. So for handling this huge amount of data is really a big challenge, so it turns towards the concept of big data. This paper try to cover major aspects of big data is discussed in II Important Aspect's in Big Data along with its costing issues. The issues in transformation of traditional database into big data is discussed in III important points in transition from traditional data base to big data.},
  keywords={Big data;Databases;Organizations;Technological innovation;Costing;Computer architecture;Hadoop;MapReduce;Costing Issues in Big Data;Storage & Processing},
  doi={10.1109/CICN.2015.148},
  ISSN={2472-7555},
  month={Dec},}@INPROCEEDINGS{633083,
  author={Sandhu, G.S. and Rattan, K.S.},
  booktitle={1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation}, 
  title={Design of a neuro-fuzzy controller}, 
  year={1997},
  volume={4},
  number={},
  pages={3170-3175 vol.4},
  abstract={The essence of fuzzy control is to build a model of human expert who is capable of controlling the plant without thinking in terms of mathematical model. The transformation of expert's knowledge in terms of control rules to fuzzy framework has not been formalized and arbitrary choices concerning, for example, the shape of membership functions have to be made. The quality of fuzzy controller can be drastically affected by the choice of membership functions. Thus, methods for tuning the fuzzy logic controllers are needed. In this paper, neural networks are used in a novel way to solve the problem of tuning a fuzzy logic controller. The neuro-fuzzy controller uses the neural network learning techniques to tune the membership functions while keeping the semantics of the fuzzy logic controller intact. Both the architecture and the learning algorithm are presented for a general neuro-fuzzy controller. From this general neuro-fuzzy controller, a proportional neuro-fuzzy controllers is derived. A step by step algorithm for off-line training is given along with numerical examples.},
  keywords={Fuzzy control;Fuzzy logic;Neural networks;Shape control;Medical control systems;Mathematical model;Humans;Fuzzy neural networks;Proportional control;Fuzzy systems},
  doi={10.1109/ICSMC.1997.633083},
  ISSN={1062-922X},
  month={Oct},}@INPROCEEDINGS{4052744,
  author={Thapa, Devinder and Park, Chang Mok and Dangol, Suraj and Wang, Gi-nam},
  booktitle={2006 International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce (CIMCA'06)}, 
  title={III-Phase Verification and Validation of IEC Standard Programmable Logic Controller}, 
  year={2006},
  volume={},
  number={},
  pages={111-111},
  abstract={The objective of this paper is to define an integrated approach for offline verification and validation of the control logics to provide absolute solution by implementing the Ill-phase V&V method in a manufacturing industry. The control logic plays vital role in an agile manufacturing system for proper functioning of the FMS. The effort to integrate the formal verification techniques with virtual commissioning is emerging, which is still not in a full fledged industrial usage, due to the isolated thinking of the user about formal verification techniques. Existing techniques like simulation has not been able to detect the hidden errors, which may propagate from one workcell to another workcell in a long run and create a complete breakdown in the manufacturing unit. These errors required to be carefully tested before the real time implementation. Control logics play a vital role to reduce the down-time and ramp-up time in a manufacturing industry. We need an integrated approach and techniques to support the consistent running of the production cycle. This paper explained about the positive aspects of manual and software based automated and virtual commissioning techniques to provide an applicable solution to the fast paced manufacturing industries.},
  keywords={IEC standards;Programmable control;Logic;Formal verification;Manufacturing industries;Control systems;Agile manufacturing;Flexible manufacturing systems;Electrical equipment industry;Electric breakdown;Verification & Validation (V&V);Virtual Commissioning;Model Checking;PLC;Flexible Manufacturing System (FMS).},
  doi={10.1109/CIMCA.2006.118},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{699499,
  author={Dozier, G. and Homaifar, A. and Bryson, S. and Moore, L.},
  booktitle={1998 IEEE International Conference on Evolutionary Computation Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98TH8360)}, 
  title={Artificial potential field based robot navigation, dynamic constrained optimization and simple genetic hill-climbing}, 
  year={1998},
  volume={},
  number={},
  pages={189-194},
  abstract={The authors show a relationship between artificial potential field (APF) based motion planning/navigation and constrained optimization. They then present a simple genetic hill-climbing algorithm (SGHC) which is used to navigate a point robot through an environment using the APF approach. The motivation for the research is a robot that they are currently developing, named AGIE-3 (Autonomous Guided Intelligent Equipment 3), which senses and navigates through the use of a stereo vision head. They compare the SGHC with steepest descent hill-climbing (SDHC), using two environments. The first environment is composed of stationary obstacles while the second environment is composed of non-stationary obstacles. In SDHC, candidate moves are evaluated within a 360 degree radius and the best candidate is selected by the robot. One would think that the SGHC would be at a disadvantage; however, the performance of the SGHC is comparable with SDHC even though it does not search 360 degrees for candidate moves. The SGHC has an advantage in that it is capable of evolving the appropriate step size as well as the appropriate angle of movement.},
  keywords={Navigation;Constraint optimization;Robot sensing systems;Stereo vision;Robot vision systems;Magnetic heads;Genetics;Intelligent robots;NASA;Computer science},
  doi={10.1109/ICEC.1998.699499},
  ISSN={},
  month={May},}@INPROCEEDINGS{6463329,
  author={Yi, Jincong and Zhang, Hesheng and Qiao, Xiaoping and Zhu, Xiaojin},
  booktitle={2012 IEEE Fifth International Conference on Advanced Computational Intelligence (ICACI)}, 
  title={Shape monitoring for wing structure using fiber Bragg grating sensors}, 
  year={2012},
  volume={},
  number={},
  pages={1032-1036},
  abstract={To reconstruct the shape of wing structure using fiber Bragg grating sensors, an implementation method was presented in this paper. First, the principle of curvature measurement based upon fiber Bragg grating sensor was introduced, and the design of the layout of sensor's locations was optimized by the finite element (FE) analysis of the experimental model. Then, the algorithm description of surface reconstruction was given in detail. Finally, an experiment setup was built using an epoxy resin trapezoid plate equipped with distributed FBG sensors, combined with a data acquisition and a shape reconstruction algorithm system. Afterwards, the experiments of steady deformation and dynamic vibration behavior were implemented for the real-time shape reconstruction of wing model structure. The results verify the feasibility and effectiveness of the presented method of deformation shape detection for a sort of wing model structure based on fiber Bragg grating sensor array, and indicate that the proposed method can provide useful research thinking for the further study of active monitoring for aerospace wing structures.},
  keywords={Shape;Fiber gratings;Vibrations;Sensor arrays;Surface reconstruction},
  doi={10.1109/ICACI.2012.6463329},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10158552,
  author={Csiszráaik-Kocsir, Ágnes and Varga, János},
  booktitle={2023 IEEE 17th International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
  title={The advancing role of digitalisation through the example of the Perlmutter project from the user side}, 
  year={2023},
  volume={},
  number={},
  pages={000327-000332},
  abstract={The events of recent years have shed new light on the crisis and change management practices of economic actors. It has been a truism that actors who are more receptive to change can be more successful and efficient than their peers in business markets. Perhaps the most significant changes in recent years have confirmed this even more. One only has to think of the impact of pandemic COVID-19, the energy crisis or the Russian-Ukrainian conflict. In a very short period of time, these events have brought about very significant changes and their impact has been largely negative for most economic actors. If it has not been sufficiently understood so far why it can be important to adapt to changes in a timely and appropriate way, or why good crisis management practices can be important, perhaps everyone will now. Meanwhile, other trends are shaping the global economy and will have an impact on the future state of the economy and society. Examples include sustainability (or the green transition) and digitalisation. Two global changes that will certainly have a long-term impact on society and business processes. No one can afford the luxury of ignoring these changes. What is more, the most competitive economic players are seeking to turn them to their advantage and to reap the benefits of sustainability or digitalisation. It is clear that our world has become faster and more complex than ever before. More and more things are changing around us, with ever more intense consequences. We need to recognise in time how we can respond to changing environmental conditions or circumstances. This is the subject of the present paper, which, after a brief literature review, draws on research findings to illustrate the importance and relevance of digitalisation.},
  keywords={Economics;Resistance;Pandemics;Green products;Switches;Market research;Sustainable development;change management;innovation;digitalisation;digital switchover},
  doi={10.1109/SACI58269.2023.10158552},
  ISSN={2765-818X},
  month={May},}@INPROCEEDINGS{8276349,
  author={Rianto and Budiyanto, Djoko and Setyohadi and Suyoto},
  booktitle={2017 1st International Conference on Informatics and Computational Sciences (ICICoS)}, 
  title={AHP-TOPSIS on selection of new university students and the prediction of future employment}, 
  year={2017},
  volume={},
  number={},
  pages={125-130},
  abstract={Universities are institutions that educate and generate labor candidates; as a result, the process of selecting new university students should pay attention to several matters and these matters should be considered. Many universities in the process base the selection on the academic skills and consequently problems will appear when an individual should evaluate all the job criteria as he or she enters employment. Through this paper the researchers would like to propose a model, AHP-TOPSIS, for the process of selecting new university students and for predicting their future employment. With the sample of 30 students from Diploma 3 Aeronautics STTA Yogyakarta, an evaluation model was designed using the indicators of academic skills, English proficiency skills, psycho test, soft skills (communication, problem solving and critical thinking, time management, cooperation, and adaptation skills), and attitudes. The load for these indicators were attained using the AHP and then these indicators would be calculated using the TOPSIS in order to find the alternative rank of the students' selection. The rank was determined by gathering the interest score from the calculation using the AHP so that the integrated evaluation results could be provided. The main objective of this paper was assisting the decision-makers in the process of selecting new university students who have both academic and personality skills that would be necessary to support their performance in the future employment.},
  keywords={Employment;Analytic hierarchy process;Load modeling;Teamwork;Informatics;Predictive models;criteria;university student selection;AHP;TOPSIS},
  doi={10.1109/ICICOS.2017.8276349},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7065614,
  author={Goswami, Kavita and Pandey, Bishwajeet},
  booktitle={2014 International Conference on Computational Intelligence and Communication Networks}, 
  title={LVCMOS Based Thermal Aware Energy Efficient Vedic Multiplier Design on FPGA}, 
  year={2014},
  volume={},
  number={},
  pages={921-924},
  abstract={In this work, we are integrating thermal aware design approach in energy efficient Vedic multiplier on FPGA. In the beginning of this universe, Veda describes heat receiving from the Sun god as Suryamrit (Surya i.e. Sun +Amrit i.e. Nectar= Suryamrit i.e. Nectar coming from the Sun God). Now, whole world is feeling anxious about temperature. How our thinking pattern is changing with evolution of mankind? This paper deals with that question and the whole work is going in direction to get solution of this problem with mechanism of ambient (room) temperature scaling and energy efficient LVCMOS I/O standard. LVCMOS is an acronym for low voltage complementary metal oxide semiconductor. In this Vedic multiplier, we are using three LVCMOS I/O standard. LVCMOS12 is available only in 65nm and 40nm FPGA. Rest LVCMOS18 and LVCMOS25 is available among 40nm, 65nm and 90nm FPGA. In order to test the thermal sustainability of our Vedic multiplier, we are testing it in three different room temperature 20°C, 30°C, and 40°C. Using LVCMOS25, there is 12.99%, 19.23% and 10.28% reduction in power dissipation on 90nm, 65nm and 40nm respectively. For LVCMOS25, when our Vedic multiplier design is migrated from 40nm design to 90nm design, there is 87.72% reduction in power dissipation of Vedic multiplier when temperature is constant 20°C.},
  keywords={Field programmable gate arrays;Power dissipation;Standards;Energy efficiency;Junctions;Mathematics;Conferences;Thermal aware;Vedic Multiplier;LVCMOS;IO Standard;Energy Efficient Design},
  doi={10.1109/CICN.2014.194},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{6005994,
  author={Murat, Zunairah Hj. and Taib, Mohd Nasir and Lias, Sahrim and Kadir, Ros Shilawani S. Abdul and Sulaiman, Norizam and Hanafiah, Zodie Mohd},
  booktitle={2011 Third International Conference on Computational Intelligence, Communication Systems and Networks}, 
  title={Development of Brainwave Balancing Index Using EEG}, 
  year={2011},
  volume={},
  number={},
  pages={373-378},
  abstract={In this research, Wireless EEG equipment via Bluetooth technology named g-Mobilab was used to measure the brainwave signals in the right and left frontal area of the brain. The recorded EEG signals were channelled into an automatic artifact removal analysis whereby signals above values of 100 micro-volts were removed by means of a program using Matlab. Consequently, Power Spectral Density techniques and specific algorithm were employed to further enhance the EEG signals. The correlation between the left and the right brainwaves were achieved using paired T test from SPSS. The results, which are brainwave balancing index (BBI) and brainwave dominance, were presented via Graphic User Interface (GUI). The outcome shows that BBI system could be established using EEG signals. These findings (brainwave dominance and BBI) could be used as a straightforward indicator of one's ability to think and work leading to vast opportunity for constructive human potential advancement.},
  keywords={Electroencephalography;Indexes;Data acquisition;Graphics;Electrodes;Electric potential;Humans;Brainwaves;brain dominance;EEG;Power Spectral Density},
  doi={10.1109/CICSyN.2011.84},
  ISSN={},
  month={July},}@INPROCEEDINGS{8441011,
  author={Lazányi, Kornelia},
  booktitle={2018 IEEE 12th International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
  title={Are we Ready for Self-Driving Cars-a Case of Principal-Agent Theory}, 
  year={2018},
  volume={},
  number={},
  pages={000251-000254},
  abstract={ICT readiness is not an issue any more-or so we think. In the 21st century, when the industry and society are infused with IT one would reason the more the better, because there cannot possibly be anyone to detest, or stand up against automatization and IT. However, it is not so. Not only the elderly people, who were born before the 2nd world war, but even GenZ people can be afraid of the speed and scope of ICT and modern technology taking over territories of their lives [1]. Of course, there is a substantial part of people who are eagerly looking forward the future fully automatized, and there are others, who simply don't care. But there is a significant group of people, who are not prepared for automatization, who simply do not trust robots and autonomous systems in their lives. Present paper endeavours to approach the notion of ICT readiness from the social, psychological point of view, utilising the framework of the principal-agent theory.},
  keywords={Autonomous automobiles;Monitoring;Automobiles;Autonomous systems;Task analysis;Automation;self-driving cars;automated vehicles;trust;principal;agent;principal agent theory},
  doi={10.1109/SACI.2018.8441011},
  ISSN={},
  month={May},}@INPROCEEDINGS{6160092,
  author={Chen, Huangqiong and Zeng, Zhigang},
  booktitle={The Fourth International Workshop on Advanced Computational Intelligence}, 
  title={Deformation prediction of landslide based on genetic-simulated annealing algorithm and BP neural network}, 
  year={2011},
  volume={},
  number={},
  pages={675-679},
  abstract={In this paper, a modified method for landslide prediction is presented. This method is based on the back propagation neural network(BPNN), and we use the combination of genetic algorithm and simulated annealing algorithm to optimize the weights and biases of the network. The improved BPNN modeling can work out the complex nonlinear relation by learning model and using the present data. This paper demonstrates that the revised BPNN modeling can be used to predict and calculate landslide deformation, quicken the learning speed of network and improve the predicting precision. Applying this thinking and method into research of some landslide in the Three Gorges reservoir, the validity and practical value of this model can be demonstrated. And it also shows that the dynamic prediction of landslide deformation is very crucial.},
  keywords={Terrain factors;Prediction algorithms;Biological neural networks;Artificial neural networks;Annealing;Predictive models;Simulated annealing},
  doi={10.1109/IWACI.2011.6160092},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7078687,
  author={Hadj Ahmed, Bouarara and Amine, Abdelmalek and Reda Mohamed, Hamou},
  booktitle={2015 IEEE International Conference on Computational Intelligence & Communication Technology}, 
  title={New Private Information Retrieval Protocol Using Social Bees Lifstyle over Cloud Computing}, 
  year={2015},
  volume={},
  number={},
  pages={161-165},
  abstract={Recently, a novel form of web services had seen the light under the name of Cloud Computing which presents the dematerialisation of software, systems and infrastructures. However, in a world where digital information is everywhere, finding the desired information has become a crucial problem. In other hand, the users of cloud services starting asking about their privacy protection, particularly when they lose control of their data during the treatment and even some of them think about counting the service providers themselves as honest attackers. For that, new approaches had been published in every axis of the privacy preserving domain. One of these axis consists of a special retrieval models which allow both finding and hiding sensitive desired information at the same time. The substance of our work is a new system of private information retrieval protocol (PIR) composed of four steps the authentication to ensure the identification of authorised users. The encryption of stored documents by the server using the boosting algorithm based on the life of bees and multi-filter cryptosystems. The information retrieval step using a combination of distances by social bees where a document must pass through three dams controlled with three types of worker bees, the bee queen represents the query and the hive represents the class of relevant documents. Finally, a visualization step that permits the presentation of the results in graphical format understandable by humans as a 3D cube. Our objectives is to amend the response to users' demands.},
  keywords={Information retrieval;Protocols;Encryption;Cloud computing;Boosting;Private Information Retrieval;Visualisation;Social bees;Boosting Cryptosystem;Cloud Computing},
  doi={10.1109/CICT.2015.163},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{7975189,
  author={Dhande, Bharti S. and Pacharaney, Utkarsha S.},
  booktitle={2017 International Conference on Inventive Communication and Computational Technologies (ICICCT)}, 
  title={Unmanned level crossing controller and rail track broken detection system using IR sensors and Internet of Things technology}, 
  year={2017},
  volume={},
  number={},
  pages={206-210},
  abstract={Railways provide the cheapest and most convenient mode of passenger transport both for long distance and suburban traffic. Also, most of transport in India is being carried out by railway network. Still accidents are the major concern in terms of railway track crossing and unidentified crack in rail tracks in Indian railway. About 60% accidents are occurring at railway track crossing and due to crack in railway tracks resulting in loss of precious life and loss of economy. Therefore there is need to think about new technology which is robust, efficient and stable for both automatic gate closure system and crack detection in railway track. This paper proposes an unmanned gate crossing and faulty rail track detection. Unmanned level crossing is a IR sensors base system and crack detection is an dynamic approach which combines the use of GPS (global positioning system) tracking system and GSM (global system for mobile communication) modem to send geographical coordinate of location. Unmanned gate crossing controller system prevents accident which are caused due to railway track crossing and railway crack detection system prevents train derailment by detecting crack in railway track using internet of things technology.},
  keywords={Rail transportation;Logic gates;Global Positioning System;Sensor systems;Rails;GSM;unmanned gate crossingGSM modemGPS moduleIR transmitter and ReceiverInternet of Things technology},
  doi={10.1109/ICICCT.2017.7975189},
  ISSN={},
  month={March},}@INPROCEEDINGS{6141690,
  author={Afrouzi, Hadi Nabipour and Mashak, Saeed Vahabi and Dastgheib, Ali Mohammad and Tavalaei, Jalal},
  booktitle={2011 First International Conference on Informatics and Computational Intelligence}, 
  title={Economic Sizing of Solar Array for a Photovoltaic Building in Malaysia with Matlab}, 
  year={2011},
  volume={},
  number={},
  pages={306-311},
  abstract={This article illustrates a simulation method to find a sizing and economic of a required photovoltaic array for a photovoltaic building in Malaysia. This paper represents the result using by Matlab software and also mathematic equation. It is known that the important factor for photovoltaic system is cost of a system, and because of several kinds of the photovoltaic array we have the right to select the best array with the best efficiency and best price. The popular types of materials are crystalline and thin films, which have differences in terms of light absorption efficiency, energy conversion efficiency, manufacturing technology and cost of production. Different kinds of crystalline materials like a mono-crystalline, polycrystalline are available. In this paper, the generated current and generated power by the photovoltaic array is calculated according to daily solar irradiation when the case study is Malaysia. Think over generated power of each array's and also according to required energy for a typically building, the number of photovoltaic array is estimated then the cost of the solar array is calculated. System is simulated by Matlab software, and the results are discussed. The simulation is about sizing and economic in order to select the best array for photovoltaic system to have a optimize system according to size and price of the system.},
  keywords={Arrays;Photovoltaic systems;Radiation effects;Mathematical model;Equations;Sun;Photovoltaic;Array;Crystalline;Solar Irradiation;Matlab Software;Sizing;economic},
  doi={10.1109/ICI.2011.57},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{1554326,
  author={Eri Sato and Aika Nakajima and Toru Yamaguchi},
  booktitle={2005 International Symposium on Computational Intelligence in Robotics and Automation}, 
  title={Nonverbal interface for user-friendly manipulation based on natural motion}, 
  year={2005},
  volume={},
  number={},
  pages={499-504},
  abstract={In this research, we show two experiments using non-verbal interaction. We think nonverbal communication is basic, and important for communication between human. Moreover, We focus on the networked robotics which is fusion of network technology and robot technology. We constructed nonverbal interface by using human natural motion. In the first experiment, we created commands using hand motion which is based on natural motion, such as beckoning, hissing away and so on. We constructed robot manipulation system using these commands. Furthermore, we compared the user-friendly of our system with present keyboard manipulation system. In the second experiment, in order to manipulate a robot using more natural motion, we proposed 'pointing movement'. Moreover, we constructed networked robots that recognizes human motion spatially. Accordingly, the user was able to manipulate the robot with more natural motion in larger space.},
  keywords={Orbital robotics;Humans;Keyboards;Humanoid robots;Cameras;Space technology;Mice;Robot vision systems;Open source software;Systems engineering and theory;robot;nonverbal interface;networked robot},
  doi={10.1109/CIRA.2005.1554326},
  ISSN={},
  month={June},}@INPROCEEDINGS{495258,
  author={Bjorn, V.},
  booktitle={Proceedings of 1995 Conference on Computational Intelligence for Financial Engineering (CIFEr)}, 
  title={Multiresolution methods for financial time series prediction}, 
  year={1995},
  volume={},
  number={},
  pages={97-},
  abstract={Summary form only given. Fractional Brownian motion (fBm), a 1/f, fractal process, has long been considered a plausible model for financial time series. A fractal structure of the market, indicating the presence of correlations across time, hints at the possibility of some predictability. Recent advances in time/frequency localized transforms by the applied mathematics and electrical engineering communities provide us with powerful new methods for the analysis of this type of process. In fact, it has been proven by Wornell that the wavelet transform is an optimal (KL) transform for fBm processes. With this result, we consider using the wavelet decomposition to analyze financial time series. Specifically, the discrete wavelet transform can be used to decompose a signal into several scales, while maintaining time localization of events in each scale. In terms of financial time series, we can conceptually think of each of these scales as the contribution to the price movement from the information and traders associated with a given investment horizon, for instance, long term traders, such as institutional investors, basing their trades on long term information, form the low-frequency component of the market. Once we have extracted out these scales, we can view each as a stationary time series, which can be modeled, analyzed and predicted individually, either independently, or in conjunction with other scales and data that is relevant to that scale. For the case of prediction, the forecasts from each scale can be fused together, with traditional techniques such as hard coded decision rules, or with a neural network, to arrive at tomorrow's direction and/or price.},
  keywords={Discrete wavelet transforms;Fractals;Time series analysis;Signal resolution;Brownian motion;Frequency;Mathematics;Electrical engineering;Wavelet analysis;Investments},
  doi={10.1109/CIFER.1995.495258},
  ISSN={},
  month={April},}@INPROCEEDINGS{8441004,
  author={Costea, Felicia-Mirabela and Chirila, Ciprian-Bogdan and Creţu, Vladimir-Loan},
  booktitle={2018 IEEE 12th International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
  title={Towards Auto-Generative Learning Objects for Industrial IT Services}, 
  year={2018},
  volume={},
  number={},
  pages={000155-000160},
  abstract={In eastern Europe, in the last few years the IT services industry has significantly grown due to the externalization of IT operations from western Europe and America: production plants, communications, satellites, etc. In this context the pressure on the eastern IT services labor market has increased. IT services companies employed students with no IT background and trained them in their in house academies in order to respond fast to their contractual obligations. The time frame to form IT operations specialists is very narrow so they need to think of new strategies to speedup their training. In this sense auto-generative learning objects as the second generation of learning objects are a potential solution since it allows autonomous learning anytime during the day, when queuing, in the subway or during school or job breaks. Learners are trained with automatically generated dynamic content, get automatic evaluation of their responses and receive dynamic feedback. Thus, they can exercise autonomously different learning situations benefiting from automatic evaluation.},
  keywords={Linux;Operating systems;Load modeling;Browsers;Computers;Libraries;Europe},
  doi={10.1109/SACI.2018.8441004},
  ISSN={},
  month={May},}@INPROCEEDINGS{5656629,
  author={Xiaodong, Li and Zhongyang, Guo and Ran, Xu and Xiaoyan, Dai and Yizhi, Hu and Shufeng, Ye},
  booktitle={2010 International Conference on Artificial Intelligence and Computational Intelligence}, 
  title={Application of Artificial Neural Network in the Typhoon Flood Prediction System - A Case Study in Shanghai, China}, 
  year={2010},
  volume={1},
  number={},
  pages={191-195},
  abstract={In order to decrease the damages caused by typhoon, an Artificial Neural Network (ANN) model has been established to predict the trend of storm flood in Shanghai, China. The model has capacity to simulate the brain’s thinking process objectively and avoid the influence of the forecasters’ subjective judgment. The present model is capable to predict the 12-hour ahead typhoon surge deviation in high tide efficiently. At the same time, an intelligent storm-flood forecasting system is designed and built, and the system not only can predict the storm flood in the future 12 hours, but also is useful to mitigate the typhoon disasters in Shanghai. It has been proved that the ANN model is a new effective way to predict the storm surge, and the intelligent storm-flood forecasting system is a kind of new method to manage the typhoon disasters as well.},
  keywords={Typhoons;Storms;Surges;Floods;Predictive models;Artificial neural networks;Geographic Information Systems;ANN;BP;storm flood;prediction},
  doi={10.1109/AICI.2010.46},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8473228,
  author={Bonde, Sharayu N. and Kirange, D. K.},
  booktitle={2018 Second International Conference on Inventive Communication and Computational Technologies (ICICCT)}, 
  title={Survey on Evaluation of Student's Performance in Educational Data Mining}, 
  year={2018},
  volume={},
  number={},
  pages={209-213},
  abstract={Educational information mining is rising field that spotlights on breaking down educational information to create models for enhancing learning encounters and enhancing institutional viability. Expanding enthusiasm for information mining and educational frameworks, make educational information mining as another developing exploration group. Educational Data Mining intends to remove the concealed learning from expansive Educational databases with the utilization of procedures and apparatuses. Educational Data Mining grows new techniques to find information from Educational database and it is utilized for basic decision making in Educational framework. The knowledge is hidden among the Educational informational Sets and it is extractable through data mining techniques. It is essential to think about and dissect Educational information particularly understudies execution. Educational Data Mining (EDM) is the field of study relates about mining Educational information to discover intriguing examples and learning in Educational associations. This investigation is similarly worried about this subject, particularly, the understudies execution. This study investigates numerous components theoretically expected to influence student's performance in higher education, and finds a subjective model which best classifies and predicts the student's performance in light of related individual and phenomenal elements.},
  keywords={Data mining;Decision trees;Education;Classification algorithms;Conferences;Databases;Predictive models;Education Data Mining;Students Performance;Data mining techniques;Association rule},
  doi={10.1109/ICICCT.2018.8473228},
  ISSN={},
  month={April},}
