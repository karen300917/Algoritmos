@ARTICLE{7937927,
  author={Setchi, Rossitza and Asikhia, Obokhai K.},
  journal={IEEE Transactions on Affective Computing}, 
  title={Exploring User Experience with Image Schemas, Sentiments, and Semantics}, 
  year={2019},
  volume={10},
  number={2},
  pages={182-195},
  abstract={Although the concept of user experience includes two key aspects, experience of meaning (usability) and experience of emotion (affect), the empirical work that measures both the usability and affective aspects of user experience is currently limited. This is particularly important considering that affect could significantly influence a user's perception of usability. This paper uses image schemas to quantitatively and systematically evaluate both these aspects. It proposes a method for evaluating user experience that is based on using image schemas, sentiment analysis, and computational semantics. The aim is to link the sentiments expressed by users during their interactions with a product to the specific image schemas used in the designs. The method involves semantic and sentiment analysis of the verbal responses of the users to identify (i) task-related words linked to the task for which a certain image schema has been used and (ii) affect-related words associated with the image schema employed in the interaction. The main contribution is in linking image schemas with interaction and affect. The originality of the method is twofold. First, it uses a domain-specific ontology of image schemas specifically developed for the needs of this study. Second, it employs a novel ontology-based algorithm that extracts the image schemas employed by the user to complete a specific task and identifies and links the sentiments expressed by the user with the specific image schemas used in the task. The proposed method is evaluated using a case study involving 40 participants who completed a set task with two different products. The results show that the method successfully links the users' experiences to the specific image schemas employed to complete the task. This method facilitates significant improvements in product design practices and usability studies in particular, as it allows qualitative and quantitative evaluation of designs by identifying specific image schemas and product design features that have been positively or negatively received by the users. This allows user experience to be assessed in a systematic way, which leads to a better understanding of the value associated with particular design features.},
  keywords={Usability;Product design;Semantics;Sentiment analysis;Tools;Context;Ontologies;Affect;computational semantics;image schema;interaction design;ontology;sentiment analysis;usability;user experience},
  doi={10.1109/TAFFC.2017.2705691},
  ISSN={1949-3045},
  month={April},}@INPROCEEDINGS{9893636,
  author={Margarido, Solange and Machado, Penousal and Roque, Licínio and Martins, Pedro},
  booktitle={2022 IEEE Conference on Games (CoG)}, 
  title={Let’s Make Games Together: Explainability in Mixed-initiative Co-creative Game Design}, 
  year={2022},
  volume={},
  number={},
  pages={638-645},
  abstract={There has been growing development of co-creative systems for game design, where both humans and computers work as colleagues, proactively contributing with creative input. However, the collaborative process is still not as seamless as in human-human co-creativity. A key element still underdeveloped in these approaches is the communication between the human and the machine, which can be facilitated by providing the computational agent with explanatory capabilities. Based on principles of explainability for co-creative systems from previous literature, we propose a framework of explainability specifically applied to mixed-initiative scenarios in game design. We illustrate the applications of the framework by suggesting possible solutions adapted to different use cases of existing approaches and, additionally, of our own proposed approach.},
  keywords={Computers;Visualization;Collaboration;Games;Guidelines;explainability;mixed-initiative;game design;computational creativity;co-creativity},
  doi={10.1109/CoG51982.2022.9893636},
  ISSN={2325-4289},
  month={Aug},}@INPROCEEDINGS{6602429,
  author={Sayama, Hiroki and Dionne, Shelley D.},
  booktitle={2013 IEEE Symposium on Artificial Life (ALife)}, 
  title={Using evolutionary computation as models/tools for human decision making and creativity research}, 
  year={2013},
  volume={},
  number={},
  pages={35-42},
  abstract={This paper presents a review of our recently completed interdisciplinary research project “Evolutionary Perspective on Collective Decision Making” that was conducted through close collaboration between computational, organizational and social scientists at Binghamton University. In this project, we utilized Evolutionary Computation in several non-traditional ways-(l) as a theoretical framework for reinterpreting the dynamics of collective human decision making processes, (2) as a computational simulation model of idea generation and selection, and (3) as a research tool for collecting high-resolution experimental data of actual collaborative design and decision making from human subjects.},
  keywords={Decision making;Computational modeling;Sociology;Statistics;Evolution (biology);Computer simulation;Cultural differences;Evolution of ideas;human decision making;collaborative design;creativity;agent-based simulation;human subject experiments;evolutionary computation;hyperinteractive evolutionary computation},
  doi={10.1109/ALIFE.2013.6602429},
  ISSN={2160-6382},
  month={April},}@ARTICLE{8836111,
  author={Southwick, Daniel},
  journal={IEEE Annals of the History of Computing}, 
  title={High Noon on the Creative Frontier: Configuring Human and Machine Expertise}, 
  year={2019},
  volume={41},
  number={4},
  pages={97-109},
  abstract={In 1960, CBS aired a special issue entitled “The Thinking Machine” which featured three Western playlets scripted by a computer programmed by MIT researchers. Almost 60 years later, two researchers at Autodesk used a computer program to help design a chair. In this article, I link these two seemingly discrete examples of computational creativity in order to highlight how digital fabrication technologies have served as an important test site for defining human and computational expertise. I do so by illustrating how concepts of “creativity” and “routine” were produced alongside the concepts of computational creativity during the development of digital fabrication. This dichotomy of “creative” and “routine” is not only used to determine the kinds of tasks that are appropriate for humans and computers to perform within the design and production process, but it is also used to render invisible the embodied craft knowledge required to substantiate these systems.},
  keywords={History;Fabricatoin;Digital systems;Design automation;Creativity;Computational modeling;Programming;Automation;Computer-aided design;Computer-aided manufacturing;Industrial automation},
  doi={10.1109/MAHC.2019.2941108},
  ISSN={1934-1547},
  month={Oct},}@INPROCEEDINGS{7474583,
  author={Pech, Robert and Lin, Barry and Cho, Chung-Suk and Al-Muhairi, Hassan},
  booktitle={2016 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Innovation, design and entrepreneurship for engineering students: Development and integration of innovation and entrepreneurship curriculum in an engineering degree}, 
  year={2016},
  volume={},
  number={},
  pages={389-396},
  abstract={The authors of this paper introduced junior (3rd year BSc) students for the first time to the principles and practices of innovation and entrepreneurship in engineering design at Khalifa University in the United Arab Emirates, in 2014. This included an overview of the techniques that managers in organizations and startup entrepreneurs use to initiate and manage innovation effectively. The course introduces four main phases of innovation and entrepreneurship: (i) identification of a new need or want; (ii) invention of a technological solution; (iii) testing and implementing that solution; and (iv) the mock-start of an entrepreneurial venture. These are explored at length. The course uses a hands-on approach to engage students in groups of four, to the full process of innovation and entrepreneurship from concept generation and selection, needs finding and screening leading to the development of viable financial strategies in their business plans. The innovation/entrepreneurship part of the course is taught in parallel with the design engineering part. The emphasis of the course is on the development of innovative and competitive needs-based solutions for real world engineering problems through the creation of prototypes and simulations. Students are taught "tools" to assist them: design modelling, problem-solving methods, ethical debate, reasoning and logic, and a business plan canvas to help them organize their thinking about business prospects in a realistic fashion.},
  keywords={5G mobile communication;Engineering education;Conferences;innovation;engineering design;entrepreneurship;curriculum;experiential learning},
  doi={10.1109/EDUCON.2016.7474583},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{8248136,
  author={Wildman, Wesley J. and Fishwick, Paul A. and Shults, F. LeRon},
  booktitle={2017 Winter Simulation Conference (WSC)}, 
  title={Teaching at the intersection of simulation and the humanities}, 
  year={2017},
  volume={},
  number={},
  pages={4162-4174},
  abstract={Human simulation (applying Modeling and Simulation (M&S) to topics in the humanities, the interpretative social sciences, and the arts) is a potent extension of social simulation. This paper offers reflections on teaching at this intersection, presenting best practices in pedagogy for undergraduate and graduate students engaged in formal studies, and for established researchers having no structured curriculum. The fact that human simulation is possible drives home the presence of formal patterns in a host of phenomena that for a long time were thought to be inimical to mathematical analysis. That implies a double pedagogical challenge: teaching humanities students to recognize formal structures in the phenomena they study (counter-intuitive for them), and teaching M&S students to collaborate with humanities people who think very differently (equally counter-intuitive). The three perspectives presented here underline the usefulness of human simulation, as well as the difficulties and benefits associated with teaching and learning human simulation.},
  keywords={Iron;Reflection;Complexity theory;History},
  doi={10.1109/WSC.2017.8248136},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{10070941,
  author={Yao, Jianguo and Zhou, Hao and Zhang, Yalin and Li, Ying and Feng, Chuang and Chen, Shi and Chen, Jiaoyan and Wang, Yongdong and Hu, Qiaojuan},
  booktitle={2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA)}, 
  title={High Performance and Power Efficient Accelerator for Cloud Inference}, 
  year={2023},
  volume={},
  number={},
  pages={1003-1016},
  abstract={Facing the growing complexity of Deep Neural Networks (DNNs), high-performance and power-efficient AI accelerators are desired to provide effective and affordable cloud inference services. We introduce our flagship product, i.e., the Cloudblazer i20 accelerator, which integrates the innovated Deep Thinking Unit (DTU 2.0). The design is driven by requests drawn from various AI inference applications and insights learned from our previous products. With careful tradeoffs in hardware-software co-design, Cloudblazer i20 delivers impressive performance and energy efficiency while maintaining acceptable hardware costs and software complexity/flexibility. To tackle computation- and data-intensive workloads, DTU 2.0 integrates powerful vector/matrix engines and a large-capacity multi-level memory hierarchy with high bandwidth. It supports comprehensive data flow and synchronization patterns to fully exploit parallelism in computation/memory access within or among concurrent tasks. Moreover, it enables sparse data compression/decompression, data broadcasting, repeated data transfer, and kernel code prefetching to optimize bandwidth utilization and reduce data access overheads. To utilize the underlying hardware and simplify the development of customized DNNs/operators, the software stack enables automatic optimizations (such as operator fusion and data flow tuning) and provides diverse programming interfaces for developers. Lastly, the energy consumption is optimized through dynamic power integrity and efficiency management, eliminating integrity risks and energy wastes. Based on the performance requirement, developers also can assign their workloads with the entire or partial hardware resources accordingly. Evaluated with 10 representative DNN models widely adopted in various domains, Cloudblazer i20 outperforms Nvidia T4 and A10 GPUs with a geometric mean of 2.22x and 1.16x in performance and 1.04x and 1.17x in energy efficiency, respectively. The improvements demonstrate the effectiveness of Cloudblazer i20’s design that emphasizes performance, efficiency, and flexibility.},
  keywords={Full stack;Bandwidth;Programming;Hardware;Energy efficiency;Synchronization;Task analysis},
  doi={10.1109/HPCA56546.2023.10070941},
  ISSN={2378-203X},
  month={Feb},}@INPROCEEDINGS{1432316,
  author={Joongsun Yoon and Sangjoo Park and Jinyoung Kim},
  booktitle={30th Annual Conference of IEEE Industrial Electronics Society, 2004. IECON 2004}, 
  title={Emotional robotics based on iT/spl I.bar/Media}, 
  year={2004},
  volume={3},
  number={},
  pages={3148-3153 Vol. 3},
  abstract={Intelligence is thought to be related to interaction rather than a deep but passive thinking. Interactive tangible media "iTMedia" is proposed to explore these issues. Personal robotics is a major area to investigate these ideas. A new design methodology for personal and emotional robotics is proposed. Sciences of the artificial and intelligence have been investigated. A short history of artificial intelligence is presented in terms of logic, heuristics, and mobility; a science of intelligence is presented in terms of imitation and understanding; intelligence issues for robotics and intelligence measures are described. A design methodology for personal robots based on science of emotion is investigated. We investigate three different aspects of design: visceral, behavioral, and reflective. We also discuss affect and emotion in robots, robots that sense emotion, robots that induce emotion in people, and implications and ethical issues of emotional robots. Personal robotics for the elderly is investigated to explore these ideas.},
  keywords={Artificial intelligence;Intelligent robots;Robot sensing systems;Humans;Design methodology;History;Logic;Mobile robots;Mechanical engineering;Intelligent systems},
  doi={10.1109/IECON.2004.1432316},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7244619,
  author={Bachtiar, Vincent and Kerrigan, Eric C. and Moase, William H. and Manzie, Chris},
  booktitle={2015 10th Asian Control Conference (ASCC)}, 
  title={Smoothness properties of the MPC value function with respect to sampling time and prediction horizon}, 
  year={2015},
  volume={},
  number={},
  pages={1-6},
  abstract={Sampling time and the prediction horizon length are two underlying design choices for the implementation of model predictive control (MPC). Smoothness properties of the open- and closed-loop value function with respect to the two parameters are essential to characterise for the purpose of providing knowledge that is useful in the context of MPC design optimisation to maximise system performance. Specifically, these properties are continuity, differentiability and monotonicity. This paper presents both numerical and analytical results to reveal the smoothness properties of the value function. Increasing sampling rate and/or prediction horizon does not necessarily improve closed-loop performance. Furthermore, the value function in open-loop under input constraints is differentiable, which may contradict the traditional thinking and expectations.},
  keywords={Optimization;Harmonic analysis;Oscillators;Taylor series;Electronic mail;Predictive control;Context},
  doi={10.1109/ASCC.2015.7244619},
  ISSN={},
  month={May},}@ARTICLE{1637974,
  author={Arroyo, A.A.},
  journal={IEEE Instrumentation & Measurement Magazine}, 
  title={Machine intelligence grounded in reality}, 
  year={2006},
  volume={9},
  number={3},
  pages={17-23},
  abstract={The design, realization, and application of intelligent, autonomous, sensor-driven, behavior-based robotic agents are discussed. The authors have identified four philosophical goals for machine intelligence grounded in reality to flourish: integration, real-world issues, interdisciplinary teamwork, and critical thinking. Building a robot requires that the designer integrates control in electronic and mechanical systems and produces a working device, confronts the user with interactions, between different subsystems, and gives the designer the opportunity to trade off between the different subsystems in constructing an autonomous agent. The environment also encourages biomedical engineers to confront the issues involved in getting a physical agent to operate reliably in a realistic environment by giving them the opportunity to build their own animal, providing a unique perspective on the many problems that nervous systems actually solve.},
  keywords={Machine intelligence;Intelligent robots;Robot sensing systems;Intelligent agent;Intelligent sensors;Teamwork;Buildings;Control systems;Mechanical systems;Autonomous agents},
  doi={10.1109/MIM.2006.1637974},
  ISSN={1941-0123},
  month={June},}@ARTICLE{9138677,
  author={McCain, E. C. and Bastien, P. and Belmar, B. F. and Bhattacharya, B. and Cheruiyot, K. K. and Coq, M. and Dartey, R. and Deekaram, K. and Ghadai, K. and Lalima, L. D. and Nettey, J. and Owolabi, A. W. and Phillips, K. and Shiling, T. M. and Schroeder, D. T. and Slegel, C. and Steen, B. and Thorne, D. A. and Venuto, E. and Willoughby, J. D. and Yaniv, D. and Ziemis, N.},
  journal={IBM Journal of Research and Development}, 
  title={IBM Z development transformation}, 
  year={2020},
  volume={64},
  number={5/6},
  pages={14:1-14:13},
  abstract={This article discusses how the product development cycle is being transformed with “Artificial Intelligence” (AI) for the first time in zSeries history. This new era of AI, under the project name IBM Z Development Transformation (zDT), has allowed the team to grow and learn new skills in data science. This transformation forces change structurally in how data is prepared and stored. In z14, there were incremental productivity gains with enhancements to automation with eServer Automation Test Solution and a technology data analysis engine called zDataAssist. However, in z15, AI will significantly accelerate our efficiency. This article explains how Design Thinking and Agile principles were used to identify areas that are of high impact and feasible to implement: 1) what and how data is collected via System Test Event Logging and Analysis engine, Problem ticket management system (Jupitr), and Processor data analysis engine (Xrings); 2) problem identification, analysis, and management (AutoJup) along with Intelligent Recovery Verification Assistant; 3) product design documentation search engine (AskTheMachine); and 4) prototype microprocessor allocation processes Intelligent Commodity Fulfillment System using Machine Learning. This article details the approach of these areas for z15, the implementation of these solutions under the zDT project, as well as the results and future work.},
  keywords={Tools;Artificial intelligence;Automation;Engines;Databases;Hardware;Writing},
  doi={10.1147/JRD.2020.3008122},
  ISSN={0018-8646},
  month={Sep.},}@INPROCEEDINGS{9146085,
  author={Cepni, Elif},
  booktitle={2019 IEEE 18th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC)}, 
  title={The Science and Art Of Decision Making}, 
  year={2019},
  volume={},
  number={},
  pages={272-277},
  abstract={Decision makers of today routinely encounter increasingly complex and interrelated problems, preceding the necessity for a large number of significant decisions to be dynamic in nature. Frequently rather than a single decision the requirement of a number of decisions exists, conventionally being interdependent on each other in an environment of progressive change. For thousands of years people have endeavoured to document observations of the environment and surroundings, with the aspiration of comprehending situations, which in turn enable a form of anticipation or prediction of the future. Through the contributions of a range of scientists and philosophers' humanity has affected the achievement of an improved quality of life, commencement of influence on the essence of life and encouragement to attempt to gain even further knowledge through travel to other planets. Without any doubt science is exceptional and dynamic and by far the optimum means of discovering the world and all that it encompasses. What hasn't changed is the curiosity, imagination and intelligence of those doing science [1]. Despite the fact that scientific discoveries and inventions invariably enhance life to a large degree as well as being accredited with expanding the expected lifespan of humans, scientific and technological improvements may equally precipitate alienation, loss of privacy, environmental problems (chemical and electronic waste), and a greater uncertainty or a black swan event. Science is perceived to be subject about knowledge with curiosity lying at the heart of it, differing from technology in that technology is preferably explained as doing. The 19th century scientist Pierre Laplace elevated determinism to a key place in science. He linked determinism and the ability to predict to the very notion of success in science [2]. For technical decisions science is an unrivalled tool to use, however, for managerial, institutional and personal daily life decisions the same recommendation cannot be given. Numerous key systems incorporated in the life of humans exhibit diverse complexities. Markets compromised of various buyers and sellers all categorized in groups participating in mutual funds, economies with hierarchies of workers, departments, firms, and industries; multi-celled organisms consisting of proteins, membranes, organelles, cells, and organs, the internet with users, stations, servers, and websites. Each of these complex systems exhibits a distinctive property called “emergence” roughly described by a phrase “the whole is more than the sum of the actions of the parts [3]. Scientists depend on the law of rationality; however, the fact that emotion habitually dominates humans on innumerable occasions is well recognized. Perhaps a more effective method for solving the problems of humanity should include deciphering the laws of human nature. As an alternative to the law of rationality, consideration could be given to whether it is preferable for scientists use the law of bounded rationality which may entail radical paradigm shift in scientific studies. The fundamental gap between the explicit accomplishments of knowledge acquisition in the natural sciences versus the rather minimal successes in understanding the dynamics of the social realm is the inherent nonlinearity, instability, and uncertainty of behaviour consistent with social systems. However, the possibility that an alternative strategy exists to close this gap is highly feasible. This article aims at showing the justification for the discarding the rule of rationality assumption in engagement and comprehension of scientific studies, and as a substitute insert human behaviours and emotions. Our emotional self is the principal power behind our creativity and passion and constitutes humanity. Controlling the nature may be easier than controlling the human nature. Today the study of chaos, and systemic thinking (emphasis is given to complexity, networks and patterns of organization) has emerged at the forefront of natural sciences too. Disquiet exists concerning events that may lead to the destruction of our civilization even the elimination of life on Earth. In 2050 the World population will reach 9.7 billion. There is also an urgent need to introduce eco-ethical standards into science. Decision making is not merely a science; there is a requisite for creative and individuality aspects of it to be examined. In the development of technologies, the human nature, psychological and sociological impacts of these technologies must be analysed in a holistic way. The main aim of the paper is to show that decision making especially under uncertainty is partly scientific partly heuristic or artistic phenomenon. The art side of decision making shouldn't be expelled from science.},
  keywords={Uncertainty;Decision making;Standards;Mathematical model;Art;Complexity theory;complexity neuroeconomics;styling;decision-making},
  doi={10.1109/ICCICC46617.2019.9146085},
  ISSN={},
  month={July},}@INPROCEEDINGS{9028656,
  author={Shoaib, Huma and Cardella, Monica E. and Madamanchi, Aasakiran and Umulis, David},
  booktitle={2019 IEEE Frontiers in Education Conference (FIE)}, 
  title={Computation, Gender, and Engineering Identity Among Biomedical Engineering Undergraduates}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={This study explores interactions between computational thinking, gender and engineering identity among biomedical engineering undergraduate students. Biomedical engineering enjoys higher rates of women's enrollment than other engineering disciplines, but nevertheless has gender disparities in persistence within the field. Additionally, trends towards greater incorporation of computation into biomedical engineering have the potential to recreate the gender inequities seen in more computationally intensive engineering disciplines. Recently, `engineering identity' has emerged as a powerful analytic lens to understand persistence in engineering, particularly for underrepresented groups such as women. However, there is limited work examining how experiences using computational methods influences engineering identity formation in undergraduate biomedical engineers. Further, it remains unclear to what extent gender differentially mediates the effects of computational practice on engineering identity formation. In order to explore the intersection of these issues, we study a thermodynamics course in the biomedical engineering department of a large Midwestern public research institution in the United States. The thermodynamics course includes in-class computational modeling group activities and has an enrollment of more than 120, primarily sophomore year, undergraduate students. We use a qualitative study approach that includes gathering data through classroom observation and detailed semi-structured interviews. We analyze classroom observation data to try to understand student experiences of learning and participation during in-class computational modeling exercises. Specifically, we look for evidence of gendered differences in task sorting and engagement with the exercise. Classroom data is complemented by semi-structured interviews. Thematic analysis of semi-structured interviews gains student's perspectives on how gender has influenced their learning experience and their identity as engineers.},
  keywords={computation;engineering identity;gender},
  doi={10.1109/FIE43999.2019.9028656},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{7829303,
  author={John, Lawrence and John, Georganne Brier and Parker, Matthew and Sauser, Brian J. and Wade, Jon P.},
  journal={IEEE Systems Journal}, 
  title={Self-Organizing Cooperative Dynamics in Government Extended Enterprises}, 
  year={2018},
  volume={12},
  number={3},
  pages={2905-2916},
  abstract={This paper presents the results of our research into cooperation in Government Extended Enterprises, a type of system of systems. The effort proposed and evaluated a novel theory that these decisions are the result of the interaction of four canonical forces-Sympathy, Trust, Fear, and Greed. A computational simulation involving the Stag Hunt game examined information sharing decisions in a series of key decision points in three large case studies. For the five hypotheses tested, exploratory data analysis and nonparametric statistical testing show strong support for three of the hypotheses (cooperation is positively correlated with actors' levels of Sympathy and Trust and negatively correlated with actors' levels of Fear) and moderate support for the fourth (cooperation is negatively correlated with actors' levels of Greed). Indications are that the fifth hypothesis (cooperation is correlated with history of behavior) is not needed to explain observed behavior. Multiple correspondence analysis showed significant interactions both among pairs of forces and when a force is paired with decision making strategies. These results can form the basis for: 1) analysis of additional case studies; 2) development of an agent-based simulation; and 3) creation of training programs for current and future organizational leaders.},
  keywords={Government;System of systems;Ethics;Standards organizations;Data analysis;Information management;Cooperative systems;computational modeling;complex systems engineering;extended enterprise;game theory;institutional analysis;system of systems;systems thinking},
  doi={10.1109/JSYST.2016.2647598},
  ISSN={1937-9234},
  month={Sep.},}@INPROCEEDINGS{9653337,
  author={Carlos, Enríquez Ramírez and Mariza, Raluy Herrero and Sosa, Luz María Vega},
  booktitle={2021 9th International Conference in Software Engineering Research and Innovation (CONISOFT)}, 
  title={Use of Techno-Pedagogical Tools to Incorporate Remote Collaboration in a Data Structure Course}, 
  year={2021},
  volume={},
  number={},
  pages={232-237},
  abstract={Traditionally, teaching-learning activities in typical schools in most of the states in the Mexican Republic have been face-to-face interactions between students and learning facilitators, but obviously, in 2020, everything changed, so that educational videoconferencing will gain ground in the academic world. Participation in solving individual and / or group problems was adapted to a remote scheme, stimulating the use of different skills in students to face the new normal, as is the case in the development of remote programming projects for the purpose of training novice programmers to solve problems collaboratively, going through the entire global software development process. To do so, it is necessary to incorporate skills that allow them to adapt this work philosophy, which is why in this work the use of competencies that allows to detonate social and cognitive aspects in the development of software in small teams was evaluated, as well as the frequency of use. It is also important to determine if the gender has any influence on the adoption of a certain trait. For this, groups of students were trained by developing computational problems in the field of data structure.},
  keywords={Training;Teleconferencing;Technological innovation;Collaboration;Data structures;Software;Task analysis;Collaborative programming;Skills;Computational thinking},
  doi={10.1109/CONISOFT52520.2021.00039},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10020957,
  author={Gosselar, Ashley},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={A Data-Driven Approach to Reparative Description at the University of Chicago}, 
  year={2022},
  volume={},
  number={},
  pages={2532-2540},
  abstract={Reparative description of collections is a growing element of diversity, equity, and inclusion efforts at cultural heritage institutions. However, the scale and complexity of the work can be overwhelming in practice. I demonstrate that computational methodologies and data analytics can be used to kickstart the planning stage for reparative description of archival finding aids. I discuss auditing and analyzing finding aids at the University of Chicago Library’s Hanna Holborn Gray Special Collections Research Center for potentially problematic language utilizing Python, Trifacta, Tableau, and Neo4j. I describe insights gained by treating finding aids as data, and I share recommendations for structuring reparative description work in a logical and attainable way.},
  keywords={Pain;Forestry;Metadata;Big Data;Propulsion;Data science;Libraries;Computational Thinking;Data Analysis;Reparative Description;Inclusive Description;Archives;Archival Description;Archival Metadata;Finding Aids},
  doi={10.1109/BigData55660.2022.10020957},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6826147,
  author={Giordano, Daniela and Maiorana, Francesco},
  booktitle={2014 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Use of cutting edge educational tools for an initial programming course}, 
  year={2014},
  volume={},
  number={},
  pages={556-563},
  abstract={Programming skills are an important component of an engineering curriculum, not only because they enable the customization of software tools to be used in the profession, but also (and perhaps more crucially) because of the "computational thinking" and problem solving capabilities that are ideally developed by young students who learn to program for the first time. The necessity to expand the computing curriculum across a wider range of schools and university courses for students who are not majoring in Computer Science (CS) ) it is well-documented in literature [1], as is the difficulty of teaching 21st century skills (www.p21.org. This work presents an educational approach to teaching initial programming based on the development of fundamental and transversal skills and computer science skills, including creative and computational thinking as well as problem solving and critical thinking. The approach is based on cutting-edge educational tools, namely the visual programming frameworks Scratch, AppInventor, BYOB, and the well-known C/C++ language; curriculum material is drawn from CSPrinciples pilot courses, CS unplugged, school level preparation material for the International Olympiad in Informatics, and are complemented by supplementary information. The pedagogical approaches used in the course are based on constructivist learning theory, experiential learning and guided inquiry. This paper presents a year-long teaching experience in a 10th/13th grade high school with 14 to 16-year-old students. Ways to extend the experience to a university course are also presented. An initial analysis of the course results, both qualitative (based on two student surveys) and quantitative (based on formal written examinations) is presented and discussed. Results are encouraging, showing how visual programming languages help students to improve their problems solving skills and reasoning practices. Exposing the younger generation to computational concepts is fundamental in order to improve the mastering of these concepts and increase the success rate in university studies.},
  keywords={Educational institutions;Programming profession;Visualization;Problem-solving;Pedagogy;Curriculum design;Initial programming course;Visual programming frameworks},
  doi={10.1109/EDUCON.2014.6826147},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{9962737,
  author={Barman, Arko and Beckman, Leslie S. and Chebaro, Yasmin},
  booktitle={2022 IEEE Frontiers in Education Conference (FIE)}, 
  title={Interdisciplinary Computing Education: An Introductory Programming and Data Science Course for Postdoctoral Researchers in the Biosciences}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={This Innovative-Practice Full Paper presents the curriculum development of an introductory course in programming and data science for postdoctoral researchers (PDRs) in the biosciences. The use of computing software has become ubiquitous and a working knowledge of data science has become increasingly essential for researchers in all domains. However, curriculum development focusing on imparting foundational programming skills and fundamentals of data science for researchers in domains other than computing has been scarce. Thus, there is an unmet need for curriculum development involving computational thinking, programming, and the fundamentals of data science for this audience. Recognizing these growing needs and demands of researchers to learn programming and data science that can then be applied to their area of research or practice, we developed an introductory course in programming and data science for PDRs in biology and medicine. The primary goal of the course was to develop computational thinking skills in PDRs who hail from backgrounds that have traditionally not focused on inculcating computational thinking. This course covered the fundamental concepts of programming using either Python or R - languages that researchers outside the computing community use in numerous ways including the statistical analysis of large datasets that are becoming increasingly common in biomedical research. Further, PDRs enrolled in the course were introduced to some of the broad categories of problems in data science - exploratory data analysis, classification, regression, and clustering - along with relevant algorithms and how they can be applied to real-world datasets in their respective domains using packages or libraries in Python or R. We also report the feedback from the enrolled PDRs, lessons learned, and recommendations for instructors interested in designing similar curricula. Our course focusing on computing and data science education for postdoctoral scholars from a non-computing background demonstrates a promising model for incorporating computing education in other areas of study that do not traditionally have a focus on computing education as well as in continuing education.},
  keywords={Statistical analysis;Education;Curriculum development;Focusing;Data science;Software;Libraries;computer science education;interdisciplinary computing education;data science education;continuing education},
  doi={10.1109/FIE56618.2022.9962737},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{5470704,
  author={},
  booktitle={2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)}, 
  title={Workshop on parallel and distributed Computing in Finance - PDCoF}, 
  year={2010},
  volume={},
  number={},
  pages={1-2},
  abstract={Today, principles of finance are combined with advanced mathematical structures to form useful financial products, strategies and models that are tested and implemented with the use of advanced quantitative techniques. Use of computing technology is pervasive throughout this process. Quantitative and Computational Finance is an area referred to under a variety of names, for example, ‘computational finance’, ‘financial engineering’, and ‘mathematical finance’. But in all cases there is an effort that involves ‘financial’, ‘mathematical’, ‘quantitative’ and ‘computational’ thinking to build, test and implement models that are at the center of these financial activities. In the last decade Computational Finance (CF) has influenced the market place extensively with enormous impact on wealth building, employment opportunities, and tremendous economic growth. This field forms an ever-expanding part of the financial sector, in numerous ways today. The time is, therefore, ripe now to bring together researchers in the areas of finance using complicated financial models to solve computationally intensive problems and computer scientists having the resources and solution methodologies to solve such problems. The main goal of this workshop is to provide a timely forum for these two groups to exchange and disseminate new ideas, techniques, and research in computational finance. Strong discussions will follow the presentations and the experience could lead them into the formulation, implementation of the models used by the practitioners in financial sector. This workshop will be a first such effort in bringing together researchers in the areas of finance and advanced computing (i) who develop and employ parallel and distributed computing extensively (ii) at a venue where parallel, distributed, high performance computing is the fundamental thread of discussions and arguments.},
  keywords={USA Councils;Finance;Biological system modeling;Computational modeling;Australia;Conferences;Distributed computing},
  doi={10.1109/IPDPSW.2010.5470704},
  ISSN={},
  month={April},}@INPROCEEDINGS{5510833,
  author={Scorcioni, Ruggero},
  booktitle={2010 Biomedical Sciences and Engineering Conference}, 
  title={6.8: Presentation session: Neuroanatomy, neuroregeneration, and modeling: “GPGPU implementation of a synaptically optimized, anatomically accurate spiking network simulator”}, 
  year={2010},
  volume={},
  number={},
  pages={1-2},
  abstract={Simulation of biological spiking networks is becoming more relevant in understanding neuronal processes. An increasing proportion of these simulations focuses on large scale modeling efforts. Unfortunately the size of large networks is often limited by both computational power and memory. Computational power constrains both the maximum number of differential equations and the maximum number of spikes that can be processed per unit time. Memory size limits the maximum number of neurons and synapses that can be simulated. To solve for the computational bottleneck, a neuronal simulator is implemented on a CUDA-based General Purpose Graphic Processing Unit (GPGPU). CUDA provides a C-like environment to harness the computational power of specialized video cards from NVIDIA (these cards provide a computational peak power on single precision floats of 1TFLOPS, at least an order of magnitude higher than the fastest CPU). To solve for the memory bottleneck, a just-in-time synapse storing algorithm is implemented requiring only 4 bytes per synapse. Only the synaptic weight is stored, while both post-synaptic contact and delay are recomputed at run-time. This allows a resource shift from memory to computation which fits with the peculiar GPGPU architecture, where an abundance of compute nodes access the memory via a bandwidth-limited bus. Neurons are represented by a single compartment whose activity is modeled by the Izhikevich formalism. Excitatory synapses are plastic and follow both a spike-timing-dependent plasticity rule and a short term potentiation/depression rule. We are able to simulate networks with up to a million neurons and up to 100 million synapses on a single GPGPU card. Networks of this size cannot be simulated on desktop computers. For smaller networks the speedup obtained is at least of an order of magnitude compared to traditional CPU platform. As an example of possible use of the present work we present preliminary results on the simulation of early stage of the visual pathway. In the retina, Retinal Ganglion Cells (RGC) project to the Lateral Geniculate Nucleus (LGN). LGN projects to the cortical area V1. V1 projects back to LGN. The network is represented by 100,000 neurons, 10 million synapses, and 32 different morphological classes with >350 topological projections. Input to the network is provided by current injection in the RGC layer. The RGC layer models midget and parasol ganglion cells (representing 80% of the RGC in primates). Each ganglion type is then subdivided into on- and off-center cells for a total of 4 different types of RGC. Training is performed via natural stimuli while testing is done with vertical and horizontal bars. The network average spiking frequency is within biological limits. Testing performed with both vertical and horizontal bars shows each pattern propagating along the network's anatomical projections. At each stage the pattern is progressively elaborated and modified. In conclusion we present a novel simulator that is fast, synaptically optimized and anatomically accurate. At an additional cost to an available desktop PC of few hundred dollars we think the GPGPU is an ideal platform to simulate large spiking networks.},
  keywords={Computational modeling;Biological system modeling;Neurons;Biology computing;Computer networks;Central Processing Unit;Retina;Performance evaluation;Testing;Bars},
  doi={10.1109/BSEC.2010.5510833},
  ISSN={},
  month={May},}@INPROCEEDINGS{7739687,
  author={Xie, Benjamin and Abelson, Hal},
  booktitle={2016 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Skill progression in MIT app inventor}, 
  year={2016},
  volume={},
  number={},
  pages={213-217},
  abstract={This paper contributes to the growing body of research that attempts to measure online, informal learning. We analyze skill progression in MIT App Inventor, an informal online learning environment with over 5 million users and 15.9 million projects/apps created. Our objective is to understand how people learn computational thinking concepts while creating mobile applications with App Inventor. In particular, we are interested in the relationship between the progression of skill in using App Inventor functionality and in using computational thinking concepts as learners create more apps. We model skill progression along two dimensions: breadth and depth of capability. Given a sample of 10,571 random users who have each created at least 20 apps, we analyze the relationship between demonstrating domain-specific skills by using App Inventor functionality and generalizable skills by using computational thinking concepts. Our findings indicate that domain-specific and generalizable skills progress similarly; there is a common pattern of expanding breadth of capability by using new skills over the first 10 projects, then developing depth of capability by using previously introduced skills to build more sophisticated apps.},
  keywords={Trajectory;Computational modeling;Programming;Atmospheric measurements;Particle measurements;Vocabulary;Analytical models},
  doi={10.1109/VLHCC.2016.7739687},
  ISSN={1943-6106},
  month={Sep.},}@INPROCEEDINGS{1716123,
  author={Hecht-Nielsen, R.},
  booktitle={The 2006 IEEE International Joint Conference on Neural Network Proceedings}, 
  title={The Mechanism of Thought}, 
  year={2006},
  volume={},
  number={},
  pages={419-426},
  abstract={A fast winners-take-all competition process, termed confabulation, is proposed as the fundamental mechanism of all aspects of cognition (vision, hearing, planning, language, initiation of thought and movement, etc.). Multiple, contemporaneous, mutually interacting confabulations -in which millions of items of relevant knowledge are applied in parallel -are typically employed in thinking. At the beginning of such a multiconfabulation, billions of distinct, potentially viable, conclusion sets are considered. At the end, only one remains. This fast, massively parallel application of relevant knowledge (an alien kind of information processing with no analogue in today's computational intelligence, computational neurobiology, or computer science) is hypothesized to be the core explanation for the information processing effectiveness of thought. This paper presents a synopsis of this confabulation theory of human cortical and thalamic function.},
  keywords={Information processing;Cognition;Auditory system;Process planning;Application software;Computational intelligence;Analog computers;Concurrent computing;Computer science;Humans},
  doi={10.1109/IJCNN.2006.246712},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{7463799,
  author={Abidi, Leila and Cérin, Christophe and Fedak, Gilles and He, Haiwu},
  booktitle={2015 IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity)}, 
  title={Towards an Environment for Doing Data Science That Runs in Browsers}, 
  year={2015},
  volume={},
  number={},
  pages={662-667},
  abstract={This article proposes a path for doing Data Science using browsers as computing and data nodes. This novel idea is motivated by the cross-fertilized fields of desktop grid computing, data management in grids and clouds, Web technologies such as NoSQL tools, models of interactions and programming models in grids, cloud and Web technologies. We propose a methodology for the modeling, analyzing, implementation and simulation of a prototype able to run a MapReduce job in browsers. This work allows to better understand how to envision the big picture of Data Science in the context of the Javascript language for programming the middleware, the interactions between components and browsers as the operating system. We explain what types of applications may be impacted by this novel approach and, from a general point of view how a formal modeling of the interactions serves as a general guidelines for the implementation. Formal modeling in our methodology is a necessary condition but it is not sufficient. We also make round-trips between the modeling and the Javascript or used tools to enrich the interaction model that is the key point, or to put more details into the implementation. It is the first time to the best of our knowledge that Data Science is operating in the context of browsers that exchange codes and data for solving computational and data intensive programs. Computational and data intensive terms should be understand according to the context of applications that we think to be suitable for our system.},
  keywords={Browsers;Prototypes;Computational modeling;Context;Adaptation models;Servers;System design using formal modeling;Desktop grids;Data management;Web ecosystem},
  doi={10.1109/SmartCity.2015.145},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6974063,
  author={Li, Bin},
  booktitle={2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={A novel particle swarm optimization with small world network and group decision information}, 
  year={2014},
  volume={},
  number={},
  pages={1113-1120},
  abstract={Particle swarm optimization (PSO) is a daughter of artificial society and social learning. Hence, this paper excavates the ultimate source of PSO further, and then introduces the thinking of small world network and group decision information into it to obtain a new conceptual framework and algorithm variation for PSO, which is named PSO-WG. At the same time, the PSO-WG is discussed from the perspective of evolutionary computing to clarify the optimizing mechanism and improvement principles, which mainly includes the biological metaphor, implicit parallelism, operator mapping and feedback control analysis. Next, the computational model is proposed for achieve a self-contained optimization solution. Subsequently, a series of benchmark functions are tested and contrasted with the former representative algorithms to validate the feasibility and creditability of the new algorithm whose comprehensive performance is analyzed detailedly. Finally, the deficiency of PSO-WG and the working direction are pointed out clearly.},
  keywords={Birds;Sociology;Statistics;Particle swarm optimization;Optimization;Equations;Topology;particle swarm optimization;small world network;group decision information;evolutionary computing;swarm intelligence;metaphor;computational experiment},
  doi={10.1109/SMC.2014.6974063},
  ISSN={1062-922X},
  month={Oct},}@ARTICLE{9094300,
  author={Lathrop, Scott A. and Cahill, Katharine and Gordon, Steven I. and Houchins, Jennifer and Panoff, Robert M. and Weeden, Aaron},
  journal={Computing in Science & Engineering}, 
  title={Preparing a Computationally Literate Workforce}, 
  year={2020},
  volume={22},
  number={4},
  pages={7-16},
  abstract={There is a saying, “Everything changes, but nothing changes.” We are realizing a rapid technological revolution in the development, deployment, and application of computing technologies within every discipline and every sector of society. Yet, our ability to respond to the well-documented need for a large, diverse, computationally literate workforce remains a challenge. We summarize our 35 years of lessons learned for preparing the workforce that can inform efforts to address this challenge. We have pursued a multiprong approach to reach instructors, researchers, professionals, and students on a national scale. Our efforts in scaling up and sustaining activities range from teaching computational thinking through imparting HPC skills. We have been able to scale up these activities through community efforts to share, cooperate, and collaborate. The potential for providing life-long learning to everyone wishing to expand their computational knowledge and skills is greater than any organization can achieve on its own.},
  keywords={Scientific computing;Computational modeling;Computer science education;Program processors;Software tools},
  doi={10.1109/MCSE.2020.2994763},
  ISSN={1558-366X},
  month={July},}@INPROCEEDINGS{7926870,
  author={Wu, Lijun and Meng, Kun and Xu, Shuo and Li, Shuqin and Ding, Meng and Suo, Yanfeng},
  booktitle={2017 IEEE International Conference on Energy Internet (ICEI)}, 
  title={Democratic Centralism: A Hybrid Blockchain Architecture and Its Applications in Energy Internet}, 
  year={2017},
  volume={},
  number={},
  pages={176-181},
  abstract={Blockchain is attracting more and more attentions from many kinds of fields, such as finance, industry, and theory researchers. Rather than viewing blockchain as a novel technology, we should think it as an innovation for managing digital society, which provides fundamental principles to support democratically distributed applications. Based on the design and application of the Energy Internet, this paper analyzes the core architecture of the initial blockchain technology, and combines the security of the public chain with the efficiency of the private chain, solving the poor efficiency problem of the initial blockchain by using the high efficiency of private chain. At the same time, it inherits the security and non-tampering of initial blockchain. This paper designs a new hybrid blockchain storaging mode that is Block Static Storage(BSS, internal structure is N+X hybrid blockchain, following can be referred to as N+X HBC),for purpose that improving the overall efficiency of the Internet running, achieving decentralized supervision, and provoding a credible, safe and efficient performance of the Energy Internet in the storage of its massive data, as well as a huge business system.},
  keywords={Distributed databases;Internet;Peer-to-peer computing;Cryptography;Hybrid power systems;Online banking;energy internet;hybrid blockchain;decentralized data storage},
  doi={10.1109/ICEI.2017.38},
  ISSN={},
  month={April},}@INPROCEEDINGS{5384111,
  author={Goetz, S. M. and Weyh, Th. and Herzog, H.-G.},
  booktitle={2009 International Conference on Biomedical and Pharmaceutical Engineering}, 
  title={Analysis of a novel magnetic stimulation system: Magnetic harmonic multi-cycle stimulation (MHMS)}, 
  year={2009},
  volume={},
  number={},
  pages={1-6},
  abstract={Magnetic stimulation is nowadays a standard instrument in research as well as clinical applications. But available systems still have some vital problems; these include the extreme energetic ineffectiveness and the poor flexibility of stimulation properties. In the following text we analyse a new degree of freedom for stimulation devices in the time domain. This approach owes its high potential from the simplicity to implement this feature in existing commercial systems. A similar principle has already been applied for a stimulation device long time ago, but was intentionally overdamped to mimic a monophasic system and therefore energetically meaningless. For the current work, the alternative design was implemented into a sophisticated simulation model to predict its properties. A substantial benefit is for instance the feasibility to lower the threshold of the required current within the stimulation coil for creating nervous action potentials dramatically. Accordingly, the energetic impact with its even quadratic relation to the amplitude and especially the reduction of the coil heating are remarkable. The opportunity to control the nervous reaction more precisely and to gain access to the field of more complex spiking patterns is another special attribute. The realization of the concept seems reasonably simple, whereas the impact was found to be enormous. But this shall not block the view of the fact that the discovery and the explanation needs a change of thinking about the stimulating effect of inductive stimulation.},
  keywords={Harmonic analysis;Magnetic analysis;Magnetic stimulation;Coils;Predictive models;Heating;Pulse shaping methods;Skin;Voltage;Shape control;Magnetic Stimulation;Inductive Neurostimulation;TMS;Pulse Shape;Waveform},
  doi={10.1109/ICBPE.2009.5384111},
  ISSN={1947-1394},
  month={Dec},}@INPROCEEDINGS{6944860,
  author={Wu, Ying Choon and Jung, Melody and Lock, Derrick and Chao, Eric and Swartz, Jerome and Jung, Tzyy-Ping},
  booktitle={2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society}, 
  title={Resting state and task-related brain dynamics supporting insight}, 
  year={2014},
  volume={},
  number={},
  pages={5454-5457},
  abstract={Problems can be solved in a variety of ways. One might systematically evaluate a known space of possible solutions until the right one is found. Alternatively, it may prove necessary to enlarge or restructure the expected problem space - so called “thinking outside the box.” This approach can yield an experience of unexpected insight or feeling of Aha!. Current challenges to understanding this phenomenon from a neurocognitive perspective include the vast diversity of problem domains and time scales for solutions. Whereas the subjective suddenness of an “Aha!” moment may lead to the impression that insight must be precipitated by a set of discrete, short-lived neural events, this report outlines research revealing that even before a problem is presented, scalp-recorded measures of resting or baseline brain states are linked with future performance and likelihood of experiencing insight during the search for a solution. Additionally, this study also shows that compared to more systematic problem solving approaches, insight is accompanied by differences in cortical and likely cognitive engagement that are detectable throughout much of the problem solving phase, rather than being confined to a distinct interval immediately preceding the dawn of a solution. These findings are important for the development of therapies targeting problem solving and reasoning skills, such as those used in cognitive training interventions to mitigate the effects of cognitive decline.},
  keywords={},
  doi={10.1109/EMBC.2014.6944860},
  ISSN={1558-4615},
  month={Aug},}@ARTICLE{6882302,
  author={Subbu, Kalyan P. and Zhang, Chi and Luo, Jun and Vasilakos, Athanasios V.},
  journal={IEEE Wireless Communications}, 
  title={Analysis and status quo of smartphone-based indoor localization systems}, 
  year={2014},
  volume={21},
  number={4},
  pages={106-112},
  abstract={Over the past decade, indoor localization has been a topic of interest for both the academic and industrial communities. The need for location estimation, fueled mainly by inaccuracies of GPS indoors, has been addressed by specifically designed systems achieving a high localization accuracy but with a high deployment cost. Lately, dedicated systems are being replaced by smartphones through intelligent use of the built-in sensors. For instance, an accelerometer that can detect user activity can be combined with a wireless radio that captures wireless signal strength information to locate a user. With the advent of such technology, a myriad of systems have been proposed in the literature presenting an indefinite picture to a reader as to which systems actually work and which do not given practical considerations. This article takes up the goal of surveying state-of-the-art smartphone based indoor localization systems with critical analysis on their properties such as accuracies across various sensor designs, energy consumption and computational cost, user satisfaction and so on, thereby providing a status quo of such systems.},
  keywords={Smart phones;IEEE 802.11 Standards;Buildings;Indoor communcation;Fingerprint recognition;Magnetometers;Accelerometers},
  doi={10.1109/MWC.2014.6882302},
  ISSN={1558-0687},
  month={August},}@ARTICLE{10050860,
  author={Han, Binghui and Zahraoui, Younes and Mubin, Marizan and Mekhilef, Saad and Seyedmahmoudian, Mehdi and Stojcevski, Alex},
  journal={IEEE Access}, 
  title={Home Energy Management Systems: A Review of the Concept, Architecture, and Scheduling Strategies}, 
  year={2023},
  volume={11},
  number={},
  pages={19999-20025},
  abstract={Growing electricity demand, the deployment of renewable energy sources and the widespread use of smart home appliances provide new opportunities for home energy management systems (HEMSs), which can be defined as systems that improve the overall energy production and consumption of residential buildings by controlling and scheduling the use of household equipment. By saving energy, reducing residential electricity costs, optimizing the utilization rate and reliability of utility companies’ power systems, and reducing air pollution for society, HEMSs lead to an enhancement in the socioeconomic development of low-carbon economies. This review aims to systematically analyze and summarize the development trends and challenges of HEMSs in recent years. This paper reviews the development history of the HEMS architecture and discusses the characteristics of several major communication technologies in the current HEMS infrastructure. In addition, the common objectives and constraints related to scheduling optimization are classified, and several optimization methods in the literature, including various intelligent algorithms, have been introduced, compared, and critically analyzed. Furthermore, experimental studies and challenges in the real world are also summarized and recommendations are given. This paper reveals the trend from simple to complex in the architecture and functionality of HEMSs, discusses the challenges for future improvements in modeling and scheduling, and shows the development of various modeling and scheduling methods. Based on this review, researchers can gain a comprehensive understanding of current research trends in HEMSs and open up ideas for developing new modeling and scheduling approaches by gaining insight into the trade-offs between optimum solutions and computational complexity.},
  keywords={Optimization;Energy management systems;Home appliances;Renewable energy sources;Market research;Reliability;Optimal scheduling;Demand response;home appliances;home energy management system;optimization;renewable energy resources;smart grid},
  doi={10.1109/ACCESS.2023.3248502},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7145764,
  author={Adeel, Ahsan and Larijani, Hadi and Javed, Abbas and Ahmadinia, Ali},
  booktitle={2015 IEEE 81st Vehicular Technology Conference (VTC Spring)}, 
  title={Critical Analysis of Learning Algorithms in Random Neural Network Based Cognitive Engine for LTE Systems}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={In this paper, we critically analyze the performance of an intelligent Long-Term Evolution-Uplink (LTE-UL) system having a cognitive engine (CE) embedded in e-NodeB. Performance characterization, optimal radio parameters prediction, and inter-cell-interference coordination (ICIC) are studied. The embedded CE allocates the optimal radio parameters to serving users and suggests the acceptable transmit power to users served by adjacent cells for ICIC. The desired cognition has been achieved with a novel random neural network (RNN) based CE architecture. To achieve the best learning performance, we critically analyzed three learning algorithms, gradient descent (GD), adaptive inertia weight particle swarm optimization (AIW-PSO) and differential evolution (DE). The analysis showed that AIW-PSO was 10.57% better than GD and 8.012% better than DE in terms of learning accuracy (based on MSE), but with considerable compromise on computational time as compared to GD. Moreover, in terms of convergence time (to achieve the MSE less than 1.04E-03), AIW-PSO took 60% less iterations than GD and 50% less than DE.},
  keywords={Training;Artificial intelligence;Neurons;Decision making;Mathematical model;Cognitive radio;Neural networks},
  doi={10.1109/VTCSpring.2015.7145764},
  ISSN={1550-2252},
  month={May},}@INPROCEEDINGS{7883513,
  author={Liu, Xiaotong and Xu, Anbang and Gou, Liang and Liu, Haibin and Akkiraju, Rama and Shen, Han-Wei},
  booktitle={2016 IEEE Conference on Visual Analytics Science and Technology (VAST)}, 
  title={SocialBrands: Visual analysis of public perceptions of brands on social media}, 
  year={2016},
  volume={},
  number={},
  pages={71-80},
  abstract={Public perceptions of a brand is critical to its performance. While social media has demonstrated a huge potential to shape public perceptions of brands, existing tools are not intuitive and explanatory for domain users to use as they fail to provide a comprehensive analysis framework for perceptions of brands. In this paper, we present SocialBrands, a novel visual analysis tool for brand managers to understand public perceptions of brands on social media. Social-Brands leverages brand personality framework in marketing literature and social computing approaches to compute the personality of brands from three driving factors (user imagery, employee imagery, and official announcement) on social media, and construct an evidence network explaining the association between brand personality and driving factors. These computational results are then integrated with new interactive visualizations to help brand managers understand personality traits and their driving factors. We demonstrate the usefulness and effectiveness of SocialBrands through a series of user studies with brand managers in an enterprise context. Design lessons are also derived from our studies.},
  keywords={Data visualization;Electronic mail;Companies;Twitter;Visual analytics},
  doi={10.1109/VAST.2016.7883513},
  ISSN={},
  month={Oct},}@ARTICLE{976436,
  author={Mishra, B.},
  journal={Computing in Science & Engineering}, 
  title={Comparing gnomes}, 
  year={2002},
  volume={4},
  number={1},
  pages={42-49},
  abstract={The theory behind biocomputing is to look to biological structures and processes for new ways of solving difficult computational problems. But this, need not, be a one-way street: advances in computing can feed back into the study of biology, leading to better biotechnological tools.},
  keywords={Genomics;Bioinformatics;Biology computing;Neoplasms;Quantum computing;Cancer;Biological materials;Laboratories;Springs;Genetics},
  doi={10.1109/5992.976436},
  ISSN={1558-366X},
  month={Jan},}@INPROCEEDINGS{8890176,
  author={Alfieri, L. and Bracale, A. and Varilone, P. and Leonowicz, Z. and Kostyla, P. and Sikorski, T. and Wasowski, M.},
  booktitle={2019 International Conference on Clean Electrical Power (ICCEP)}, 
  title={Methods for Assessment of Supraharmonics in Power Systems. Part I: Theoretical Issues}, 
  year={2019},
  volume={},
  number={},
  pages={110-115},
  abstract={Modern Smart Grids (SGs) are characterized by the simultaneous presence of time-varying and non-linear loads as well as distributed energy sources with power converters which contribute to wide spectra waveform distortions. Moreover, one of the crucial device of the SG architectures is the smart metering systems which utilize high frequencies for the power line communication (PLC) transmission. In particular, the presence of spectral components in the range of 2÷ 150kHz (supraharmonics) has recently become an issue of great interest due to the interaction between widespread diffusion of high-spectral emission devices (e.g., end-user devices and converter-interfaced distributed generation systems) and power line communication systems. The complexity of these waveforms distortions makes their assessment a challenge. This paper critically analyses and compares two methods proposed in recent literature which seem particularly suitable for the spectral analysis of waveforms with wide spectra. One of the methods is based on the sliding-window discrete Fourier transform (SWDFT) referring to IEC standard harmonic estimation. The second method utilizes the sliding-window wavelet-modified ESPRIT-based method (SWWMEM). This is a companion document to a paper of the same title, Part II, where the methods are tested on synthetic and measured waveforms in terms of accuracy and computational efforts.},
  keywords={Microsoft Windows;Distortion;Time-frequency analysis;Spectral analysis;IEC Standards;Discrete Fourier transforms;Discrete wavelet transforms;Power Quality;high-frequency distortions;Wavelet decomposition;ESPRIT method;IEC standard;power line communication},
  doi={10.1109/ICCEP.2019.8890176},
  ISSN={2474-9664},
  month={July},}@ARTICLE{10538326,
  author={Tan, Qian and Li, Hongxiu},
  journal={IEEE Access}, 
  title={Application of Computer Aided Design in Product Innovation and Development: Practical Examination on Taking the Industrial Design Process}, 
  year={2024},
  volume={12},
  number={},
  pages={85622-85634},
  abstract={The intersection of computer science and art has sparked a wave of innovation, particularly in digital visualizations and interactive installations. This abstract explores the symbiotic relationship between these disciplines, highlighting groundbreaking advancements and creative endeavors. Innovations in digital visualizations leverage algorithms and computational techniques to transform data into visually engaging representations. From intricate data sculptures to immersive virtual reality experiences, computer scientists and artists collaborate to push the boundaries of storytelling and communication. These visualizations not only convey complex information effectively but also evoke emotional responses, bridging the gap between technology and human perception. Interactive installations blur the lines between audience and artwork, inviting participation and engagement. Through sensors, augmented reality, and responsive environments, users become active participants in the creation of art, shaping and influencing their experiences in real-time. This dynamic interaction fosters new forms of expression and challenges traditional notions of artistic production. By exploring the intersection of computer science and art, this abstract underscores the transformative power of interdisciplinary collaboration. Through experimentation, exploration, and innovation, digital visualizations and interactive installations continue to redefine the possibilities of creative expression in the digital age.},
  keywords={Design automation;Solid modeling;Industries;Three-dimensional printing;Product development;Collaboration;Design automation;Optimization methods;Computer science;art;digital visualizations;interactive installations;innovation},
  doi={10.1109/ACCESS.2024.3404963},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{6076415,
  author={Xhafa, Fatos and Poulovassilis, Alex},
  booktitle={2011 International Conference on Emerging Intelligent Data and Web Technologies}, 
  title={Awareness in P2P Groupware Systems: A Convergence of Contextual Computing, Social Media and Semantic Web}, 
  year={2011},
  volume={},
  number={},
  pages={14-21},
  abstract={P2P systems are currently considered as an important and effective alternative to web-based centric approaches of groupware systems. Decentralisation, direct and interactive communication, personalization and context are among the features of P2P systems that could be beneficial to groupware systems. In particular, such features can support monitoring, awareness, social networking and scaffolding in group collaboration. In this work we present an analysis of advantages in using P2P networks to better support group collaborative processes. In our analysis, P2P groupware systems are conceived as a convergence of several views: contextual computing, social media and semantic web. The contextual computing is an important ingredient to capture the context of the collaboration in a multi-dimension way, including workspace context, documents and information context, time and location contexts, etc. The social media is also considered important for an effective collaboration of peer group, to support members with efficient and scalable communication techniques in social interaction among members. The semantic web concepts and use of languages such as RDF/S enable the representation and reasoning with the diverse range of information required by the P2P middleware and the awareness services. We focus in particular how to achieve event-based awareness in P2P groupware systems that includes different forms of awareness. The user and technical requirements are first derived with reference to Project-Based Learning in P2P learning environments, which is the learning setting that we consider in our work. We then present our computational model for supporting group awareness in such environments and discuss how it meets the identified user and technical requirements.},
  keywords={Collaborative work;Context;Collaborative software;Peer to peer computing;Resource description framework;Availability;P2P systems;Social Networking;Awareness;Distributed Event-Processing;Event-Condition-Action rules;RDF;Project-Based Learning;Scenario-Based Learning;Collaboration},
  doi={10.1109/EIDWT.2011.42},
  ISSN={},
  month={Sep.},}@ARTICLE{4589066,
  author={Rover, Diane T. and Mercado, Ramon A. and Zhang, Zhao and Shelley, Mack C. and Helvick, Daniel S.},
  journal={IEEE Transactions on Education}, 
  title={Reflections on Teaching and Learning in an Advanced Undergraduate Course in Embedded Systems}, 
  year={2008},
  volume={51},
  number={3},
  pages={400-412},
  abstract={An integrated series of courses on embedded systems has been developed at Iowa State University, Ames, spanning early undergraduate to graduate levels. The newest course in the series is CPRE 488: Embedded Systems Design, an advanced undergraduate course that fills a gap in the curriculum by providing system-level design experiences and incorporating new technology advancements. CPRE 488 development focused on lecture-lab integration and laboratory learning. Course and lab activities were designed using a learning model that captures lower-order and higher-order cognition levels of Bloom's taxonomy. The learning experience in the laboratory is characterized using a technique to assess cognitive behavior. Results of applying the Florida Taxonomy of Cognitive Behavior are presented to summarize the depth of student learning and the opportunities for students to progress to higher-order thinking in the laboratory. After two years of experience with the new course, the authors reflect on the course design and outcomes, from both disciplinary and pedagogical viewpoints.},
  keywords={Laboratories;Education;Hardware;Embedded system;Computers;Software;Computational modeling;Cognitive behavior;curriculum integration;embedded computer systems},
  doi={10.1109/TE.2008.921792},
  ISSN={1557-9638},
  month={Aug},}@INPROCEEDINGS{7980111,
  author={Singh, Munindar P. and Chopra, Amit K.},
  booktitle={2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={The Internet of Things and Multiagent Systems: Decentralized Intelligence in Distributed Computing}, 
  year={2017},
  volume={},
  number={},
  pages={1738-1747},
  abstract={Traditionally, distributed computing concentrates on computation understood at the level of information exchange and sets aside human and organizational concerns as largely to be handled in an ad hoc manner. Increasingly, however, distributed applications involve multiple loci of autonomy. Research in multiagent systems (MAS) addresses autonomy by drawing on concepts and techniques from artificial intelligence. However, MAS research generally lacks an adequate understanding of modern distributed computing. In this Blue Sky paper, we envision decentralized multiagent systems as a way to place decentralized intelligence in distributed computing, specifically, by supporting computation at the level of social meanings. We motivate our proposals for research in the context of the Internet of Things (IoT), which has become a major thrust in distributed computing. From the IoT's representative applications, we abstract out the major challenges of relevance to decentralized intelligence. These include the heterogeneity of IoT components; asynchronous and delay-tolerant communication and decoupled enactment; and multiple stakeholders with subtle requirements for governance, incorporating resource usage, cooperation, and privacy. The IoT yields high-impact problems that require solutions that go beyond traditional ways of thinking. We conclude with highlights of some possible research directions in decentralized MAS, including programming models; interaction-oriented software engineering; and what we term enlightened governance.},
  keywords={Distributed computing;Monitoring;Medical services;Temperature sensors;Multi-agent systems;Computational modeling;Governance;Multiagent systems;Decentralization;Sociotechnical systems;Norms},
  doi={10.1109/ICDCS.2017.304},
  ISSN={1063-6927},
  month={June},}@INPROCEEDINGS{7575888,
  author={Al-Ruithe, Majid and Benkhelifa, Elhadj and Hameed, Khawar},
  booktitle={2016 IEEE 4th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={Key Dimensions for Cloud Data Governance}, 
  year={2016},
  volume={},
  number={},
  pages={379-386},
  abstract={Forward thinking organizations recognize that data management solutions on their own are becoming very expensive and failing cope with reality. They need to solve the data problem in a different way, through the implementation of an effective Data Governance. Data Governance needs to take a policy-centric approach to data models, data quality standards, data security and lifecycle management, and processes for defining, implementing and enforcing these policies. Until recently, data governance has largely been informal, in siloes around specific enterprise repositories, lacking structure and the wider support of the organization. In many government departments, data governance exists as a set of very ambiguous and generic regulations. The area of data governance is still under-researched, despite its importance. With the emergence of Cloud computing, and its increased adoption by businesses, public organisations and governments, as much as the potential gains from adopting the technology, businesses face new and more complex challenges. Such emphasize the need for effective data governance strategy and programs, which can ensure best returns for cloud adoption. This paper is one of very few published research, which tackles this subject domain, and attempts to lay its foundations.},
  keywords={Cloud computing;Security;Organizations;Computational modeling;Data models;Law;Data Governance;Cloud Computing;E-Government;Adoption;Data Management},
  doi={10.1109/FiCloud.2016.60},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9350788,
  author={Chen, Yini and Hou, Jun and Li, Qianmu and Long, Huaqiu},
  booktitle={2020 IEEE International Conference on Progress in Informatics and Computing (PIC)}, 
  title={DDoS Attack Detection Based on Random Forest}, 
  year={2020},
  volume={},
  number={},
  pages={328-334},
  abstract={With the development of network technology, distributed denial of service (DDoS) attacks have increasingly become an important security risk that endangers the network. It uses common protocols and services when attacking, so it is difficult to detect through traditional methods. Based on the idea of rational thinking, DDoS attack detection can be simulated as a classification problem that distinguishes between "rational" and "irrational" network flow states. This article analyzes the common TCP flood attacks, UDP flood attacks, and ICMP flood attacks in detail. Define the characteristics of data stream information entropy (DSIE) to characterize attack behavior. A DDoS attack detection method based on random forest classification (RFC) model is proposed. Establish classification models for the above three types of typical attack methods. Through training and learning, it is finally predicted whether the network traffic is normal. Experimental results show that the RFC model can more accurately distinguish between normal traffic and attack traffic, with a higher detection rate and a lower false alarm rate.},
  keywords={Computational modeling;Hidden Markov models;Denial-of-service attack;Floods;Computer crime;Information entropy;Random forests;DDoS attack;random forest classification;attack detection},
  doi={10.1109/PIC50277.2020.9350788},
  ISSN={2329-6259},
  month={Dec},}@INPROCEEDINGS{1174599,
  author={Mendonca, D. and Beroggi, G.E.G. and Wallace, W.A.},
  booktitle={36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the}, 
  title={Evaluating support for improvisation in simulated emergency scenarios}, 
  year={2003},
  volume={},
  number={},
  pages={9 pp.-},
  abstract={Technological systems involving hazards are typically managed by experienced personnel guided by well-formulated, pre-determined procedures. These procedures are designed to ensure that operations proceed in a safe and cost-effective manner. Yet normal operations in these systems are exposed to unexpected contingencies that can require personnel to develop and deploy new procedures in real-time. Creative thinking in such situations is therefore necessary in order to prevent degradation of operations, particularly when there is potential for personal injury, economic loss or environmental damage. One approach to addressing these situations is improvisation. The research described here discusses a series of studies conducted to evaluate the efficacy of a computer-based system for supporting improvisation in simulated crisis situations. The design and implementation of the system are first discussed, drawing upon prior work in blackboard-based systems. The experimental design is then reviewed, followed by a discussion of how the studies were run using groups of emergency response personnel from the Port of Rotterdam in The Netherlands. The group task was to address unexpected contingencies in a timely fashion. A number of measures of group decision effectiveness and uniqueness are presented. Results of the studies suggest that availability of decision support may have had an uneven influence on solution effectiveness and no influence on solution uniqueness. Possible implications for the design of group decision support systems for improvisation are then discussed, along with a number of observations on conducting experimentally-based research on group improvisation.},
  keywords={Personnel;Hazards;Disaster management;Technology management;Real time systems;Degradation;Injuries;Environmental economics;Computational modeling;Computer simulation},
  doi={10.1109/HICSS.2003.1174599},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9497216,
  author={Lim, Thian Li and Lee, Angela Siew Hoong},
  booktitle={2021 International Conference on Computer & Information Sciences (ICCOINS)}, 
  title={Extended TAM and TTF Model: A Framework for the 21st Century Teaching and Learning}, 
  year={2021},
  volume={},
  number={},
  pages={339-334},
  abstract={The use of Information and Communication Technology (ICT) in everyday life of an individual has expanded in recent years. The much-needed skills for 21st century are creativity, able to think critically, communication and collaboration skills. By equipping students with these skills, it will able to prepare students for the challenges in life and work environments in 21st century. The advancement of technology has led to e-learning in education. E-learning refers to online learning, which provides students with a virtual environment in which students engage in several activities. However, even with the increasingly utilise of e-learning platform, research has proven that the issues of students were not fully utilise the functions of e-learning platforms in their learning process still exist. It is just act as a supporting tool for them and lack of communication support provided by learning management system (LMS) has leads to using other platform for communication purposes. Pervasive tools in education such as mobile devices, wearable technology, and RFID has proven to have positive impact on student learning outcome, however its application in higher education settings is still relatively little. Hence with the limitations of current teaching practice with limitations of study focusing on utilizing pervasive tools, therefore the aim of this study is to investigate the important factors which affect the user behaviour of IT devices (pervasive tools). To achieve this, theories of technology acceptance model (TAM) and task technology fit (TTF) was used. Along with TAM and TTF characteristics, factors of enjoyment, usefulness, convenience, compatibility, social influence, computer self-efficacy, and mobility were also considered. This study provides a framework to better understand the factors affect the acceptance of pervasive tools in private universities in Malaysia.},
  keywords={Electronic learning;Technology acceptance model;Computational modeling;Education;Virtual environments;Tools;Mobile handsets;21st century learners;e-learning;pervasive tools;technology acceptance model;task technology fit},
  doi={10.1109/ICCOINS49721.2021.9497216},
  ISSN={},
  month={July},}@ARTICLE{5680622,
  author={Chang, Shu-Hsuan and Chen, Mei-Ling and Kuo, Yen-Kuang and Shen, Yung-Chi},
  journal={IEEE Transactions on Education}, 
  title={A Simulation-Based LED Design Project in Photonics Instruction Based on Industry–University Collaboration}, 
  year={2011},
  volume={54},
  number={4},
  pages={582-589},
  abstract={In response to the growing industrial demand for light-emitting diode (LED) design professionals, based on industry-university collaboration in Taiwan, this paper develops a novel instructional approach: a simulation-based learning course with peer assessment to develop students' professional skills in LED design as required by industry as well as to enhance cognition and metacognition in students in higher education. The simulation-based learning course enables students to understand the influences on LED performance of the variation of different parameters and to seek the best design through comparing the effectiveness of different combinations of parameters. The evaluation results of pre- and post-test knowledge maps and a photonics scoreboard indicate that this project-based instruction may help students understand the operating principles of LEDs and enhance their skill in LED design. The Constructivist Project-based Learning Environment Survey is adopted to demonstrate that the proposed project-based learning environment is beneficial in cultivating student inquiry learning, reflective thinking, teamwork, and skills in creative problem solving.},
  keywords={Light emitting diodes;Education;Photonics;Computational modeling;Physics;Software;Teamwork;Light-emitting diode (LED);peer assessment (PA);project-based learning (PBL);simulation-based learning (SBL)},
  doi={10.1109/TE.2010.2098877},
  ISSN={1557-9638},
  month={Nov},}@INPROCEEDINGS{7016358,
  author={Jacobs, Patricia and List, Phillip and Ludin, Mobeen and Weeden, Aaron and Panoff, Robert M.},
  booktitle={2014 Workshop on Education for High Performance Computing}, 
  title={The Blue Waters Student Internship Program: Promoting Competence and Confidence for Next Generation Researchers in High-Performance Computing}, 
  year={2014},
  volume={},
  number={},
  pages={49-55},
  abstract={The Blue Waters Student Internship Program (BWSIP), a year-long program funded for three years by the National Science Foundation, motivates and trains the next generation of supercomputing researchers. A community engagement partnership of the Blue Waters Petascale Computing Facility at the National Center for Supercomputing Applications (NCSA) and Shodor, the BWSIP has developed, demonstrated, and evaluated novel lessons involving hands-on, interactive, and collaborative methodologies to teach parallel and distributed computing (PDC) and high-performance computing (HPC) topics. Students participating in the program gain experience in the application of highperformance computing to real-world problems in science, mathematics, and engineering through a year-long internship. By engaging undergraduate and graduate students in Petascale computing research and development projects, students build confidence and competence in PDC and HPC.The BWSIP recruited a large and diverse applicant pool from across the US from which 21 research interns reflecting that diversity were selected and each matched with a mentor and a project for the year-long internship. Students, many having only introductory programming experience, began their internship by attending the two-week Petascale Institute -- each day including 6.5 hours of directed, inquiry-based learning and 2 hours of open lab using the run-modify-write paradigm -- during which they were trained in PDC and HPC tools, techniques, and technologies using Blue Waters at NCSA, and by analogy other XSEDE HPC resources. Students then continued working all summer on their home campuses, or were hosted by their mentor, with on-going work expected to be continued during both Fall and Spring semesters.The project engaged an external evaluator to conduct formative and summative assessments of the program. BWSIP Interns participated in pre- and post-surveys, daily reflections/evaluation questions, as well as in a focus group during their training. Even with significant differences in background, knowledge, and with varying projects, participants stated that the two-week institute was an essential element to help them learn conceptual thinking and how to program using parallel computing. It is proposed that the curriculum and approach for the Institute could be adapted for a semester course at the undergraduate or graduate level.},
  keywords={Training;Supercomputers;Collaboration;Conferences;Computational modeling;Communities;Petascale education; Interactive; Templates; Inquiry-based Learning; Experience; Evaluation; Curriculum; Pedagogy; Parallel Computing; High-Performance Computing; Distributed Computing; Supercomputing; Programming},
  doi={10.1109/EduHPC.2014.6},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{5380345,
  author={Yu, Zhiyong and Yu, Zhiwen and Zhou, Xingshe and Nakamura, Yuichi},
  booktitle={2009 Eighth IEEE International Conference on Dependable, Autonomic and Secure Computing}, 
  title={Toward an Understanding of User-Defined Conditional Preferences}, 
  year={2009},
  volume={},
  number={},
  pages={203-208},
  abstract={User-defined preferences in a natural style is useful in the pervasive computing environment, but bring a great challenge to understand. People often express conditional as well as independent preferences. We propose an ontology-based quantitative model for conditional preferences that aims to enhance the inference capacity of conditional preference statements and thus reduce users' workload. Different interpretations of the statements of our model are depicted and compared, including the inheritance property of the concept hierarchy in ontology, the connotation of sufficient and necessary conditions, and the bipolar property of preferences in human thinking. An experiment in the trip domain is conducted and shows the feasibility of our conditional preference model.},
  keywords={Pervasive computing;Ontologies;Humans;Computational intelligence;Context awareness;Inference algorithms;Computer science;Recommender systems;Transportation;Costs;Conditional preferences;Preference model;Preference acquisition;Ontology},
  doi={10.1109/DASC.2009.52},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9793458,
  author={Terlapu, Panduranga Vital and Yugandhar, M. and Ramesh, B. and Kumar, B. Vijay and Pemula, Rambabu},
  booktitle={2022 International Conference on Computing, Communication and Power Technology (IC3P)}, 
  title={Student Cognitive Learning Capability (SCLC) Prediction System using PCA-ANN based Model}, 
  year={2022},
  volume={},
  number={},
  pages={11-18},
  abstract={Educational institutions and education system play the important role in any society or country for development in all aspects like agriculture, industrial, economic and political. Teaching methodologies, learning preferences and techniques, socio-economics decide the student learning capabilities. Cognitive Learning (CL) is a kind of learning that is constructive, active, durable, and productive. It employs educates in the learning measures, encouraging them to think effectively to make connections when learning new things. In this paper, we want to demonstrate the student learning capabilities using their cognitive abilities. For this, we demeanor training and examines on different cognitive abilities and also collect the personal and other factors which impact student learning. In this process, we conduct training and examine the 313 engineering educates from AITAM Eng. College, A.P., India. We apply the Principal Component Analysis (PCA) algorithm for feature selection, and for prediction, use the ANN with back-propagation algorithm. The Artificial Neural Network (ANN) model is constructed, as that the hidden layer of ANN neurons initially is two, after that we increment the neurons by one until reach good accurate results. The 5-neurons HL ANN is performed well as per performance parameters like accuracy (100%), AUC (1), R-value (1), recall, and precisions values.},
  keywords={Training;Industrial economics;Computational modeling;Neurons;Artificial neural networks;Predictive models;Prediction algorithms;Education;Machine Learning;Cognitive Learning;Student Learning Capability;ANN;PCA},
  doi={10.1109/IC3P52835.2022.00013},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9982358,
  author={Figueiredo, José and García-Peñalvo, Francisco José},
  booktitle={2022 International Symposium on Computers in Education (SIIE)}, 
  title={Strategies to increase success in learning programming}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Programming is a special activity, which requires very special skills. Creativity, problem solving, persistence, collaboration, communication, critical thinking, commitment, dedication and hard work are some of the skills and characteristics required of those who learn programming. They are also essential characteristics to face all the challenges of the 21st century. Learning programming is a good way to practice and develop these skills. That is why most courses, in the most diverse areas of knowledge, include programming in their curricula. However, programming courses have a bad reputation. These courses have high failure and dropout rates. It is recognized by the whole scientific community in the area that there are problems and difficulties in teaching and learning programming. With this work we want to present our set of strategies and results in the improvement of our system of teaching and learning initial programming, and with that also contribute to the development and resolution of the problem. In this work, we describe a set of activities related to the initial learning of programming with good results. We present the results of the application of a machine-learning model for predicting student failure, with excellent accuracy and precision results. Finally, we argue the improvements in our teaching system and initial learning of programming, with the final results of the course of the last 5 years.},
  keywords={Analytical models;Technological innovation;Computational modeling;Education;Neural networks;Machine learning;Programming;CSO;CS1;programming;teaching programming;learning programming;machine learning},
  doi={10.1109/SIIE56031.2022.9982358},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{5280074,
  author={Kaufman, David and Ireland, Alice and Sauve, Louise},
  booktitle={2009 Fourth International Multi-Conference on Computing in the Global Information Technology}, 
  title={A Collaborative, Online, Problem-Based Simulation Platform (COMPSoft) for Medical Education}, 
  year={2009},
  volume={},
  number={},
  pages={186-191},
  abstract={In this project, we transferred Problem-Based Learning (PBL), a well-known pedagogy for medical education, to an online environment by transforming it into a simulation where students could practice their skills collaboratively in a risk-free setting. This paper describes the design of a conceptual model and development of a software platform to allow learners to collaborate online in discussing PBL cases. Early testing has been extremely promising, largely due to the extensive work done earlier to build the ENJEUX-S online game platform. Thanks to this work, it has been possible to extend this platform from online games to online simulations. Our first test of the PBL model with undergraduate students was successful in facilitating their critical thinking and was well-received. We are now planning to use COMPSoft in medical schools and to conduct comprehensive evaluation studies of both the model and the platform.},
  keywords={Online Communities/Technical Collaboration;Medical simulation;Collaborative work;Education;International collaboration;Collaborative software;Testing;Medical services;Information technology;Computational modeling;problem-based learning;PBL;COMPsoft;online platform;medical education;simulation;online education},
  doi={10.1109/ICCGI.2009.52},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8190661,
  author={Tabrizi, Nozar},
  booktitle={2017 IEEE Frontiers in Education Conference (FIE)}, 
  title={Fostering an entrepreneurial mindset in “digital systems” class through a jigsaw-puzzle model}, 
  year={2017},
  volume={},
  number={},
  pages={1-8},
  abstract={In this paper we introduce a jigsaw-puzzle model to instill an entrepreneurial mindset in students. We then use our model to craft and add innovative lab assignments to “Digital Systems”, which is a core course taken by Electrical Engineering, Computer Engineering and Computer Science students worldwide. In each lab assignment, students are provided with some components or puzzle pieces as well as the user guide of a digital system, and possibly some reading materials to better understand the operation theory of the system. One selling point of our model is its significant flexibility, so that the game may be played in different ways. Here is one example: students go over the user guide and the reading materials to get a solid understating of the underlying digital system. To comprehend what they have available, students also study the puzzle pieces. Then students challenge themselves to complete the puzzle and eventually build the digital system physically and test it. The resulting system is supposed to function in accordance with its user guide. Our work is an attempt to fulfill the Kern Entrepreneurial Engineering Network (KEEN) Students Outcomes. The anonymous survey from the students is encouraging and shows that our work is able to excite students' curiosity, provide them with an opportunity to apply creative thinking, and instill in students a feeling of value creation among other things.},
  keywords={Digital systems;Entrepreneurship;Libraries;Adders;Computational modeling;Field programmable gate arrays;Digital circuits;Digital systems;entrepreneurial mindset;FPGA;innovation in education;jigsaw-puzzle model;KEEN;VHDL},
  doi={10.1109/FIE.2017.8190661},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10448961,
  author={Yang, Qianyi and Zhou, Jing},
  booktitle={2023 IEEE Smart World Congress (SWC)}, 
  title={Incorporating Time Perspectives into Detection of Suicidal Ideation}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={As a vital risk to the public heath, suicide has been a hot topic for related research. Time perspectives (TPs) have attracted increasing attention in recent years in that making use of TPs can help gain insights into the real motives behind suicide ideation. TPs take into consideration how people think of or appraise their past, present, or future life would shape their behavior. Conventional TP-oriented studies on suicide tendency detection tend to rely on questionnaire surveys to help identify suicide thoughts or attempts. Such efforts suffer from weaknesses including low data collection efficiency and self-report bias. We proposed a TP-enhanced deep multitask model, TP-GloVe-GRU, in which TP is regarded as the synergy of both time and emotions. The model performance was evaluated against the CEASE dataset using a range of metrics. Results show that incorporating TP into the detection of suicide ideation leads to a better performance in most cases with an increase of 2.27% in the accuracy of suicide risk assessment.},
  keywords={Surveys;Shape;Computational modeling;Text categorization;Moon;Multitasking;Risk management;suicide note;time perspective;GRU;GloVe},
  doi={10.1109/SWC57546.2023.10448961},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8442008,
  author={Abu Hadba, Safa'a Yousef and Nafea, Ibtehal},
  booktitle={2018 1st International Conference on Computer Applications & Information Security (ICCAIS)}, 
  title={An Intelligent Agent Model and a Simulation for a Given Task in a Specific Environment}, 
  year={2018},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper presents An Intelligent Agent Model for a Given Task in a Specified Environment. The methodology in this work is based on mixing algorithmic and function approaches to construct the intelligent agent model. The paper concentrates on building an intelligent agent model as a knowledge-based system interacting with dynamic environment to perform tasks. The class structure used to represent the environment in the knowledge base depends on three types of knowledge representation forms: production rule, semantic net, and frames. Each object in the environment is an instance of the class environment. Algorithms and functions are used for gaining knowledge from the state space of environment to build the task. The intelligent agent model can understand the environment from any position and can detect many subtasks, arrange them in a queue for execution, and has the ability to make a decision at a high level of thinking. The intelligent agent model is able to calculate the persistent changes in the external dynamic environment and any sudden change, such as observing the existence of any obstacle in the environment and avoiding it. The intelligent agent is also able to learn and take the reasonable decision in the dynamic environment and automatically select action based on task characteristics. Therefore, the intelligent agent can solve many different types of problems.},
  keywords={Intelligent agents;Task analysis;Knowledge based systems;Search problems;Engines;User interfaces;Computational modeling;Intelligent agent;dynamic environment;performance},
  doi={10.1109/CAIS.2018.8442008},
  ISSN={},
  month={April},}@INPROCEEDINGS{6997634,
  author={Sui, Tingting and Wang, Xiaofeng},
  booktitle={2014 International Conference on Multisensor Fusion and Information Integration for Intelligent Systems (MFI)}, 
  title={A concept acquisition method based on visual perception}, 
  year={2014},
  volume={},
  number={},
  pages={1-8},
  abstract={In a physicalist theory of mind, a concept is a mental representation, which the brain uses to denote a class of things in the world. They can help us classify newly encountered objects on the basis of our past experiences. But how can we get the concepts? As visual information account for about 80% of total perceptual information, this paper proposes a concept acquisition method based on visual cognition. Firstly, we give a new definition of concept based on the classic views. Then, we imitate the process of visual cognition to get the approximate locations of the salient proto-objects. By using the improved cerebral cortex learning algorithm, the concepts of the objects can be acquired. However, the whole model also has top-down process. The concepts learned in turn affect the former saliency-based region selection method. We demonstrate that the suggested method can not only yield dynamic and phase-smooth concepts, but also recognize objects with good precise. Our findings will facilitate further studies on human thinking.},
  keywords={Visualization;Image color analysis;Prototypes;Brain modeling;Cognition;Educational institutions;Computational modeling;Concept;Object recognition;Visual perception;Cognition},
  doi={10.1109/MFI.2014.6997634},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10158192,
  author={Wang, Ren},
  booktitle={2023 Asia-Europe Conference on Electronics, Data Processing and Informatics (ACEDPI)}, 
  title={Research on Intelligent Control System of Landscape Ecology Based on Computer Virtual Reality Technology}, 
  year={2023},
  volume={},
  number={},
  pages={531-538},
  abstract={The application of virtual reality technology for landscape planning and design, designers will have a more intuitive and interactive space experience, but also better reflect the authenticity of the landscape scene, so as to help designers constantly improve the design scheme. In addition, through the virtual reality system, the audience can watch the scheme design from multiple angles, which not only deepens the understanding of the designer’s design intention, but also makes them feel as if they are on the scene. This paper takes virtual reality technology as the research object and focuses on its specific application in assisting landscape planning and design. Firstly, the literature on computer aided technology and its application at home and abroad is analyzed and studied. It also introduces modern landscape planning and design, including the thinking of landscape planning and design, advantages of computer-aided landscape planning and design and related design software. Secondly, the concept and theory of virtual reality technology are simply analyzed, and the application of virtual reality technology in each stage of landscape architecture is analyzed, and the key technologies of virtual reality technology assisted landscape architecture design are introduced emphatically. Thirdly, it introduces the software of landscape planning and design assisted by virtual reality technology, and analyzes its practical application, such as SketchUp modeling technology, Lumion3D technology and baking technology. Finally, from the actual case, the specific operation of landscape architecture design assisted by virtual reality technology is analyzed and studied.},
  keywords={Solid modeling;Computational modeling;Virtual reality;Computer architecture;Data processing;Software;Ecology;computer aided design;virtual reality technology;landscape planning and design},
  doi={10.1109/ACEDPI58926.2023.00106},
  ISSN={},
  month={April},}@INPROCEEDINGS{10343685,
  author={Pardo Regueiro, José Manuel and de Los Ángeles Constantino-González, María and López, Omar Olmos and Ángel López Mariño, Miguel and Heredia, Alfonso Serrano and Rubio Názer, Francisco},
  booktitle={2023 World Engineering Education Forum - Global Engineering Deans Council (WEEF-GEDC)}, 
  title={Competences development and significative learning through engineering design competition}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={First engineering and science formation units (blocks) of Tec21 competences-based model [1], defined by Tecnologico de Monterrey, include students solving a real challenge supported by knowledge obtained in modules on mathematics, physics, and computing. A new challenge "Design, construction and modeling of a water-powered rocket" was proposed for the F1007B "Modeling in Engineering with Conservation Laws" block. This challenge involves designing, modeling and construction of a rocket, powered by a jet of water due to the pressure of a hand pump. Students compete in teams to achieve the greatest distance with their rockets. The educational intention of this challenge is to enhance student learning experience by (1) Covering many more topics of Physics that can been applied by students (2) Improve students grades and professor evaluation, (3) Increasing the use of technology by incorporating the Tracker program for video analysis, (4) Enabling comparison of real results with those obtained through MATLAB modeling, and (5) Fostering enthusiasm among students by facilitating teams’ competition within the same class and even among different campuses. Considering the analysis made, it was observed that the water rocket contest helped most of the students to better understand the concepts of Physics included in this block and in the previous block, F1006B "Modeling the Movement in Engineering". The topics in this unit include the Principle of conservation of energy, the Principle of conservation of lineal momentum, Bernoulli’s Principle, Projectile motion and Air friction. A large percentage of students consider that this activity was good for using technological tools such as Matlab (72%) or Tracker (84%) and to compare theory with reality. A good number of students believe that this challenge helped them develop and implement solutions, demonstration of operation of engineering systems and devices, written language, and scientific thinking competences. It can be concluded that this rocket contest challenge is a good educational innovation since it incorporates a change in the materials, methods, contents and contexts involved in the formation unit.},
  keywords={Rockets;Technological innovation;Analytical models;Tracking;Computational modeling;Projectiles;Water conservation;Water Rockets;Energy;Momentum;Pressure;Bernoulli;Tracker;Matlab;Modeling;Parabolic;Educational Innovation},
  doi={10.1109/WEEF-GEDC59520.2023.10343685},
  ISSN={2837-5025},
  month={Oct},}@INPROCEEDINGS{9990065,
  author={Vapiwala, Fatima and Pandita, Deepika},
  booktitle={2022 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)}, 
  title={Harnessing the Power of Games for E-learning in Higher Education}, 
  year={2022},
  volume={},
  number={},
  pages={333-337},
  abstract={Learners nowadays are susceptible to stress and boredom due to the prevalence of e-learning. Young adults form their personalities in the context of dynamic networks that heavily depend on technological advances. As a way to involve learners, game-based learning refers to the adoption of some gaming ideas and their adaptation to actual contexts. Computer and video games can give e-learners the opportunity to engage in educational strategies that emphasize practical immersion and are accompanied by frameworks that foster competence, professionalism, and creative thinking. Through this study, the authors explore the use of game-based learning in the higher education sector in India. The authors aim to understand e-learners’ perceptions regarding game-based learning especially as elearning is growing in popularity and to bring out the various factors that contribute to the success of game-based learning in higher education. Based on the study, the authors also propose a 6C Strategy Model highlighting various strategies that faculty members and educators can use. The model will enable faculty members to effectively utilize game-based learning to keep the e-learners motivated and engaged throughout the e-learning process.},
  keywords={Video games;Technological innovation;Electronic learning;Computational modeling;Education;Decision making;Games;e-learning;higher education;game-based learning;technology;learners;motivation;engagement;contribution},
  doi={10.1109/3ICT56508.2022.9990065},
  ISSN={2770-7466},
  month={Nov},}@INPROCEEDINGS{9974884,
  author={Behúnová, A. and Knapčíková, L. and Behún, M.},
  booktitle={2022 20th International Conference on Emerging eLearning Technologies and Applications (ICETA)}, 
  title={Enhancing Education Process Supported by Virtual Reality}, 
  year={2022},
  volume={},
  number={},
  pages={40-45},
  abstract={In the higher education system, the introduction of information technologies is part of the modern unit of education. At the present time, when universities commonly use the form of distance and mixed education, this method places the student at the center of the entire educational system and among all other components related to this system. Supporting the development of skills, competencies, critical thinking, communication, and expressing ideas and concepts naturally, in a free form, stimulate the student. The motivation of individuals has a great influence on education and even on learning itself. These information technologies can implicitly greatly enhance motivation and also education through innovative teaching, learning, and assessment technologies. Motivation is increased through interactivity, dynamics, and effects provided by information technology. Virtual reality (VR) is the most interactive of these technologies. The contribution is devoted to the use of virtual reality in the educational process, where the basis of the use of virtual reality is the effort to display spatial models and scenes as faithfully as possible, their manipulation, the creation of the real world, a certain part of it with all its regularities and rules, movement in three-dimensional space and that all in real-time. In doing so, basic procedures from the field of computer graphics are used.},
  keywords={Visualization;Solid modeling;Electronic learning;Three-dimensional displays;Computational modeling;Education;Virtual reality},
  doi={10.1109/ICETA57911.2022.9974884},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{1222264,
  author={Tanaka, K. and Matsunaga, K. and Kanamori, N. and Hori, S. and Wang, H.O.},
  booktitle={Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No.03EX694)}, 
  title={Electroencephalogram-based control of a mobile robot}, 
  year={2003},
  volume={2},
  number={},
  pages={688-693 vol.2},
  abstract={This paper describes electroencephalogram-based control of a mobile robot. The control purpose is to achieve direction control of a mobile robot only by electroencephalogram. We develop an algorithm for detecting direction thinking ('going left' or 'going right') and apply it to direction control of a mobile robot. The detecting algorithm is based on time-frequency domain analysis using continuous wavelet transformation. Our experimental results demonstrate the possibility of achieving direction control of a mobile robot only by electroencephalogram.},
  keywords={Mobile robots;Electroencephalography;Electrodes;Mechanical engineering;Sampling methods;Robot control;Communication system control;Control systems;Brain computer interfaces;Application software},
  doi={10.1109/CIRA.2003.1222264},
  ISSN={},
  month={July},}@INPROCEEDINGS{7881513,
  author={Uemura, Yoshihiro and Kajiwara, Yusuke and Shimakawa, Hiromitsu},
  booktitle={2016 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Estimating Distracted Pedestrian from Deviated Walking Considering Consumption of Working Memory}, 
  year={2016},
  volume={},
  number={},
  pages={1164-1167},
  abstract={This paper proposes a method to distinguish distracted pedestrians from normal pedestrians, using the acceleration and the angular velocity while walking. This method uses an acceleration sensor attached on the back of the pedestrian. The acceleration and the angular velocity are obtained while the pedestrian is walking. In addition to that, walking features are calculated based on the obtained data. Some studies points out distraction of the pedestrian relates to consumption of working memory. We assume considering the relationship between consumption of working memory and walking behavior suggest the effectiveness to estimate distraction of the pedestrian. When each pedestrian is walking while consuming working memory, for example thinking about something, their walk deviates from normal. Machine Learning method, Random Forest, is applied to classify whether the pedestrian is distracted using features of walking. An experiment suggests we can distinguish walking features represent both distracted state and normal state completely. The result indicates the method can find distracted pedestrians whose working memory is highly consumed. We discuss why we can distinguish the distraction of the pedestrian from walking feature components with the variable importance. In addition, we have conducted regression analysis on the significant feature components to figure out the reasons. Finally, we discuss the feasibility of our proposed method.},
  keywords={Legged locomotion;Acceleration;Angular velocity;Accidents;Vehicles;Geographic information systems;Geographic Information System;pedestrian;walk;acceleration sensor;working memory},
  doi={10.1109/CSCI.2016.0220},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{7424072,
  author={Saleh, Eman M. and Al Sheik Salem, Omar},
  booktitle={2015 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={A Model-Driven Engineering Transition-Based GUI Testing Technique}, 
  year={2015},
  volume={},
  number={},
  pages={108-113},
  abstract={Model Driven Engineering (MDE) have arisen as a new software development paradigm which is based on creating a set of models that represent the GUI, afterwards to generate the GUI based on these models using a series of transformations to convert the models between the different levels of abstractions, which enables the automation of the development process. This inspires us to think of a model-based testing technique that is able to test the GUIs that are designed using Model-Driven engineering by finding the proper model that can serve as a testing model. This paper proposes model-based testing technique that is derived from the design models used to develop the GUI in the Model-Driven Engineering paradigm.},
  keywords={Testing;Graphical user interfaces;Unified modeling language;Navigation;Heuristic algorithms;Switches;Concur Task Trees;Model-based testing;Model-Driven Engineering;Task models},
  doi={10.1109/CSCI.2015.109},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9799181,
  author={Han, ChoongHee},
  booktitle={2021 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Enhanced cybersecurity for safe smart world}, 
  year={2021},
  volume={},
  number={},
  pages={1886-1890},
  abstract={Unfortunately, convenience is getting more overemphasized, the risk of smart world is getting more neglected. Smart worlds like smart cities, smart homes, smart factories, smart traffics are making web-based IT systems more and more. Many research papers tells us that web-based IT systems are fundamentally vulnerable. Truly, it is very difficult to defend against every cyber attack. Definitely, it is impossible to think about safe smart world without cybersecurity. It is really needed to reduce the risk of smart world. If access from overseas is not necessary, blocking cyber threats from abroad is the best way to reduce the risk of cyber infringements for smart world.},
  keywords={Performance evaluation;Smart cities;Scientific computing;Smart homes;Blocklists;Internet;IP networks;Network Security;Smart world Security;Enhanced Security Control},
  doi={10.1109/CSCI54926.2021.00078},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{4133184,
  author={Mahdavi, Somayeh and Gharibzadeh, Shahriar and Rezaei-Tavirani, Mostafa and Towhidkhah, Farzad and Shafiee, Soheil},
  booktitle={2006 IEEE Symposium on Computational Intelligence and Bioinformatics and Computational Biology}, 
  title={PSpice Simulation of Cardiac Impulse Propagation: studying the mechanisms of action potential propagation}, 
  year={2006},
  volume={},
  number={},
  pages={1-5},
  abstract={For many years, local circuit current through gap junctions has been seemed to be the main fundamental route for impulse transmission. In the last few years, some different evidences suggest another view on action potential propagation via myocardial cells. Some researches offered that myocardial cells may not require low-resistance connections for successful propagation of action potential. It seems that some other mechanisms are involved in the action potential propagation. Electrical field has been suggested as the main effective mechanism in action potential propagation. It is demonstrated that in the lack of gap junctions, electrical field is sufficient for action potential propagation. We simulated the mechanism of electrical field and local circuit current separately, studied the effect of these mechanisms on action potential propagation and compared them with each other. Our results demonstrate that although the mechanism of electrical field alters the resting potential of the post-junctional cell, but it is not sufficient to excite the post-junctional cell. These results offer a new view on action potential propagation in which both of the abovementioned mechanisms are necessary for normal cardiac functioning, but in different times of a cardiac cycle. It seems that gap junction has a dynamic behavior in each cardiac cycle, managing different routes of propagation in the diverse moments of normal cycle. Closure of gap junctions allows the negative cleft potential to develop and enhance the cell excitability by reducing cell potential. Then opening the gap junction produces AP. Based on this view, we think that most of the paradox about the role of gap junctions in cardiac impulse propagation will be solved},
  keywords={Myocardium;Laboratories;Biomedical engineering;Biological system modeling;Circuit simulation;Humans;Immune system;Biomembranes;Cells (biology);Systems biology},
  doi={10.1109/CIBCB.2006.330948},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8947673,
  author={Sayed Javed, Ahmad},
  booktitle={2018 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Total e-Governance: Pros & Cons}, 
  year={2018},
  volume={},
  number={},
  pages={245-249},
  abstract={"Good Governance" - may it be corporate or governmental, is a badly needed focus area in the world today where the companies and governments are struggling to survive the political and economical turmoil around the globe. All governments around the world have a tendency of expanding the size of their government, but eventually they would be forced to think reducing the size by incorporating information technology as a way to provide services to the citizens effectively and efficiently. Hence our attempt is to offer a complete solution from birth of a citizen till death encompassing all the necessary services related to the well being of a person living in a society. Our research and analysis would explore the pros and cons of using IT as a solution to our problems and ways to implement them for a best outcome in e-Governance occasionally comparing with the present scenario when relevant.},
  keywords={Government;Information technology;Databases;Security;Finance;Big Data;e-governance, ERP, computer security, data center, big data},
  doi={10.1109/CSCI46756.2018.00053},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{1222167,
  author={Ito, S. and Mitsukura, Y. and Fukumi, M. and Akamatsu, N. and Khosla, R.},
  booktitle={Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No.03EX694)}, 
  title={An EEG feature detection system using the neural networks based on genetic algorithms}, 
  year={2003},
  volume={3},
  number={},
  pages={1196-1200 vol.3},
  abstract={It is often known that an EEG has a personal characteristic. However, there are no researches to achieve the consideration of the personal characteristic. Then, the analyzed frequency components of the EEG have that the frequency components in which characteristics are contained significantly, and that not. Moreover, these combinations have the human equation. We think that these combinations are the personal characteristics frequency components of the EEG. In this paper, the EEG analysis method by using the GA, the FA and the NN is proposed. The GA is used for selecting the personal characteristics frequency components. The FA is used for extracting the characteristic data of the EEG. The NN is used for estimating extracted the characteristics data of the EEG. Finally, in order to show the effectiveness of the proposed method, EEG pattern was classified using computer simulations. The EEG pattern has 4 conditions, which are listening to rock music, Schmaltzy Japanese ballad music, healing music and classical music. The result, in the case of not using the personal characteristics frequency components, gave over 95% accuracy. This result of our experiment shows the effectiveness of the proposed method.},
  keywords={Electroencephalography;Computer vision;Neural networks;Genetic algorithms;Frequency;Data mining;Humans;Equations;Indium tin oxide;Australia},
  doi={10.1109/CIRA.2003.1222167},
  ISSN={},
  month={July},}@INPROCEEDINGS{7881546,
  author={Aldahari, Eiman},
  booktitle={2016 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Visualization Techniques for Effective Software Comprehend}, 
  year={2016},
  volume={},
  number={},
  pages={1355-1359},
  abstract={Program comprehension procedure have been attracted a lot of attentions and have been investigated using a variant methodologies such as thinking aloud, summary analysis, and Eye-tracking. Program comprehension tools main objective is understanding source code which is substantial factor in software maintenance activities. Visualization is a popular approach in earning this understanding. This paper present a comprehend analysis of concepts and techniques that have been used in building the visualization tools. Then we display a thorough comparison between two widely visualization tools which are SHriMP and LEONARDO.},
  keywords={Data visualization;Software;Switches;Programming profession;Image color analysis;Context;Program comprehension;visualization;SHriMP;LEONARDO},
  doi={10.1109/CSCI.2016.0253},
  ISSN={},
  month={Dec},}@ARTICLE{9817115,
  author={Mahmoud, Abeer M. and Lashin, Maha M. A. and Alrowais, Fadwa and Karamti, Hanen},
  journal={IEEE Access}, 
  title={A Dual Soft-Computing Based on Genetic Algorithm and Fuzzy Logic Defect Recognition for Gearbox and Motors: Attempts Toward Optimal Performance}, 
  year={2022},
  volume={10},
  number={},
  pages={73956-73968},
  abstract={Motor and gearbox are considered the main components in various machines related to its supplying power and transmitting motion role. Operating machines acquire vibration signal that are continuously monitoring by sensors placing close to vibration source. This for processing and identify the machine’ components status. Breakdown of the rotating machine causes significant losses and costs, so the analysis of its vibration signals proved literately avoiding these drawbacks with effective faults diagnosis. This paper proposing two models for gearbox and motor faults identification as an attempt towards finding the optimal performance: The first developed model is a fuzzy logic (FL) based model and the other is genetic algorithm (GA) based model. The intended output of both models reduce time and cost of maintenance. It also indirectly increases the machine component’s life. Additionally, the computational analysis proved that, concerning execution time and accuracy; and with the powerful straight forward representation for uncertainties offered by the Fuzzy Logic; it is indeed reliable, however it presented lower classification accuracy (96% for gear box faults and 93% for motor faults) and lower generalization schema. Yet, the proposed strategy which integrates GA and SVM recorded high performances in optimization and higher classification capabilities (97% for both gear box and motors faults). These factors illustrate the effectiveness and optimal performance of the genetic based model.},
  keywords={Feature extraction;Fault diagnosis;Fuzzy logic;Genetic algorithms;Support vector machines;Biological system modeling;Computational modeling;Genetic algorithm (GA);fuzzy logic (FL);gear box and motor;fault identification},
  doi={10.1109/ACCESS.2022.3188780},
  ISSN={2169-3536},
  month={},}@ARTICLE{10444104,
  author={Benson, Seth P. and Cruickshank, Iain J.},
  journal={IEEE Access}, 
  title={Developing a Natural Language Understanding Model to Characterize Cable News Bias}, 
  year={2024},
  volume={12},
  number={},
  pages={31798-31807},
  abstract={Media bias has been extensively studied by both social and computational sciences. However, current work still has a large reliance on human input and subjective assessment to label biases. This is especially true for cable news, which has a continued presence in American media but a lack of text-based bias identification in research. To address these issues, we develop an unsupervised machine learning method to characterize the bias of cable news programs without any human input. This method relies on the analysis of what topics are mentioned through Named Entity Recognition and how those topics are discussed through Stance Analysis in order to cluster programs with similar biases together. Applying our method to 2020 cable news transcripts, we find that cable news programs tend to cluster together consistently over time and roughly correspond to the cable news network of the program. This method reveals the potential for future tools to more objectively assess media bias and characterize unfamiliar media environments, and the empirical results insight into the nature of bias in American cable news programs.},
  keywords={Media;Cable TV;Writing;Sentiment analysis;Encoding;Computational modeling;Logic gates;Natural language processing;Social factors;Clustering methods;Information analysis;Natural language understanding;cable news;media bias;stance analysis;named entity recognition},
  doi={10.1109/ACCESS.2024.3369490},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{1087496,
  author={Drumheller, M. and Poggio, T.},
  booktitle={Proceedings. 1986 IEEE International Conference on Robotics and Automation}, 
  title={On parallel stereo}, 
  year={1986},
  volume={3},
  number={},
  pages={1439-1448},
  abstract={We review some of the open issues in computational stereo. In particular, we will discuss the problem of extracting better matching primitives and of dealing with occlusions. Markov Random Field models - an extension of standard regularization - suggest sophisticated stereo matching algorithms. They are, however, ill-suited to efficient, real-time applications. We will conclude reviewing a new simple but fast algorithm implemented by one of us (Drumheller, 1986) on the TMC Connection Machine (TM) computer. Some of its features are: (a) the potential for combining different primitives, including color information; (b) the use of a stronger and new formulation of the uniqueness constraint; and (c) its disparity representation that maps efficiently into the architecture of the Connection Machine computer.},
  keywords={Humans;Application software;Feature extraction;Computational intelligence;Machine intelligence;Laboratories;Markov random fields;Computer architecture;Robots;Robustness},
  doi={10.1109/ROBOT.1986.1087496},
  ISSN={},
  month={April},}@ARTICLE{219861,
  author={Bailey, D.H. and Barszcz, E. and Dagum, L. and Simon, H.D.},
  journal={IEEE Parallel & Distributed Technology: Systems & Applications}, 
  title={NAS parallel benchmark results}, 
  year={1993},
  volume={1},
  number={1},
  pages={43-51},
  abstract={Benchmark results for the Numerical Aerodynamic Simulation (NAS) Program at NASA Ames Research Center, which is dedicated to advancing the science of computational aerodynamics are presented. The benchmark performance results are for the Y-MP, Y-MO EL, and C-90 systems from Cray Research; the TC2000 from Bolt Baranek and Newman; the Gamma iPSC/860 from Intel; the CM-2, CM-200, and CM-5 from Thinking Machines; the CS-1 from Meiko Scientific; the MP-1 and MP-2 from MasPar Computer; and the KSR-1 from Kendall Square Research. The results for the MP-1 and -2, the KSR-1, and the CM-5 have not been published before. Many of the other results are improved from previous listings, reflecting improvements both in compilers and in implementations.<>},
  keywords={Concurrent computing;Computational fluid dynamics;Computational modeling;High performance computing;Kernel;NASA;Aerodynamics;Supercomputers;Power system reliability;Data structures},
  doi={10.1109/88.219861},
  ISSN={1558-1861},
  month={Feb},}@INPROCEEDINGS{7274607,
  author={Ferschin, Peter and Di Angelo, Monika and Brunner, Gerhard},
  booktitle={2015 IEEE 7th International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM)}, 
  title={Rapid prototyping for kinetic architecture}, 
  year={2015},
  volume={},
  number={},
  pages={118-123},
  abstract={Architecture was perceived for many centuries as the design of static buildings that will last for extended periods of time, with static changes or additions at most. Traditional design tools reflect this approach. Kinetic architecture, however, defines a kind of architecture that incorporates dynamic properties which accommodate for environmental or utilization changes. The integration of mechanics, electronics, and computer technology into contemporary architectural design, requires a change of thinking and designing, as well as suitable design tools. To communicate design ideas, the architectural design process utilizes effective strategies such as sketching and model building. A well-established design technique in diverse disciplines is rapid prototyping. Our goal is to have an integrated environment for designing kinetic architecture, including its mechanical parts, electronic units, and software modules with a rapid prototyping approach. This paper discusses conceptual ideas for rapid prototyping design environments for kinetic architecture. An exemplary environment is introduced where a small design task has been realized to provide feedback for the concept.},
  keywords={Prototypes;Kinetic theory;Computer architecture;Architecture;Buildings;Software;Virtual environments;rapid prototyping;kinetic architecture;design process},
  doi={10.1109/ICCIS.2015.7274607},
  ISSN={2326-8239},
  month={July},}@INPROCEEDINGS{10578608,
  author={Choi, Wan-Chong and Lam, Chan-Tong and Mendes, António José},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={How Various Educational Features Influence Programming Performance in Primary School Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In the digital age, programming education has become increasingly important, even in primary schools. However, introducing programming at such an early stage presents unique challenges, given the need for students to grasp mathematical concepts, abstract thinking, and the intricacies of programming syntax. Educational Data Mining (EDM) offers a potential contribution by predicting learning performance, facilitating the optimization of the learning processes, and providing real-time guidance. A notable gap in the current literature about EDM in programming education is its predominant emphasis on the university level. Our research objectives were to identify features influencing primary school students' programming capabilities. A more comprehensive dataset was introduced, incorporating psychometric data and highlighting features such as learning motivation and attitude, computational thinking data, and other potentially influential variables, which set our study apart from previous studies. We found that the strongest predictor was academic performance in Information Technology, followed by psychometric data on students' learning attitudes and motivation. Computational thinking also emerged as a significant feature in predicting programming performance. It's worth highlighting that involvement in extra-curricular activities, like Olympic Mathematics training, showed a significant association, underscoring the importance of mathematical logic and reasoning in programming. This is further bolstered by the evident correlation with academic performance in Mathematics, confirming its pivotal role in shaping programming abilities. Interestingly, the correlation of academic performance in Chinese is also significant, indicating that the language medium of instruction can notably influence success.},
  keywords={Training;Performance evaluation;Computers;Correlation;Syntactics;Mathematics;Cognition;Computer science;Programming Education;Educational Data Mining;Educational features correlation;Performance prediction;Features selection},
  doi={10.1109/EDUCON60312.2024.10578608},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{7410695,
  author={Cao, Chunshui and Liu, Xianming and Yang, Yi and Yu, Yinan and Wang, Jiang and Wang, Zilei and Huang, Yongzhen and Wang, Liang and Huang, Chang and Xu, Wei and Ramanan, Deva and Huang, Thomas S.},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Look and Think Twice: Capturing Top-Down Visual Attention with Feedback Convolutional Neural Networks}, 
  year={2015},
  volume={},
  number={},
  pages={2956-2964},
  abstract={While feedforward deep convolutional neural networks (CNNs) have been a great success in computer vision, it is important to note that the human visual cortex generally contains more feedback than feedforward connections. In this paper, we will briefly introduce the background of feedbacks in the human visual cortex, which motivates us to develop a computational feedback mechanism in deep neural networks. In addition to the feedforward inference in traditional neural networks, a feedback loop is introduced to infer the activation status of hidden layer neurons according to the "goal" of the network, e.g., high-level semantic labels. We analogize this mechanism as "Look and Think Twice." The feedback networks help better visualize and understand how deep neural networks work, and capture visual attention on expected objects, even in images with cluttered background and multiple objects. Experiments on ImageNet dataset demonstrate its effectiveness in solving tasks such as image classification and object localization.},
  keywords={Neurons;Visualization;Biological neural networks;Feedforward neural networks;Semantics;Feedback loop;Logic gates},
  doi={10.1109/ICCV.2015.338},
  ISSN={2380-7504},
  month={Dec},}@ARTICLE{9199553,
  author={Ji, Shaoxiong and Pan, Shirui and Li, Xue and Cambria, Erik and Long, Guodong and Huang, Zi},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Suicidal Ideation Detection: A Review of Machine Learning Methods and Applications}, 
  year={2021},
  volume={8},
  number={1},
  pages={214-226},
  abstract={Suicide is a critical issue in modern society. Early detection and prevention of suicide attempts should be addressed to save people's life. Current suicidal ideation detection (SID) methods include clinical methods based on the interaction between social workers or experts and the targeted individuals and machine learning techniques with feature engineering or deep learning for automatic detection based on online social contents. This article is the first survey that comprehensively introduces and discusses the methods from these categories. Domain-specific applications of SID are reviewed according to their data sources, i.e., questionnaires, electronic health records, suicide notes, and online user content. Several specific tasks and data sets are introduced and summarized to facilitate further research. Finally, we summarize the limitations of current work and provide an outlook of further research directions.},
  keywords={Feature extraction;Machine learning;Psychology;Twitter;Task analysis;Deep learning;feature engineering;social content;suicidal ideation detection (SID)},
  doi={10.1109/TCSS.2020.3021467},
  ISSN={2329-924X},
  month={Feb},}@ARTICLE{9245567,
  author={Xie, Zheng},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={A Prediction Method of Publication Productivity for Researchers}, 
  year={2021},
  volume={8},
  number={2},
  pages={423-433},
  abstract={Publication productivity affects nearly every aspect of researchers’ scientific career, whereas it is difficult to be predicted due to diversity in researchers’ productivity patterns. This study proposed a model for the publication dynamics of researchers. The model is based on Lotka’s law as well as the relationship between the annual number of publications and time given a historical number of publications. The law and the statistical significance of the relationship are validated by applying them to the high-quality dblp data set. The model allows to predict the number of publications for research groups, and its effectiveness is tested on the data set by fine fittings on the distribution of the number of publications for researchers, the evolutionary trend of their publication productivity, and the probability of producing publications. Due to its nature of regression, the model has the potential to be extended to assess the confidence level of the prediction results and thus would be useful for other empirical research.},
  keywords={Productivity;Predictive models;Sociology;Statistics;Data models;Creativity;Engineering profession;Data modeling;productivity prediction;scientific publication},
  doi={10.1109/TCSS.2020.3032568},
  ISSN={2329-924X},
  month={April},}@ARTICLE{9432475,
  author={Ni, Li and Luo, Wenjian and Zhu, Tao and Xu, Peilan},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={On Followers Search}, 
  year={2021},
  volume={8},
  number={5},
  pages={1068-1082},
  abstract={Although followership has been widely studied in sociology and management, the problem of finding followers has not drawn attention in the field of artificial intelligence. We refer to the problem of finding followers of a given object as followers search. In sociology, followers are close to their leaders, and leaders are superior to their followers. In this article, aimed at finding followers of a given object, we formulate followers on the basis of both superiority and closeness. The former means that the given object should be superior to followers, and the latter means that followers should be close to the given object. We present a followers search algorithm to find the followers of the given object. Furthermore, we apply the ideas of followers to the market basket and recommender system datasets. The experimental results demonstrate the rationality of the discovered followers on the market basket dataset and the improved performance of the TrustPMF algorithm by adopting followership on recommender system datasets, which indicate a promising future for followers search.},
  keywords={Recommender systems;Itemsets;Search problems;Sociology;Task analysis;Social networking (online);Detection algorithms;Data intelligence;followers search;market basket analysis;recommender systems},
  doi={10.1109/TCSS.2021.3076469},
  ISSN={2329-924X},
  month={Oct},}@INPROCEEDINGS{9658965,
  author={Fotiadis, Filippos and Vamvoudakis, Kyriakos G.},
  booktitle={2021 IEEE Conference on Control Technology and Applications (CCTA)}, 
  title={Recursive Reasoning for Bounded Rationality in Multi-Agent Non-Equilibrium Play Learning Systems}, 
  year={2021},
  volume={},
  number={},
  pages={741-746},
  abstract={In this work, and inspired by the theory of bounded rationality and recursive reasoning, we propose two frameworks for modeling players’ behaviors and for choosing their policies in multi-agent dynamic stochastic game settings. In particular, we define multiple levels of rationality for each player, where at each level a player may reason about everyone else in two different ways; first, they may assume that the rest of the players have a cognitive level that is immediately lower than theirs, which is known as level-k thinking; second, they may assume that the rest of the players’ cognitive level follows a Poisson distribution, which is known as cognitive hierarchy. We construct algorithms for estimating the players’ policies at each level of rationality, both in a level-recursive as well as in a level-paralleled manner, and we study these algorithms’ convergence properties. Simulations on a grid world are provided to illustrate the efficacy of the proposed models.},
  keywords={Learning systems;Heuristic algorithms;Computational modeling;Simulation;Conferences;Stochastic processes;Games;Recursive reasoning;bounded rationality;stochastic games;level-k thinking;cognitive hierarchy},
  doi={10.1109/CCTA48906.2021.9658965},
  ISSN={2768-0770},
  month={Aug},}@INPROCEEDINGS{6670623,
  author={Ontiveros, Erika Paola Holguín and Antolinez, Sandra Valbuena},
  booktitle={2013 XXXIX Latin American Computing Conference (CLEI)}, 
  title={Design, construction and implementation of a professional education program of software engineering: Design curriculum experience for the software industry}, 
  year={2013},
  volume={},
  number={},
  pages={1-12},
  abstract={A competence-based teaching curriculum approach and propaedeutic cycles model has been taken by Fundación Universitaria Panamericana, which aims to ensure the appropriateness for the industry, so that is the reason it has focused its efforts to develop mechanisms to understand the needs and translate them into a dynamic, flexible and pertinent curriculum. For the software engineering program there was a systemic thinking approach, consisting of the different units and areas of knowledge and the functions and responsibilities from the perspective of the production sector which provided to the curriculum design model a minimalist point of view of factors that influence the elements, structures, processes, interrelations and reactions compared to the expectations for a professional in the field. This is supported with pedagogical guidance, academic environment implementation through integrating projects and active methodologies, self-assessment and continuous updating.},
  keywords={Software engineering;Education;Software;Industries;Computational modeling;Knowledge engineering;Context modeling;competence;curriculum design;discipline;education;fields of knowledge;software engineering;systemic thinking},
  doi={10.1109/CLEI.2013.6670623},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{6083687,
  author={Wang, Song and Xu, Li and Li, Ling and Wang, Kanliang and Choi, Jung},
  booktitle={2011 IEEE International Conference on Systems, Man, and Cybernetics}, 
  title={Features of enterprise information systems integration: A systemic analysis}, 
  year={2011},
  volume={},
  number={},
  pages={333-339},
  abstract={This paper strives to review the contribution of systems theory to enterprise architecture and integration, make a summary of methods or tools at systems level and probe into some crucial concepts and thinking of systems theory applied in the enterprise integration activities. As the summary to this paper, some new prospects in enterprise architecture and integration are presented to tackle the increasing complexity and new requirements on modern enterprises.},
  keywords={Information systems;Computer architecture;Computational modeling;Data models;Organizations;Educational institutions;systems theory;systems thinking;enterprise information systems;enterprise architecture;enterprise integration},
  doi={10.1109/ICSMC.2011.6083687},
  ISSN={1062-922X},
  month={Oct},}@INPROCEEDINGS{9677413,
  author={Al-Tahat, Khalid},
  booktitle={2021 22nd International Arab Conference on Information Technology (ACIT)}, 
  title={Alice Adventures in ComputingLand: A review}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={Computer programming is often presented to students as an abstract discipline that looks aseptic and ultimately boring to many learners; learners find their first computing course uninspiring and programming hard and socially isolating. This causes a decline in the interest in computing among learners. Although there have been many attempts to make computing appealing, more interesting, easier and enjoyable, many educators are still using the classic methods in teaching and learning computer programming. The aim of this work is to call the attention of computing educators to an approach that uses 3D virtual environments to teaching programming. We introduce this approach through a tool that offers innovative methods for teaching wide spectrum of computing topics; Alice. Alice is an innovative programming environment that can be used to create stories by animating characters in a 3D world. Alice is written in Java and has an object-oriented flavor. The paper presents a review of research on using Alice in motivating teaching programming and problem solving, algorithmic thinking, software modeling, and game design and implementation. New trends of using Alice in teaching computing are also suggested.},
  keywords={Three-dimensional displays;Object oriented modeling;Computational modeling;Education;Software algorithms;Virtual environments;Software;Alice;computing education;programming environments;teaching programming;algorithmic thinking;software modeling;game programming},
  doi={10.1109/ACIT53391.2021.9677413},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10512888,
  author={Oladejo, Sunday O.},
  booktitle={2024 IEEE International Conference on Artificial Intelligence and Mechatronics Systems (AIMS)}, 
  title={Metaheuristics for Protein Structure Prediction: Review and Empirical Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Metaheuristics have been employed in solving several optimization and NP-hard problems owing to their ability to avoid local optima entrapment, flexibility and robustness, simplicity, and reasonable computational time. In this work, an empirical analysis is carried out on the application of metaheuristics in solving the protein structure prediction (PSP) problem. The PSP problem entails predicting a three-dimensional (3D) structure of proteins based on the amino acid sequences. This study employs the Ab Initio method, which relies on the thermodynamic properties of the proteins, such as the minimal free energy levels, bond angles, and torsional angles, in determining the protein structure. Five real protein sequences, namely 1CB3, 1BXL, 2H3S, 1TZ4, and 1CRN from the Protein Data Bank (PDB), and 11 metaheuristics including DE, GA, PSO, DSO, ACO, and HS were employed in the empirical analysis. Moreover, extensive Monte Carlo simulations were carried out to generate the results of the empirical analysis and these results were statistically tested using the Friedman test.},
  keywords={Proteins;Ranking (statistics);Thermodynamics;Monte Carlo methods;Three-dimensional displays;NP-hard problem;Reviews;Protein structure prediction problem;meta-heuristics;empirical analysis;DSO;free energy levels},
  doi={10.1109/AIMS61812.2024.10512888},
  ISSN={},
  month={Feb},}@ARTICLE{8589035,
  author={Song, Sijie and Mei, Tao},
  journal={IEEE MultiMedia}, 
  title={When Multimedia Meets Fashion}, 
  year={2018},
  volume={25},
  number={3},
  pages={102-108},
  abstract={Through transforming visual fashion into computational images, multimedia technologies are transforming fashion industry at a faster pace than before. The huge demand for fashion analytics triggers promising applications and theoretical research in this area. The future of fashion is being reshaped by multimedia, and researchers are working toward computational fashion.},
  keywords={Industries;Visualization;Market research;Tools;Task analysis;Generative adversarial networks;Companies},
  doi={10.1109/MMUL.2018.2875860},
  ISSN={1941-0166},
  month={July},}@INPROCEEDINGS{4020025,
  author={Liu, Hong and Liu, Xiyu},
  booktitle={The Sixth IEEE International Conference on Computer and Information Technology (CIT'06)}, 
  title={Generative Design Supported by Tree Based Genetic Algorithm}, 
  year={2006},
  volume={},
  number={},
  pages={267-267},
  abstract={This paper presents a novel computational approach that uses tree based genarative algorithm to generate design. This approach is illustrated by a reading lamp design example, which uses general mathematical expressions and tree-based genetic algorithm to generate 2D sketch shapes. Then, these 2D sketch shapes are processed to form 3D components and saved in component base. A complex design is produced by combining different components. The result shows that approach is able to generate some innovative solutions and demonstrates the power of computational approach.},
  keywords={Algorithm design and analysis;Genetic algorithms;Evolution (biology);Shape;Buildings;Tree data structures;Information science;Genetic engineering;Design engineering;Engineering management},
  doi={10.1109/CIT.2006.93},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8190553,
  author={Alm, Cecilia Ovesdotter and Bailey, Reynold},
  booktitle={2017 IEEE Frontiers in Education Conference (FIE)}, 
  title={Team-based, transdisciplinary, and inclusive practices for undergraduate research}, 
  year={2017},
  volume={},
  number={},
  pages={1-5},
  abstract={We present work-in-progress reflecting on the initial year of a distinctive summer Research Experiences for Undergraduates (REU) program. Our REU model combines fundamental research in computational sensing with a scholarly context that connects computer science with computational liberal arts. Students are intellectually stimulated to make sense of people's behaviors and cognitive processes with multimodal sensing hardware and software. In doing so, they explore the fundamental challenges found at the intersection of computing, the human experience, and scientific interrogation. The placement of the human experience at the core of the research theme enables an environment that stimulates and cultivates an innovative undergraduate research model. We highlight outcomes from the first year and discuss three emerging practices that are central to our REU framework: (1) team-based collaborative training; (2) transdisciplinary integration; and (3) systematic prioritization of inclusiveness. We also describe how these practices are incorporated into our overall undergraduate research framework and touch upon lessons learned from feedback collected.},
  keywords={Sensors;Training;Mentoring;Art;Electronic mail;Computer science;Collaboration},
  doi={10.1109/FIE.2017.8190553},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10242723,
  author={Zhang, Keyuan and Liu, Yuan and Wang, Licheng and Li, Lixiang},
  booktitle={2023 International Conference on Mobile Internet, Cloud Computing and Information Security (MICCIS)}, 
  title={Identity-Based Proxy Re-Encryption Based on LWE with Short Parameters}, 
  year={2023},
  volume={},
  number={},
  pages={118-124},
  abstract={Proxy re-encryption (PRE) can guarantee the security of data sharing in the cloud making it important in ciphertext sharing in the cloud computing environment. Plenty of the current PRE algorithms based on the learning with errors (LWE) problem are constructed under the random oracle model or have problems such as long public parameter size, large ciphertext expansion rate, etc. We propose an identity-based PRE (IB-PRE) scheme using the LWE problem with short public parameters which can solve the mentioned challenges. Our scheme uses the blocking operation to decrease the public parameter size and a more useful trapdoor generation algorithm to reduce the trapdoor size. These two technologies improve the computational efficiency of the public key. We think that when we divide the identity id into 16 blocks, without much increase in computational overhead, the public key size can be reduced by 88.34%, and the scheme’s security level can remain unchanged. Our scheme achieves adaptive IND-ID-CPA security. It is unidirectional, collusion-resistant, and constructed under the standard model.},
  keywords={Cloud computing;Adaptation models;Computational modeling;Data security;Public key;Information security;Computational efficiency;lattice;IBE;LWE;PRE;short parameters},
  doi={10.1109/MICCIS58901.2023.00024},
  ISSN={},
  month={April},}@INPROCEEDINGS{6252902,
  author={Zhang, Anhong and Saunders, Rob},
  booktitle={2012 IEEE Congress on Evolutionary Computation}, 
  title={Towards the evolution of a language for creative design}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  abstract={To explore the possibility of evolving grounded artificial languages for creative design, this paper presents an approach to evolving mappings between spatial relations between simple shapes and artificial utterances. An implementation of this approach is presented, which combines Holographic Reduced Representations (HRR) and Self-Organizing Map (SOM). The results from experiments with this implementation have shown that the transformation between artificial language and design concepts can be realised and the hybrid computational system could be utilised in curious design agents for the evolution of artificial language in computational language games.},
  keywords={Shape;Convolution;Games;Vectors;Art;Australia;Steel},
  doi={10.1109/CEC.2012.6252902},
  ISSN={1941-0026},
  month={June},}@INPROCEEDINGS{5652922,
  author={Diakopoulos, Nicholas and Naaman, Mor and Kivran-Swaine, Funda},
  booktitle={2010 IEEE Symposium on Visual Analytics Science and Technology}, 
  title={Diamonds in the rough: Social media visual analytics for journalistic inquiry}, 
  year={2010},
  volume={},
  number={},
  pages={115-122},
  abstract={Journalists increasingly turn to social media sources such as Facebook or Twitter to support their coverage of various news events. For large-scale events such as televised debates and speeches, the amount of content on social media can easily become overwhelming, yet still contain information that may aid and augment reporting via individual content items as well as via aggregate information from the crowd's response. In this work we present a visual analytic tool, Vox Civitas, designed to help journalists and media professionals extract news value from large-scale aggregations of social media content around broadcast events. We discuss the design of the tool, present the text analysis techniques used to enable the presentation, and provide details on the visual and interaction design. We provide an exploratory evaluation based on a user study in which journalists interacted with the system to explore and report on a dataset of over one hundred thousand twitter messages collected during the U.S. State of the Union presidential address in 2010.},
  keywords={Media;Twitter;Aggregates;Context;Classification algorithms;Filtering;Visual analytics;Computational Journalism;Computer Assisted Reporting;Social Media;Sensemaking},
  doi={10.1109/VAST.2010.5652922},
  ISSN={},
  month={Oct},}@ARTICLE{5560631,
  author={Lan, Chung-Hsien and Graf, Sabine and Lai, K. Robert and Kinshuk, Kinshuk},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Enrichment of Peer Assessment with Agent Negotiation}, 
  year={2011},
  volume={4},
  number={1},
  pages={35-46},
  abstract={This study presents a conceptual framework for providing intelligent supports through agent negotiation and fuzzy constraints to enhance the effectiveness of peer assessment. By using fuzzy constraints, it not only provides a flexible marking scheme to deal with the imprecision and uncertainty for the representation of assessment but also provides a computational framework to incorporate student's personal characteristics into the process for the reduction of assessment bias. Additionally, a fuzzy constraint-based negotiation mechanism is employed to coordinate the cognitive differences between students. Through iterative agent negotiation, students can reconcile the differences and reach an agreement on the assessment results. Thus, the proposed framework allows students to provide more detailed, informed, and less biased assessments for their peers' work. To demonstrate the usefulness and effectiveness of the proposed approach, a negotiation-based peer assessment system, NePAS, has been built and used in classroom. Experimental results suggested that students were more willing to accept the assessment results and able to acquire more useful information to reflect upon and revise their work. Instructors can also observe students' participation and performance to appropriately adjust instructional strategies.},
  keywords={Materials;Book reviews;Cognition;Uncertainty;Proposals;Computational modeling;Reflection;Peer assessment;assessment bias;agent negotiation;fuzzy constraints.},
  doi={10.1109/TLT.2010.30},
  ISSN={1939-1382},
  month={Jan},}@ARTICLE{8961340,
  author={Chen, Min and Jiang, Yingying and Cao, Yong and Zomaya, Albert Y.},
  journal={IEEE Systems, Man, and Cybernetics Magazine}, 
  title={CreativeBioMan: A Brain- and Body-Wearable, Computing-Based, Creative Gaming System}, 
  year={2020},
  volume={6},
  number={1},
  pages={14-22},
  abstract={Current artificial intelligence (AI) technology is used mainly in rational work, i.e., computational and logical analysis. How to best make the machine as aesthetic and creative as humans has gradually gained attention. This article presents a unique, creative game system called CreativeBioMan. This system combines brain wave and multimodal emotion data and uses an AI algorithm for intelligent decision fusion, which can then be used in artistic creation with the goal being to separate the artist from repeated labor creation.},
  keywords={Artificial intelligence;Games;Brain models;Emotion recognition;Creativity;Computational modeling},
  doi={10.1109/MSMC.2019.2929312},
  ISSN={2333-942X},
  month={Jan},}@ARTICLE{7478499,
  author={Phethean, Christopher and Simperl, Elena and Tiropanis, Thanassis and Tinati, Ramine and Hall, Wendy},
  journal={IEEE Intelligent Systems}, 
  title={The Role of Data Science in Web Science}, 
  year={2016},
  volume={31},
  number={3},
  pages={102-107},
  abstract={Web science relies on an interdisciplinary approach that seeks to go beyond what any one subject can say about the World Wide Web. By incorporating numerous disciplinary perspectives and relying heavily on domain knowledge and expertise, data science has emerged as an important new area that integrates statistics with computational knowledge, data collection, cleaning and processing, analysis methods, and visualization to produce actionable insights from big data. As a discipline to use within Web science research, data science offers significant opportunities for uncovering trends in large Web-based datasets. A Web science observatory exemplifies this relationship by offering an online platform of tools for carrying out Web science research, allowing users to carry out data science techniques to produce insights into Web science issues such as community development, online behavior, and information propagation. The authors outline the similarities and differences of these two growing subject areas to demonstrate the important relationship developing between them.},
  keywords={Computational modeling;Internet and web services;Artificial intelligence;Government policies;Social network services;web science;data science;big data;web observatory;interdisciplinary;data analysis;intelligent systems},
  doi={10.1109/MIS.2016.54},
  ISSN={1941-1294},
  month={May},}@INPROCEEDINGS{6033635,
  author={Marupaka, Nagendra and Minai, Ali A.},
  booktitle={The 2011 International Joint Conference on Neural Networks}, 
  title={Connectivity and creativity in semantic neural networks}, 
  year={2011},
  volume={},
  number={},
  pages={3127-3133},
  abstract={Creativity and insight are distinctive attributes of human cognition, but their neural basis remains poorly understood due to the difficulty of experimental study. As such, computational modeling can play an important role in understanding these phenomena. Some researchers have proposed that creative individuals have a “deeper” organization of knowledge, allowing them to connect remote associates and form novel ideas. It is reasonable to assume that the depth and richness of semantic organization in individual minds is related to the connectivity of neural networks involved in semantic representation. In this paper, we use a simple and plausible neurodynamical model of semantic networks to study how the connectivity structure of these networks relates to the richness of the semantic constructs, or ideas, they can generate. This work is motivated, in part, by research showing that experimentally obtained semantic networks have a specific connectivity pattern that is both small-world and scale-free. We show that neural semantic networks reflecting this structure have richer semantic dynamics than those with other connectivity structures. Though simple, this model may provide insight into the important issue of how the physical structure of the brain determines one of the most profound features of the human mind - its capacity for creative thought.},
  keywords={Semantics;Neural networks;Organizations;Educational institutions;Modulation;Computational modeling;Productivity},
  doi={10.1109/IJCNN.2011.6033635},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{5585934,
  author={Bui, Vinh and Abbbass, Hussein and Bender, Axel},
  booktitle={IEEE Congress on Evolutionary Computation}, 
  title={Evolving stories: Grammar evolution for automatic plot generation}, 
  year={2010},
  volume={},
  number={},
  pages={1-8},
  abstract={In this paper, we propose a computational framework for automated story-based scenario generation. Under this framework, a regular grammar is developed to model various causal relationships inside a given story world. The grammar is then evolved using evolutionary computation techniques to generate novel story plots, i.e. story-based scenarios. To evaluate these newly generated scenarios, a human-in-the-loop model is used. An experimental study was carried out, in which the proposed framework was used to create novel plots based on the famous Little Red Riding Hood fairy tale. The experimental study demonstrated that evolutionary computation can potentially contribute significantly to story generations. Some challenges were identified including the difficulty to quantify such subjective measures as plot interestingness and creativity.},
  keywords={Grammar;Production;Semantics;Computational modeling;Coherence;Evolutionary computation;Cognition},
  doi={10.1109/CEC.2010.5585934},
  ISSN={1941-0026},
  month={July},}@INPROCEEDINGS{9196331,
  author={Pournaras, Evangelos},
  booktitle={2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS)}, 
  title={Collective Learning: A 10-Year Odyssey to Human-centered Distributed Intelligence}, 
  year={2020},
  volume={},
  number={},
  pages={205-214},
  abstract={This paper illustrates a 10-year research endeavor on collective learning, a paradigm for tackling tragedy of the commons problems in socio-technical systems using human-centered distributed intelligence. In contrast to mainstream centralized artificial intelligence (AI) allowing algorithmic discrimination and manipulative nudging, the decentralized approach of collective learning is by-design participatory and value-sensitive: it aligns with privacy, autonomy, fairness and democratic values. Engineering such values in a socio-technical system results in computational constraints that turn collective decision-making into complex combinatorial NP-hard problems. These are the problems that collective learning and the EPOS research project tackles. Collective learning finds striking applicability in energy, traffic, supply-chain and the self-management of sharing economies. This grand applicability and the social impact are demonstrated in this paper along with a future perspective of the collective learning paradigm.},
  keywords={Artificial intelligence;Optimization;Sociotechnical systems;Privacy;Decision making;Computational modeling;Multi-agent systems;collective learning;artificial intelligence;human-centered AI;multi-agent system;combinatorial optimization;distributed computing;EPOS},
  doi={10.1109/ACSOS49614.2020.00043},
  ISSN={},
  month={Aug},}@ARTICLE{9822984,
  author={Barthet, Matthew and Liapis, Antonios and Yannakakis, Georgios N.},
  journal={IEEE Transactions on Games}, 
  title={Open-Ended Evolution for Minecraft Building Generation}, 
  year={2023},
  volume={15},
  number={4},
  pages={603-612},
  abstract={This article proposes a procedural content generator which evolves Minecraft buildings according to an open-ended and intrinsic definition of novelty. To realize this goal, we evaluate individuals’ novelty in the latent space using a 3-D autoencoder (AE), and alternate between phases of exploration and transformation. During exploration the system evolves multiple populations of CPPNs through CPPN-NEAT and constrained novelty search in the latent space (defined by the current AE). We apply a set of repair and constraint functions to ensure candidates adhere to basic structural rules during evolution. During transformation, we reshape the boundaries of the latent space to identify new interesting areas of the solution space by retraining the AE with novel content. In this study, we evaluate five different approaches for training the AE during transformation and its impact on populations’ quality and diversity during evolution. Our results show that by retraining the AE we can achieve better open-ended complexity compared to a static model, which is further improved when retraining using larger datasets of individuals with diverse complexities.},
  keywords={Games;Creativity;Buildings;Generators;Search problems;Complexity theory;Three-dimensional displays;3-D voxels;computational creativity;deep learning;  $Minecraft$  ;procedural content generation (PCG)},
  doi={10.1109/TG.2022.3189426},
  ISSN={2475-1510},
  month={Dec},}@INPROCEEDINGS{6659151,
  author={Repenning, Alexander and Basawapatna, Ashok and Klymkowsky, Michael},
  booktitle={2013 IEEE International Games Innovation Conference (IGIC)}, 
  title={Making educational games that work in the classroom: A new approach for integrating STEM simulations}, 
  year={2013},
  volume={},
  number={},
  pages={228-235},
  abstract={The development of analytical skills is a central goal of the Next Generation Science Standards and foundational to subject mastery in STEM fields. Yet, significant barriers exist to students gaining such skills. Here we describe a new “gentle-slope” cyberlearning strategy that gradually introduces students to the authoring of scientific simulations via a Web-based modding approach called CyberMOD. Modding involves adding agents with predefined functionality to a simulation world to produce a unique combination whose behavior can then be visualized by running the simulation. This permits low barrier experimentation on the modded simulation, which is hoped to help students gain a deeper understanding of scientific phenomena that is the focus of the activity. Our research questions are: i) does this approach encourage students' interest in computational science and ii) does it enhance their analytical abilities, and iii) does it foster a deeper understanding of the processes modded? Here we take an in-depth look at what was created for the CyberMOD infrastructure and analyze the results of initial in-class studies as to the effectiveness of this strategy. The results support the premise that teachers can easily integrate CyberMOD into their in-class activities, that CyberMOD activities encourage creative student learning, and that the CyberMOD approach facilitates student understanding.},
  keywords={Computational modeling;Educational institutions;Biological system modeling;Sugar;Blood;Liver;efficacy of educational games;modding;CyberMOD;STEM Education;Next Generation Science Standards;effect size},
  doi={10.1109/IGIC.2013.6659151},
  ISSN={2166-675X},
  month={Sep.},}@INPROCEEDINGS{4354026,
  author={Dandurand, Frederic and Shultz, Thomas R. and Rivest, Francois},
  booktitle={2007 IEEE 6th International Conference on Development and Learning}, 
  title={Complex problem solving with reinforcement learning}, 
  year={2007},
  volume={},
  number={},
  pages={157-162},
  abstract={We previously measured human performance on a complex problem-solving task that involves finding which ball in a set is lighter or heavier than the others with a limited number of weightings. None of the participants found a correct solution within 30 minutes without help of demonstrations or instructions. In this paper, we model human performance on this task using a biologically plausible computational model based on reinforcement learning. We use a SARSA-based Softmax learning algorithm where the reward function is learned using cascade-correlation neural networks. First, we find that the task can be learned by reinforcement alone with substantial training. Second, we study the number of alternative actions available to Softmax and find that 5 works well for this problem which is compatible with estimates of human working memory size. Third, we find that simulations are less accurate than humans given equivalent amount of training We suggest that humans use means-ends analysis to self-generate rewards in non-terminal states. Implementing such self-generated rewards might improve model accuracy. Finally, we pretrain models to prefer simple actions, like humans. We partially capture a simplicity bias, and find that it had little impact on accuracy.},
  keywords={Problem-solving;Learning;Humans;Biological system modeling;Computational modeling;Biology computing;Information processing;Feedback;Psychology;Cognition;Problem Solving;Reinforcement Learning;Complex Cognition},
  doi={10.1109/DEVLRN.2007.4354026},
  ISSN={2161-9476},
  month={July},}@ARTICLE{8412574,
  author={van Pinxten, Joost and Geilen, Marc and Hendriks, Martijn and Basten, Twan},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
  title={Parametric Critical Path Analysis for Event Networks With Minimal and Maximal Time Lags}, 
  year={2018},
  volume={37},
  number={11},
  pages={2697-2708},
  abstract={High-end manufacturing systems are cyber-physical systems, where productivity depends on the close cooperation of mechanical (physical) and scheduling (cyber) aspects. Mechanical and control constraints impose minimal and maximal time differences between events in the product flow. Sequence-dependent constraints are used by a scheduler to optimize system productivity while satisfying operational requirements. The numerous constraints in a schedule are typically related to a relatively small set of parameters, such as speeds, lengths, or settling times. We contribute a parametric critical path algorithm that identifies bottlenecks in terms of the feasible parameter combinations. This algorithm allows analysis of schedules to identify bottlenecks in terms of the underlying cause of constraints. We also contribute a way to find Pareto-optimal cost-performance tradeoffs and their associated parameter combinations. These results are used to quantify the impact of relaxing constraints that hinder system productivity.},
  keywords={Schedules;Productivity;Task analysis;Automata;Manufacturing systems;Job shop scheduling;Stochastic processes;Combinatorial mathematics;Embedded systems;Convex functions;Pareto optimization;Planning;Algorithms;combinatorial computational geometry;convex functions;network theory;Pareto optimization;planning},
  doi={10.1109/TCAD.2018.2857360},
  ISSN={1937-4151},
  month={Nov},}@ARTICLE{10286410,
  author={Wortman, Benjamin and Wang, James Z.},
  journal={IEEE Transactions on Affective Computing}, 
  title={HICEM: A High-Coverage Emotion Model for Artificial Emotional Intelligence}, 
  year={2024},
  volume={15},
  number={3},
  pages={1136-1152},
  abstract={As social robots and other intelligent machines enter the home, artificial emotional intelligence (AEI) is taking center stage to address users’ desire for deeper, more meaningful human-machine interaction. To accomplish such efficacious interaction, the next-generation AEI needs comprehensive human emotion models for training. Unlike theory of emotion, which has been the historical focus in psychology, emotion models are a descriptive tool. In practice, the strongest models need robust coverage, which means defining the smallest core set of emotions from which all others can be derived. To achieve the desired coverage, we turn to word embeddings from natural language processing. Using unsupervised clustering techniques, our experiments show that with as few as 15 discrete emotion categories, we can provide maximum coverage across six major languages–Arabic, Chinese, English, French, Spanish, and Russian. In support of our findings, we also examine annotations from two large-scale emotion recognition datasets to assess the validity of existing emotion models compared to human perception at scale. Because robust, comprehensive emotion models are foundational for developing real-world affective computing applications, this work has broad implications in social robotics, human-machine interaction, mental healthcare, computational psychology, and entertainment.},
  keywords={Emotion recognition;Computational modeling;Affective computing;Psychology;Biological system modeling;Appraisal;Annotations;Basic emotions;emotion theory;modeling human emotion;multilingual emotion models;natural language;psychology;statistical clustering},
  doi={10.1109/TAFFC.2023.3324902},
  ISSN={1949-3045},
  month={July},}@INPROCEEDINGS{9991737,
  author={Gerczuk, Maurice and Triantafyllopoulos, Andreas and Amiriparian, Shahin and Kathan, Alexander and Bauer, Jonathan and Berking, Matthias and Schuller, Björn},
  booktitle={2022 E-Health and Bioengineering Conference (EHB)}, 
  title={Personalised Deep Learning for Monitoring Depressed Mood from Speech}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={We utilise a longitudinal dataset of 17 526 speech samples collected from 30 patients with major depressive disorder and 11 sub-clinically depressed individuals to perform a personalised prediction of depressed mood. The data has been recorded via a smartphone app over a two-week ecological momentary assessment with three recording sessions per day. Each session's speech samples are accompanied by a self-assessed rating on the discrete visual analogue mood scale (VAMS) from 0-10. As these ratings are highly subjective, a personalised machine learning method is leveraged. For this purpose, the beginning of the recording period is utilised to train both a shared model backbone, and adapt personalised layers added at the end to each speaker's speech. Our approach yields a Spearman's correlation coefficient (p) of 0.79 on the test set, compared to the non-personalised baseline of p=0.61. Furthermore, we analyse our results with regard to the type of speech sample - reading three depression-related questions, answering them, and freely formulating an uplifting spontaneous thought. Here, we find that personalisation boosts performance across all types, especially for the fixed content question readings. Overall, our work highlights the efficacy of personalised machine learning for depressed mood monitoring.},
  keywords={Deep learning;Emotion recognition;Visualization;Mood;Biological system modeling;Speech recognition;Depression;computational paralinguistics;digital health;depression;personalisation},
  doi={10.1109/EHB55594.2022.9991737},
  ISSN={2575-5145},
  month={Nov},}@INPROCEEDINGS{4639172,
  author={Yingxu Wang},
  booktitle={2008 7th IEEE International Conference on Cognitive Informatics}, 
  title={The cognitive processes of analysis and synthesis in formal inferences}, 
  year={2008},
  volume={},
  number={},
  pages={223-231},
  abstract={Analyses and syntheses are a pair of fundamental cognitive processes at the meta-inference layer of the brain. This paper presents the cognitive processes of analysis and synthesis as a part of the brain’s inference mechanisms. The cognitive foundations of analysis and synthesis are explored, and their mathematical models are created in concept algebra and system algebra by concept and/or system decomposition, composition, specification, and aggregation. Based on the cognitive and mathematical models, the cognitive processes of analysis and synthesis are formally described in Real-Time Process Algebra (RTPA). The formal modeling and rigorous explanation of this pair of cognitive processes for formal inference reveal a part of the mechanisms of the brain as modeled in the Layered Reference Model of the Brain (LRMB).},
  keywords={Cognitive informatics;the brain;LRMB;cognitive models;cognitive processes;mathematical models;denotational mathematics;concept lagbera;system algebra;RTPA;computational intelligence;AI;inference},
  doi={10.1109/COGINF.2008.4639172},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8441824,
  author={Hwang, Jungsik and Tani, Jun},
  booktitle={2018 15th International Conference on Ubiquitous Robots (UR)}, 
  title={A Dynamic Neural Network Approach to Generating Robot's Novel Actions: A Simulation Experiment}, 
  year={2018},
  volume={},
  number={},
  pages={355-361},
  abstract={In this study, we investigate how a robot can generate novel and creative actions from its own experience of learning basic actions. Inspired by a machine learning approach to computational creativity, we propose a dynamic neural network model that can learn and generate robot's actions. We conducted a set of simulation experiments with a humanoid robot. The results showed that the proposed model was able to learn the basic actions and also to generate novel actions by modulating and combining those learned actions. The analysis on the neural activities illustrated that the ability to generate creative actions emerged from the model's nonlinear memory structure self-organized during training. The results also showed that the different way of learning the basic actions induced the self-organization of the memory structure with the different characteristics, resulting in the generation of different levels of creative actions. Our approach can be utilized in human-robot interaction in which a user can interactively explore the robot's memory to control its behavior and also discover other novel actions.},
  keywords={Robots;Encoding;Neurons;Training;Neural networks;Predictive models;Computational modeling},
  doi={10.1109/URAI.2018.8441824},
  ISSN={},
  month={June},}@INPROCEEDINGS{8632306,
  author={Hofmann, Marko A. and Meyer-Nieberg, Silja and Uhlig, Tobias},
  booktitle={2018 Winter Simulation Conference (WSC)}, 
  title={INFERENTIAL STATISTICS AND SIMULATION GENERATED SAMPLES: A CRITICAL REFLECTION}, 
  year={2018},
  volume={},
  number={},
  pages={479-490},
  abstract={A review of recently published papers demonstrates: simulation practitioners apply the standard methods of inferential and descriptive statistics for their reasoning with simulation generated samples without much critical reflection. Yet, simulation-generated samples differ in important aspects from empirical samples, for which the standard statistical methods have been developed. Simulation models do have inherent epistemic and computational limits for replication that do not exist with empirical data sets. Consequently, neither is simulation-based data generation the same as the collection of empirical data nor is the analysis of synthetic data equally beneficial as of empirical data. These differences are much more fundamental for computer simulation than the problems of specific techniques of inferential statistics which have been criticized recently. If simulation generated data is used for testing research hypotheses the core issue is not the method of statistical reasoning but the assurance of what might be called evidential content.},
  keywords={Computational modeling;Analysis of variance;Standards;Atmospheric modeling;Analytical models;Data models},
  doi={10.1109/WSC.2018.8632306},
  ISSN={1558-4305},
  month={Dec},}
