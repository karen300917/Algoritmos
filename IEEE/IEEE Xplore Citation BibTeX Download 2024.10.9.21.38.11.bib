@INPROCEEDINGS{6891883,
  author={Molnárka, Gergely I. and Kovács, Szilveszter and Kóczy, László T.},
  booktitle={2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, 
  title={Fuzzy rule interpolation based fuzzy signature structure in building condition evaluation}, 
  year={2014},
  volume={},
  number={},
  pages={2214-2221},
  abstract={The complexity of the residential house structures makes their condition evaluation difficult. Taking the human experts' thinking into consideration the linguistic approach seems reasonable, therefore the fuzzy set theory may provide a basis for creating an expert system. In practice, the assessment of some predefined attributes of building components may give a comprehensive value about the condition of the examined building on a relative scale. The data structure of building evaluation procedure makes clear that the fuzzy signature structure is helpful in analysis. The numerous building components that determine the character of the given building can turn to an unnecessarily large rule-base. The fuzzy rule interpolation and the corresponding sparse fuzzy rule-based knowledge representation could be a reasonably efficient structure for handling the building evaluation procedure. In this paper the fuzzy rule interpolation as a novel aggregation method in fuzzy signature structures is proposed. Its application is presented with a case study of roof structure evaluation of a classic urban-type residential house located in a historic district of Budapest, Hungary.},
  keywords={Buildings;Maintenance engineering;Interpolation;Vectors;Pragmatics;Radio frequency;Standards},
  doi={10.1109/FUZZ-IEEE.2014.6891883},
  ISSN={1098-7584},
  month={July},}@INPROCEEDINGS{10084967,
  author={Abraham, Juby and Cherian, George Joseph and Jayapandian, N.},
  booktitle={2023 Second International Conference on Electronics and Renewable Systems (ICEARS)}, 
  title={Systematic Review on Humanizing Machine Intelligence and Artificial Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={1092-1097},
  abstract={In this era, Machine Learning is transforming human lives in a very different way. The need to give machines the power to make decisions or giving the moral compass is a big dilemma when humanity is more divided than it has ever been. There are two main ways in which law and AI interact. AI may be subject to legal restrictions and be employed in courtroom procedures. The world around us is being significantly and swiftly changed by AI in all of its manifestations. Public law includes important facets such as nondiscrimination law and labor law. In a manner similar to this when artificial intelligence (AI) is applied to tangible technology like robots. In certain cases, artificial intelligence (AI) might be hardly noticeable to customers but evident to those who built and are using it. The behavior research offers suggestions for how to build enduring and beneficial interactions between intelligent robots and people. The human improvement is main obstacles in the development and implementation of artificial intelligence. Best practices in this area are not governed by any one strategy that is generally acknowledged. Machine learning is about to revolutionize society as it is know it. It is crucial to give intelligent computers a moral compass now more than ever before because of how divided mankind is. Although machine learning has limitless potential, inappropriate usage might have detrimental long-term implications. It will think about how, for instance, earlier cultures built trust and improved social interactions via creative answers to many of the ethical issues that machine learning is posing now.},
  keywords={Ethics;Renewable energy sources;Systematics;Law;Machine learning;Regulation;Behavioral sciences;Artificial Intelligence;Cognitive Intelligence;Machine Learning;Humanizing;Social Interactions;},
  doi={10.1109/ICEARS56392.2023.10084967},
  ISSN={},
  month={March},}@ARTICLE{7258498,
  author={Zhao, Qiangfu and Brine, John and Filev, Dimitar P.},
  journal={IEEE Systems, Man, and Cybernetics Magazine}, 
  title={Defining Cybernetics: Reflections on the Science of Governance}, 
  year={2015},
  volume={1},
  number={2},
  pages={18-26},
  abstract={In this article, we have reconsidered the meaning of cybernetics and provided a taxonomy that can be useful for us to understand various cybernetics more clearly. We have also investigated some fundamental properties of governable or self-governable distributed systems. In particular, we believe that ontology plays a key role for a distributed system to become governable or even self-governable. We think that automatic construction of a good ontology in a distributed system is an interesting topic for further study. In fact, constructing a good ontology for a mobile communication network, a social network, a traffic control network, and any network related to our daily lives is important to make the network governable, safe, and secure. For large-scale distributed systems (e.g., the Internet), certain self-governability is also indispensable for the network to be more reliable or dependable. Of course, full self-governability of these systems may not be expected from the point of view of human beings.},
  keywords={Cybernetics;Ontologies;Governance;Internet;Control systems},
  doi={10.1109/MSMC.2015.2421325},
  ISSN={2333-942X},
  month={April},}@INPROCEEDINGS{9590227,
  author={Chang, Carl K. and Ceravolo, Paolo and Chang, Rong N. and Helal, Sumi and Jin, Zhi and Liu, Xuanzhe and Ming, Hua},
  booktitle={2021 IEEE International Conference on Web Services (ICWS)}, 
  title={Software Services Engineering Manifesto - A Cross-Cutting Declaration}, 
  year={2021},
  volume={},
  number={},
  pages={703-709},
  abstract={As we have entered the Internet-of-Things (IoT) era, further blessed with rapid advances in several key technological areas including DevOps, AI/ML, 5G/6G/, neurocomputing, to name a few, it is imperative we think big and aim high. This new venture will require professionals in both software engineering and services computing to collaborate with an unprecedented intensity, and jointly develop the new interdisciplinary field hereby named Software Services Engineering (SSE). In SSE, the ever-deepening system dynamics emerging from both environments and humans in varying contexts are imposing steep challenges to both researchers and practitioners. Humans, both developers and the vast number of end users, are embedded ever closer to IoT environments, and are being afforded ample opportunities to continuously inject inputs during system development and after deployment. In fact, humans are increasingly playing the roles of both sensor and actuator. Traditional requirements engineering researchers are being lured more than ever into exploiting the IoT environments where human users are deeply embedded, to gather contextual information that inevitably introduces lots of ambiguity and uncertainty. Provisioning of highly adaptable and scalable microservices would be key to timely meeting ever-changing human desires and ever-evolving system requirements in the nimblest manner. As such, an ultra-agile and field-programmable development methodology and environment will be imperative to achieving such ultrafine grained microservices provisioning. Such ultra-agility and ultrafine granularity requirements imposed to the services industry obligate company executives to expect extreme manageability assurance to become the centroid of system operations and administration. The ultimate goal in pursuit of such a noble dream will be to provide genuinely individualized and trustworthy service, possibly enabled by AI, but it should be both explainable and ethical. Facing such grand challenges, this declaration samples a subset of burning issues in SSE through observations in seven themes, only meant to be starting points for the SSE community to further investigate. Through our declarations we also call for heightened attention to an assorted array of existing, barely emerging or non-existent services computing and software engineering methods for a concerted effort to research and explore.},
  keywords={Industries;Ethics;Uncertainty;Web services;System dynamics;Systems operation;Service computing;agile;AI;context-aware;DevOps;IoT;microservice;ML;requirements engineering;services computing;situation-aware;software engineering;software services engineering;uncertainty},
  doi={10.1109/ICWS53863.2021.00014},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{7757589,
  author={Martin, Christopher R. and Moore, Jacob P. and Ranalli, Joseph A.},
  booktitle={2016 IEEE Frontiers in Education Conference (FIE)}, 
  title={Teaching the foundations of thermodynamics with PYro}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={One of the key skills developed in foundational thermodynamics courses is obtaining property and state data for various substances of interest. Typically, students are instructed to perform this task through the use of tables or computer software. In this paper, we present and evaluate modules for teaching the foundations of thermodynamics using free open-source software intended to port to students' professional lives. The approach introduces the PYro thermodynamic property calculator. PYro is implemented in Python, which is free and available on most widely used platforms. PYro is clearly documented, and all data are readily traceable to reputable sources. Most of the data describe ideal gases from the NIST JANAF database, but there is also support for mixtures (such as air) and multiphase substances (such as steam). The interface design makes the software appropriate to most tasks in introductory and intermediate thermodynamics courses without requiring proficiency in the Python language. While the idea of using software to teach thermodynamics is far from new, commercial software usually comes at a substantial price and places the implementation burden on the instructor. On the other hand, educational software rarely transitions into students' professional lives. This paper proposes a model for productively separating the development of skills (like table look-ups) from knowledge and concepts. In addition to an introduction of the tool, this paper provides results of preliminary evaluation conducted within a thermodynamics classroom. The authors developed a learning module demonstrating the use of PYro to compute states for an ideal Brayton cycle. Students were tasked with performing parametric analysis on the cycle, by varying various limiting factors (e.g. combustor pressure, turbine inlet temperature). Students were asked to compare power produced and cycle efficiency computed under these conditions. At the end of the module, students were surveyed about the experience of working with the software. Evaluation is provided in the form of instructor and student feedback from a classroom implementation. We propose that this utilization of the tool demonstrates its ability to promote higher-level cognitive thinking in problem solving, removing the time intensive task of performing table look-ups and allowing them to focus on more holistic questions of cycle performance.},
  keywords={Software;Thermodynamics;Calculators;Education;Temperature;Chemicals;Documentation},
  doi={10.1109/FIE.2016.7757589},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10283649,
  author={Bozkaya, Elif and Canberk, Berk and Schmidt, Stefan},
  booktitle={2023 IEEE International Conference on Communications Workshops (ICC Workshops)}, 
  title={Digital Twin-Empowered Resource Allocation for 6G-Enabled Massive IoT}, 
  year={2023},
  volume={},
  number={},
  pages={727-732},
  abstract={6G technology is expected to lead to an unpredictable increase of Internet of Things (IoT) devices. The need for maintaining continuous connectivity of these devices has in turn led to re-thinking of the traditional design of wireless networks. In particular, the integration of 6G and Digital Twin (DT) is expected to reshape the network management as it offers powerful features in design, development and optimization processes. DT is a digital representation of physical entities, which are designed around a two-way information flow. Therefore, this technology not only collects data, and employs intelligent learning methods by performing complex computations, but it also can send feedback to improve system performance for 6G-enabled massive IoT. However, deploying such a technology requires addressing complex challenges such as limited resources, seamless connectivity and lack of trust between end users and network edge. To address these challenges, we formulate the resource allocation problem including edge computation and service migration in 6G-enabled massive IoT. The contributions are threefold: First, our DT-empowered architecture is proposed that uses the real-time and historical data from end users to find the best allocation at a user. Second, it studies the impact of trust relationship between computing entities to prevent the unauthorized accesses and provides an authentication procedure. Third, it describes a Multi-Agent Reinforcement Learning (MARL) algorithm that consists of cooperative agents and aims to find the best resource allocation strategy by minimizing task processing latency. We validate the proposed DT-empowered architecture to show the reduced processing latency compared to traditional benchmark methods.},
  keywords={6G mobile communication;Conferences;Wireless networks;Authentication;Computer architecture;Benchmark testing;Digital twins},
  doi={10.1109/ICCWorkshops57953.2023.10283649},
  ISSN={2694-2941},
  month={May},}@INPROCEEDINGS{7568426,
  author={Saxena, Gaurav and Jimack, Peter K. and Walkley, Mark A.},
  booktitle={2016 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={A cache-aware approach to domain decomposition for stencil-based codes}, 
  year={2016},
  volume={},
  number={},
  pages={875-885},
  abstract={Partial Differential Equations (PDEs) lie at the heart of numerous scientific simulations depicting physical phenomena. The parallelization of such simulations introduces additional performance penalties in the form of local and global synchronization among cooperating processes. Domain decomposition partitions the largest shareable data structures into sub-domains and attempts to achieve perfect load balance and minimal communication. Up to now research efforts to optimize spatial and temporal cache reuse for stencil-based PDE discretizations (e.g. finite difference and finite element) have considered sub-domain operations after the domain decomposition has been determined. We derive a cache-oblivious heuristic that minimizes cache misses at the sub-domain level through a quasi-cache-directed analysis to predict families of high performance domain decompositions in structured 3-D grids. To the best of our knowledge this is the first work to optimize domain decompositions by analyzing cache misses - thus connecting single core parameters (i.e. cache-misses) to true multicore parameters (i.e. domain decomposition). We analyze the trade-offs in decreasing cache-misses through such decompositions and increasing the dynamic bandwidth-per-core. The limitation of our work is that currently, it is applicable only to structured 3-D grids with cuts parallel to the Cartesian Axes. We emphasize and conclude that there is an imperative need to re-think domain decompositions in this constantly evolving multi-core era.},
  keywords={Optimization;Jacobian matrices;Topology;Program processors;Load modeling;Mathematical model;Computer architecture;PDEs;Domain Decomposition;Stencil;Quasi-cache-directed;Cache-oblivious},
  doi={10.1109/HPCSim.2016.7568426},
  ISSN={},
  month={July},}@INPROCEEDINGS{7963441,
  author={Gong, Weibo and Ho, Yu-Chi},
  booktitle={2017 American Control Conference (ACC)}, 
  title={On fast retrieval of relational experiences}, 
  year={2017},
  volume={},
  number={},
  pages={3206-3211},
  abstract={Various intelligent systems are needed for cyber-physical systems. Such intelligent systems need to learn from the human intelligence about concept abstraction and analogical thinking in order to resolve complex issues using past experiences. The algorithms for abstraction and analogies are based on quick memory recall with clever information coding and processing. The quick and accurate memory recall is based on the fact that the memory mostly records the relations among the constituents of the stimulating signals, rather than the constituents themselves. Relational memories can be stored in the form of networks of neuron clusters capable of resonating to particular signal sequences. However, similarity testing for such network representations is difficult. We suggest that linear dynamic systems that relate the system matrix and the output time function can be used as a conversion mechanism between the network matrix and the temporal representations of the signals. This leads to algorithms for relational similarity testing and concept abstraction. Transient behavior based selection rules in ordinal optimization is important in achieving quickness in our development.},
  keywords={Resonant frequency;Transient analysis;Resonators;Intelligent systems;Signal processing;Computers;Neurons},
  doi={10.23919/ACC.2017.7963441},
  ISSN={2378-5861},
  month={May},}@ARTICLE{9829550,
  author={Heinonen, Henri T. and Semenov, Alexander and Veijalainen, Jari and Hämäläinen, Timo},
  journal={IEEE Access}, 
  title={A Survey on Technologies Which Make Bitcoin Greener or More Justified}, 
  year={2022},
  volume={10},
  number={},
  pages={74792-74814},
  abstract={According to recent estimates, one bitcoin transaction consumes as much energy as 1.5 million Visa transactions. Why is bitcoin using so much energy? Most of the energy is used during the bitcoin mining process, which serves at least two significant purposes: a) distributing new cryptocurrency coins to the cryptoeconomy and b) securing the Bitcoin blockchain ledger. In reality, the comparison of bitcoin transactions to Visa transactions is not that simple. The amount of transactions in the Bitcoin network is not directly connected to the amount of bitcoin mining power nor the energy consumption of those mining devices; for example, it is possible to multiply the number of bitcoin transactions per second without increasing the mining power and the energy consumption. Bitcoin is not only “digital money for hackers”. It has very promising future potential as a global reserve currency and a method to make the World Wide Web (WWW) immune to cyberattacks such as the Distributed Denial-of-Service attacks. This survey approached cryptocurrencies’ various technological and environmental issues from many different perspectives. To make various cryptocurrencies, including bitcoin (BTC) and ether (ETH), greener and more justified, what technological solutions do we have? We found that cryptocurrency mining might be cleaner than is generally expected. There is also a plan to make a vast renewable energy source available by combining Ocean Thermal Energy Conversion and Bitcoin mining. There are plans to use unconventional computing methods (quantum computing, reversible computing, ternary computing, optical computing, analog computing) to solve some of the issues regarding the vast energy consumption of conventional computing (including cryptocurrency mining). We think using spare computing cycles for grid computing efforts is justified. For example, there are billions of smartphones in the world. Many smartphones are being recharged every day. If this daily recharging period of twenty to sixty minutes would be used for grid computing, for example, finding new cures to cancer, it would probably be a significant breakthrough for medical research simulations. We call on the cryptocurrency communities to research and develop grid computing and unconventional computing methods for the most significant cryptocurrencies: bitcoin (BTC)and ether (ETH).},
  keywords={Bitcoin;Blockchains;Green products;Energy consumption;Air pollution;Peer-to-peer computing;Grid computing;Blockchain;DLT;cryptocurrency;bitcoin;green technology;sustainability;unconventional computing;climate change},
  doi={10.1109/ACCESS.2022.3190891},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{1716070,
  author={Takeuchi, J. and Shouno, O. and Tsujino, H.},
  booktitle={The 2006 IEEE International Joint Conference on Neural Network Proceedings}, 
  title={Connectionist Reinforcement Learning with Cursory Intrinsic Motivations and Linear Dependencies to Multiple Representations}, 
  year={2006},
  volume={},
  number={},
  pages={54-61},
  abstract={A significant feature of brain intelligence is flexibility. This is generally lacking in current machine intelligence We think that learning that effectively uses the combination of multiple information representations is the key to constructing flexible machine intelligence. This hypothesis is demonstrated by means of a simple connectionist model of intrinsically motivated reinforcement learning. A linear approximation of reward functions that depends on multiple representations is engaged in our model. We show preliminary results for a model network that enables a flexible learning response to several different situations. Multiple representations in our model accelerate the learning not only in complex situations that need many kinds of information, but also in simple situations.},
  keywords={Basal ganglia;Machine intelligence;Intelligent sensors;Animals;Brain modeling;Learning systems;Intelligent systems;Decision making;Machine learning;Information representation},
  doi={10.1109/IJCNN.2006.246659},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10019495,
  author={Wei, Ming-Liang and Lue, Hang-Ting and Ho, Shu-Yin and Lin, Yen-Po and Hsu, Tzu-Hsuan and Hsieh, Chih-Chang and Li, Yung-Chun and Yeh, Teng-Hao and Chen, Shih-Hung and Jhu, Yi-Hao and Li, Hsiang-Pang and Hu, Han-Wen and Hung, Chun-Hsiung and Wang, Keh-Chung and Lu, Chih-Yuan},
  booktitle={2022 International Electron Devices Meeting (IEDM)}, 
  title={Analog Computing in Memory (CIM) Technique for General Matrix Multiplication (GEMM) to Support Deep Neural Network (DNN) and Cosine Similarity Search Computing using 3D AND-type NOR Flash Devices}, 
  year={2022},
  volume={},
  number={},
  pages={33.3.1-33.3.4},
  abstract={The massively increasing data in computing world inspires the R&D of novel memory-centric computing architectures and devices. In this work, we propose a novel analog CIM technique for GEMM using 3D NOR Flash devices to support general-purpose matrix multiplication. Our analysis indicates that it’s very robust to use “billions” of memory cells with modest 4-level and large-spacing analog Icell to produce good accuracy and reliability, contrary to the past thinking to pursue many levels in each memory cell that inevitably suffers accuracy loss. We estimate that a 2.7Gb 3D NOR GEMM can provide a high-performance (frame/sec>300) image recognition inference of ResNet-50 on ImageNet dataset, using a simple flexible controller chip with 1MB SRAM without the need of massive ALU and external DRAM. The accuracy can maintain ~85% for Cifar-10 (by VGG7), and ~90% for ImageNet Top-5 (by ResNet-50) under good device control. This 3D NOR GEMM enjoys much lower system cost and flexibility than a complicated SOC. We also propose an operation and design method of “Cosine Similarity” computing using the 3D NOR. We can use a ternary similarity search algorithm with positive and negative inputs and weights to perform high-dimension feature vector (such as 512 for face recognition with FaceNet on VGGFace2 dataset) similarity computing in a high-parallelism CIM design (512 WL inputs, 1024 BL’s, at Tread=100ns). High-accuracy search (~97.8%, almost identical to 98% of software computing) and high internal search bandwidth (~5Tb/s per chip) are achieved. This in-Flash search accelerator is potential to enable new hardware-aware search algorithms in big data retrieval applications.},
  keywords={Performance evaluation;Three-dimensional displays;Software algorithms;Neural networks;Memory architecture;Random access memory;Common Information Model (computing)},
  doi={10.1109/IEDM45625.2022.10019495},
  ISSN={2156-017X},
  month={Dec},}@INPROCEEDINGS{5168916,
  author={Song, Chengqi and Zhang, Qian},
  booktitle={2009 6th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks}, 
  title={COFFEE: A Context-Free Protocol for Stimulating Data Forwarding in Wireless Ad Hoc Networks}, 
  year={2009},
  volume={},
  number={},
  pages={1-9},
  abstract={Reputation based and credit-exchange based approaches have been studied extensively to enforce cooperation among non-cooperative nodes in wireless ad hoc networks. Most of the existing solutions are fundamentally context-based ones, which need to accurately identify selfish behaviors, securely maintain the context, and appropriately punish the selfish nodes. These requirements are extremely difficult to satisfy if not impossible. From a completely new angle, this paper proposes a context-free protocol, COFFEE, to enforce cooperation among selfish nodes, which has the ability to transmit a packet over the path successfully without the dependency on the information of other packets' transmission. Considering that every node in the network is rational, during the packet forwarding stage, if the intermediate nodes can not clearly tell whether the packet is destined to them or not, they can not simply drop the packet. Thus, in our proposed COFFEE protocol, through introducing several techniques, for any packet received by any node, the node thinks the packet could be destined to it and forwards the packet to find out the answer. Detailed analysis and performance evaluation have been conducted to demonstrate the effectiveness of the proposed protocol.},
  keywords={Wireless application protocol;Mobile ad hoc networks;Peer to peer computing;Ad hoc networks;Bandwidth;Batteries;Communications Society;Context;Performance analysis;Routing},
  doi={10.1109/SAHCN.2009.5168916},
  ISSN={2155-5494},
  month={June},}@INPROCEEDINGS{6618763,
  author={Celesti, Antonio and Fazio, Maria and Villari, Massimo and Puliafito, Antonio and Mulfari, Davide},
  booktitle={2013 World Congress on Computer and Information Technology (WCCIT)}, 
  title={Remote and deep attestations to mitigate threats in Cloud Mash-Up services}, 
  year={2013},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing is an emerging technology able to offer a plethora of new advanced services. Cloud operators can use and combine such services in order to build new Mash-up Cloud platform and applications. However, security issues have strongly limited the large-scale adoption of Cloud computing, especially in business environments and similar application scenarios, where sensitive date need to be protected. At the same time the Trusted Computing technology is bringing a new way of thinking about security of systems. This paper deals with the importance to leverage the Trusted Computing for encouraging the development of secure distributed Mash-up Cloud services. We show how the Remote and Deep Attestation protocols make secure both the physical hosts and the virtual machines in a Cloud infrastructure, providing a solid framework for the deployment of federated environments.},
  keywords={Principal component analysis;Software;Servers;Hardware;Virtual machine monitors;Malware;Cloud Computing;Trusted Computing;Deep Attestation;Virtual Machine;PaaS;Federation},
  doi={10.1109/WCCIT.2013.6618763},
  ISSN={},
  month={June},}@ARTICLE{10330580,
  author={Huang, Yuhong and Sun, Qi and Li, Nan and Chen, Ziqi and Huang, Jinri and Ding, Haiyu and Ⅰ, Chih-Lin},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={Validation of Current O-RAN Technologies and Insights on the Future Evolution}, 
  year={2024},
  volume={42},
  number={2},
  pages={487-505},
  abstract={Entering the 5G era, the mobile network operators (MNO) are facing greater challenges in providing services cost effectively than any other previous generations. The potential solutions to this are lying on the emerging trend of deep convergence of information technology (IT), communication technology (CT) and data technology (DT). In particular, the O-RAN technology, the representation of such ICDT convergence and proposed by the O-RAN ALLIANCE in 2018, is transforming Radio Access Networks towards a new paradigm featuring openness, cloudification and intelligence. O-RAN has gained huge attention from both industry and academia since its inception. In this paper, we presented the recent endeavors from China Mobile, including our deployment scenarios, various test results from open fronthaul, cloud platform to the intelligent controller. Our rich and comprehensive tests have demonstrated the viability and superiority of current O-RAN technologies. Furthermore, we also provide our deep thinking on the O-RAN future evolution in order to better serve the emerging applications such as Metaverse, cloud extended-reality (XR), extensive enterprise private 5G verticals and so on.},
  keywords={Computer architecture;Hardware;5G mobile communication;Synchronization;Cloud computing;Testing;Microprocessors;O-RAN;cloudification;RAN intelligent controller;prototype;field trial},
  doi={10.1109/JSAC.2023.3336180},
  ISSN={1558-0008},
  month={Feb},}@INPROCEEDINGS{8342098,
  author={Chang, Wanli and Roy, Debayan and Hu, Xiaobo Sharon and Chakraborty, Samarjit},
  booktitle={2018 Design, Automation & Test in Europe Conference & Exhibition (DATE)}, 
  title={Cache-aware task scheduling for maximizing control performance}, 
  year={2018},
  volume={},
  number={},
  pages={694-699},
  abstract={Embedded control applications are widely implemented on small, low-cost and resource-constrained microcontrollers, e.g., in the automotive domain. Conventionally, control algorithms are designed using model-based approaches, without considering the details of the implementation platform. This leads to inefficient utilization of the resources. With the emergence of the cyber-physical system (CPS)-oriented thinking, there has lately been a strong interest in co-design of control algorithms and their implementation platforms. Some recent efforts have shown that a schedule on multiple applications with more on-chip cache reuse is able to improve the control performance. However, it has not been studied how the control performance can be maximized for a given schedule and how an optimal schedule can be computed. In this work, we propose a two-stage framework to compute the schedule maximizing the overall control performance of all the applications. First, a holistic controller design taking all the sampling periods and sensing-to-actuation delays in a schedule into account is presented, aiming to maximize the overall control performance. Second, a hybrid search algorithm for discrete decision space is reported to efficiently compute an optimal schedule. Experimental results on a case study with multiple automotive applications show that a significant improvement of 10-20% in control performance can be achieved by the proposed cache-aware scheduling approach.},
  keywords={Schedules;Task analysis;Sensors;Optimal scheduling;Control systems;Delays;Feedback control},
  doi={10.23919/DATE.2018.8342098},
  ISSN={1558-1101},
  month={March},}@INPROCEEDINGS{8601794,
  author={bin, First Li Guo and rong, Zhou Fang and Gang, Luo and Hong, Yu and chao, Qian Guo and Liangchi, Shi and En, Yang and Xiang, Li},
  booktitle={2018 International Conference on Power System Technology (POWERCON)}, 
  title={A Research Of Drawing And Application Of Distribution Diagram Of Yunnan Ice Region Based On The Typical Ice Model Of Low Latitude Plateau Area}, 
  year={2018},
  volume={},
  number={},
  pages={3440-3447},
  abstract={The international study of ice model mainly from the perspective of meteorology fluid mechanics, thermodynamics transmission line conductor and insulator ice mechanism research study of ice prediction model has been developed from Lenhard Kuoiwa simple conceptual model development experience model to Makkonen complex concept model and glaze rime hybrid numerical calculation model of freeze. Yunnan province is located in China's southwest, rolling within the territory of mountains, rivers, topography is complex, three-dimensional climate significantly, in climate resource is rich, meteorological disaster is frequent, influenced by monsoon climate, the prevalence of micro topography and microclimate characteristics; Yunnan line ice distribution characteristics of eastern Yunnan, Yunnan north southeast Yunnan wire ice mainly for glaze rime and mixed freezing, and northwest Yunnan is mainly for adhesion wet snow Is one of the areas hit hardest by the ice. Ice distribution can reflect the grid of ice in the area of distribution, further guidance inspect heavy ice monitoring and transmission lines deicing ice design application, reduce line ice disaster accident economic loss caused by ice, improve power grid ice resistance ability and the power supply reliability,This paper comprehensive analysis the Yunnan plateau region, the transmission lines ice distribution factors such as geographic conditions, climate type and on-the-spot investigation to collect typical data grid severe ice disaster in 2008, 1983, in ice model research results at home and abroad for reference, combining with the actual situation of Yunnan in northeast Yunnan, the corresponding ice model is constructed, This paper proposes a new model of ice coating in Yunnan province, which is suitable for studying the new ice model in Yunnan province. Detected in the weather station data for statistical analysis, using the computer on hd electronic topographic map, inductive areas of Yunnan power grid ice distribution, and taken as the basis of the division of ice, ice zoning map of different return period. Through in the new 500Kv DE Maoxian gold officer lines before the field site engineering feasibility study stage, according to the project line to choose the line path, in the ”Yunnan power grid ice distribution” to the first line of the path optimization and avoid ice marked lines need to focus on the path to the investigation of the ice area, fully do sufficient preparation before departure, greatly reduced the time of field reconnaissance, time reduced by about 1/3 of the original, but also improve the working efficiency and the quality of the project. Because Yunnan province special landform, geography, weather, climate, micro topography, and micro climate is numerous, Draught place, pass, canyons, air duct, windward area can cause tiny terrain conductor ice serious increase in local area, these areas of ice thickness can't, according to a broader range of meteorological data to determine when ice districts so the two ”micro” edit, finally get reasonable ice figure. Field test comparison test with many times, think theory model calculated results and the results have some discrepancy, but after altitude elevation and atmospheric circulation, the correction ”micro” two conditions, the result basically reflects the east and northeast Yunnan, Yunnan mountainous terrain upheaval and three-dimensional climate characteristics, the theory research of ice model is more reasonable. Through typical ice model, put forward a preliminary mastered the typical transmission line low latitude plateau area in Yunnan the formation law of ice, ice in Yunnan region distribution simultaneously provide basic data and model support, increased the application of ”practicality”. But transmission lines ice cover is a and the complex of the atmospheric physical processes, at the same time and the topography distribution and climate change have bigger relationship, must continue to carry out the statistical analysis of the actual ice, perfecting the model calculation model and the distribution of its ice.},
  keywords={Analytical models;Power transmission lines;Statistical analysis;Atmospheric modeling;Surfaces;Predictive models;Ice;Ice covering model;Yunnan region;Characteristics of ice;Distribution characteristics;The practical application},
  doi={10.1109/POWERCON.2018.8601794},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{4076980,
  author={Griffith, Doug},
  booktitle={2007 40th Annual Hawaii International Conference on System Sciences (HICSS'07)}, 
  title={Neo-symbiosis: A Conceptual Tool for System Design}, 
  year={2007},
  volume={},
  number={},
  pages={294b-294b},
  abstract={In 1960 Licklider advanced the notion of symbiosis between humans and computers that would think as no human brain has ever thought. This paper updates Licklider 's vision of symbiosis and recasts it into current theories of cognition. This updated version of Licklider's vision is termed neo-symbiosis. Kahneman's notion of two processing systems provides a useful theoretical framework for capturing both expertise and information processing biases. System 1, termed intuition, is fast and effortless. It is simultaneously the source of much human expertise, while also being the locus of cognitive and perceptual illusions. System 2, termed reasoning, is the locus of rational thought. It also has the task of monitoring System 1 output. Computers need to support System 2 processing. A neo-symbiotic design philosophy is presented followed by an illustrative example. Evaluative metrics are discussed. It is concluded that even absent evaluation metrics, neo-symbiosis provides a desirable design goal},
  keywords={Symbiosis;Humans;Usability;Man machine systems;Laboratories;Information systems;Cognition;Information processing;Computerized monitoring;Process design},
  doi={10.1109/HICSS.2007.397},
  ISSN={1530-1605},
  month={Jan},}@INPROCEEDINGS{5138215,
  author={Ruiting Yang and Gray, Douglas A. and Ng, Brian W. and Mingyi He},
  booktitle={2009 4th IEEE Conference on Industrial Electronics and Applications}, 
  title={Comparative analysis of signal processing in brain computer interface}, 
  year={2009},
  volume={},
  number={},
  pages={580-585},
  abstract={Brain computer interface (BCI) systems utilise Electroencephalography (EEG) to translate specific human thinking activities into control commands. An essential part of any BCI is a pattern recognition system. In this paper, a number of different features and classifiers are compared in terms of classification accuracy and computation time. Two typical features are studied: autoregressive (AR) and spectrum components along with three different classifiers; the K-nearest neighbor, linear discriminant analysis (LDA) and Bayesian statistical classifiers. The results showed that all classifiers achieved very high accuracies and short computation times.},
  keywords={Signal analysis;Signal processing;Brain computer interfaces;Electroencephalography;Rhythm;Signal processing algorithms;Feature extraction;Frequency;Pattern recognition;Humans;Electroencephalography (EEG);brain computer interface;feature;classifier},
  doi={10.1109/ICIEA.2009.5138215},
  ISSN={2158-2297},
  month={May},}@ARTICLE{9286505,
  author={Wang, Xiaoyi and Eiselmayer, Alexander and Mackay, Wendy E. and Hornbaek, Kasper and Wacharamanotham, Chat},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Argus: Interactive a priori Power Analysis}, 
  year={2021},
  volume={27},
  number={2},
  pages={432-442},
  abstract={A key challenge HCl researchers face when designing a controlled experiment is choosing the appropriate number of participants, or sample size. A priori power analysis examines the relationships among multiple parameters, including the complexity associated with human participants, e.g., order and fatigue effects, to calculate the statistical power of a given experiment design. We created Argus, a tool that supports interactive exploration of statistical power: Researchers specify experiment design scenarios with varying confounds and effect sizes. Argus then simulates data and visualizes statistical power across these scenarios, which lets researchers interactively weigh various trade-offs and make informed decisions about sample size. We describe the design and implementation of Argus, a usage scenario designing a visualization experiment, and a think-aloud study.},
  keywords={Fatigue;Tools;Human computer interaction;Statistics;Sociology;Task analysis;History;Experiment design;power analysis;simulation},
  doi={10.1109/TVCG.2020.3028894},
  ISSN={1941-0506},
  month={Feb},}@INPROCEEDINGS{10363466,
  author={Saxena, Divarshana and Bhowmik, Biswajit},
  booktitle={2023 IEEE International Conference on Recent Advances in Systems Science and Engineering (RASSE)}, 
  title={Paradigm Shift From Monolithic to Microservices}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Microservices have been making waves among forward-thinking application development organizations. In the realm of software development, software architecture holds paramount importance because it serves as a guiding force to shape the entire life cycle of a software system. Software architecture is a foundation for complex digital components built upon a software system. Within this domain, two prevalent paradigms, monolithic and service-oriented architecture (SOA), stand distinct. While monolithic simplifies development using its integrated structure, SOA reduces complexity through modular services. However, both paradigms suffer severe scalability, development cycle, and flexibility challenges. Subsequently, microservice architecture as a modern paradigm emerges to overcome these challenges. This paper presents an in-depth analysis of the paradigm shift from monolithic to microservice architecture. It begins with exploring the monolithic and SOA conceptual landscape and their pros and cons. After that, we delve into the microservice platform, including its basic architecture and implementation stages. Furthermore, we provide the trend of the paradigm shift that highlights the recent developments in the field and identifies the research challenges associated with it. Thus, the paper brings multiple research dimensions for the researchers and lets the software and application development teams improve resilience and expedite their time to market.},
  keywords={Technological innovation;Software architecture;Shape;Scalability;Microservice architectures;Time to market;Computer architecture;Monolithic Architecture;Service Oriented Architecture;Microservice Architecture;Deployment;Scalability},
  doi={10.1109/RASSE60029.2023.10363466},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{1611585,
  author={Beynon, W.M. and Boyatt, R.C. and Russ, S.B.},
  booktitle={Third International Conference on Information Technology: New Generations (ITNG'06)}, 
  title={Rethinking Programming}, 
  year={2006},
  volume={},
  number={},
  pages={149-154},
  abstract={The accepted view of programming, rooted in Turing's fundamental characterization of algorithms, has had a profound impact on the theory and practice of computing with yet broader implications for thinking about mind and culture. Where programming is traditionally conceived in terms of requirements, specification and implementation, this paper argues for a complementary conceptualization to support the development of the next generation of computing applications. It briefly reviews an extended programme of research into empirical modeling, an approach to creating interactive environments to enable programming based on identification and prescription},
  keywords={Application software;Pervasive computing;Functional programming;Concrete;Computer languages;Computer science;Computer applications;Constraint theory;Reliability engineering;History;programming;specification;identification;prescription},
  doi={10.1109/ITNG.2006.114},
  ISSN={},
  month={April},}@INPROCEEDINGS{6617433,
  author={Filev, Dimitar P. and Zhao, Qiangfu and Brine, John},
  booktitle={2013 IEEE International Conference on Cybernetics (CYBCO)}, 
  title={Cybernetics: Where shall we go?}, 
  year={2013},
  volume={},
  number={},
  pages={25-31},
  abstract={Cybernetics, as defined by Plato and later by Ampère is the science of governance. In the 1940s, Wiener used cybernetics as an umbrella term to refer to control and communication in both the animal and the machine. In the following decades, the term has been defined in various ways by different researchers, and because of this, cybernetics has been perceived rather negatively as a “nomad science”. Consequently, few people understand the true meaning of cybernetics. For the appropriate development of our field of research, we think it is necessary to re-consider the meaning and the scope of cybernetics, so that we can have a relatively clear mission in our research. In this paper, we try to provide a kind of governance message that might also be very weak, but nevertheless may be helpful for the cybernetics community to become cybernetic itself.},
  keywords={Cybernetics;Neurons;Animals;Ontologies;Vehicles;Organizations;Cybernetics;governance;self-governance;artificial intelligence;awareness;search;evolution},
  doi={10.1109/CYBConf.2013.6617433},
  ISSN={},
  month={June},}@INPROCEEDINGS{1530848,
  author={Jinlei Jiang and Shaohua Zhang and Yushun Li and Meilin Shi},
  booktitle={IEEE International Conference on Web Services (ICWS'05)}, 
  title={CoFrame: a framework for CSCW applications based on grid and Web services}, 
  year={2005},
  volume={},
  number={},
  pages={577},
  abstract={Though 20 years have passed since the birth of CSCW, the original goal of it is not reached as well as people expected. This situation is mostly due to the supporting technology especially the infrastructure. Today, great changes have taken place in technology, including grid computing and Web services. These technologies, we think, significantly affect the application of CSCW. In this paper, a framework called CoFrame is proposed to answer the challenges faced by CSCW. Based on the emerging grid and Web service technologies, CoFrame provides some general yet flexible cooperation related services and organizes them into different layers. The elaborately designed services and architecture make CoFrame adaptive to diverse requirements of different domains. The paper details the framework and demonstrates its application with a case study in e-learning.},
  keywords={Web services;Application software;Grid computing;Electronic learning;Costs;Protocols;Cooperative systems;Computer science;Computer architecture;Collaborative work;CSCW;Grid Computing;Web Services;ELearning},
  doi={10.1109/ICWS.2005.33},
  ISSN={},
  month={July},}@INPROCEEDINGS{1390730,
  author={Kumar, B.R. and Shanmugam, J. and Janarthanan, S. and Santhiseela, R.},
  booktitle={The 23rd Digital Avionics Systems Conference (IEEE Cat. No.04CH37576)}, 
  title={Development of expert system for the design of airborne equipment}, 
  year={2004},
  volume={2},
  number={},
  pages={6.C.4-61},
  abstract={This work focuses on the construction of an expert system shell for airborne equipment design. Traditional expert systems are constructed using a single monolithic software program for a specific application. Since the airborne equipment design is critical & complex, it demands the use of expert system technology. Since present aircrafts take in different equipments for different purposes, it is not feasible to think in terms of independently developed monolithic expert system program for each equipment. To overcome these problems, we have designed and developed a complex competent system i.e., a generic component based expert system for airborne equipment design. The main advantage of the component-based approach is that, the knowledge base is not hard coded and these components can be coupled with any domain-specific knowledge bases. The expert system with its expertise knowledge is made to guide the designer by providing design guidelines & testing procedures for the desired equipment. The expert system also audits the design and provides guidelines to modify & to improve the design.},
  keywords={Expert systems;Application software;Aerospace electronics;Weapons;Guidelines;System testing;Diagnostic expert systems;Process design;Software systems;Aircraft},
  doi={10.1109/DASC.2004.1390730},
  ISSN={},
  month={Oct},}@ARTICLE{6964896,
  author={Rojahn, T. and Lebsack, R. and Pavlovski, C.},
  journal={IBM Journal of Research and Development}, 
  title={Toward a computing workload classifier}, 
  year={2014},
  volume={58},
  number={5/6},
  pages={19:1-19:12},
  abstract={Midrange and mainframe computers have a history for supporting critical business systems. As businesses have adapted to technological changes, including the emergence of the Internet and the ubiquitous connectivity offered by mobile devices, these computers have evolved to support these trends. The availability of further server and deployment options such as x86 servers, virtualization, and cloud platforms have also presented compelling alternatives for some enterprises and their business applications. The emergence of these alternatives has challenged organizations to develop sound processes when deciding where to deploy IT applications. IT applications and supporting tools are generally referred to as workloads, and their placement is often based upon budgetary constraints rather than on a combined assessment of the qualities of service aspects such as service level, performance, security, and cost. We present an approach toward a workload classifier for several compute technologies that may assist system engineers and designers in their initial decisions of where to place particular workloads. This paper is not meant to be the final word in classifying workloads, but rather a step toward classification and to stimulate debate and thinking on the subject.},
  keywords={Computers;Internet;Ubiquitous computing;Information technology;Technology forecastig;Mobile communication;Business;Market research},
  doi={10.1147/JRD.2014.2352491},
  ISSN={0018-8646},
  month={Sep.},}@INPROCEEDINGS{8795793,
  author={Gong, Weibo and Kelly, Patrick and Hollot, Christopher},
  booktitle={2019 18th European Control Conference (ECC)}, 
  title={Visual signal representation for fast and robust object recognition}, 
  year={2019},
  volume={},
  number={},
  pages={3231-3236},
  abstract={Internal signal representation is critical for accurate perception, memory, and rapid recall in natural intelligence. In this paper we consider a model for cognitive computation that has as its base an algorithm for converting spatial signals into temporal representations. The model is motivated by vision functions but is supported by applications to concept abstraction and analogical thinking, as well as experimental comparison with the pixel intensity representation of visual images. In fact our method has demonstrated ability to defend against a well-known adversarial attack on the MNIST digits recognition. Ordinal optimization is important in achieving quickness of the algorithm.},
  keywords={},
  doi={10.23919/ECC.2019.8795793},
  ISSN={},
  month={June},}@ARTICLE{10443445,
  author={Bi, Zhuming and Mikkola, Aki and Ip, Andrew W. H. and Yung, Kai Leung and Luo, Chaomin},
  journal={IEEE Transactions on Aerospace and Electronic Systems}, 
  title={Brain–Computer Interface for Shared Controls of Unmanned Aerial Vehicles}, 
  year={2024},
  volume={60},
  number={4},
  pages={3860-3871},
  abstract={To control an intelligent system in an unstructured environment, it is desirable to synergize human and machine intelligence to deal with changes and uncertainty cost-effectively. A shared control takes advantage of human and computer strengths in decision-making support, and this helps to improve the adaptability, agility, reliability, responsiveness, and resilience of the system. Since the decision spaces for human thinking and machine intelligence are quite different, challenges occur to fuse human intelligence and machine intelligence effectively. A brain–computer interface (BCI) can bridge human and machine intelligence; however, traditional BCIs are unidirectional that support interaction in one of two scenarios: first, human or machine takes effect at different control layers, and second, either human or machine takes effect at a time. There is an emerging need to close the loop of BCI-based control to alleviate the adverse effects of a machine's error or a human's mistake. In this article, available technologies for acquisition, processing, and mining of brain signals are reviewed, the needs of integrating human's capability to control unmanned aerial vehicles (UAV) are elaborated, and research challenges in advancing BCI for a shared human and machine control are discussed at the aspects of data acquisition, mapping of human's and machine's decision spaces, and the fusion of human's and machine's intelligence in automated controls. To address unsolved problems in the aforementioned aspects, we proposed a new platform of using BCI for human–machine interactions and three innovations are, first, an advanced BCI to acquire multimodal brain signals and extract features related to the intentions of motion and the quantified human's affection, second, an arbitrating mechanism in system control to determine the weight of human's decisions based on quantified human's affection, and finally, a decision support system that is capable of fusing human's and machine's decisions from different decision spaces seamlessly in controlling a UAV for real-time performance in application.},
  keywords={Autonomous aerial vehicles;Reliability;Robots;Brain-computer interfaces;Accidents;Machine intelligence;Uncertainty},
  doi={10.1109/TAES.2024.3368402},
  ISSN={1557-9603},
  month={Aug},}@INPROCEEDINGS{6260285,
  author={Chen, Xi and Wang, Wei and Li, Wei},
  booktitle={2012 Proceedings of International Conference on Modelling, Identification and Control}, 
  title={An overview of Hierarchical Temporal Memory: A new neocortex algorithm}, 
  year={2012},
  volume={},
  number={},
  pages={1004-1010},
  abstract={The overview presents the development and application of Hierarchical Temporal Memory (HTM). HTM is a new machine learning method which was proposed by Jeff Hawkins in 2005. It is a biologically inspired cognitive method based on the principle of how human brain works. The method invites hierarchical structure and proposes a memory-prediction framework, thus making it able to predict what will happen in the near future. This overview mainly introduces the developing process of HTM, as well as its principle, characteristics, advantages and applications in vision, image processing and robots movement, some potential applications by using HTM, such as thinking process, are also put forward.},
  keywords={Humans;Prediction algorithms;Bayesian methods;Image recognition;Artificial intelligence;Pattern recognition;Biological system modeling;hierarchical Bayesian network;spatial-temporal;memory-prediction;temporal sequence;pattern recognition},
  doi={},
  ISSN={},
  month={June},}@INPROCEEDINGS{4052923,
  author={Afsharchi, Mohsen and Far, Behrouz H. and Denzinger, Jorg},
  booktitle={2006 IEEE/WIC/ACM International Conference on Intelligent Agent Technology}, 
  title={Learning Non-Unanimous Ontology Concepts to Communicate with Groups of Agents}, 
  year={2006},
  volume={},
  number={},
  pages={211-217},
  abstract={We present an extension to the definition of a concept in an ontology that allows an agent to simultaneously communicate with a group of agents that might have different understandings of some concepts. We also provide a way to learn such non-unanimous concepts by using a method for learning concepts from a group of teachers. The general idea of non-unanimous concepts is to use the teachers to identify the core of a concept everyone agrees on and what else at least some of the teachers think belongs into the concept. The learning agent also decides what belongs to the concept for itself and whenever it needs to communicate with a group of other agents and needs to be precise it makes use of these three concept aspects by providing additional example objects for what might be misunderstood.},
  keywords={Ontologies;Humans;Computer science;Multiagent systems;Education;Broadcasting},
  doi={10.1109/IAT.2006.85},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6088970,
  author={Roquier, Ghislain and Thavot, Richard and Mattavelli, Marco},
  booktitle={2011 IEEE Workshop on Signal Processing Systems (SiPS)}, 
  title={Methodology for the hardware/software co-design of dataflow programs}, 
  year={2011},
  volume={},
  number={},
  pages={174-179},
  abstract={New generations of multi-core processors and reconfigurable hardware platforms are expected to provide a dramatic increase of processing capabilities. However, one obstacle for exploiting all the promises of such new platforms is the legacy of current applications and the development methodologies used, which is deeply rooted in a sequential way of thinking. A paradigm shift is necessary at all levels of application development to yield portable and efficient implementations, capable of exploiting the full potential of such platforms. Dataflow programming is an alternative approach that address the problem of providing portable and scalable parallel applications. Dataflow programming is able to explicitly expose the intrinsic parallelism of applications. This paper presents a hardware/software co-design methodology that starting from a unique dataflow program enables, by the direct synthesis of both hardware (HDL) and software components (C/C++), to map a signal processing application onto heterogeneous systems architectures composed by reconfigurable hardware and multi-core processors. Experimental results based on the implementation of the MPEG-4 Simple Profile decoder onto an heterogeneous platform are also provided to show the capabilities and flexibility of the approach.},
  keywords={Hardware;Software;Field programmable gate arrays;Decoding;Multicore processing;Transform coding;dataflow programming;hardware/software co-design;reconfigurable hardware;multi-core processor},
  doi={10.1109/SiPS.2011.6088970},
  ISSN={2162-3570},
  month={Oct},}@INPROCEEDINGS{1244618,
  author={Ovaska, S.J. and Bose, T. and Vainio, O.},
  booktitle={SMC'03 Conference Proceedings. 2003 IEEE International Conference on Systems, Man and Cybernetics. Conference Theme - System Security and Assurance (Cat. No.03CH37483)}, 
  title={Genetic algorithm-aided design of predictive filters for electric power applications}, 
  year={2003},
  volume={2},
  number={},
  pages={1463-1468 vol.2},
  abstract={We introduce a genetic algorithm (GA)-based method for structural optimization of multiplicative general parameter (MGP) finite impulse response (FIR) filters. These computationally efficient reduced-rank adaptive filters are robust, suitable for predictive configurations, and they have numerous applications in 50/60 Hz power systems instrumentation. The design process of such filters has three independent stages: Lagrange multipliers-based optimization of the sinusoid-predictive basis filter, genetic algorithm-based search of optimal FIR tap cross-connections and, finally, the online MGP-adaptation phase guided by variations in signal statistics. Thus, our multi-stage design procedure is a complementary fusion of hard computing (HC) and soft computing (SC) methodologies. Such advantageous fusion (or symbiosis) thinking is emerging among researchers and practicing engineers, and it can potentially lead to competitive combinations of individual HC and SC methods.},
  keywords={Prediction algorithms;Algorithm design and analysis;Power filters;Finite impulse response filter;Genetic algorithms;Optimization methods;Adaptive filters;Robustness;Power systems;Instruments},
  doi={10.1109/ICSMC.2003.1244618},
  ISSN={1062-922X},
  month={Oct},}@ARTICLE{10290980,
  author={Gonçalves, Bernardo},
  journal={IEEE Annals of the History of Computing}, 
  title={Lady Lovelace’s Objection: The Turing–Hartree Disputes Over the Meaning of Digital Computers, 1946–1951}, 
  year={2024},
  volume={46},
  number={1},
  pages={6-18},
  abstract={Can machines think? Or can they do “whatever we know how to order” them to perform? Should machines be liberated from slavery and given “fair play” to “compete with men in all purely intellectual fields”? Or should this be associated with a fashion that decries “human reason” and a path that “leads straight to Nazism”? In the postwar years, these questions were debated by Alan Turing and Douglas Hartree, who differed in their interpretations of the digital computer as a new piece of science and technology. Hartree emphasized its unprecedented calculation speed and envisioned applications in physics, logistics, energy, and warfare. Turing, who envisioned applications in biology and cognition, emphasized its potential to outperform humans intellectually, including capabilities considered distinctly human, which Hartree downplayed by mobilizing the notes of Ada Lovelace. This article examines the Turing–Hartree disputes and draws a parallel between their positions and their perspectives on postwar Britain.},
  keywords={History;Computers;Valves;Machinery;Digital computers;Presses;Physics},
  doi={10.1109/MAHC.2023.3326607},
  ISSN={1934-1547},
  month={Jan},}@INPROCEEDINGS{5567924,
  author={Wu, Liang and Chen, Zhanlong and Ma, Lina and Wan, Lin},
  booktitle={2010 18th International Conference on Geoinformatics}, 
  title={Key technniques of distributed geospatial information operations}, 
  year={2010},
  volume={},
  number={},
  pages={1-6},
  abstract={In order to improve spatial operations efficiency of massive data in distributed environment and to solve the interactive design problems of spatial analysis processing module designed to service agreement with the underlying database, spatial data models, map display and so on. For the status quo that there is no GIS software for a practical analysis of distributed computing, we have carried out in-depth study combined with the distributed characteristics of spatial data and information. The distributed geospatial information operation framework was designed in this paper. The basic characteristics of distributed computing are analyzed in this paper. The author of this paper discussed the distributed computing spatial information technology system form following aspects: apace computing task decomposition, distributed spatial data classification method, sharing data replication strategy, the data partitioning strategy based on the load and the caching mechanism of space computing framework, based on this framework, the author has developed the system for resolving the practical problems. In this paper, the proposed distributed computing framework suitable for distributed spatial analysis has solved the key technical problems of distributed spatial analysis computing framework. And it is accordant with "service-oriented" thinking, takes into account the heterogeneity of spatial data sources, and the distributed spatial computing among the different systems on different platforms. The dynamic load scheduling has improved the static data partitioning method, it avoids the load imbalance problem in the phase of static data partitioning. It solved the efficiency of large-scale spatial data operations in the complex distributed environment in practical applications. At last, based on the software, we do the distributed clipping computing environment test of the classic space experiments, a detailed result has given at the last of the article, it has shown that, the framework is designed novelty, and can reduce the spatial computing time in the distributed environments extremely.},
  keywords={Spatial databases;Distributed databases;Geographic Information Systems;Servers;Dynamic scheduling;Software;distributed computing framework;spatial data partition;computing load balancing;GIS},
  doi={10.1109/GEOINFORMATICS.2010.5567924},
  ISSN={2161-0258},
  month={June},}@INPROCEEDINGS{7828929,
  author={Lu, Kunfeng and Qi, Zhenqiang and Liu, Jiarun and Bao, Weimin},
  booktitle={2016 IEEE Chinese Guidance, Navigation and Control Conference (CGNCC)}, 
  title={Analyses and reflection of intelligent autonomous technology for Chinese manned deep space exploration}, 
  year={2016},
  volume={},
  number={},
  pages={1033-1038},
  abstract={Chinese manned deep space exploration (CMDSE) will make outstanding contributions to the progress of human civilization, and make human beings understand the origin, evolution and status of the universe in a wider and deeper level. Intelligent autonomous technology, which has the ability of automatic acquisition and application of knowledge, thinking and reasoning, problem solving and automatic learning, will provide broader prospects for the development of CMDSE activities. This paper will introduce briefly the development of CMDSE and analyze the problems and challenges encountered in this missions, and summarize the requirements for intelligent autonomous technology from rocket launching, flighting into orbit, flight on orbit, celestial landing to successful return to earth. Secondly, intelligent autonomous technology will be discussed in some important fields including high reliability, low cost, adapting of different uncertainties and unknown environment disturbances, emergency handling and obtaining maximum scientific return. In addition, the prospects for the future development of CMDSE mission and the progress of intelligent autonomous technology will be discussed. Finally, in view of CMDSE mission, a system architecture which is based on intelligent sensing, intelligent computing, intelligent control, intelligent material, intelligent communication and other intelligent techniques will be presented, and the future development of those technologies will be also proposed.},
  keywords={Space vehicles;Space exploration;Moon;Orbits;Reliability;Navigation;Earth;Intelligent autonomous technology;Chinese manned deep space exploration;Development situation;Technical requirement;Development trend},
  doi={10.1109/CGNCC.2016.7828929},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{1039324,
  author={Pontelli, E. and Ranjan, D. and Milligan, B. and Gupta, G.},
  booktitle={Proceedings. IEEE Computer Society Bioinformatics Conference}, 
  title={/spl Phi/LOG: a domain specific language for solving phylogenetic inference problems}, 
  year={2002},
  volume={},
  number={},
  pages={9-20},
  abstract={Domain experts think and reason at a high level of abstraction when they solve problems in their domain of expertise. We present the design and motivation behind a domain specific language (DSL), called /spl Phi/LOG, to enable biologists (domain experts) to program solutions to phylogenetic inference problems at a very high level of abstraction. The implementation infrastructure (interpreter, compiler, debugger) for the DSL is automatically obtained through a software engineering framework based on denotational semantics and logic programming.},
  keywords={Domain specific languages;Phylogeny;DSL;Biology computing;Software engineering;Bioinformatics;Application software;Computer science;Biological system modeling;Programming profession},
  doi={10.1109/CSB.2002.1039324},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10112083,
  author={Gupta, Urvashi and Sharma, Rohit},
  booktitle={2023 6th International Conference on Information Systems and Computer Networks (ISCON)}, 
  title={A Study of Cloud Based Solution for Data Analytics in Healthcare}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The healthcare industry generates vast amounts of data that are crucial for improving patient outcomes and advancing medical research. However, traditional on premise solutions for data storage and analysis can become inadequate to handle the increasing volume, variety and velocity of healthcare data. The study aims to investigate the potential benefits and challenges of using cloud-based solutions for data analytics in healthcare. This paper reports about latest development and detailed role of using Artificial intelligence and capabilities of cloud Computing in health care sector/industry to foster innovative thinking, optimum wellbeing of the patient, focused medicinal support. This paper discusses various applications, algorithms and future of big data analytics with a focus on architecture, application and applicability of big data analytics using Hadoop and Cloud Computing in healthcare industry such as monitoring, prediction, performance, management etc including intensive care unit. many cloud platforms, like MMAP, are working in this field to provide a fast, reliable cost effective, efficient, and patient centric and solution to community health issues with capability of forecasting the health impact of various diseases on community for a given region or nation. Cloud computing framework, along with Artificial intelligence and Hadoop, aids healthcare management in completing analytical computations to identify logical, pertinent, and factual trends essential to strategize and enhanced readiness in event of catastrophes by facilitating data exchange among all stake holders.},
  keywords={Industries;Cloud computing;Analytical models;Data analysis;Costs;Memory;Medical services;Big Data;Healthcare;Cloud Computing;Data Analytics;Hadoop},
  doi={10.1109/ISCON57294.2023.10112083},
  ISSN={2832-143X},
  month={March},}@INPROCEEDINGS{7062605,
  author={Silapachote, Piyanuch and Srisuphab, Ananta and Srikosamatara, Sompoad},
  booktitle={2014 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={A reverse engineering approach to teach biology students mathematical complexity in ecology: Interdisciplinary teaching connects mathematical literacy and outdoor practice}, 
  year={2014},
  volume={},
  number={},
  pages={141-147},
  abstract={Mathematics has long held a prominent spot in common core competencies. Rapid advances in information and communication technology literacy have gained it recognition as an essential skill in the 21st century. Mastering both is a challenge, as is teaching them. Integration with other disciplines, addressing STEM education, makes this even more challenging. Tackling this dilemma, we adapt cooperative learning and co-teaching schemes. Hands-on class activities effectively convey an understanding of a complex model without equations. Computer simulations promote visual comprehensions for highly dynamic systems. In our course, general ecology for biologists, mathematical complexity is a crucial element required for transitioning from the real world to the world of numbers pertaining both linear and non-linear relationships. We designed indoor activities to initiate analytical thinking and to extend appreciations of outdoor experiences to abstract reasoning in numerical terms and computer models. Our approach fulfills the objectives of guiding biology students to construct scenarios reflecting complex interactions among organisms in the natural world. They overcame their primarily negative mindset, feeling intimidated by mathematics and uncomfortably unfamiliar with computer technology. To evaluate our teaching method, students were asked to qualitatively write an after action evaluation. They expressed enjoyment in their learning. Though struggling at times, the experience was very rewarding and worthwhile. Students came to a realization of the importance of mathematics and information literacy skills, while drawing appreciation and awareness from outdoor experiences. Besides, we quantitatively analyzed students' performance, which effectively serves as a guideline for adjusting our course contents for the next offering of this subject.},
  keywords={Decision support systems;Handheld computers;Education;Conferences;Sociology;Statistics;Estimation;interdisciplinary co-teaching;active and cooperative learning;mathematical literacy;computer simulations},
  doi={10.1109/TALE.2014.7062605},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{1602314,
  author={Rodriguez, R. and Costilla, C. and Calleja, A.},
  booktitle={Advanced Int'l Conference on Telecommunications and Int'l Conference on Internet and Web Applications and Services (AICT-ICIW'06)}, 
  title={A Topic-based approach to express dynamic capabilities of Semantic WS-Resources}, 
  year={2006},
  volume={},
  number={},
  pages={181-181},
  abstract={The release of WSRF showed that an OGSA infrastructure of stateful WS-Resources could be built on top of plain WSDL, while retaining Web services as stateless entities. This Grid and SOA convergence allows developers to focus on enrich descriptions with current Semantic Web services technologies (SWS), whereas WSRF and WSNotification provide the mechanisms to build stateful and distributed architectures. However, we think a direct exportation of SWS interfaces to describe WS-Resources would be of limited value, due to property changes are not properly captured with static profiles, and current WSRF lacks of semantic features. We propose a topic-based modeling of WS-Resource capabilities, along with simple WSRF and WSNotification extensions to achieve 'semantic-by-design' WS-Resource descriptions. We also illustrate how these enhancements can be applied to our Semantic Web Data Sources Integrated Architecture (DAWIS), allowing dynamic matching and discovering of Semantic WSResources.},
  keywords={Web services;Service oriented architecture;Computer architecture;Semantic Web;Information systems;Databases;Cyclic redundancy check;Information technology;Solids;XML},
  doi={10.1109/AICT-ICIW.2006.39},
  ISSN={},
  month={Feb},}@ARTICLE{8733781,
  author={Patterson, Bradley and Sakellariou, Nicholas},
  journal={IEEE Technology and Society Magazine}, 
  title={Computer Scientists as Modern Hypnotists: Placing a Trance on Societal Norms}, 
  year={2019},
  volume={38},
  number={2},
  pages={78-87},
  abstract={It is without question that the use of digital technology (DT) has pervaded everyday life. From video chatting with a family member in another country, to checking the weather on a handheld computer, technology has provided society with many benefits. Social media, like Facebook (FB), Twitter, and LinkedIn, have seemingly brought the world closer, but at what cost? In this article, we show that the mass use of technology, more specifically social media, have led to the conscious will of users to be hijacked by platforms in order to increase their user-base and capital. We do this by first evaluating the impact of technology on one's conscious will, the feeling that one's actions are caused by oneself. After finding that technology makes users feel as though their actions are more consciously willed, and people naturally want to feel consciously willed, the next logical step is to analyze how modern tech companies use this to their advantage. Looking at features from popular social media, we describe how these features artificially increase the feeling of users' actions being consciously willed, regardless of if the users are actually consciously willing their actions. Finally, we discuss ways in which individuals can reclaim control over their conscious will, and how to reduce this commodification of will at a company level. The ability of a company to control the decision-making metrics of their users should strike one as troubling; whereas the power of a company to hypnotize its users into thinking that they are using the platform because they want to, and not because the company wants them to, is quite concerning.},
  keywords={Handheld computers;Cyberspace;Digital systems;Twitter;Facebook;Social networking (online);Decision making;Social implications of technology},
  doi={10.1109/MTS.2019.2913074},
  ISSN={1937-416X},
  month={June},}@INPROCEEDINGS{10611246,
  author={Kumar, Nithesh and Chao, Hsin-Ming and Da Silva Tassari, Bruno Dantas and Sabinson, Elena and Walker, Ian D. and Green, Keith E.},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Design of Two Morphing Robot Surfaces and Results from a User Study On What People Want and Expect of Them, Towards a "Robot-Room"}, 
  year={2024},
  volume={},
  number={},
  pages={11239-11244},
  abstract={We propose, examine prototypes of, and collect user input on morphing robotic surfaces, "robot-room" elements that, individually or in combination, change the functionality of the rooms we live in, directly controlled by the room’s occupants engaging with it. Robot-rooms represent an advance in human-robot interaction whereby human interaction is within a machine that physically envelops us. We discuss the motivation for such robot-rooms, present initial work aimed at their physical realization, and report on a user study of 80 participants to learn what people might want of and expect from robot rooms, the results of which will inform both the iterative design of the robot room and the thinking of our community as it grapples with how we want to live with (and "in") robots.},
  keywords={Productivity;Prototypes;Human-robot interaction;Iterative methods;Artificial intelligence;Robots;Robot surfaces;User studies},
  doi={10.1109/ICRA57147.2024.10611246},
  ISSN={},
  month={May},}@ARTICLE{10195993,
  author={Li, Song and Zhong, Hong and Wang, Liangmin and Cui, Jie and Han, Jinguang and Ying, Zuobin and Yang, Guannan},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={SecuCar: Data Loss Prevention for Cloud Assisted VSS Based on Public Auditing Technique}, 
  year={2023},
  volume={72},
  number={11},
  pages={14815-14827},
  abstract={Intelligent and networked vehicle is a popular developing trend in future. However, Data Loss Prevention (DLP) is an import problem need to be solved. Especially, in the Vehicle Sharing System (VSS), the data authority is hard to be guaranteed based on the current technology. VSS provides the users with a convenient way to access vehicles nearby. However, the driving data security which can be used to record the driving conditions cannot be guaranteed by either cloud server or the vehicle. The camera in the cab is also not accepted because it will leak the user's privacy. This article solves this problem based on the cryptography with the public auditing technology. We design a multi-signature scheme so that the OBU and the PDA equipment of the vehicle renter can jointly sign a signature as a meta data for the driving information and upload it to the cloud server together with the raw data. In the event of a dispute, such as a vehicle accident, anyone can conduct an integrity checking with batch jobs on the stored data in the cloud server, so that the cloud and the vehicle renter cannot deny these information. We think that our scheme can be used to prevent some obvious data modification in cloud or as a part of the reference for accident identification. We also use the provable security technology to prove that our protocol is secure, and we realize its core algorithms. The experimental result shows that our scheme is efficient.},
  keywords={Vehicular ad hoc networks;Servers;Security;Cloud computing;Data privacy;Industries;Clouds;VANET;cloud security;cryptographic protocol;public auditing;integrity checking},
  doi={10.1109/TVT.2023.3281728},
  ISSN={1939-9359},
  month={Nov},}@INPROCEEDINGS{8046315,
  author={Hoozemans, Joost and van Straten, Jeroen and Wong, Stephan},
  booktitle={2017 IEEE 23rd International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)}, 
  title={Using a polymorphic VLIW processor to improve schedulability and performance for mixed-criticality systems}, 
  year={2017},
  volume={},
  number={},
  pages={1-9},
  abstract={As embedded systems are faced with ever more demanding workloads and more tasks are being consolidated onto a smaller number of microcontrollers, system designers are faced with opposing requirements of increasing performance while retaining real-time analyzability. For example, one can think of the following performance-enhancing techniques: caches, branch prediction, out-of-order (OoO) superscalar processing, simultaneous multi-threading (SMT). Clearly, there is a need for a platform that can deliver high performance for non-critical tasks and full analyzability and predictability for critical tasks (mixed-criticality systems). In this paper, we demonstrate how a polymorphic VLIW processor can satisfy these seemingly contradicting goals by allowing a schedule to dynamically, i.e., at run-time, distribute the computing resources to one or multiple threads. The core provides full performance isolation between threads and can keep multiple task contexts in hardware (virtual processors, similar to SMT) between which it can switch with minimal penalty (a pipeline flush). In this work, we show that this dynamic platform can improve performance over current predictable processors (by a factor of 5 on average using the highest performing configuration), and provides schedulability that is on par with an earlier study that explored the concept of creating a dynamic processor based on a superscalar architecture. Furthermore, we measured a 15% improvement in schedulability over a heterogeneous multi-core platform with an equal number of datapaths. Finally, our VHDL design and tools (including compiler, simulator, libraries etc.) are available for download for the academic community.},
  keywords={Dynamic scheduling;Schedules;VLIW;Context;Real-time systems;Multicore processing;Timing},
  doi={10.1109/RTCSA.2017.8046315},
  ISSN={2325-1301},
  month={Aug},}@INPROCEEDINGS{7456775,
  author={Yagmur, Serap},
  booktitle={2016 International Conference on Platform Technology and Service (PlatCon)}, 
  title={A Literature Review: Usability Aspects of Ubiquitous Computing}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={We live in a digital world which controls our physical environment. The increasing use of wireless network supports these digital devices to use mostly people. People prefer mobile devices such as smart phones and tablets to personal computers or laptops. This brings that accessing to information and services is available any time and everywhere. This can be called ubiquitous computing. There is a high demand of pervasive computing applications and they have grown in the last years. However, a large group of people do not engage with these developments. This attracted the researchers to think this problem and they link it with usability of systems. In this study we reviewed 37 the articles which published on usability of ubiquitous computing. Within the scope of this study, the first stage is defining ubiquitous and usability. In the second stage, this paper organizes and classifies the literature on the area in order to facilitate future research. The review covers 37 peer-reviewed journal articles from 18 journals published between 2000 and 2014. The resulting framework summarizes the progress in usability studies on pervasive computing environments research and provides future research directions.},
  keywords={Usability;Ubiquitous computing;Human computer interaction;Mobile communication;Conferences},
  doi={10.1109/PlatCon.2016.7456775},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10421076,
  author={Liu, Yichun and Gong, Qianxi and Ji, Chenlu},
  booktitle={2023 International Conference on Integrated Intelligence and Communication Systems (ICIICS)}, 
  title={Research on Automatic Recognition Technology of Print Robot in Human-Computer Interaction}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={In the digital era, the interaction between people and machines is constantly changing the way of interaction between people and between people and society, making people feel the unprecedented development of science and technology. In order to systematically study the influence of human-computer interaction on automatic recognition technology of print robot, the influence of human-computer interaction on human thinking mode, behavior mode and experience demand is analyzed. Secondly, from the perspective of media and its interaction, it describes the impact of human-computer interaction on machine recognition methods from four aspects: expanding the range of spatial information through multisource data, and improving the sensory experience through multi-channel interaction. Finally, under the background of new information technology, new interaction mode, intelligent feedback and new emotional factors, the dynamic response process is improved through real-time recording and feedback. The interaction between machines can create more opportunities for the automatic recognition technology of printing robots, and expand the research direction and the development of new designs.},
  keywords={Human computer interaction;Printing;Virtual reality;Robot sensing systems;Real-time systems;Recording;System analysis and design;Computer;Human-Automatic Recognition;Interaction;Print;Robot},
  doi={10.1109/ICIICS59993.2023.10421076},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{6756269,
  author={Chen, Yu-Tso and Su, Bo-Yu},
  booktitle={2013 Eleventh International Conference on ICT and Knowledge Engineering}, 
  title={Sketch an ICT-based Data Management Scheme for liberalizing electricity market}, 
  year={2013},
  volume={},
  number={},
  pages={1-6},
  abstract={Electricity has been the most important energy resource for daily applications. With the trends of continuously increasing of electricity cost and imperative need of CO2 emission reductions, forward-thinking governments are taking great importance of optimization on electricity trading for national economic and environmental developments. Although conventional electricity trading approaches such as electricity pool, bilateral market, and so on have been applied in many countries, these methods are lack of the attention to emerging renewable energy options. Based on the above, this paper presents a Data Management Scheme for Electricity Trading (DaMaSET), especially adding the role of Micro-gird. With the support of ICT-enabled load forecasting model, the proposed DaMaSET is capable of shaping an information processing module for electricity-oriented Energy Management System, addressing a valuable research direction in terms of advancing electricity trading, and further indicating a systematic perspective on energy-related environmental sustainability.},
  keywords={Load forecasting;Electricity;Power markets;Energy management;Load modeling;Predictive models;electricity trading;energy management;load forecasting;ICT;environmental sustainability},
  doi={10.1109/ICTKE.2013.6756269},
  ISSN={2157-099X},
  month={Nov},}@INPROCEEDINGS{10118630,
  author={Sutrisna, Sutrisna and Maulani, Giandari and Anwar, Muhammad Rehan and Nurtino, Tio and Bhima, Bhima},
  booktitle={2022 IEEE Creative Communication and Innovative Technology (ICCIT)}, 
  title={FAST-Based Production Monitoring Information System for Extra-High Voltage Power Line Towers}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={The role of computers is indispensable in various aspects of life, especially in the Production Monitoring information system which increases work productivity. PT Citra Banjar Abadi is a company that produces iron and steel electric towers for the needs of making High Voltage Power Line Towers, where this research takes place. The problem that occurs at this time is that the steel production monitoring information system is not optimal because it still uses a manual system so that there are often problems, one of which is the problem of production progress that cannot be monitored properly so that the completion of production is not on time. The purpose of this study is to provide solutions to problems that occur using the FAST (Framework Analytical System Thinking) method. The result of this research is to produce a steel production monitoring information system for the Tower Extra High Voltage Power Line for PT Citra Banjar Abadi, Indonesia.},
  keywords={Poles and towers;Production;High-voltage techniques;Manuals;Voltage;Iron;Steel;Information System;Production Monitoring;FAST Method},
  doi={10.1109/ICCIT55355.2022.10118630},
  ISSN={},
  month={Nov},}@ARTICLE{9790317,
  author={Wang, Xintao and Liang, Jiaqing and Xiao, Yanghua and Wang, Wei},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Prototypical Concept Representation}, 
  year={2023},
  volume={35},
  number={7},
  pages={7357-7370},
  abstract={Concepts are building blocks of human thinking. For machines, concept understanding has also been increasingly important, which makes concept representation a fundamental problem in artificial intelligence. While many concepts have their instances, the massive amount of information carried by instances has long been ignored in current concept representation, which limits the usage of these concepts in applications. In this paper, inspired by prototype theory in cognitive science, we propose prototypical concept representation for machines, which represents each concept with a distributed prototype derived from representations of its instances. For prototypical representation learning, we further introduce a novel model named Prototypical Siamese Network (PSN). PSN is trained under the supervision of isA determination, one of the most important concept-related applications. Results of extensive experiments demonstrate that, our method achieves state-of-the-art performance, thus validating the effectiveness of prototypical concept representation.},
  keywords={Prototypes;Task analysis;Taxonomy;Semantics;Context modeling;Cognition;Representation learning;Concept learning;distributed representations;knowledge graphs;machine learning},
  doi={10.1109/TKDE.2022.3180886},
  ISSN={1558-2191},
  month={July},}@INPROCEEDINGS{10539509,
  author={Zhou, Zihan and Li, Zihao and Zhang, Xiaoshuai and Sun, Yunqing and Xu, Hao},
  booktitle={2023 IEEE 9th World Forum on Internet of Things (WF-IoT)}, 
  title={A Review of Gaps between Web 4.0 and Web 3.0 Intelligent Network Infrastructure}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={World Wide Web is speeding up its pace into an intelligent and decentralized ecosystem, as seen in the campaign of Web 3.0 and forthcoming Web 4.0. Marked by the Europe Commission's latest mention of Web 4.0, a race towards strategic Web 4.0 success has started. Web 4.0 is committed to bringing the next technological transition with an open, secure, trustworthy fairness and digital ecosystem for individuals and businesses in private and public sectors. Despite overlapping scopes and objectives of Web 3.0 and Web 4.0 from academic and industrial perspectives, there are distinct and definitive features and gaps for the next generation of WWW. In this review, a brief introduction to WWW development unravels the entangled but consistent requirement of a more vivid web experience, enhancing human-centric experience in both societal and technical aspects. Moreover, the review brings a decentralized intelligence prospect of view on native AI entities for Web 4.0, envisioning sustainable, autonomous and decentralized AI services for the entire Web 4.0 environment, powering a self-sustainable Decentralized Physical and Software Infrastructure for Computing Force Network, Semantic Network, Virtual/Mixed Reality, and Privacy-preserving content presumption. The review aims to reveal that Web 4.0 offers native intelligence with focused thinking on utilizing decentralized physical infrastructure, in addition to sole requirements on decentralization, bridging the gap between Web 4.0 and Web 3.0 advances with the latest future-shaping blockchain-enabled computing and network routing protocols.},
  keywords={Semantic Web;Reviews;Force;Ecosystems;Semantics;World Wide Web;Software;Routing protocols;Web sites;Artificial intelligence;Web 4.0;Web 3.0;Blockchain;Intelligence;AI;Semantic network;VR;AR;Computing Force Network},
  doi={10.1109/WF-IoT58464.2023.10539509},
  ISSN={2768-1734},
  month={Oct},}@INPROCEEDINGS{10342945,
  author={Andrei, Stefan and Wang, Sujing},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={An Innovative Way to Teach Computer Programming for Middle and High Schools Students in Summer Camps}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={This Innovative Practice Full Paper presents our design of teaching computer programming for middle and high school students during an one-week Summer camp for the past five years, with an interruption in the Summer of 2020 due to the Covid-19 pandemic. Many researchers believe that good Summer camps can improve many students' educational and career development outcomes. Teachers and administrators are increasingly promoting Summer camp opportunities for introducing programming skills to middle and high school students. The motivation of our program is to offer hands-on projects for middle and high school students to increase their interests and knowledge in computing to meet the growing demand. Like some Summer coding camps, we picked Scratch as the programming language (designed and offered for free by the Massachusetts Institute of Technology) for the students to learn important mathematical and computer programming concepts. In addition, the students learn how to think and reason creatively, reason systematically, and work collaboratively, while also having fun during the one-week Summer camp. For the students already familiar with Scratch, the instructor exposed students to basic concepts of Java programming language, such as Java virtual machine, computer memory, data representation, primitive data types, casting, arithmetic, and relational operators, as well as the assignment, selection and printing statements. This article presents our findings from Summer camps organized in 2018 and 2022. Our conclusion is that all students showed a better understanding of programming concepts and confidence in computing. In the upcoming paper sections, we will describe details about how we made one-week camps to be unique compared to other similar camps. One element of our own approach is to teach in an effective and innovative using an interactive teaching approach. For example, when we designed the lecture notes, we imagine that we are students taking for the first time a computer programming course. In addition, we designed simple programming exercises for the students to solve immediately. The instructors and Teaching Assistants promptly checked the solution and award the students with stars for completing the work. This environment was very well received because it was viewed as a student collegiate competition instead of a race against time. Besides learning about computer programming, we adopted during Summer camps several strategies like those enumerated earlier to enrich our camps, as well as social events, career and professional development, and academic exposure. Our findings indicate that these additional activities proved to be beneficial to our students attending the Summer camps.},
  keywords={Printing;Java;Computer languages;Casting;Career development;Engineering profession;Stars;Computing;Scratch and Java programming languages;Summer Camp},
  doi={10.1109/FIE58773.2023.10342945},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{9525802,
  author={Jagoda, S.U.M. and Gamage, J.R. and Karunathilake, Hirushie},
  booktitle={2021 Moratuwa Engineering Research Conference (MERCon)}, 
  title={A Comparative Analysis of the Environmental and Structural Performance of PET Bottle Designs in Sri Lanka}, 
  year={2021},
  volume={},
  number={},
  pages={214-219},
  abstract={Polyethylene Terephthalate (PET) has become the most commonly used material in the global beverage bottling industry. PET bottle production has increased by over seven times within the last three decades. However, the use of PET has a considerably detrimental effect on the environment, and many studies have been carried out on curbing this damage. Reducing the amount of material used, design for recycling, repurposing, and reusing are possible approaches for mitigating the negative environmental impacts of the PET bottle industry. The local PET bottle market has a range of products to cater the various customer requirements. To obtain a holistic vision of the actual impacts of this industry, life cycle thinking becomes necessary. The objective of this study is to present a methodological framework for comparing the environmental performance and structural performance of PET bottle designs, using case studies from the Sri Lankan market. A life cycle assessment and a finite element analysis were carried out to evaluate the overall environmental impacts of the PET supply chain and the structural performance of PET bottles. The outcomes of the study are used to provide recommendations on the short and long-term strategies to increase the eco-friendliness of the PET bottle industry.},
  keywords={Industries;Polyethylene;Supply chains;Production;Recycling;Finite element analysis;Bottling;PET bottle design;Life cycle analysis;Environmental impact;Methodological Framework},
  doi={10.1109/MERCon52712.2021.9525802},
  ISSN={2691-364X},
  month={July},}@INPROCEEDINGS{10397668,
  author={Saxena, Aditi and Taluja, Resham and Sararswat, Manish and Shalini, N and Krishna, Om and Kumar, Pushpendra},
  booktitle={2023 6th International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={Data Mining Methods for Internet of Things: A Survey}, 
  year={2023},
  volume={6},
  number={},
  pages={2610-2618},
  abstract={It is fascinating to think about all the many ways in which information, intellect, and knowledge may be used in human existence. Because of the lightning-fast pace at which technology is advancing, it is now essential to amass a large quantity of data in order to forecast and investigate potential developments in the field of artificial intelligence. In order to identify new information inside databases, it is necessary to apply strategies and procedures taken from a variety of information systems specializations. The practice of data mining entails not only the finding of new information but also the extraction of information that may be put to beneficial use. In recent years, considerable advances have been made in decision-making abilities in a variety of contexts, including expert systems, artificial agent networks, and machine intelligence. These businesses include companies in the fields of commerce, education, architecture, and building construction, among others. The approach that was taken in this piece was derived from an analysis of the data mining strategies and developments that have seen the greatest amount of adoption across a variety of business sectors over the course of the last five years. These patterns and modes of operation were investigated. Throughout the course of this enquiry, the processes and patterns described above were scrutinized. The use of text mining as a tool for database analysis, the enhancement of worker productivity in the industrial sector, and the application of data mining for instructional practices are only a few instances of what has been learnt in the area of education. One other illustration of this would be the use of text mining as a technique for image recognition. It was also found in the fields of trade and industry.},
  keywords={Text mining;Surveys;Databases;Education;Data mining;Internet of Things;Expert systems;Database;Data Mining;Data Mining Techniques;Database Management Systems;Data Mining Processes},
  doi={10.1109/IC3I59117.2023.10397668},
  ISSN={},
  month={Sep.},}@ARTICLE{9456884,
  author={Lin, Guojun and Zhang, Qinrui and Zhou, Shunyong and Jiang, Xingguo and Wu, Hao and You, Hairong and Li, Zuxin and He, Ping and Li, Heng},
  journal={IEEE Access}, 
  title={Extended JSSL for Multi-Feature Face Recognition via Intra-Class Variant Dictionary}, 
  year={2021},
  volume={9},
  number={},
  pages={91807-91819},
  abstract={This paper focuses on how to represent the testing face images for multi-feature face recognition. The choice of feature is critical for face recognition. The different features of the sample contribute differently to face recognition. The joint similar and specific learning (JSSL) has been effectively applied in multi-feature face recognition. In the JSSL, although the representation coefficient is divided into the similar coefficient and the specific coefficient, there is the disadvantage that the training images cannot represent the testing images well, because there are probable expressions, illuminations and disguises in the testing images. We think that the intra-class variations of one person can be linearly represented by those of other people. In order to solve well the disadvantage of JSSL, in the paper, we extend JSSL and propose the extended joint similar and specific learning (EJSSL) for multi-feature face recognition. EJSSL constructs the intra-class variant dictionary to represent the probable variation between the training images and the testing images. EJSSL uses the training images and the intra-class variant dictionary to effectively represent the testing images. The proposed EJSSL method is perfectly experimented on some available face databases, and its performance is superior to many current face recognition methods.},
  keywords={Face recognition;Feature extraction;Training;Testing;Dictionaries;Data mining;Collaboration;Sparse representation;image classification;multi-feature;face recognition},
  doi={10.1109/ACCESS.2021.3089836},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10200202,
  author={Govindasamy, P. and Ganesh, R. Sankar and Ramesh, R.},
  booktitle={2023 International Conference on Applied Intelligence and Sustainable Computing (ICAISC)}, 
  title={Redefining the Performance Management using Emotional Artificial Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Over the last two decades, the relevant literature has focused a lot on the human intelligence of (EI) and the machine intelligence of AI. The present research integrates these two schools of thinking and examines how employee retention and productivity are impacted by mental agility and artificial intelligence. How successfully individuals execute tasks during their internal and external services contacts with clients and colleagues, respectively. These interactions may take place either internally or outside and are categorized as either internal or external. The research demonstrates that emotive artificial intelligence has a major effect on both the performance of employees and their retention rates.},
  keywords={Productivity;Human intelligence;Employment;Buildings;Collaboration;Organizations;Artificial intelligence;Artificial Intelligence;Performance Management.},
  doi={10.1109/ICAISC58445.2023.10200202},
  ISSN={},
  month={June},}@INPROCEEDINGS{9637349,
  author={Francis, Royce and Riedner, Rachel and Paretti, Marie},
  booktitle={2021 IEEE Frontiers in Education Conference (FIE)}, 
  title={A dramaturgical exploration of engineering judgment processes in undergraduate student writing}, 
  year={2021},
  volume={},
  number={},
  pages={1-9},
  abstract={The objective of this full paper is to explore the interplay between engineering judgment and communication practices involved in completing an undergraduate systems engineering senior project. We view engineering judgment as an embodied process that emerges through discourse as individuals position themselves relative to both other individuals and disciplinary norms in a range of contexts. It happens, broadly, through a series of tasks and thinking processes through which students choose and formulate problems, make assumptions, select data, and adopt roles in relation to disciplinary norms in different contexts. We explore this conceptualization of engineering judgment using thematic and dramaturgical analysis of a single case. The data collected are a semi-structured 90-minute interview collected with one systems engineering senior after completion of their senior project and graduation from their degree program. These data are first coded using a thematic analysis approach, then re-analyzed using a dramaturgical approach. Our findings raise important issues about the blend of communication demands faced by practicing engineers that potentially impact the socialization of engineering students. Different communication demands require students to use different ways to navigate complexity. The varied communication forms also prompt students to view themselves as professionals with the capacity to judge and act from a position of professional authority that vary with the situational context.},
  keywords={Navigation;Conferences;Writing;Complexity theory;Task analysis;Interviews;Engineering students;engineering judgment;engineering identity;thematic analysis;dramaturgical analysis},
  doi={10.1109/FIE49875.2021.9637349},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10541749,
  author={Singh, Rashmi and Padma, Juhi and Singh, Jagrati},
  booktitle={2023 5th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)}, 
  title={Cyborg Intelligence-Current study and challenges}, 
  year={2023},
  volume={},
  number={},
  pages={930-935},
  abstract={Cyborg Intelligence is a major component in replacing lost body part functions in the twenty-first century by incorporating cyborg technology; a human body will be able to function even if it loses one or more of its functioning parts, such as its arms or legs, which would significantly benefit society. The study of cyborgs and the creation of humanoid robots from them Cyborgs, as the title implies, are hybrids of humans and robots. The study examines cyborg technology that is cybernetic. An artificial intelligence is referred to as a cyborg in this context. Artificial intelligence, sometimes referred to as machine intelligence, is the ability of a computer to create software and act and think like a human. Cybernetics is a branch of science that focuses on the fundamentals of communication and control in both machines and biological things. The discussion of how cybernetics and artificial intelligence interact will be the main focus of this article. Additionally, this article will assess cyborg technology in the real world, examining its benefits and drawbacks as well as the ways in which cyborgs and robots are different. Cyborgs are conceivable in today’s world. A cyborg is a humanoid robot or, more accurately, a hybrid of humans and robots. Robots are mechanical humans that depend on the intellect offered by people. With the use of artificial intelligence, cyborgs may now create their own algorithms. The fusion of logic and technology is a key aspect in the creation of a cyborg.},
  keywords={Legged locomotion;Program processors;Human-machine systems;Humanoid robots;Software;Biology;Artificial intelligence;Cyborg intelligence;Rat cyborgs spatial cognition;Bio robotics Cyborgology},
  doi={10.1109/ICAC3N60023.2023.10541749},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9758337,
  author={Suryawanshi, Renuka and Vanjale, Sandeep and Vanjale, Mousami},
  booktitle={2022 International Conference on Emerging Smart Computing and Informatics (ESCI)}, 
  title={A Fuzzy Statistical Perspective for Empirical Evaluation of EEG Classification Models for Epileptic Seizures}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Electroencephalography (EEG) signals are a combination of complex pattern sequences, which are periodic in nature. These pattern sequences include a gamma waves that indicates deep thinking behaviour, a beta wave sequence that indicates busy and active mind status, an alpha wave segment which indicates reflective and restful behaviour, a theta wave which is an indicative of drowsiness, and a delta wave which indicates sleeping & dreaming conditions. Features like frequency changes, amplitude changes, pattern changes, etc. are used to identify chronic, ischemic and other diseases related to the brain. In order to classify these wave patterns into brain diseases like epilepsy, a series of high complexity signal processing operations are needed to be executed in tandem. These operations include signal pre-processing, feature extraction, feature selection, classification into epileptic & non-epileptic seizure and post-processing. A large variety of algorithms are developed by researchers for each of these operations. Performance of these algorithms varies largely w.r.t. the number of leads used for EEG capture, filtering efficiency, feature extraction & selection efficiency, and classifier efficiency. Thus, it becomes ambiguous for researchers and system designers to select the best possible algorithm set for their application. In order to reduce the ambiguity, this text provides a comprehensive comparison of a wide variety of epileptic & non-epileptic seizure classification system models. These models are statistically compared on the basis of overall accuracy, delay of decision making, precision, recall, f-measure and field of application. It is observed that convolutional neural network (CNN) based models outperform other models in terms of general-purpose performance, while specialized CNN models must be used for application specific deployments.},
  keywords={Support vector machines;Transfer learning;Signal processing algorithms;Brain modeling;Feature extraction;Electroencephalography;Real-time systems;EEG;classification;deep learning;convolutional;neural;network;epileptic & non-epileptic seizure},
  doi={10.1109/ESCI53509.2022.9758337},
  ISSN={},
  month={March},}@INPROCEEDINGS{10659792,
  author={Duan, Chenxu and Zhang, Pan},
  booktitle={2024 International Conference on Intelligent Computing and Robotics (ICICR)}, 
  title={Research on Path Planning of Mobile Robot Based on A* Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={189-194},
  abstract={Mobile robots are widely used in industrial, medical, agricultural and other scenarios. The core technology is path planning. The existing methods have limited ability to deal with complex environment, low search efficiency, unsmooth path, easy to trap local optimum, and lack of real-time performance. Intelligent algorithm is a better method to solve this problem. Because the A * algorithm has strong search ability, clear algorithm thinking, and can be constrained to the global optimal path, it has the advantages of high efficiency, stability and optimality. Therefore, a motion trajectory planning method based on A * algorithm is proposed for mobile robots. Firstly, this paper analyzes several commonly used mobile robot path planning algorithms, and selects the A * algorithm as the object of this study. Secondly, the working principle, advantages and disadvantages of the A * algorithm are introduced in detail, as well as the design modules of the A * algorithm. Then, the problem of motion trajectory planning for mobile robots is analyzed and a solution is proposed. Aiming at the problems of low planning efficiency, turning path, sharp and unsmooth path, the efficiency and stability of A * algorithm are optimized by adding heuristic algorithm, corner optimization and path smoothing. Finally, the working environment of the mobile robot is established by using the grid method, and the path planning simulation experiment is carried out on the MATLAB platform. The experimental results show that the method of path planning using A * algorithm is effective and has a wide application prospect.},
  keywords={Smoothing methods;Service robots;Trajectory planning;Heuristic algorithms;Power system stability;Stability analysis;Real-time systems;Mobile robot;Path planning;A * algorithm;Grid method;MATLAB},
  doi={10.1109/ICICR61203.2024.00042},
  ISSN={},
  month={April},}@INPROCEEDINGS{969790,
  author={Ovaska, S.J. and Xiao-Zhi Gao},
  booktitle={2001 IEEE International Conference on Systems, Man and Cybernetics. e-Systems and e-Man for Cybernetics in Cyberspace (Cat.No.01CH37236)}, 
  title={Soft computing in industrial innovation: case study on home appliance technology}, 
  year={2001},
  volume={1},
  number={},
  pages={70-76 vol.1},
  abstract={Soft computing (SC) is an evolving collection of methodologies, which aims to exploit tolerance for imprecision, uncertainty, and partial truth to achieve robustness, tractability, and low total cost. It differs from conventional hard computing in that it is strongly based on intuition or subjectivity. Therefore, soft computing provides an attractive opportunity to represent the ambiguity in human thinking with real life uncertainty. Fuzzy logic (FL), neural networks (NN), and evolutionary computation (EC) are the core methodologies of soft computing. However, FL, NN, and EC should not be viewed as competing with each other, but synergistic and complementary instead. In this paper, we discuss the role of soft computing in developing innovative features for home appliances. Such development work is particularly active in Japan and South Korea. In those Asian countries even ordinary consumers do appreciate the capabilities of SC in developing user-friendly products with high machine IQ. Although home appliance technology is not a popular academic research area, it is an important application area for soft computing methods.},
  keywords={Home computing;Computer industry;Technological innovation;Fuzzy logic;Neural networks;Uncertainty;Home appliances;Robustness;Costs;Humans},
  doi={10.1109/ICSMC.2001.969790},
  ISSN={1062-922X},
  month={Oct},}@INPROCEEDINGS{6017666,
  author={Pruyt, Erik},
  booktitle={2011 Proceedings of PICMET '11: Technology Management in the Energy Smart World (PICMET)}, 
  title={Smart transition management to smarten energy systems in a deeply uncertain world}, 
  year={2011},
  volume={},
  number={},
  pages={1-9},
  abstract={Enormous future investments are needed to replace old energy systems/technologies, and prepare them for future needs. Moreover, smarter technologies/systems are needed. And in this ever more complex, interconnected, and uncertain world, smarter policymaking in the energy field is certainly needed too. After all, current energy policymaking still mainly ignores (dynamic) complexity and (deep) uncertainty. This paper illustrates two model-based approaches for supporting policymaking for complex and uncertain issues as well as their combination. First, Exploratory System Dynamics Modeling and Analysis allows exploring and analyzing millions of plausible (uncertain) dynamic system behaviors and testing the robustness of policies. This approach is illustrated by means of a System Dynamics simulation model related to energy grid investments. Second, Experiential Model-Based Gaming allows policymakers to experience dynamic complexity and deep uncertainty, and helps them feel the need to embrace both in policymaking. Before having experienced different plausible futures, almost all high-level managers and highly-educated students that played such experiential games applied inappropriate strategies in most plausible futures played, and hence failed in the face of uncertainty. Failing repeatedly actually prepared them for thinking outside their old/reactive/predictive modes in subsequent bounce-casting sessions. Exploratory System Dynamics Modeling and Analysis and Experiential Model-Based Gaming may also be mutually beneficial: most subjects only acknowledge the need to take uncertainty and dynamic complexity seriously into account after having participated in experience-oriented gaming sessions.},
  keywords={Robustness},
  doi={},
  ISSN={2159-5100},
  month={July},}@INPROCEEDINGS{10369475,
  author={Priya, V. Sathya and Ramana, Bathula Venkata and Kumar, Abbaraboina Shiva and Tanvireddy, Anthareddy and Jasta, Abhinav},
  booktitle={2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Crop Recommendation Using Machine Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In current decades India has knowing a significant decline in land crop depiction generally due to the damaging belongings of feeling change accurate prognosis of crop yield before harvest is essential for laborers and policymakers to make conversant resolutions concerning marketing and depository this project aims to evolve an common prediction method original that allows farmers to estimate crop result before education bureaucracy will feature a user-friendly netting-located graphical interface and engage a machine intelligence invention anticipated effects will be determined to laborers empowering ruling class to create appropriate resolutions based on the news miscellaneous methods and algorithms including the usual chance forest invention will be promoted to resolve essential variables such as weather environments heat dampness rainfall and liquid for land result forecasting furthermore dossier excavating a comprehensive approach to resolving dossier from multiple outlooks will be used to extract valuable judgments random thicket a strong directed machine learning treasure worthy operating classification and reversion tasks builds an ensemble of conclusion trees all along preparation and generates prophecies established the fad of classes classification or the mean prognosis reversion from individual shrubs by integrating these methods this project aims to specify an direct solution for thinking crop yield in India portion of food to address the challenges formal by climate change in the land area},
  keywords={Support vector machines;Scalability;Forestry;Prediction algorithms;Robustness;Decision trees;Climate change;Agriculture;Crop Prediction;Data Mining;Random Forest Algorithm;Crop yield},
  doi={10.1109/RMKMATE59243.2023.10369475},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10452115,
  author={Zhang, Hui and Jia, Dexing and Chen, Lei and Wang, Xiongru and Wang, Shuai and Li, Rui},
  booktitle={2023 China Automation Congress (CAC)}, 
  title={Acceleration and Implementation of Database Aggregation Query Based on FPGA}, 
  year={2023},
  volume={},
  number={},
  pages={817-822},
  abstract={Database is an important carrier to meet information overall management. With the continuous development of global information construction in recent years, the types and quantities of information stored in databases are increasing. Implementing high-speed query response to massive database storage resources through hardware-level optimization design has become an important research direction in related fields. Aiming at the key problems such as low efficiency and high delay existing in the process of performing aggregation operation in the current mainstream database, this paper thorough analysis the principles and key steps of database execution of aggregation queries, and a new FPGA-based database aggregation query accelerator is designed using heterogeneous thinking. The accelerator is designed according to the actual application scenario of relational database aggregation query, and implements the aggregation grouping strategy based on hash algorithm and five commonly used aggregation functions through FPGA; In order to maximize processing efficiency and fully utilize the excellent parallel processing capabilities of FPGA, this study also optimizes the existing aggregation query architecture and proposes a decentralized multi-core collaborative aggregation query architecture to meet the needs of single time period and multithreaded queries. The aggregation query experiments on ZNBase, an open source database platform, show that the proposed database aggregation query accelerator based on FPGA is 21.71 times more efficient than the traditional software algorithm to realize the aggregation query scheme.},
  keywords={Databases;Query processing;Software algorithms;Collaboration;Computer architecture;Relational databases;Parallel processing;database;FPGA;heterogeneous acceleration;aggregation;hash grouping;aggregation function},
  doi={10.1109/CAC59555.2023.10452115},
  ISSN={2688-0938},
  month={Nov},}@INPROCEEDINGS{7836183,
  author={Acholonu, Ugochi and Amato, Dominic and Dickinson, Jessa and Smith, Leslie and Engel, Joshua and Walker, Erin and Grant, Gina and Pinkard, Nichole},
  booktitle={2016 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT)}, 
  title={Remixing Minecraft to broaden participation in computing}, 
  year={2016},
  volume={},
  number={},
  pages={1-1},
  abstract={Minecraft is one of the most popular games among youth today, experiencing sales over 100 million worldwide and channels on YouTube generating over 47 billion views. Our interest in the game environment is due to its innate computational mechanics that integrate logic, design, and scripting elements. Because of these traits, many organizations and schools are looking to incorporate Minecraft into their curriculum to support computational thinking and computational practices. However, there are challenges surrounding the distribution and availability of individuals who possess the technical and computational expertise needed to support these opportunities. In this poster we introduce the DYN Minecraft Server project. The project is designed to address barriers of entry for adults at schools and youth-serving organizations who want to provide computing-related learning opportunities to diverse youth. We worked with families, city organizations, mentors, and youth to modify the commercially available Minecraft to support adults who may have limited expertise in computing or Minecraft, yet wish to use the platform in order to teach computational content The modifications include the integration of an information network that promotes STEM learning opportunities that are available throughout the city. We discuss our design process, designed activities and interfaces, and feedback from youth, partners, and mentors using the system.},
  keywords={Organizations;Games;Urban areas;Media;Electronic mail;YouTube;Servers},
  doi={10.1109/RESPECT.2016.7836183},
  ISSN={},
  month={Aug},}@ARTICLE{8782559,
  author={Zhang, Dongyu and Lin, Hongfei and Liu, Xikai and Zhang, Heting and Zhang, Shaowu},
  journal={IEEE Access}, 
  title={Combining the Attention Network and Semantic Representation for Chinese Verb Metaphor Identification}, 
  year={2019},
  volume={7},
  number={},
  pages={137103-137110},
  abstract={Metaphor is the central issue of language and thinking. Metaphor identification plays a significant preliminary role in the field of machine translation, reading comprehension, and automatic summarization, making it a focus of natural language processing. Recently, research into Chinese verb metaphor identification has become a widespread concern. The main problem is that the usage of semantic resources is relatively simple, and there is a lack of deep semantic support. Therefore, this paper proposes a word representation method suitable for metaphor classification tasks, which combines the traditional word vector with structural information from the Synonym Thesaurus, so that the word vector can contain the abstraction degree of the word in the metaphor. On this basis, we propose a verb metaphor attention network based on subject-predicate and verb-object relationships, which gives full consideration to the global syntactic information when we perform LSTM encoding and calculate the weight of each word. At the same time, it can facilitate the understanding of literalness and non-literalness. The experimental results show that the identification effect improves on the existing results, indicating that word representation combining semantic resources and attention network can improve the verb metaphor identification performance.},
  keywords={Thesauri;Semantics;Task analysis;Deep learning;Computational modeling;Natural language processing;Attention network;metaphor identification;metaphor dataset;semantic representation},
  doi={10.1109/ACCESS.2019.2932136},
  ISSN={2169-3536},
  month={},}@ARTICLE{10320351,
  author={Yang, Shengying and Wang, Xu and Qian, Xiaohong and Yu, Yunxiang and Jin, Wuyin},
  journal={IEEE Access}, 
  title={Trident-LK Net: A Lightweight Trident Structure Network With Large Kernel for Muti-Scale Defect Detection}, 
  year={2023},
  volume={11},
  number={},
  pages={131073-131080},
  abstract={Identifying defects at different scales is a challenge in industrial defect detection. To solve this problem, many multi-scale feature fusion networks have been proposed to improve multi-scale target detection accuracy by fusing fine-grained information from shallow networks and semantic information from deep networks. This approach requires the introduction of extraÂ parameters. Thinking from another perspective, can the accuracy of multi-scale target detection be improved by fusing the feature information under different receptive fields? For this purpose, we designed a three-layer network structure called Trident-LK Net. our model uses convolutional kernels of different sizes (31, 25, 1) in the feature extraction phase and establishes cross-fusion connections. This omits the feature fusion part and greatly reduces the network parameters while obtaining a good detection accuracy. Finally we perform experiments on the neu-det dataset and the gc10 dataset to verify the feasibility of our idea. While keeping the number of parameters to a minimum, our model achieves competitive detection results on the neu-det dataset (76.9% mAP) and optimal on the gc10 dataset (63.55% mAP). Our code will be publicly available at https://github.com/syyang2022/Trident-LK-Net.},
  keywords={Feature extraction;Convolutional neural networks;Kernel;Computational modeling;Detectors;Data mining;Steel;Industrial engineering;Structural engineering;Convolutional neural network;defect detection;feature fusion;lightweight network},
  doi={10.1109/ACCESS.2023.3333918},
  ISSN={2169-3536},
  month={},}@ARTICLE{10097489,
  author={Klimo, Martin and Kopčan, Jaroslav and Králik, L’ubomír},
  journal={IEEE Access}, 
  title={Explainability as a Method for Learning From Computers}, 
  year={2023},
  volume={11},
  number={},
  pages={35853-35865},
  abstract={Humans have rich experience applying linear models and logical thinking, but only experts understand the behaviour of non-linear systems. However, the deep neural network (DNN) implementation of text non-linear systems outperforms optimal linear models. Therefore, the forward DNN (the pattern recognition system in this paper) attracts attention to the necessity of interpreting the results obtained by DNN. To preserve the high performance of DNN, we focus on a post-hoc explanation; this approach means building an explainable model for the decision obtained by the black box. To avoid the interpretation of a set of millions of non-linear functions, we divide DNN into two parts: the feature extractor and the classifier. Following that, we argue for a specific interpretation of each of them. While for classifiers, we have several suitable explainable models (and we decided on the fuzzy logical function), we believe that feature interpretation is a creative scientific activity corresponding to the usual research. The paper presents a tool to help researchers and users understand extracted features not necessarily known in the specific application domain. Explaining the new features offers a way to learn from computers.},
  keywords={Feature extraction;Neural networks;Decision making;Data mining;Deep learning;Fuzzy logic;Computational modeling;Explainability;feature extraction;neural networks;machine learning;pattern classification},
  doi={10.1109/ACCESS.2023.3265582},
  ISSN={2169-3536},
  month={},}@ARTICLE{10273694,
  author={Zhang, Shuo and Chang, Yujian and Wang, Shuohe and Li, Yuesong and Gu, Tangqi},
  journal={IEEE Access}, 
  title={An Improved Lightweight YOLOv5 Algorithm for Detecting Railway Catenary Hanging String}, 
  year={2023},
  volume={11},
  number={},
  pages={114061-114070},
  abstract={Aiming at the problems of small target and low recognition accuracy of high-speed railway contact network hanging chord defects, this paper proposes a target detection algorithm for hanging chord defects based on YOLOv5. To enhance the original YOLOv5 algorithm, the MobielNetv3 module was used as the efficient and lightweight backbone feature extraction network. Depth-separable convolution was adopted instead of standard convolution, reducing the number of network parameters by  $2\times 10 ^{6}$  and increasing detection speed by 23%. Introducing BiFPN feature pyramid structure with fusion of different feature layers in neck network improves detection accuracy by 0.4%. Adding CBAM attention mechanism at the prediction end improves the feature extraction ability of the model for small target images, which further improves the detection accuracy by 0.5%. The loss function CIoU was improved to Focal EIoU in order to solve the problems of unbalanced sample datasets and vanishing IoU gradients during the training process. The experimental results exhibit that the improved algorithm achieves an average accuracy of 98.5% on the dataset, a 39% enchancment in model detection speed and a 28% reduction in model parameters, verifying that the algorithm has the advantages of high recognition accuracy and fast detection speed. It can effectively solve the technical difficulties in the detection of defects in the existing contact network suspension chords, and provides a new way of thinking for intelligent railway inspection.},
  keywords={Feature extraction;Convolutional neural networks;Deep learning;Rail transportation;Training;Predictive models;Computational efficiency;YOLO;YOLOv5;lightweight network;image detection;railway;deep learning},
  doi={10.1109/ACCESS.2023.3322444},
  ISSN={2169-3536},
  month={},}@ARTICLE{10632117,
  author={Asiri, Mashael M. and Alfraihi, Hessa and Said, Yahia and Othman, Kamal M. and Salama, Ahmed S. and Marzouk, Radwa},
  journal={IEEE Access}, 
  title={Securing Consumer Electronics Devices: A Blockchain-Based Access Management Approach Enhanced by Deep Learning Threat Modeling for IoT Ecosystems}, 
  year={2024},
  volume={12},
  number={},
  pages={110671-110680},
  abstract={Securing user electronics devices has become a significant concern in the digital period, and a forward-thinking solution covers the fusion of blockchain (BC) technology and deep learning (DL) methods. Blockchain improves device safety by transforming access management, storing credentials on a tamper-resistant ledger, mitigating the risk of unauthorized access and giving a robust defence against malevolent actors. Integrating DL into this framework also raises safety measures, as it permits devices to inspect and regulate to develop attacks distinctly. DL models accurately recognize intricate designs and anomalies, allowing the technique to distinguish and threaten possible attacks in real time. The fusion of BC and DL not only improves the reliability of user electronics but also establishes a dynamic and adaptive safety system, enhancing consumer confidence in the safety of their devices. Therefore, this study presents a BC-Based Access Management with DL Threat Modeling (BCAM-DLTM) technique for securing consumer electronics devices in the IoT ecosystems. The BCAM-DLTM technique mainly follows a two-phase procedure: access management and threat detection. Moreover, BC technology can be applied to the access management of consumer electronics devices. Besides, the BCAM-DLTM technique applies a deep belief networks (DBNs) model for proficiently identifying threats. To enhance the recognition results of the DBN model, the hyperparameter tuning procedure uses the reptile search algorithm (RSA). The experimental outcome study of the BCAM-DLTM approach employs the NSLKDD dataset. The comprehensive results of the BCAM-DLTM approach portrayed a superior accuracy outcome of 99.63% over existing models in terms of distinct metrics.},
  keywords={Biological system modeling;Safety;Consumer electronics;Internet of Things;Computational modeling;Threat modeling;Ecosystems;Blockchains;Deep learning;Search methods;Evidence theory;Blockchain;Internet of Things;deep learning;reptile search algorithm;deep belief network},
  doi={10.1109/ACCESS.2024.3441094},
  ISSN={2169-3536},
  month={},}@ARTICLE{8735819,
  author={Oozeer, Mohammad Irshaad and Haykin, Simon},
  journal={IEEE Access}, 
  title={Cognitive Dynamic System for Control and Cyber-Attack Detection in Smart Grid}, 
  year={2019},
  volume={7},
  number={},
  pages={78320-78335},
  abstract={This paper introduces a new way of thinking that characterizes itself by uniting two entities, namely state estimation in the smart grid (SG) and cognitive dynamic system (CDS). False data injection (FDI) attacks are a family of new attacks that have been considered to be the most dangerous cyber-attack as it leads to cascaded bad decision making throughout the SG network, which can lead to severe repercussions. The conventional state estimation and bad data detection techniques, which have been applied to reduce observation errors and detect bad data in energy system state estimators, cannot detect FDI attacks. Here, we bring into play an objective-seeking system to act as the supervisor of the SG network. To this end, we propose to introduce a new metric for the SG: the entropic state. The entropic state has two purposes: 1) it provides an indication of the grid's health on a cycle-to-cycle basis and 2) it can be used to detect FDI attacks. Consequently, improving the entropic state is the goal of the supervisor. To achieve that objective, the supervisor dynamically optimizes the state estimation process by reconfiguring the weights of the sensors in the network. With optimality in mind, the CDS is the superior choice for the supervisory system. In this structure, the CDS interacts with the SG network, which is considered as the environment. Computer simulations are carried out on a 4-bus and the IEEE 14-bus systems to highlight the performance of the proposed approach in detecting both bad data and FDI attacks in the SG, respectively.},
  keywords={State estimation;Transmission line measurements;Power measurement;Smart grids;Measurement uncertainty;Mathematical model;Voltage measurement;Bad data detection (BDD);false data injection;cognitive dynamic systems;cognitive control;cumulative sum (CUSUM);cyber-physical attack;cyber-physical systems;online estimation;smart grid;smart grid security},
  doi={10.1109/ACCESS.2019.2922410},
  ISSN={2169-3536},
  month={},}@ARTICLE{10197372,
  author={Gaba, Shivani and Khan, Haneef and Almalki, Khalid Jaber and Jabbari, Abdoh and Budhiraja, Ishan and Kumar, Vimal and Singh, Akansha and Singh, Krishna Kant and Askar, S. S. and Abouhawwash, Mohamed},
  journal={IEEE Access}, 
  title={Holochain: An Agent-Centric Distributed Hash Table Security in Smart IoT Applications}, 
  year={2023},
  volume={11},
  number={},
  pages={81205-81223},
  abstract={The accomplishment of blockchain has increased the focus on the various applications for simplifying the confidentiality and transaction sanctuary using the decentralized architecture via consensus mechanisms between different internet of things (IoT) nodes in daily increasing societal areas. The growth of blockchain lasted to grow and used to do compare technologies. The major shortcomings of blockchain is the lack of scalability in modern application settings. Holochain technology vends itself as a “thinking” exterior to blocks, and it is a peer-to-peer disseminated ledger technology. It works contrarily compared to the blockchain, and it offers an exclusive value in the existing market. IoT devices are continuously used in distributed environments, in various smart applications. The peer-to-peer IoT networks, connected to smart agricultural systems are exposed to the security issues. Specifically, the personal data of agricultural land records need protection against unauthorized access and eradicate corruption in land transactions. The Blockchain offers a possible solution based on distributed ledger, but it has scalability issues due to high storage and processing requirements with growing network size. Also data is not locally stored in a Blockchain. This paper studies the conventions of holochain technology, its architecture and challenges, and critical mechanisms of holochain applications. We also analyze the numerous models utilized for the implementation of protected transactions. We discuss an agent centric framework with distributed hash table for secured applications.},
  keywords={Internet of Things;Blockchains;Decentralized applications;Distributed ledger;Security;Peer-to-peer computing;Array signal processing;Distributed ledger;Holochain;communication infrastructure;holo;ledger;process models;distributed ledger technology;agent centric technology;blockchain},
  doi={10.1109/ACCESS.2023.3300220},
  ISSN={2169-3536},
  month={},}@ARTICLE{8164418,
  author={Chen, Bo and Frank, Joachim},
  journal={Microscopy}, 
  title={Two promising future developments of cryo-EM: capturing short-lived states and mapping a continuum of states of a macromolecule}, 
  year={2016},
  volume={65},
  number={1},
  pages={69-79},
  abstract={The capabilities and application range of cryogenic electron microscopy (cryo-EM) method have expanded vastly in the last two years, thanks to the advances provided by direct detection devices and computational classification tools. We take this review as an opportunity to sketch out promising developments of cryo-EM in two important directions: (i) imaging of short-lived states (10–1000 ms) of biological molecules by using time-resolved cryo-EM, particularly the mixing-spraying method and (ii) recovering an entire continuum of coexisting states from the same sample by employing a computational technique called manifold embedding. It is tempting to think of combining these two methods, to elucidate the way the states of a molecular machine such as the ribosome branch and unfold. This idea awaits further developments of both methods, particularly by increasing the data yield of the time-resolved cryo-EM method and by developing the manifold embedding technique into a user-friendly workbench.},
  keywords={classification;manifold embedding;microfluidics;ribosome;time-resolved imaging;translation},
  doi={10.1093/jmicro/dfv344},
  ISSN={1477-9986},
  month={Feb},}@INPROCEEDINGS{8826801,
  author={Guo, Yida and Zhang, Cheng and Lu, Shaofeng},
  booktitle={IET Doctoral Forum on Biomedical Engineering, Healthcare, Robotics and Artificial Intelligence 2018 (BRAIN 2018)}, 
  title={A decision-making approach for semi-decentralized rail transit control system}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={At present, the primary control system in the field of rail transit is in the form of centralised control, which is based on the communication of the ground side system and the on-board side system. A central controller will play the role of information flow centre and has to afford a lot of computational loads when it needs to manage a large number of trains simultaneously. It is believed that with the development of artificial intelligence algorithms, the control system could be built based on a semi-decentralised multi-agent system (MAS). This paper proposes an innovative MAS system to enhance the decision-making of the rail transit control system. This proposed MAS includes several agents, e.g., train agents, station agents, and a central agent. A train agent can exchange information with other agents directly and make decisions based on the collected data. A case study is carried out to build a preliminary MAS for a rail transit control in Suzhou Metro. Compared with the centralised control system, this MAS can reduce the computational pressure of the central controller and improve the information exchange efficiency. The proposed method is expected to advance the thinking of how to achieve fully automated train control in the future.},
  keywords={Medical services;Safety;Artificial intelligence;Rails;Optimization;Rail transportation;Biomedical engineering;MULTI-AGENT;RAIL TRANSIT;DECISION APPROACH},
  doi={10.1049/cp.2018.1732},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9622328,
  author={},
  booktitle={2021 IEEE Real-Time Systems Symposium (RTSS)}, 
  title={Hot Topic Day}, 
  year={2021},
  volume={},
  number={},
  pages={17-17},
  abstract={Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. RTSS 2021 features the Hot Topics Day (HTD) that highlights emerging research topics related to realtime systems. The HTD features a combination of workshops, special sessions, and tutorials. Unfortunately the uncertainties due to COVID-19 affected the number of proposed events during the HTD. Still, the 2021 HTD will welcome the following very interesting special session "Self-Adaptive Safety- and Mission-critical CPS: Wishful Thinking or Absolute Necessity?" Due to the increasing performance demands of mission- and safety-critical Cyber Physical Systems (CPS), these systems exhibit a rapidly growing complexity, manifested by an increasing number of (distributed) computational cores and application components connected via complex networks. However, with the growing complexity and interconnectivity of these systems, the chances of hardware failures as well as disruptions due to cyber-attacks will also quickly increase. System adaptivity, for example in the form of dynamically remapping of application components to processing cores, represents a promising technique to handle this challenging scenario. In this session, we address the (consequences of the) idea of deploying runtime adaptivity to mission and safety-critical CPS, yielding dynamically morphing systems, to establish robustness against computational hurdles, component failures, and cyberattacks. This special session reports some of the research findings of the European Union's Horizon 2020 research and innovation project ADMORPH (http://admorph.eu/).},
  keywords={Complexity theory;Uncertainty;Tutorials;Technological innovation;Runtime;Robustness;Real-time systems},
  doi={10.1109/RTSS52674.2021.00009},
  ISSN={2576-3172},
  month={Dec},}@INPROCEEDINGS{10343283,
  author={Walker, Justice T. and Barany, Amanda and Acquah, Alex and Reza, Sayed Mohsin and Barrera, Alan and Del Rio Guzman, Karen and Johnson, Michael A.},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Coding Like a Data Miner: A Sandbox Approach to Computing-Based Data Science for High School Student Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Personal health tracking devices and internet-based digital platforms with the capacity to collect, aggregate, and store data at massive scales are examples of tools that have broadened priorities in computing to include data science. In response, there has been growing attention in research and practice emphasizing pre-college groups. This is partly because of the growing recognition-reflected in initiatives like CS4ALL, Code.org, Bootstrap: Data Science, Exploring Computer Science-that learning experiences before college are consequential in sustaining a robust pipeline of computer scientists and engineers. Despite these inroads, there is justifiable concern that existing efforts might not fully support learner development in the necessary conceptual, epistemological, and heuristic styles needed to productively parse and understand “big data.” This is because computing-based curricula that include data science often involve data curated by others (rather than learners directly), which results in simulated versions of practice instead of engagement that is realistically discursive and messy. This is further complicated by the persistent shortage of K-12 computer science teachers in general and even fewer who can design and implement curricula that support authentic engagement with data science. To address these issues, we leverage culturally relevant and constructionist perspectives in a sandbox (i.e., open-ended) science where tools like Scratch and electronic textiles (E-textiles) have had success expanding possibilities in computing to also include activities where learners can engage broadly along varied pursuits-and encounter challenges that spur computational thinking and problem-solving. The literature suggests that learning activities framed in this way encourage knowledge construction, practice literacies, and seriously impact learner attitudes, interest, and perceptions of growth in the field. This latter set of self-concept measures represents a few of many related key predictors of long-term field participation and persistence. In this work-in-progress scholarship of discovery research, we co-develop, with youth and educators, “Coding Like a Data Miner” (CLDM)-a sandbox approach to computing-based data science wherein learners access a social media platform, Twitter, to mine, analyze, and understand quantitative and qualitative data sources. In this preliminary work, we assess affordances in co-developing a curriculum that leverages sandbox approaches to data science. Ultimately (and what will be presented in our final submission), we aim to study learning outcomes when high school students' access, analyze and make sense of “big data” sets of their own. We collaborated with high school teachers in a West Texas/Paso Del Norte region where computer science educators are exceptionally scarce and where there is an urgent and persistent need to support underrepresented learner access to burgeoning areas of computing. Using mixed-methodological approaches (e.g., quantitative analysis of learner pre- and post-survey responses along with qualitative assessments of semi-structured interview data), we address the following research questions: (1) What affordances exist using co-design approaches to develop sandbox data science for pre-college learners? (2) Which computational concepts do students learn when carrying out CLDM activities, (3) Which computational practices do high school students enact when mining, processing, and analyzing big data sets in CLDM? (4) How do learner knowledge and perceptions about data science shift after participating in CLDM? We use contemporary perspectives in computing education, constructionism, and equity to discuss how open-ended sandbox approaches to computing-based data science support learner computational thinking, practice literacies, and field perceptions.},
  keywords={Computer science;Smart textiles;Social networking (online);Statistical analysis;Affordances;Soft sensors;Scholarships;Computer Science Education;Data Science Education;Constructionism;Curriculum Design;Computer Science Learning},
  doi={10.1109/FIE58773.2023.10343283},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{88101,
  author={Ayache, N. and Faugeras, O.D.},
  journal={IEEE Transactions on Robotics and Automation}, 
  title={Maintaining representations of the environment of a mobile robot}, 
  year={1989},
  volume={5},
  number={6},
  pages={804-819},
  abstract={A description is given of current ideas related to the problem of building and updating three-dimensional representations of the environment of a mobile robot that uses passive vision as its main sensory modality. The authors attempt to represent both geometry and uncertainty. The authors motivate their approach by defining the problems they are trying to solve and then give some simple didactic examples. They then present a tool they think is extremely well adapted to solving most of these problems: the extended Kalman filter (EKF). The authors discuss the notions of minimal geometric representations for three-dimensional lines, planes, and rigid motions. They show how the EKF and the representations can be combined to provide solutions for some of the problems. A number of experimental results on real data are given.<>},
  keywords={Mobile robots;Computational geometry;Uncertainty;Noise reduction;Position measurement;Information geometry;Computer vision;Stereo vision;Motion analysis;Sonar},
  doi={10.1109/70.88101},
  ISSN={2374-958X},
  month={Dec},}@ARTICLE{499793,
  author={Tani, J.},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)}, 
  title={Model-based learning for mobile robot navigation from the dynamical systems perspective}, 
  year={1996},
  volume={26},
  number={3},
  pages={421-436},
  abstract={This paper discusses how a behavior-based robot can construct a "symbolic process" that accounts for its deliberative thinking processes using models of the environment. The paper focuses on two essential problems; one is the symbol grounding problem and the other is how the internal symbolic processes can be situated with respect to the behavioral contexts. We investigate these problems by applying a dynamical system's approach to the robot navigation learning problem. Our formulation, based on a forward modeling scheme using recurrent neural learning, shows that the robot is capable of learning grammatical structure hidden in the geometry of the workspace from the local sensory inputs through its navigational experiences. Furthermore, the robot is capable of generating diverse action plans to reach an arbitrary goal using the acquired forward model which incorporates chaotic dynamics. The essential claim is that the internal symbolic process, being embedded in the attractor, is grounded since it is self-organized solely through interaction with the physical world. It is also shown that structural stability arises in the interaction between the neural dynamics and the environmental dynamics, which accounts for the situatedness of the internal symbolic process, The experimental results using a mobile robot, equipped with a local sensor consisting of a laser range finder, verify our claims.},
  keywords={Mobile robots;Navigation;Robot sensing systems;Grounding;Solid modeling;Computational geometry;Chaos;Structural engineering;Laser stability;Laser theory},
  doi={10.1109/3477.499793},
  ISSN={1941-0492},
  month={June},}@ARTICLE{8585034,
  author={Cao, Y. and Romero, J. and Aspuru-Guzik, A.},
  journal={IBM Journal of Research and Development}, 
  title={Potential of quantum computing for drug discovery}, 
  year={2018},
  volume={62},
  number={6},
  pages={6:1-6:20},
  abstract={Quantum computing has rapidly advanced in recent years due to substantial development in both hardware and algorithms. These advances are carrying quantum computers closer to their impending commercial utility. Drug discovery is a promising area of application that will find a number of uses for these new machines. As a prominent example, quantum simulation will enable faster and more accurate characterizations of molecular systems than existing quantum chemistry methods. Furthermore, algorithmic developments in quantum machine learning offer interesting alternatives to classical machine learning techniques, which may also be useful for the biochemical efforts involved in early phases of drug discovery. Meanwhile, quantum hardware is scaling up rapidly into a regime where an exact simulation is difficult even using the world’s largest supercomputers. We review how these recent advances can shift the paradigm with which one thinks about drug discovery, focusing on both the promises and caveats associated with each development. In particular, we highlight how hybrid quantum-classical approaches to quantum simulation and quantum machine learning could yield substantial progress using noisy-intermediate scale quantum devices, whereas fault-tolerant, error-corrected quantum computers are still in their development phase.},
  keywords={Quantum computing;Drugs;Proteins;Computers;Machine learning;Computational modeling},
  doi={10.1147/JRD.2018.2888987},
  ISSN={0018-8646},
  month={Nov},}@ARTICLE{8726069,
  author={Zeng, Deze and Gu, Lin and Pan, Shengli and Cai, Jingjing and Guo, Song},
  journal={IEEE Network}, 
  title={Resource Management at the Network Edge: A Deep Reinforcement Learning Approach}, 
  year={2019},
  volume={33},
  number={3},
  pages={26-33},
  abstract={With the advent of edge computing, it is highly recommended to extend some cloud services to the network edge such that the services can be provisioned in the proximity of end users, with better performance efficiency and cost efficiency. Compared to cloud computing, edge computing has high dynamics, and therefore the resources shall be correspondingly managed in an adaptive way. Traditional model-based resource management approaches are limited in practical application due to the involvement of some assumptions or prerequisites. We think it is desirable to introduce a model-free approach that can fit the network dynamics well without any prior knowledge. To this end, we introduce a model-free DRL approach to efficiently manage the resources at the network edge. Following the design principle of DRL, we design and implement a mobility- aware data processing service migration management agent. The experiments show that our agent can automatically learn the user mobility pattern and accordingly control the service migration among the edge servers to minimize the operational cost at runtime. Some potential future research challenges are also presented.},
  keywords={Resource management;Edge computing;Dynamic scheduling;Servers;Task analysis;Computational modeling},
  doi={10.1109/MNET.2019.1800386},
  ISSN={1558-156X},
  month={May},}@INPROCEEDINGS{6623561,
  author={Fuhr, Thomas and Jaulmes, Eliane and Lomné, Victor and Thillard, Adrian},
  booktitle={2013 Workshop on Fault Diagnosis and Tolerance in Cryptography}, 
  title={Fault Attacks on AES with Faulty Ciphertexts Only}, 
  year={2013},
  volume={},
  number={},
  pages={108-118},
  abstract={Classical Fault Attacks often require the ability to encrypt twice the same plaintext, in order to get one or several pairs of correct and faulty cipher texts corresponding to the same message. This observation led some designers to think that a randomized mode of operation may be sufficient to protect block cipher encryption against this kind of threat. In this paper, we consider the case where the adversary neither chooses nor knows the input messages, and has only access to the faulty cipher texts. In this context, we are able to describe several attacks against AES-128 by using non uniform fault models. Our attacks target the last 4 rounds and allow to recover the correct key with practical time complexity, using a limited number of faulty cipher texts. This work highlights the need for dedicated fault attack countermeasures in secure embedded systems.},
  keywords={Ciphers;Encryption;Mathematical model;Context;Computational modeling;Protocols;Fault Attacks;AES},
  doi={10.1109/FDTC.2013.18},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9123060,
  author={Qiu, Meikang and Qiu, Han},
  booktitle={2020 IEEE 6th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)}, 
  title={Review on Image Processing Based Adversarial Example Defenses in Computer Vision}, 
  year={2020},
  volume={},
  number={},
  pages={94-99},
  abstract={Recent research works showed that deep neural networks are vulnerable to adversarial examples, which are usually maliciously created by carefully adding deliberate and imperceptible perturbations to examples. Several states of the art defense methods are proposed based on the existing image processing methods like image compression and image denoising. However, such approaches are not the final optimal solution for defense adversarial perturbations in DNN models. In this paper, we reviewed two main approaches to deploying image processing methods as a defense. By analyzing and discus!sing the remaining issues, we present two open questions for future research direction including the definition of adversarial perturbations and noises, the novel defense-aware threat model. A further research direction is also given by re-thinking the impacts of adversarial perturbations on all frequency bands.},
  keywords={Deep learning;Computer vision;Image coding;Perturbation methods;Computational modeling;Conferences;Robustness;Deep learning;adversarial examples;image denoising;image compression;computer vision},
  doi={10.1109/BigDataSecurity-HPSC-IDS49724.2020.00027},
  ISSN={},
  month={May},}@ARTICLE{1510539,
  author={Naps, T.L.},
  journal={IEEE Computer Graphics and Applications}, 
  title={JHAVE: supporting algorithm visualization}, 
  year={2005},
  volume={25},
  number={5},
  pages={49-55},
  abstract={JHAVE fosters the use of algorithm visualization as an effective pedagogical tool for computer science educators, helping students to better understand algorithms. The Java-hosted algorithm visualization environment (JHAVE) is not an AV system itself but rather a support environment for a variety of AV systems (called AV engines by JHAVE). In broad terms, JHAVE gives such an engine a drawing context on which it can render its pictures in any way. In return, JHAVE provides the engine with effortless ways to synchronize its graphical displays with i) a standard set of VCR-like controls, ii) information and pseudocode windows, iii) input generators, iv) stop-and-think questions, and v) meaningful content generation tools.},
  keywords={Visualization;Computer graphics;Computer science;Animation;Computer science education;Computer displays;Uniform resource locators;Materials science and technology;Computational modeling;Computer simulation;graphics;algorithm visualization;computer science education;active learning;active engagement},
  doi={10.1109/MCG.2005.110},
  ISSN={1558-1756},
  month={Sep.},}@INPROCEEDINGS{9004659,
  author={Shao, Guodong and Jain, Sanjay and Laroque, Christoph and Lee, Loo Hay and Lendermann, Peter and Rose, Oliver},
  booktitle={2019 Winter Simulation Conference (WSC)}, 
  title={Digital Twin for Smart Manufacturing: The Simulation Aspect}, 
  year={2019},
  volume={},
  number={},
  pages={2085-2098},
  abstract={The purpose of this panel is to discuss the state of the art in digital twin for manufacturing research and practice from the perspective of the simulation community. The panelists come from the US, Europe, and Asia representing academia, industry, and government. This paper begins with a short introduction to digital twins and then each panelist provides preliminary thoughts on concept, definitions, challenges, implementations, relevant standard activities, and future directions. Two panelists also report their digital twin projects and lessons learned. The panelists may have different viewpoints and may not totally agree with each other on some of the arguments, but the intention of the panel is not to unify researchers' thinking, but to list the research questions, initiate a deeper discussion, and try to help researchers in the simulation community with their future study topics on digital twins for manufacturing.},
  keywords={Data models;Manufacturing;Analytical models;Biological system modeling;Computational modeling;Standards;Virtual manufacturing},
  doi={10.1109/WSC40007.2019.9004659},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{9711074,
  author={Zhou, Ziqi and Qiu, Xi and Xie, Jiangtao and Wu, Jianan and Zhang, Chi},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Binocular Mutual Learning for Improving Few-shot Classification}, 
  year={2021},
  volume={},
  number={},
  pages={8382-8391},
  abstract={Most of the few-shot learning methods learn to transfer knowledge from datasets with abundant labeled data (i.e., the base set). From the perspective of class space on base set, existing methods either focus on utilizing all classes under a global view by normal pretraining, or pay more attention to adopt an episodic manner to train meta-tasks within few classes in a local view. However, the interaction of the two views is rarely explored. As the two views capture complementary information, we naturally think of the compatibility of them for achieving further performance gains. Inspired by the mutual learning paradigm and binocular parallax, we propose a unified framework, namely Binocular Mutual Learning (BML), which achieves the compatibility of the global view and the local view through both intraview and cross-view modeling. Concretely, the global view learns in the whole class space to capture rich inter-class relationships. Meanwhile, the local view learns in the local class space within each episode, focusing on matching positive pairs correctly. In addition, cross-view mutual interaction further promotes the collaborative learning and the implicit exploration of useful knowledge from each other. During meta-test, binocular embeddings are aggregated together to support decision-making, which greatly improve the accuracy of classification. Extensive experiments conducted on multiple benchmarks including cross-domain validation confirm the effectiveness of our method1.},
  keywords={Learning systems;Degradation;Computer vision;Computational modeling;Decision making;Focusing;Performance gain;Transfer/Low-shot/Semi/Unsupervised Learning;Recognition and classification},
  doi={10.1109/ICCV48922.2021.00829},
  ISSN={2380-7504},
  month={Oct},}@INPROCEEDINGS{344301,
  author={Falsafi, B. and Lebeck, A.R. and Reinhardt, S.K. and Schoinas, I. and Hill, M.D. and Larus, J.R. and Rogers, A. and Wood, D.A.},
  booktitle={Supercomputing '94:Proceedings of the 1994 ACM/IEEE Conference on Supercomputing}, 
  title={Application-specific protocols for user-level shared memory}, 
  year={1994},
  volume={},
  number={},
  pages={380-389},
  abstract={Recent distributed shared memory (DSM) systems and proposed shared-memory machines have implemented some or all of their cache coherence protocols in software. One way to exploit the flexibility of this software is to tailor a coherence protocol to match an application's communication patterns and memory semantics. This paper presents evidence that this approach can lead to large performance improvements. It shows that application-specific protocols substantially improved the performance of three application programs-appbt, em3d, and barnes-over carefully tuned transparent shared memory implementations. The speed-ups were obtained on Blizzard, a fine-grained DSM system running on a 32-node Thinking Machines CM-5.<>},
  keywords={Access protocols;Hardware;Program processors;Distributed computing;Pattern matching;Parallel languages;Computational modeling;Concurrent computing;Sun;Protection},
  doi={10.1109/SUPERC.1994.344301},
  ISSN={},
  month={Nov},}@ARTICLE{8556046,
  author={Carmean, Douglas and Ceze, Luis and Seelig, Georg and Stewart, Kendall and Strauss, Karin and Willsey, Max},
  journal={Proceedings of the IEEE}, 
  title={DNA Data Storage and Hybrid Molecular–Electronic Computing}, 
  year={2019},
  volume={107},
  number={1},
  pages={63-72},
  abstract={Moore's law may be slowing, but our ability to manipulate molecules is improving faster than ever. DNA could provide alternative substrates for computing and storage as existing ones approach physical limits. In this paper, we explore the implications of this trend in computer architecture. We present a computer systems perspective on molecular processing and storage, positing a hybrid molecular-electronic architecture that plays to the strengths of both domains. We cover the design and implementation of all stages of the pipeline: encoding, DNA synthesis, system integration with digital microfluidics, DNA sequencing (including emerging technologies such as nanopores), and decoding. We first draw on our experience designing a DNA-based archival storage system, which includes the largest demonstration to date of DNA digital data storage of over three billion nucleotides encoding over 400 MB of data. We then propose a more ambitious hybrid-electronic design that uses a molecular form of near-data processing for massive parallelism. We present a model that demonstrates the feasibility of these systems in the near future. We think the time is ripe to consider molecular storage seriously and explore system designs and architectural implications.},
  keywords={Molecular computing;Memory;Sequential analysis;Substrates;Computer architecture;Market research;Computational modeling;Data storage systems;Future computer architectures;molecular data storage and computing},
  doi={10.1109/JPROC.2018.2875386},
  ISSN={1558-2256},
  month={Jan},}@ARTICLE{1093885,
  author={Ferguson, M.},
  journal={IEEE Transactions on Communications}, 
  title={An Approximate Analysis of Delay for Fixed and Variable Length Packets in an Unslotted ALOHA Channel}, 
  year={1977},
  volume={25},
  number={7},
  pages={644-654},
  abstract={In this paper we compute the mean delay for an unslotted ALOHA random access channel for both fixed and variable length packets. The analysis is based on the concept of a user cycle and obtains steady state results. When the channel is "stable", the results seem quite accurate. The input parameters to the model are the number of users, the mean think time, and mean retransmission time. The model yields total traffic, throughput and delay but only the latter is emphasized here. Because of the steady state nature of the analysis, no information is obtained on stability. The results are verified by simulation.},
  keywords={Throughput;Delay effects;Steady-state;Traffic control;Stability analysis;Communications Society;Monitoring;NASA;US Government;Computational modeling},
  doi={10.1109/TCOM.1977.1093885},
  ISSN={1558-0857},
  month={July},}@INPROCEEDINGS{5589539,
  author={Dugan, R. C. and Arritt, R. F. and McDermott, T. E. and Brahma, S. M. and Schneider, K.},
  booktitle={IEEE PES General Meeting}, 
  title={Distribution System Analysis to support the Smart Grid}, 
  year={2010},
  volume={},
  number={},
  pages={1-8},
  abstract={The “Smart Grid” refers to various efforts to modernize the power grid through the application of intelligent devices. This paper describes current thinking by members of the Distribution System Analysis Subcommittee (DSA SC) on how distribution system analysis might evolve to support the Smart Grid. Various issues related to Smart Grid and distribution system analysis are identified. The essential characteristics of distribution system analysis tools to support these issues are discussed. Relevant activities of the DSA SC are described.},
  keywords={Smart grids;Load modeling;Integrated circuit modeling;Analytical models;Computational modeling;Planning;Monitoring;Power Distribution System Analysis;Smart grid},
  doi={10.1109/PES.2010.5589539},
  ISSN={1944-9925},
  month={July},}@ARTICLE{8395028,
  author={RichardWebster, Brandon and Anthony, Samuel E. and Scheirer, Walter J.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={PsyPhy: A Psychophysics Driven Evaluation Framework for Visual Recognition}, 
  year={2019},
  volume={41},
  number={9},
  pages={2280-2286},
  abstract={By providing substantial amounts of data and standardized evaluation protocols, datasets in computer vision have helped fuel advances across all areas of visual recognition. But even in light of breakthrough results on recent benchmarks, it is still fair to ask if our recognition algorithms are doing as well as we think they are. The vision sciences at large make use of a very different evaluation regime known as Visual Psychophysics to study visual perception. Psychophysics is the quantitative examination of the relationships between controlled stimuli and the behavioral responses they elicit in experimental test subjects. Instead of using summary statistics to gauge performance, psychophysics directs us to construct item-response curves made up of individual stimulus responses to find perceptual thresholds, thus allowing one to identify the exact point at which a subject can no longer reliably recognize the stimulus class. In this article, we introduce a comprehensive evaluation framework for visual recognition models that is underpinned by this methodology. Over millions of procedurally rendered 3D scenes and 2D images, we compare the performance of well-known convolutional neural networks. Our results bring into question recent claims of human-like performance, and provide a path forward for correcting newly surfaced algorithmic deficiencies.},
  keywords={Visualization;Computer vision;Computational modeling;Psychology;Task analysis;Machine learning;Observers;Object recognition;visual psychophysics;neuroscience;psychology;evaluation;deep learning},
  doi={10.1109/TPAMI.2018.2849989},
  ISSN={1939-3539},
  month={Sep.},}@ARTICLE{8665896,
  author={Shah, Syed Sarmad and Ali, Muhammad and Malik, Asad Waqar and Khan, Muazzam A. and Ravana, Sri Devi},
  journal={IEEE Access}, 
  title={vFog: A Vehicle-Assisted Computing Framework for Delay-Sensitive Applications in Smart Cities}, 
  year={2019},
  volume={7},
  number={},
  pages={34900-34909},
  abstract={The inception of the smart cities concept provides a compelling platform to support innovative applications. It provides distinctive view of cities, where mobile devices, pedestrians, and electronic gadgets can communicate with each other to build an effective urban environment to further improve the living standards. Similarly, the role of the Internet of Things (IoT) and vehicular computing has emerged due to smart cities. This is further complemented by edge and fog computing architectures. The emerging concept of vehicular fog computing has enabled the platform to support delay-sensitive applications and to reduce the workload on the backend networks. Vehicular fog computing is a paradigm that touches the boundaries of thinking vehicles as an infrastructures-as-a-service. The use of vehicles to provide computation on-the-move poses various challenges. The vehicles with onboard computing equipment can facilitate delay-sensitive applications. These vehicles can act as an edge device to reduce the load from a backbone network. However, due to continuous mobility, it is difficult to use traditional frameworks to distribute the computation task among vehicles. In this paper, we propose a framework termed vFog. The vFog is designed to provide computing facilities from nearby fog vehicles. The framework utilizes the onboard computing facility of vehicles without the support of roadside units (RSUs). Moreover, the proposed framework handles churn behavior and supports multi-hop communication to improve the task delivery ratio. The proposed framework allows researchers to benchmark their own task distribution algorithms over the dynamic vehicular networks.},
  keywords={Edge computing;Task analysis;Vehicular ad hoc networks;Processor scheduling;Smart cities;Servers;Computational modeling;Vehicular fog computing;tasks scheduling policy;edge devices;multi-vehicle relay},
  doi={10.1109/ACCESS.2019.2903302},
  ISSN={2169-3536},
  month={},}@ARTICLE{4049910,
  author={Cai, Xiaodong and Wang, Xiaodong},
  journal={IEEE Signal Processing Magazine}, 
  title={Stochastic modeling and simulation of gene networks - A review of the state-of-the-art research on stochastic simulations}, 
  year={2007},
  volume={24},
  number={1},
  pages={27-36},
  abstract={This paper provides a comprehensive review of the state-of-the-art research on stochastic simulations. It stimulates the interest of tackling the problem of stochastic simulation using statistical signal processing methods, as well as innovative thinking of stochastic modeling of gene networks from the viewpoint of signal processing},
  keywords={Stochastic processes;Computational modeling;Gene expression;RNA;Biological system modeling;Polymers;Computer networks;Working environment noise;Kinetic theory;DNA},
  doi={10.1109/MSP.2007.273051},
  ISSN={1558-0792},
  month={Jan},}@INPROCEEDINGS{9578518,
  author={Chandrasegaran, Keshigeyan and Tran, Ngoc-Trung and Cheung, Ngai-Man},
  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={A Closer Look at Fourier Spectrum Discrepancies for CNN-generated Images Detection}, 
  year={2021},
  volume={},
  number={},
  pages={7196-7205},
  abstract={CNN-based generative modelling has evolved to produce synthetic images indistinguishable from real images in the RGB pixel space. Recent works have observed that CNN-generated images share a systematic shortcoming in replicating high frequency Fourier spectrum decay attributes. Furthermore, these works have successfully exploited this systematic shortcoming to detect CNN-generated images reporting up to 99% accuracy across multiple state-of-the-art GAN models.In this work, we investigate the validity of assertions claiming that CNN-generated images are unable to achieve high frequency spectral decay consistency. We meticulously construct a counterexample space of high frequency spectral decay consistent CNN-generated images emerging from our handcrafted experiments using DCGAN, LSGAN, WGAN-GP and StarGAN, where we empirically show that this frequency discrepancy can be avoided by a minor architecture change in the last upsampling operation. We subsequently use images from this counterexample space to successfully bypass the recently proposed forensics detector which leverages on high frequency Fourier spectrum decay attributes for CNN-generated image detection.Through this study, we show that high frequency Fourier spectrum decay discrepancies are not inherent characteristics for existing CNN-based generative models—contrary to the belief of some existing work—, and such features are not robust to perform synthetic image detection. Our results prompt re-thinking of using high frequency Fourier spectrum decay attributes for CNN-generated image detection. Code and models are available at https://keshik6.github.io/Fourier-Discrepancies-CNN-Detection/},
  keywords={Computer vision;Systematics;Codes;Forensics;Computational modeling;Detectors;Computer architecture},
  doi={10.1109/CVPR46437.2021.00712},
  ISSN={2575-7075},
  month={June},}@ARTICLE{933500,
  author={Buttazzo, G.},
  journal={Computer}, 
  title={Artificial consciousness: Utopia or real possibility?}, 
  year={2001},
  volume={34},
  number={7},
  pages={24-30},
  abstract={Since the beginnings of computer technology, researchers have speculated about the possibility of building smart machines that could compete with human intelligence. Given the current pace of advances in artificial intelligence and neural computing, such an evolution seems to be a more concrete possibility. Many people now believe that artificial consciousness is possible and that, in the future, it will emerge in complex computing machines. However, a discussion of artificial consciousness gives rise to several philosophical issues: can computers think or do they just calculate? Is consciousness a human prerogative? Does consciousness depend on the material that comprises the human brain, or can computer hardware replicate consciousness? Answering these questions is difficult because it requires combining information from many disciplines including computer science, neurophysiology, philosophy, and religion. Further, we must consider the influence of science fiction, especially science fiction films, when addressing artificial consciousness. As a product of the human imagination, such works express human desires and fears about future technologies and may influence the course of progress. At a societal level, science fiction simulates future scenarios that can help prepare us for crucial transitions by predicting the consequences of significant technological advances. The paper considers robots in science fiction, the Turing test, computer chess and artificial consciousness.},
  keywords={Humans;Artificial intelligence;Intelligent structures;Machine intelligence;Concrete;Hardware;Computer science;Neurophysiology;Computational modeling;Predictive models},
  doi={10.1109/2.933500},
  ISSN={1558-0814},
  month={July},}@INPROCEEDINGS{8675198,
  author={Hill, Mark and Janapa Reddi, Vijay},
  booktitle={2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)}, 
  title={Gables: A Roofline Model for Mobile SoCs}, 
  year={2019},
  volume={},
  number={},
  pages={317-330},
  abstract={Over a billion mobile consumer system-on-chip (SoC) chipsets ship each year. Of these, the mobile consumer market undoubtedly involving smartphones has a significant market share. Most modern smartphones comprise of advanced SoC architectures that are made up of multiple cores, GPS, and many different programmable and fixed-function accelerators connected via a complex hierarchy of interconnects with the goal of running a dozen or more critical software usecases under strict power, thermal and energy constraints. The steadily growing complexity of a modern SoC challenges hardware computer architects on how best to do early stage ideation. Late SoC design typically relies on detailed full-system simulation once the hardware is specified and accelerator software is written or ported. However, early-stage SoC design must often select accelerators before a single line of software is written. To help frame SoC thinking and guide early stage mobile SoC design, in this paper we contribute the Gables model that refines and retargets the Roofline model---designed originally for the performance and bandwidth limits of a multicore chip---to model each accelerator on a SoC, to apportion work concurrently among different accelerators (justified by our usecase analysis), and calculate a SoC performance upper bound. We evaluate the Gables model with an existing SoC and develop several extensions that allow Gables to inform early stage mobile SoC design.},
  keywords={Computer architecture;Computational modeling;Smart phones;Bandwidth;Fabrics;Software;Hardware;Accelerator architectures;Mobile computing;System-on-Chip;Processor Architecture},
  doi={10.1109/HPCA.2019.00047},
  ISSN={2378-203X},
  month={Feb},}@INPROCEEDINGS{9760970,
  author={William, P. and Badholia, Abhishek and Patel, Brijesh and Nigam, Manoj},
  booktitle={2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)}, 
  title={Hybrid Machine Learning Technique for Personality Classification from Online Text using HEXACO Model}, 
  year={2022},
  volume={},
  number={},
  pages={253-259},
  abstract={Personality refers to a person's unique collection of traits that influence their habits, behaviors, attitudes, and thinking patterns. Text accessible on social networking sites may be used to automatically identify an individual's personality characteristics. In the trials, a publicly accessible benchmark dataset from Kaggle is utilized. The major problem with the previous study was the skewness of the dataset, which was reduced by using the Re-sampling method, essentially random over-sampling, which resulted in improved performance. Although the results produced by all classifiers across all personality characteristics are acceptable, the performance of the XGBoost classifier is exceptional, reaching more than 99 percent precision and accuracy for various qualities. Individual preferences, talents, social and human values, personality variations, and human will power must all be addressed while analyzing entrepreneurial activities, intents, and performance, especially with entrepreneurship playing such an important part in the contemporary dynamic. Using the HEXACO Personality Characteristics Model, this study demonstrates a link between personality traits and entrepreneurial success, indicating that personality traits have a significant and direct effect on entrepreneurial performance.},
  keywords={Text recognition;Social networking (online);Computational modeling;Entrepreneurship;Machine learning;Benchmark testing;Data models;Personality recognition;Social Networks;HEXACO model;Individual Performance;Personality Traits},
  doi={10.1109/ICSCDS53736.2022.9760970},
  ISSN={},
  month={April},}@ARTICLE{1262477,
  author={Leski, J.M.},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)}, 
  title={/spl epsiv/-insensitive fuzzy c-regression models: introduction to /spl epsiv/-insensitive fuzzy modeling}, 
  year={2004},
  volume={34},
  number={1},
  pages={4-15},
  abstract={This paper introduces a new /spl epsiv/-insensitive fuzzy c-regression models (/spl epsiv/FCRM), that can be used in fuzzy modeling. To fit these regression models to real data, a weighted /spl epsiv/-insensitive loss function is used. The proposed method make it possible to exclude an intrinsic inconsistency of fuzzy modeling, where crisp loss function (usually quadratic) is used to match real data and the fuzzy model. The /spl epsiv/-insensitive fuzzy modeling is based on human thinking and learning. This method allows easy control of generalization ability and outliers robustness. This approach leads to c simultaneous quadratic programming problems with bound constraints and one linear equality constraint. To solve this problem, computationally efficient numerical method, called incremental learning, is proposed. Finally, examples are given to demonstrate the validity of introduced approach to fuzzy modeling.},
  keywords={Statistical learning;Fuzzy sets;Error correction;Minimization methods;Computational modeling;Loss measurement;Training data;Noise robustness},
  doi={10.1109/TSMCB.2002.804371},
  ISSN={1941-0492},
  month={Feb},}@INPROCEEDINGS{5941592,
  author={Menghal, P. M. and Laxmi, A. Jaya},
  booktitle={2011 3rd International Conference on Electronics Computer Technology}, 
  title={Real time simulation: A novel approach in engineering education}, 
  year={2011},
  volume={1},
  number={},
  pages={215-219},
  abstract={Today, with the advent of computers and various easily accessible software packages, computer aided teaching tools have become an essential part of both classroom lectures and laboratory experiments in any kind of education curriculum. Real Time Simulation tools, as a part of Electrical Machine Drives laboratory experiments, enhance lab experience by providing students with the opportunity to judge the performance of Electrical Machines in real time situations. This interactive learning environment, consisting of simulations, demonstrations and exercises, can fulfill the role of a bridge from passive learning to active engagement and thus stimulate deeper thinking; grounding a problem based-learning environment. The applications are also very important for relating theory to practice, so that the students can develop engineering judgment and understand how process behavior can be captured using real time simulations. Due to advancement of the software tools like MATLAB/SEVIULINK with its Real Time Workshop(RTW) and Real Time Windows Target (RTWT), real time simulators are used extensively in many engineering fields, such as industry, education and research institutions. As a consequence, inclusion of the real time simulation applications in academic curriculum provides great learning value to the students. A case is made to present overview of the Real Time Simulations of Electrical Machines Drives possibility of including these techniques in modern engineering educational curriculum. This paper will review the various real time simulation techniques such as Real Time Laboratory (RT Lab), Rapid Control Prototyping (RCP) and Hardware in the Loop (HIL), which can be used in a modern engineering education.},
  keywords={Real time systems;Computational modeling;Mathematical model;Motor drives;Power electronics;Education;Testing;Real Time Simulation;Real Time Lab(RT Lab);Hardware in the Loop (HIL);Real Time Workshop;Education Tools},
  doi={10.1109/ICECTECH.2011.5941592},
  ISSN={},
  month={April},}@ARTICLE{192924,
  author={Alvarado, F.L. and Liu, Y.},
  journal={IEEE Transactions on Power Systems}, 
  title={General purpose symbolic simulation tools for electric networks}, 
  year={1988},
  volume={3},
  number={2},
  pages={689-697},
  abstract={Research results on the use of computers to solve simulation problems in a way closer to human thinking are reported. With the aid of techniques in artificial intelligence, database systems, and computer graphics, a set of general-purpose Lisp and Pascal based simulation tools have been developed. Each of these tools solves a specific problem in some stage of simulation. Rule-based and object oriented symbolic manipulations are extensively used. The tools provide more powerful and accurate modeling capability for complex objects, and permit simplicity and flexibility in implementation. They are used to study electrical transient problems, optimal load flow problems, linear control systems, and other simulation problems.<>},
  keywords={Object oriented modeling;Computational modeling;Computer simulation;Humans;Artificial intelligence;Database systems;Computer graphics;Power system modeling;Load flow;Control system synthesis},
  doi={10.1109/59.192924},
  ISSN={1558-0679},
  month={May},}@INPROCEEDINGS{9710781,
  author={Chen, Shoufa and Sun, Peize and Xie, Enze and Ge, Chongjian and Wu, Jiannan and Ma, Lan and Shen, Jiajun and Luo, Ping},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Watch Only Once: An End-to-End Video Action Detection Framework}, 
  year={2021},
  volume={},
  number={},
  pages={8158-8167},
  abstract={We propose an end-to-end pipeline, named Watch Once Only (WOO), for video action detection. Current methods either decouple video action detection task into separated stages of actor localization and action classification or train two separated models within one stage. In contrast, our approach solves the actor localization and action classification simultaneously in a unified network. The whole pipeline is significantly simplified by unifying the backbone network and eliminating many hand-crafted components. WOO takes a unified video backbone to simultaneously extract features for actor location and action classification. In addition, we introduce spatial-temporal action embeddings into our framework and design a spatial-temporal fusion module to obtain more discriminative features with richer information, which further boosts the action classification performance. Extensive experiments on AVA and JHMDB datasets show that WOO achieves state-of-the-art performance, while still reduces up to 16.7% GFLOPs compared with existing methods. We hope our work can inspire re-thinking the convention of action detection and serve as a solid baseline for end-to-end action detection. Code is available at https://github.com/ShoufaChen/WOO.},
  keywords={Location awareness;Computer vision;Computational modeling;Pipelines;Detectors;Predictive models;Feature extraction;Video analysis and understanding},
  doi={10.1109/ICCV48922.2021.00807},
  ISSN={2380-7504},
  month={Oct},}@ARTICLE{7529075,
  author={Cao, Bin and Wang, Jiaxing and Fan, Jing and Yin, Jianwei and Dong, Tianyang},
  journal={IEEE Transactions on Services Computing}, 
  title={Querying Similar Process Models Based on the Hungarian Algorithm}, 
  year={2017},
  volume={10},
  number={1},
  pages={121-135},
  abstract={The structural similarity between two process models is usually considered as the main measurement for ranking the process models for a given query model. Current process query methods are inefficient since too many expensive computations of the graph edit distance are involved. To address this issue, using Petri-net as the modeling method, this paper presents the Hungarian algorithm based similarity query method. Unlike previous work where the non-task nodes (i.e., place nodes in the Petri-net) were lightly studied or even ignored, we think these non-task nodes also play an essential role in measuring the structural similarity between process models. First, we extract the context for each place and define the similarity for a pair of place nodes that are from different process models from two perspectives: commonality and the graph edit distance. Then, the place mapping is transformed to classical assignment problem that can be solved by Hungarian algorithm efficiently. Furthermore, we propose a new process similarity measurement on the basis of the place similarity. The extensive experimental evaluation shows that our Hungarian based methods outperform the baseline algorithm in both retrieval quality and query response time.},
  keywords={Context;Computational modeling;Petri nets;Context modeling;Query processing;Companies;Process models;hungarian algorithm;structural similarity;query processing;petri net},
  doi={10.1109/TSC.2016.2597143},
  ISSN={1939-1374},
  month={Jan},}@INPROCEEDINGS{10205335,
  author={Lin, Haojia and Zheng, Xiawu and Li, Lijiang and Chao, Fei and Wang, Shanshan and Wang, Yan and Tian, Yonghong and Ji, Rongrong},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Meta Architecture for Point Cloud Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={17682-17691},
  abstract={Recent advances in 3D point cloud analysis bring a diverse set of network architectures to the field. However, the lack of a unified framework to interpret those networks makes any systematic comparison, contrast, or analysis challenging, and practically limits healthy development of the field. In this paper, we take the initiative to explore and propose a unified framework called PointMeta, to which the popular 3D point cloud analysis approaches could fit. This brings three benefits. First, it allows us to compare different approaches in a fair manner, and use quick experiments to verify any empirical observations or assumptions summarized from the comparison. Second, the big picture brought by PointMeta enables us to think across different components, and revisit common beliefs and key design decisions made by the popular approaches. Third, based on the learnings from the previous two analyses, by doing simple tweaks on the existing approaches, we are able to derive a basic building block, termed PointMetaBase. It shows very strong performance in efficiency and effectiveness through extensive experiments on challenging benchmarks, and thus verifies the necessity and benefits of high-level interpretation, contrast, and comparison like PointMeta. In particular, PointMetaBase surpasses the previous state-of-the-art method by 0.7%/1.4/%2.1% mIoU with only 2%/11%/13% of the computation cost on the S3DIS datasets. The code and models are available at https://github.com/linhaojia13/PointMetaBase.},
  keywords={Point cloud compression;Analytical models;Three-dimensional displays;Systematics;Computational modeling;Architecture;Search methods;3D from multi-view and sensors},
  doi={10.1109/CVPR52729.2023.01696},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{7580833,
  author={Bellini, Emanuele and Nesi, Paolo and Pantaleo, Gianni and Venturi, Alessandro},
  booktitle={2016 IEEE International Smart Cities Conference (ISC2)}, 
  title={Functional resonance analysis method based-decision support tool for urban transport system resilience management}, 
  year={2016},
  volume={},
  number={},
  pages={1-7},
  abstract={Today, managing critical infrastructure resilience in smart city is a challenge that can be undertaken by adopting a new class of smart tools, which are able to integrate modeling capability with evidence driven decision support. The Resilience Decision Support tool, as presented in this article, is an innovative and powerful tool that aims at managing critical infrasctructure resilience through a more complex and expressive model based on the Functional Resonance Analysis Method and through the connection of such a model with a system thinking based decision support tool exploiting smart city data. Thanks to ResilienceDS, FRAM model becomes computable and the functional variability that is at the core of the resilience analysis can be quantified. Such quantification allows the decision support tool to compute specific strategies and recommendations for variability dampening at strategic, tactic and operational stage. The solution has been developed in the context of RESOLUTE H2020 project of the European Commission.},
  keywords={Random access memory;Ferroelectric films;Nonvolatile memory;Computational modeling;Resilience;Analytical models;Decision support systems;smart city;Functional Resonance Analysis Method;Decision Support System;Resilience;Urban Stransport System},
  doi={10.1109/ISC2.2016.7580833},
  ISSN={},
  month={Sep.},}
