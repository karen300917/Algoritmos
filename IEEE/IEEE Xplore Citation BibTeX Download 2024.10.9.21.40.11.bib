@INPROCEEDINGS{5446782,
  author={Visnevski, Nikita A. and Castillo-Effen, Mauricio},
  booktitle={2010 IEEE Aerospace Conference}, 
  title={Evolutionary computing for mission-based test and evaluation of unmanned autonomous systems}, 
  year={2010},
  volume={},
  number={},
  pages={1-10},
  abstract={Test and evaluation may be viewed as a technology enabler for the successful deployment of unmanned vehicles and robots in all their envisioned applications. It is however a challenging endeavor, considering that roboticists and developers are not used to thinking of comprehensive test and evaluation as an integral part of robot development. Moreover, the community who has conducted test and evaluation up to this date does not possess the tools to cope with the growing complexity of unmanned and autonomous systems. This paper proposes an approach to one of the hardest problems in testing and evaluation of robots: mission-based test planning. This approach relies on constructive simulation tools and on evolutionary computing techniques for searching in high dimensional spaces of possible test scenarios. The goal of the test planner is to generate a set of tests that make highly efficient use of resources to unveil weaknesses of the system under test in a context of a specific mission.},
  keywords={System testing;Electronic equipment testing;Humans;Embedded computing;Embedded system;Control systems;Remotely operated vehicles;Mobile robots;Orbital robotics;Computational modeling},
  doi={10.1109/AERO.2010.5446782},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{10183057,
  author={Thalor, Meenakshi Anurag and Nagabhyrava, Rohith and Rajkumar, K. and Chakraborty, Abesh and Singh, Rajesh and Singh Aswal, Upendra},
  booktitle={2023 3rd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={Deep learning insights and methods for classifying wildlife}, 
  year={2023},
  volume={},
  number={},
  pages={403-407},
  abstract={With the introduction of low-cost and widely accessible sensors such as cellphones, drones, satellites, voice recorders, and bio-logging equipment, the amount of information collected about animals has expanded. Meanwhile, modern data processing systems prohibit them from collecting, digesting, and condensing data into usable information. We think that machine learning, especially deep learning algorithms, will be able to tackle this analytical difficulty by enhancing our understanding, monitoring capacities, and animal welfare. By merging machine learning with ecological processes, it may be feasible to expand the inputs to population and behavior models, resulting in integrated hybrid modeling tools where machine learning models give data-supported insights and ecological models act as constraints. Animal ecologists may basically profit from the quantity of data created by contemporary sensor technologies by integrating cutting-edge machine learning methods with ecological domain expertise. This will enable them to assess population abundances more precisely, research animal behavior, and reduce human-wildlife conflicts.},
  keywords={Deep learning;Satellites;Biological system modeling;Computational modeling;Wildlife;Sociology;Animal behavior;Deep Learning;wildlife classification;Data Analytics;Machine Learning},
  doi={10.1109/ICACITE57410.2023.10183057},
  ISSN={},
  month={May},}@ARTICLE{10168286,
  author={Wang, Beibei and Jiang, Bo and Tang, Jin and Luo, Bin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Generalizing Aggregation Functions in GNNs: Building High Capacity and Robust GNNs via Nonlinear Aggregation}, 
  year={2023},
  volume={45},
  number={11},
  pages={13454-13466},
  abstract={The main aspect powering GNNs is the multi-layer network architecture to learn the nonlinear representation for graph learning task. The core operation in GNNs is the message propagation in which each node updates its information by aggregating the information from its neighbors. Existing GNNs usually adopt either linear neighborhood aggregation (e.g. mean, sum) or max aggregator in their message propagation. 1) For linear aggregators, the whole nonlinearity and network's capacity of GNNs are generally limited because deeper GNNs usually suffer from the over-smoothing issue due to their inherent information propagation mechanism. Also, linear aggregators are usually vulnerable to the spatial perturbations. 2) For max aggregator, it usually fails to be aware of the detailed information of node representations within neighborhood. To overcome these issues, we re-think the message propagation mechanism in GNNs and develop the new general nonlinear aggregators for neighborhood information aggregation in GNNs. One main aspect of our nonlinear aggregators is that they all provide the optimally balanced aggregator between max and mean/sum aggregators. Thus, they can inherit both i) high nonlinearity that enhances network's capacity, robustness and ii) detail-sensitivity that is aware of the detailed information of node representations in GNNs’ message propagation. Promising experiments show the effectiveness, high capacity and robustness of the proposed methods.},
  keywords={Task analysis;Robustness;Message passing;Computer architecture;Computational modeling;Training;Smoothing methods;Graph neural networks;graph representation learning;message passing;nonlinear message aggregation},
  doi={10.1109/TPAMI.2023.3290649},
  ISSN={1939-3539},
  month={Nov},}@INPROCEEDINGS{10308238,
  author={Chandra, Jatin and B., Annappa and R., Rashmi Adyapady},
  booktitle={2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Cross-Database Facial Expression Recognition using CNN with Attention Mechanism}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Facial expression is one of the most effective and universal ways to express emotions and intentions. It reflects what a person is thinking or experiencing. Thus, the expression recognition is one of the key aspects of understanding non-verbal communication and interpreting emotions in social interactions. Some emotions are very confusing, and separating the features between them becomes difficult because they share the same feature space. For example, the distinction between fear, anger, and disgust is confusing. This work tried to improve the model’s class-wise performance to detect each class correctly. A distinct combination of deep-learning models is used to calculate the performance of the model, such as ResNet, XceptionNet, DenseNet, etc. The datasets like Real-world Affective Faces Database (RAF-DB), Japanese Female Facial Expression (JAFFE) & Facial Expression Recognition 2013 Plus (FER+) are used to evaluate the model’s performance. The proposed model achieved better results and overcame the previous work’s limitations. CDE’s performance on RAF-DB and FER+ evaluations was significantly better than the current SOTA methods, with an increase in accuracy of 5.18% and 3.98%, respectively.},
  keywords={Deep learning;Emotion recognition;Computer vision;Databases;Face recognition;Computational modeling;Buildings;Facial Expression Recognition (FER);Deep learning;DenseNet121;Attention-Based DenseNet},
  doi={10.1109/ICCCNT56998.2023.10308238},
  ISSN={2473-7674},
  month={July},}@INPROCEEDINGS{6572614,
  author={Wong, Chim Chwee and Alias, Emy Salfarina and Kishigami, Junichi},
  booktitle={2013 International Conference on Informatics, Electronics and Vision (ICIEV)}, 
  title={Playlist environmental analysis for the serendipity-based data mining}, 
  year={2013},
  volume={},
  number={},
  pages={1-6},
  abstract={The real recommendation will involve not only unsurprised, but some surprised elements sometimes. We are constantly experiencing this serendipity element in our daily life. However, today's data mining technology cannot support this function adequately. In this paper, we hypothesize that there should be some relevant serendipity elements on a radio station's music playlist. The radio station makes the playlist for the programme by the producer or director based on his experience and huge knowledge of music. In this research, we first determine the optimal number of clusters to be used by using BIC and AIC, and then we apply EM model clustering technique for the collection of more than 3000 playlists from the radio station. By analyzing the resulting clusters obtained, significant dependency between clusters and all the playlist metadata (i.e. time, genre, music era, and popularity) are discovered. Finally, we found that the time of playing the music and the music era (composed-year of music) has a strong correlation. This implies that music in some particular music era is popular in certain particular time of the day. For example, more classical music pieces from modern era are played at the night from 18:00 until 2:00. Furthermore, more classical music from the early Baroque era has been played in the afternoon around 12.00 to 13.00. However, we think that some music, which belong to the music era that are less popular in that particular time, will contribute to the serendipity function of the playlist to certain extend. With these studies, this serendipity would be widely used for an excellent recommendation service, which will include the personal radio station for the digital music player, marketing and knowledge capital.},
  keywords={Data visualization;Music;Internet;Mathematical model;Data models;Data mining;Computational modeling;serendipity;data mining;data visualization;playlist;classical music;radio},
  doi={10.1109/ICIEV.2013.6572614},
  ISSN={},
  month={May},}@INPROCEEDINGS{4755509,
  author={Reilly, D.F. and Inkpen, K.M. and Watters, C.R.},
  booktitle={2009 42nd Hawaii International Conference on System Sciences}, 
  title={Controlling, Integrating, and Engaging Context in Urban Computing Research}, 
  year={2009},
  volume={},
  number={},
  pages={1-10},
  abstract={Understanding the interplay between technology and urban life is the basic question of urban computing research. In addition to using context to achieve realism in evaluation, urban computing studies often need to consider context of use outright as an element under study. Doing so requires new ways of thinking about context that may not fit neatly into traditional categories of experimental design. In this paper we present our experiences in attempting to manage context in studies involving urban way finding and other social spatial activities. We reflect on our attempts to treat context as a set of controllable factors, to integrate some uncontrolled aspects of context into our experiments, and to engage contextual realism outright. The paper concludes with recommendations for managing context in urban computing study design based on these experiences.},
  keywords={Design for experiments;Navigation;Control systems;Collaboration;Context modeling;Roads;Bridges;Home computing;Computational modeling;Visualization},
  doi={10.1109/HICSS.2009.132},
  ISSN={1530-1605},
  month={Jan},}@INPROCEEDINGS{7020187,
  author={Howell, Michael and Vega, David and Doore, Karen and Fishwick, Paul},
  booktitle={Proceedings of the Winter Simulation Conference 2014}, 
  title={Enhancing model interaction with immersive and tangible representations: A case study using the Lotka-Volterra model}, 
  year={2014},
  volume={},
  number={},
  pages={3572-3583},
  abstract={Dynamic computer simulations seek to engage the viewer by providing an intuitive representational mapping of common knowledge features to new knowledge concepts. Our research aims to provide enhanced understanding of complex systems through participatory interaction with our dynamic simulation models. Previous research has indicated that virtual and tangible models are well suited for use in informal education spaces, as they increase user interaction and curiosity amongst children and adults. We designed and implemented an interactive virtual environment as well as an interactive tangible “water computer” to represent the complex interspecies behavior of Lotka-Volterra predator-prey dynamic system. We designed our simulation models for use in informal STEM education settings, with a design focus on enhanced interactions and reflexive thinking.},
  keywords={Predator prey systems;Mathematical model;Biological system modeling;Equations;Computational modeling;Education;Valves},
  doi={10.1109/WSC.2014.7020187},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{6235359,
  author={Zainal Abidin, Azizan and Saleh, Fatimah},
  booktitle={2011 3rd International Congress on Engineering Education (ICEED)}, 
  title={Team-based Electronic Portfolio}, 
  year={2011},
  volume={},
  number={},
  pages={48-53},
  abstract={An important aspect of engineering undergraduate learning is the assessment techniques as they determine the extent to which the expected so desired learning outcomes of a particular program can be measured. With the growing demands of industrial needs globally, the learning outcomes of most engineering programs do not just linger on technical skills, but equally important, if not more, on the communication skills, teamwork skills and other such process skills. Educationists thus seek for alternatives to the traditional pencil and paper tests as this instrument is useful and regarded a good measuring tool, but limited to measuring thinking skills only. Amongst the examples of alternative assessment methods is the portfolio. This research attempts to show how team-based electronic learning portfolio construction in the learning of Differential Equations is integrated as an assessment method at Universiti Teknologi PETRONAS, a private university located in Tronoh, Perak, Malaysia was employed to encompass a more comprehensive measure of students' learning in three learning domains; cognitive, affective and psychomotor. Involving over two hundred engineering undergraduates, the researcher with the assistance of two other colleagues uses a criterion-based scoring rubric to evaluate the construction of a randomly selected sample of fifteen from a pool of fifty one electronic Differential Equations Learning Portfolio or acronym, e-DELP. It is interesting to note the various levels of learning from the three learning domains; cognitive, affective and psychomotor domains that could be related to the activities involved in the construction of the team-based e-DELP. Time consuming it may be, but with proper planning, this alternative assessment is found to be well-worth implementing in achieving the objectives of measuring more than technical skills of students.},
  keywords={Atmospheric measurements;Particle measurements;Media;Software;Computational modeling;Accuracy;Planning;Assessment;Differential Equations;learning domains;team-based e- portfolio;engineering undergraduates;scoring rubrics},
  doi={10.1109/ICEED.2011.6235359},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9787590,
  author={Das, Rahul and Biswas, Chiranjit and Majumder, Swanirbhar},
  booktitle={2022 IEEE 11th International Conference on Communication Systems and Network Technologies (CSNT)}, 
  title={Study of Spiking Neural Network Architecture for Neuromorphic Computing}, 
  year={2022},
  volume={},
  number={},
  pages={373-379},
  abstract={Deep learning's progress has resulted in a multi-layered character in a variety of applications in this field. Artificial Neural Networks are becoming the old procedure in the wide region of computing, using fifty-year-old principal concepts and models. Scientists are now presenting 3rd generation intelligent models in this current computer era. The brain like a big computer, routes information that it receives from the senses and body, and sends communications back to the body. But the brain can do much more than a machine can: humans think and experience reactions with their brain, and are the root of human intelligence. The 3rd generation Spiking Neural Network bridges the gap between deep learning, machine learning, and neuroscience in a biological approach, allowing neuroscience and machine learning to work together to achieve high-level computing efficiency using the neuromorphic computing. Spiking Neural Networks promise to make use of spikes, which are discrete functions that occur at predictable emphases rather than continuous values so that they are hardware implementable as well.},
  keywords={Deep learning;Training;Neuroscience;Neuromorphic engineering;Computational modeling;Computer architecture;Brain modeling;Spiking Neural Network;Artificial Neural Networks;Deep Learning;Neuromorphic Computing},
  doi={10.1109/CSNT54456.2022.9787590},
  ISSN={2329-7182},
  month={April},}@ARTICLE{10246878,
  author={Ninrutsirikun, Unhawa and Pal, Debajyoti and Arpnikanondt, Chonlameth and Watanapa, Bunthit},
  journal={Journal of Web Engineering}, 
  title={Unified Model for Learning Style Recommendation}, 
  year={2021},
  volume={20},
  number={5},
  pages={1487-1526},
  abstract={Studying computer programming requires not only an understanding of theories and concepts but also coding adeptness. Success in studying or conducting such a course is definitely a challenge. This paper proposes a systematic learning style recommendation. The model is designed to evaluate students' attributes and ongoing or formative learning outcomes for suggesting the effective style-fit strategy that facilitates learners to enhance their learning performances in terms of knowledge and skill. A two-stage association analysis was designed and conducted on a dataset collected from IT major students who enrolled in the Introduction to Computer Programming course. The first stage of association rules is to analyze and discover important relationships amongst learning styles, students' attribute, and learning performance. The second stage of moderation analysis is then applied to probe the moderation effect of the different learning preferences on the relationship between student attributes and learning achievement. Experiments expose many insights, for example, mathematics and logical thinking are powerful assets of success in computer programming study. Association rules can effectively identify associations of learning styles and the learning performance in terms of knowledge or skills. By moderation analysis, students in the “Excellent” cluster have a broad learning style than other students. Two types of significant moderators, the universal and specific, exemplify how lecturers can flexibly post style-fit teaching strategies for a class-wide and specific group, respectively.},
  keywords={Analytical models;Systematics;Computational modeling;Education;Programming;Mathematics;Encoding;Association evaluation;association rules;guideline;learning styles;moderation analysis;style-fit strategy},
  doi={10.13052/jwe1540-9589.2058},
  ISSN={1544-5976},
  month={July},}@INPROCEEDINGS{344526,
  author={Akiyoshi, M. and Nishida, S.},
  booktitle={Proceedings of Phoenix Conference on Computers and Communications}, 
  title={A qualitative simulation-based learning environment: how to enhance causal understanding of complex phenomena in large-scale plants}, 
  year={1993},
  volume={},
  number={},
  pages={531-537},
  abstract={The authors describe a framework of a qualitative simulation-based learning environment that focuses on causal understanding of complex phenomena in large-scale plants. Training styles such as study with manuals and exercise with a numerical simulator have been developed. However, besides such training styles, a learning environment should provide the functions that enable operators to achieve deep understanding of target plants. The qualitative simulation-based learning environment aims at providing operators a thinking tool for understanding, where human-computer interaction is also designed based on this notion. To realize this environment in a computer, two problems on qualitative reasoning have to be resolved. One is how to construct qualitative models of adequate grain size as target plants become complex, and the other is how to prune spurious qualitative behaviors. New techniques on qualitative reasoning are proposed, which are called qualitative reasoning with association mechanisms to qualitative information. Its effectiveness is discussed through applying this framework to large-scale power plants.<>},
  keywords={Computational modeling;Large-scale systems;Computer simulation;Numerical simulation;Grain size;Power generation;Quality management;Analytical models;Information analysis;Manuals},
  doi={10.1109/PCCC.1993.344526},
  ISSN={},
  month={March},}@ARTICLE{10375936,
  author={Hull, Gordon},
  journal={Journal of Social Computing}, 
  title={Unlearning Descartes: Sentient AI is a Political Problem}, 
  year={2023},
  volume={4},
  number={3},
  pages={193-204},
  abstract={The emergence of Large Language Models (LLMs) has renewed debate about whether Artificial Intelligence (AI) can be conscious or sentient. This paper identifies two approaches to the topic and argues: (1) A “Cartesian” approach treats consciousness, sentience, and personhood as very similar terms, and treats language use as evidence that an entity is conscious. This approach, which has been dominant in AI research, is primarily interested in what consciousness is, and whether an entity possesses it. (2) An alternative “Hobbesian” approach treats consciousness as a sociopolitical issue and is concerned with what the implications are for labeling something sentient or conscious. This both enables a political disambiguation of language, consciousness, and personhood and allows regulation to proceed in the face of intractable problems in deciding if something “really is” sentient. (3) AI systems should not be treated as conscious, for at least two reasons: (a) treating the system as an origin point tends to mask competing interests in creating it, at the expense of the most vulnerable people involved; and (b) it will tend to hinder efforts at holding someone accountable for the behavior of the systems. A major objective of this paper is accordingly to encourage a shift in thinking. In place of the Cartesian question—is AI sentient?—I propose that we confront the more Hobbesian one: Does it make sense to regulate developments in which AI systems behave as if they were sentient?},
  keywords={Sociotechnical systems;Social computing;Computational modeling;Resists;Manuals;Regulation;Labeling;artificial intelligence;Large Language Model;consciousness;sentience;personhood;Descartes;Hobbes},
  doi={10.23919/JSC.2023.0020},
  ISSN={2688-5255},
  month={Sep.},}@INPROCEEDINGS{10179854,
  author={Khan, Lamia Parven and Hossain, Anika and Dey, Susmita},
  booktitle={2023 Fifth International Conference on Electrical, Computer and Communication Technologies (ICECCT)}, 
  title={Anomaly Detection for Beth Dataset Using Machine Learning Approaches}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Due to the advancement of technology network has become a part of our daily life. Thinking about life without network has become impossible. Sharing important and confidential information through network has become common. It is important to maintain the data integrity and confidentiality to maintain the trust on the network. Thus, network need to have strong and strict security. There are lots of criminal and unwanted ways to destroy the data integrity and confidentiality. It is import to prevent and block those illigal ways. This paper focus on Beth dataset. This analysis will give an insight of the Beth dataset. This gives researcher scientist an idea to if they can use this dataset to build strong and efficient anomaly detection model for the network.},
  keywords={Wireless communication;Machine learning algorithms;Costs;Data integrity;Computational modeling;Machine learning;Maintenance engineering;ANN;Precision;accuracy;dataset;machine learning;data pre processing},
  doi={10.1109/ICECCT56650.2023.10179854},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{1521133,
  author={Maly, P. and Woodside, C.M. and Karam, G.K. and Forrest, A.},
  booktitle={13th IEEE International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems}, 
  title={Describing and visualizing the capacity of a system with behaviour uncertainties}, 
  year={2005},
  volume={},
  number={},
  pages={191-200},
  abstract={User and system behaviour is difficult to predict for novel systems, and this affects the capacity of the system (the number of active users that can be supported with acceptable response delay). This leads to a range of values, in the form of a feasible or acceptable region for the potential capacity, conditional on the uncertain parameters. This work considers uncertainties in the delay between requests (user think time), network latency, and cache behaviour due to users' locality of reference. The acceptable region is shown to be bounded approximately by linear constraints which are easy to derive. This simple result is useful for sensitivity and scalability analysis, and appears to have been overlooked. It is applied to a Web-based system for telephony, using voiceXML for service ranging from interactive voice response, to voice-based E-mail.},
  keywords={Visualization;Uncertainty;Telecommunication computing;Computational modeling;Analytical models;Computer simulation;Delay effects;Systems engineering and theory;Computer networks;Web server},
  doi={10.1109/MASCOTS.2005.24},
  ISSN={2375-0227},
  month={Sep.},}@INPROCEEDINGS{10234310,
  author={Dutta, Joy and Puthal, Deepak},
  booktitle={2023 IEEE International Conference on Edge Computing and Communications (EDGE)}, 
  title={Human-Centered Explainable AI at the Edge for eHealth}, 
  year={2023},
  volume={},
  number={},
  pages={227-232},
  abstract={Explainable Artificial Intelligence (XAI) is a new paradigm of Artificial Intelligence (AI) that is giving different AI/ Machine Learning (ML) models a boost to penetrate sectors where people are thinking about adopting AI. This work focuses on the adoption of XAI in the health sector. It portrays that careful integration of XAI in both cloud and edge could change the whole healthcare industry and make humans more aware of their present health conditions, which is the need of the hour. To demonstrate the same, we have done an experiment based on the prediction of a particular medical condition called "cardiac arrest" in a specific subject group (patients who are 70 years old). Here, based on the explanation provided by the XAI model (e.g., SHAP, LIME) at Cloud and Edge, our system can predict the chances of a "cardiac arrest" for the subject with a valid explanation. This type of model will be the next big upgrade in the healthcare industry in terms of automation and a self-explanatory system that works as a personal health assistant for individuals.},
  keywords={Industries;Medical conditions;Databases;Computational modeling;Cardiac arrest;Machine learning;Predictive models;XAI;IoMT;Edge;Machine Learning;Interpretability;eHealth},
  doi={10.1109/EDGE60047.2023.00044},
  ISSN={2767-9918},
  month={July},}@INPROCEEDINGS{9889336,
  author={Wells, Alesha and Loveys, Kate and Sagar, Mark and Billinghurst, Mark and Broadbent, Elizabeth},
  booktitle={2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI)}, 
  title={An Exploration of Eye Gaze in Women During Reciprocal Self-Disclosure: Implications for Digital Human Design}, 
  year={2022},
  volume={},
  number={},
  pages={1085-1089},
  abstract={Digital humans are a highly realistic form of conversational computer agent. Eye gaze is a salient social cue that digital humans could use to facilitate rapport-building during conversations. However, eye gaze tendencies vary by gender and incorrect gaze patterns can have negative social implications. Analysis of observational data during human conversations can help inform the development of eye gaze models for digital humans. This study aimed to identify the eye gaze patterns of women dyads during a rapport-building conversation, and to evaluate the effect of different gaze patterns on rapport, trust, and psychological outcomes. 36 adult women (18 dyads) completed the Relationship Closeness Induction Task while wearing eye tracking glasses. Subjective rapport, trust, and psychological measures were collected. Gaze patterns of women were found to change as the conversation content became more intimate; specifically, gaze aversions for thinking (p=.042), turn-taking (p=.025), and intimacy modulation increased in duration (p=.012). Furthermore, gaze patterns were associated with perceptions of the conversation partner. Displaying fewer cognitive gaze aversions was associated with greater closeness (p=.029) and trust perceptions (p=.035). Longer periods of direct gaze while speaking was associated with greater rapport (p=.040). Results will inform the development of a humanlike gaze model for female digital humans during intimate conversations and may be applicable to social robots.},
  keywords={Analytical models;Computational modeling;Social robots;Psychology;Modulation;Oral communication;Glass;Digital human;conversational agent;eye gaze;rapport;trust;stress;intimacy;social support},
  doi={10.1109/HRI53351.2022.9889336},
  ISSN={},
  month={March},}@INPROCEEDINGS{10196862,
  author={Azmee, Abm Adnan and Murikipudi, Manohar and Al Hafiz Khan, Md Abdullah and Pei, Yong},
  booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Sentence Level Analysis for Detecting Mental Health Causes Using Social Media Posts}, 
  year={2023},
  volume={},
  number={},
  pages={1388-1393},
  abstract={Mental health is just as important as physical health. Globally, there is a growing concern due to the rise of mental health problems. Mental health problems impair individuals’ ability to think clearly, behave responsively, or express themselves. The recent pandemic has led to a spike in people using social media to express themselves. Data from these social media platforms can be used to learn more about users’ mental states and determine the causes of mental health problems. However, due to the variability and complexity of users’ language, it is very challenging for conventional machine learning and deep learning models to identify these causes. In this research, we propose a novel sentence-level analysis framework based on a hybrid deep learning model to overcome these challenges. We evaluated our model’s efficacy using data from the social media platform Reddit, and our model outperforms several baseline models. Our research findings provide a new perspective on identifying the causes behind mental health issues and would help mental health professionals develop better diagnoses and treatments for patients.},
  keywords={Deep learning;Analytical models;Social networking (online);Pandemics;Computational modeling;Mental health;Data models;Deep Learning;Mental Health;Cause Detection;Natural Language Processing;Sentence-Level Analysis},
  doi={10.1109/COMPSAC57700.2023.00211},
  ISSN={0730-3157},
  month={June},}@ARTICLE{1289316,
  author={Downing, G. and Dubois, P.F. and Cottom, T.},
  journal={Computing in Science & Engineering}, 
  title={Data sharing in scientific simulations}, 
  year={2004},
  volume={6},
  number={3},
  pages={87-96},
  abstract={Several physics processes modify the state of a scientific simulation over time. In fact, researchers often divide a simulation's development into areas - called packages - according to physics specialization. In this article, we use the word "package" primarily to mean a portion of scientific software whose components communicate internally much more than they do with outside routines, but packages can take the form of third-party libraries for common mathematical or computer science functions. Most parts of a simulation refer to the "infrastructure" portion of the state, so we can think of this portion as a package with lots of customers. How we share data within and between these packages is crucial to developer productivity. In this installment of Scientific Programming, we explore some of the pros and cons of the different ways to share data in C++ code.},
  keywords={Computational modeling;Physics;Libraries},
  doi={10.1109/MCISE.2004.1289316},
  ISSN={1558-366X},
  month={May},}@ARTICLE{7950815,
  author={Bai, Wei and Kim, Doowon and Moses, Namara and Qian, Yichen and Gage Kelly, Patrick and Mazurek, Michelle},
  journal={IEEE Internet Computing}, 
  title={"Most of us trust our email provider": Balancing security and usability in encrypted email}, 
  year={2017},
  volume={},
  number={},
  pages={1-1},
  abstract={End-to-end encryption is the best way to protect digital messages. Historically, end-to-end encryption has been extremely difficult for people to use, but recent tools have made it more broadly accessible, largely by employing key-directory services. These services sacrifice some security properties for convenience. We wanted to understand how average users think about these tradeoffs. We conducted a 52-person user study and found that participants could learn to understand properties of different encryption models. They also made coherent assessments about when different tradeoffs might be appropriate. Participants recognized the less-convenient exchange model was more secure overall, but considered the security of the registration model to be “good enough” for most everyday purposes.},
  keywords={Encryption;Electronic mail;Computational modeling;Internet;Usability;H Information Technology and Systems;H.1 Models and Principles;H.1.2 User/Machine Systems;H.1.2.a Human factors;E Data;E.3 Data Encryption;E.3.c Public key cryptosystems;K Computing Milieux;K.4 Computers and Society;K.4.1 Public Policy Issues;K.4.1.f Privacy;H.4.3.c Electronic mail < H.4.3 Communications Applications < H.4 Information Technology and Systems Applications < H Informatio},
  doi={10.1109/MIC.2017.265103059},
  ISSN={1941-0131},
  month={},}@INPROCEEDINGS{10261528,
  author={Sun, Rongfei and Cai, Shaohua and Zhan, Zehui},
  booktitle={2023 5th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={A Case Study of Computer Science General Course with C-STEAM Education Concept in Higher Education - Taking “New Media Artifacts Production” as an Example}, 
  year={2023},
  volume={},
  number={},
  pages={35-41},
  abstract={The Computer General Course is a general core course in higher education for students of non-computer science majors. With the increasing popularity of computer technology applications and the arrival of the fourth wave of the industrial revolution represented by the industrialization of the Internet, industrial intelligence, and industrial integration, the teaching of Computer General Course under the new situation also faces new dilemmas. The exploration of the integration of C-STEAM with the Computer General Course, which is oriented by culture, provides new paths to achieve the educational goal under the new situation, to realize the integration of the discipline education under the cultural orientation of the course, and to improve the students' sense of learning efficacy in the course. Through the design-based research and 2 years of exploration and practice, combined with student research and work evaluation, the curriculum reform teaching practice recognition and students' cultural literacy, thinking methods, disciplinary integration literacy, etc. have received more positive feedback, and the teaching objectives are achieved to a higher degree.},
  keywords={Computer science;Computational modeling;Education;Production;Media;Internet;Cultural differences;component;C-STEAM education;cultural orientation;computer general course;“6Cs” model;computer literacy},
  doi={10.1109/CSTE59648.2023.00014},
  ISSN={},
  month={April},}@INPROCEEDINGS{5966523,
  author={Vasantrao, Kardile Vilas},
  booktitle={2011 International Conference on Communication Systems and Network Technologies}, 
  title={Need to Understand Uncertainty in the System Development Modeling Process}, 
  year={2011},
  volume={},
  number={},
  pages={619-623},
  abstract={Accurate software cost and schedule estimation are essential for software project success. Often it referred to as the "black art" because of its complexity and uncertainty, software estimation is not as difficult or puzzling as people think. In fact, generating accurate estimates is straightforward - once you understand the intensity of uncertainty and framework for the modeling process. The mystery to successful software estimation - distilling academic information and real-world experience into a practical guide for working software professionals. Instead of arcane treatises and rigid modeling techniques, this will guide highlights a proven set of procedures, understandable formulas, and heuristics that individuals and development teams can apply to their projects to help achieve estimation proficiency with choose appropriate development approaches In the early stage of software life cycle project manager are inefficient to estimate the effort, schedule, cost estimation and its development approach. This in turn, confuses the manager to bid effectively on software project and choose incorrect development approach. That will directly effect on productivity cycle and increase level of uncertainty. This becomes a strong cause of project failure. So to avoid such problem if we know level and sources of uncertainty in model design, It will directive the developer to design accurate software cost and schedule estimation. Which are essential for software project success. However once the required efforts have estimated, little is done to recalibrate and reduce the uncertainty of the initial estimates. This paper demonstrates terminology and typology of uncertainty is presented together with a framework for the modeling process, Brief reviews have been made of 14 different (partly complementary) methods commonly used in uncertainty assessment its interaction with the broader system development process and the role of uncertainty at different stages in the modeling processes.. The applicability of these methods has been mapped according to purpose of application, stage of the modeling process and source and type of uncertainty addressed.},
  keywords={Uncertainty;Software;Programming;Schedules;Computational modeling;Estimation;Data models;software development approach;Uncertainty;Uncertainty sources;Uncertainty matrix},
  doi={10.1109/CSNT.2011.133},
  ISSN={},
  month={June},}@INPROCEEDINGS{9941929,
  author={Huang, Yi and Yang, Weihua},
  booktitle={2022 Global Reliability and Prognostics and Health Management (PHM-Yantai)}, 
  title={Correction Method of Key Movements in Basketball Training Based on Virtual Reality Technology}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={VR technology refers to virtual reality technology, which can simulate all kinds of things in the real environment, make users integrate into the simulation world and personally experience the change laws and specific characteristics of things [1]. At present, the application of virtual reality technology in training has become a major development trend of physical education. This model can help students improve the effect of physical education learning and further deepen their thinking mode and understanding of knowledge [2]. Combined with virtual reality technology and computer technology, this paper establishes a key action correction method of basketball training based on virtual reality technology. This system is composed of three-dimensional simulation database, capture motion virtual simulation model, motion technology simulation and other parts. The three-dimensional simulation of basketball based on virtual reality technology focuses on the principle, implementation method and specific application of virtual reality technology in the three-dimensional simulation of basketball. Using this method can bring more superior learning environment for athletes.},
  keywords={Training;Solid modeling;Databases;Computational modeling;Virtual reality;Market research;Reliability;Virtual reality technology;Basketball training;Training key;Key actions;Motion correction},
  doi={10.1109/PHM-Yantai55411.2022.9941929},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{5717760,
  author={Maggio, Martina and Leva, Alberto},
  booktitle={49th IEEE Conference on Decision and Control (CDC)}, 
  title={Toward a deeper use of feedback control in the design of critical computing system components}, 
  year={2010},
  volume={},
  number={},
  pages={5985-5990},
  abstract={Feedback controllers are typically applied to computing systems by acting on some quantities (“tunable parameters” in the computer science lexicon, think e.g. of a packet drop rate) in order to attain some goal (e.g., a required bandwidth allocation). In other words, control loops are closed around the computing system, that exposes tunable parameters as control actuators, and allows to measure some performance metrics. In the authors' opinion, the “classical” use of control methods sketched above heavily limits the achievable results. Indeed, many critical parts of computing systems should not be “controlled”, but rather “re-designed in the form of controllers” - quite a novel approach and an interesting research area. This manuscript formalises the statement above and illustrates some results, including a couple of application examples, to demonstrate the advantages of the proposed design approach.},
  keywords={Eigenvalues and eigenfunctions;Computational modeling;Processor scheduling;Switches;Stability analysis;Feedback control},
  doi={10.1109/CDC.2010.5717760},
  ISSN={0191-2216},
  month={Dec},}@INPROCEEDINGS{8577770,
  author={Chen, Ying and Xue, Wei Xian and Xie, Xing Long},
  booktitle={2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)}, 
  title={Big-Data-Based Modeling of Electricity Consumption Behavior}, 
  year={2018},
  volume={},
  number={},
  pages={1380-1387},
  abstract={Big data is envisioned as a game changer capable of revolutionizing the way businesses operate in sectors. The purpose of this paper is to present a big-data-based framework for dealing with electricity consumption behavior. This paper conducts an analysis of methodologies in the extraction of electro-information and drawbacks in modeling power consumption behavior through traditional peak-trough pricing. Then, the paper comes up with a fresh thinking on integration of multiple-dimensional, big data platforms, and conducts a penetrating study of pattern identification, relational analysis and deeds of using electricity. The paper designs a data-driven approach on the basis of two huge data manipulation techniques, batch process and flow process, and puts forward an algorithm concerning stochastic matrix relevance, which goes for the relationship between electricity spending and its determinants. Also, empirical evidence is presented concerning verifying robustness and validity of the proposed approach, suggesting that the framework is feasible in performing further electrical data analytics. The paper concludes with pointing out implications for governmental policy formulation, business expansion of power companies and guiding behavior of electricity use as well as quantitative methods for researching related issues.},
  keywords={Data models;Biological system modeling;Big Data;Load modeling;Loading;Computational modeling;Power demand;big data;data processing;relational modeling;stochastic matrix;interactive Mechanism},
  doi={10.1109/IAEAC.2018.8577770},
  ISSN={2381-0947},
  month={Oct},}@INPROCEEDINGS{8125355,
  author={Chitongo, Alfred M. and Pretorius, Leon},
  booktitle={2017 Portland International Conference on Management of Engineering and Technology (PICMET)}, 
  title={Engineering Consultant Project Cash Flow Controls: An Empirically-Supported System Dynamics Conceptual Model}, 
  year={2017},
  volume={},
  number={},
  pages={1-10},
  abstract={Extant literature shows different measures for business performance of a 'for-profit' organisation; including both financial performance and non-financial dimensions. Key financial performance measures, evident in existing literature, include: profit; revenue; cash flow; and return on investment, among others. Some previous scholars highlighted that without a healthy cash flow, an organisation can fail to sustain itself, even when it records huge profits and high return on investment. This paper explores further the issue of cash flow, as a key financial (and business) performance measure, with a particular focus on controls taken by an Engineering Consultant during the design stage of project execution when he/she forecasts a project cash flow shortfall. A System Dynamics conceptual model of the Engineering Consultant's project cash flow controls (and their associated unintended and undesirable effects) is formulated, in this paper, from existing literature, mental models of contemporary project managers (from an Engineering Consulting firm with many infrastructure projects in South Africa), and Systems Thinking. Results suggest some counterintuitive dynamic hypothesis: controls taken by an Engineering Consultant (aimed at increasing his/her project cash flow) when he/she forecasts a project cash flow shortfall, tend to generate some unintended and counteractive effect - a reduction of the Engineering Consultant's project cash flow.},
  keywords={System dynamics;Investment;Computational modeling;Manufacturing;Data analysis;Atmospheric measurements},
  doi={10.23919/PICMET.2017.8125355},
  ISSN={},
  month={July},}@INPROCEEDINGS{10182654,
  author={Ksibi, Sondes and Jaidi, Faouzi and Bouhoula, Adel},
  booktitle={2023 International Wireless Communications and Mobile Computing (IWCMC)}, 
  title={IoMT Security Model based on Machine Learning and Risk Assessment Techniques}, 
  year={2023},
  volume={},
  number={},
  pages={614-619},
  abstract={Internet of Medical Things (IoMT) is gaining interest as an emerging paradigm for healthcare improvement. Cyber-security is one of the major issues breaking down its expansion. Indeed, IoMT ecosystem complexities and cyber-attacks development require thinking about smart and efficient security solutions. Machine Learning (ML) techniques are widely used to help detecting abnormalities and intrusions in such environments in order to improve trustworthiness in Connected Medical Devices (CMD). Towards this direction, risk assessment is also proposed to proactively evaluate the security of such platforms. Regarding the complexity and heterogeneity of IoMT, dealing with the inherent security risks is a challenging task. In this context, we aim to evaluate the cumulative risk of CMD based on anomaly detection in IoMT traffic via ML algorithms. Our model relies on anomalies detection coupled with intrinsic risk assessment of medical devices trying to have a holistic risk evaluation for the platform.},
  keywords={Wireless communication;Privacy;Medical devices;Computational modeling;Machine learning;Complexity theory;Security;IoMT;Machine Learning;Risk Assessment;Security and Privacy},
  doi={10.1109/IWCMC58020.2023.10182654},
  ISSN={2376-6506},
  month={June},}@INPROCEEDINGS{8638048,
  author={Singla, Priyanka and Singh, Shubhankar Suman and Gopinath, K. and Sarangi, Smruti},
  booktitle={2018 IEEE 25th International Conference on High Performance Computing (HiPC)}, 
  title={Probabilistic Sequential Consistency in Social Networks}, 
  year={2018},
  volume={},
  number={},
  pages={102-111},
  abstract={Researchers have proposed numerous consistency models in distributed systems that offer higher performance than classical sequential consistency (SC). Even though these models do not guarantee sequential consistency; they either behave like an SC model under certain restrictive scenarios, or ensure SC behavior for a part of the system. We propose a different line of thinking where we try to accurately estimate the number of SC violations, and then try to adapt our system to optimally tradeoff performance, resource usage, and the number of SC violations. In this paper, we propose a generic theoretical model that can be used to analyze systems that are comprised of multiple sub-domains - each sequentially consistent. It is validated with real world measurements. Next, we use this model to propose a new form of consistency called social consistency, where socially connected users perceive an SC execution, whereas the rest of the users need not. We create a prototype social network application and implement it on the Cassandra key-value store. We show that our system has 2.4× more throughput than Cassandra and provides 37% better quality-of-experience.},
  keywords={Mathematical model;Servers;Social networking (online);Probabilistic logic;Computational modeling;Adaptation models;Load management;Hot-spot;social;load balancing;quality-of-experience;distributed;consistency violations},
  doi={10.1109/HiPC.2018.00020},
  ISSN={2640-0316},
  month={Dec},}@INPROCEEDINGS{7883310,
  author={Kulkarni, Vinay},
  booktitle={2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)}, 
  title={Model Driven Development of Business Applications - A Practitioner's Perspective}, 
  year={2016},
  volume={},
  number={},
  pages={260-269},
  abstract={We discuss our experience in use of models and model-driven techniques for developing large business applications. Benefits accrued and limitations observed are highlighted. We describe possible means of overcoming some of the limitations and experience thereof. A case for shift in focus of model driven engineering (MDE) community in the context of large enterprises is argued. Though emerging from a specific context, we think, the takeaways from this experience may have a more general appeal for MDE practitioners, tool vendors and researchers.},
  keywords={Unified modeling language;Business;Computational modeling;Object oriented modeling;DSL;Software;Databases;Modeling;meta modeling;separation of concerns;model transformation;software product-lines;model driven engineering workbench},
  doi={},
  ISSN={},
  month={May},}@INPROCEEDINGS{9201889,
  author={Babichenko, Dmitriy and Healy, Patrick and Gomez, Marcela and Kane-Gill, Sandra and Littleton, Eliza Beth and Brusilovsky, Peter and Cohen, Paul and Patel, Ravi},
  booktitle={2020 IEEE 8th International Conference on Serious Games and Applications for Health (SeGAH)}, 
  title={The Use of Agent-Based Models As Non-Player Characters in Serious Games}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={One of the shortcomings of many modern serious games and medical simulations lies in their inability to model even some modicum of unpredictability of real life situations. Interactions with a standardized patient may teach healthcare professional students how to diagnose a clinical condition, better manage a patient, or help them improve their bedside manners, but such simulated interactions will not prepare the learners to deal with unpredictability of clinical situations, interruption, and task switching. Distractions occur from colleagues, clinical decision support alerts, pagers, smartphones, or audible alarms. All these interruptions can potentially alter the course of patient care and the outcome of a patient's treatment. A simulated virtual patient (VP) may teach critical thinking skills, but once a student has successfully diagnosed a VP, the simulation stops providing educational value. In this paper we propose a generalizable method for integrating agent-based models into serious games and simulations. In the proposed paradigm, a human player (learner) takes on the role of a single agent in the model (e.g, a healthcare professional), while the output of the model controls the environment, the rules of agent interactions, and all the other agents that the human player interacts with (non-player characters). Moreover, we will present two use cases demonstrating that the use of agent-based models as behavior controllers for non-player characters introduces a degree of unpredictability in a virtual patient simulation and in a serious game designed to teach middle and high-school students about the spread of infectious diseases.},
  keywords={Games;Medical services;Artificial intelligence;Task analysis;Computational modeling;Switches;Biological neural networks;virtual patients;simulations;serious games;non-player characters;agent-based models},
  doi={10.1109/SeGAH49190.2020.9201889},
  ISSN={2573-3060},
  month={Aug},}@INPROCEEDINGS{685192,
  author={Bengu, G. and Watts, D. and Elliot, N. and Tolety, S. and Mallikarjum, Y. and Bhaumik, A. and Lipuma, J.},
  booktitle={ICC '98. 1998 IEEE International Conference on Communications. Conference Record. Affiliated with SUPERCOMM'98 (Cat. No.98CH36220)}, 
  title={Use of object-oriented intelligent simulation tools for Web based education}, 
  year={1998},
  volume={2},
  number={},
  pages={1160-1167 vol.2},
  abstract={This study explains the development of a Web based computer aided intelligent education tool. The tool is designed to enhance the knowledge and decision making capabilities of students studying engineering related environmental issues. The system enables freshmen engineering students to enhance critical thinking ability. The power of interactive simulation, animation, artificial intelligence and object-oriented technologies are incorporated to guide the students in the decision-making processes of real-life case studies. The system developed combines theory, experiments, and software tools and can be used in classroom situations or for self/group-learning. The use of intelligent simulation modules is aimed at introductory level environmental chemistry. The currently available three modules are environmentally safe paint preparation process, automobile pollution and fundamentals of gas laws. The teaching strategy of each section of courseware is centered around a text that introduces the fundamentals, theory and links to simulated laboratories. The text also contains hyperlinks to other text pictures, audio and video resources, and interactive models.},
  keywords={Object oriented modeling;Artificial intelligence;Computational modeling;Decision making;Power engineering computing;Computer science education;Design engineering;Knowledge engineering;Power engineering and energy;Engineering students},
  doi={10.1109/ICC.1998.685192},
  ISSN={},
  month={June},}@INPROCEEDINGS{6465227,
  author={Fishwick, Paul A.},
  booktitle={Proceedings of the 2012 Winter Simulation Conference (WSC)}, 
  title={A tutorial on simulation modeling in six dimensions}, 
  year={2012},
  volume={},
  number={},
  pages={1-12},
  abstract={Simulation involves modeling and analysis of real-world systems. This tutorial will provide a broad overview of the modeling practice within simulation by introducing the reader to modeling choices found using six dimensions: abstraction, complexity, culture, engineering, environment, and process. Modeling can be a daunting task even for the seasoned modeling and simulation professional, and so my goal is to introduce modeling in two ways: 1) to use one specific type of model (Petri Net) as an anchor for cross-dimensional discussion, and 2) to provide a follow up discussion, with additional non Petri Net examples, to clarify the extent of each dimension. For example, in the abstraction dimension, one must think about scale, refinement, and hierarchy when modeling regardless of the type of modeling language. The reader will come away with a broad framework within which to understand the possibilities of models and of modeling within the practice of simulation.},
  keywords={Biological system modeling;Computational modeling;Abstracts;Complexity theory;Tiles;Petri nets;Mathematical model},
  doi={10.1109/WSC.2012.6465227},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{7359999,
  author={Moscoso, William D. and Agudelo-Otálora, Luis Mauricio},
  booktitle={2015 Latin American Computing Conference (CLEI)}, 
  title={Forecast flows in a section of the Bogotá river by artificial intelligent systems}, 
  year={2015},
  volume={},
  number={},
  pages={1-7},
  abstract={This article presents a comparison between two types of intelligent models: Artificial Neural Networks - ANN and Adaptative Neuro-Fuzzy Interference System - ANFIS, for forecasting flows in a section of Bogotá (Colombia) river, looking for the most efficient. The simulation was performed in the Matlab computer software, with data collected by hydrological stations of the Corporación Autónoma Regional of Cundinamarca (CAR), from September 2009 to October 2013. The findings suggest that by using artificial intelligence models you can reach a successful outcome, with Correlation Coefficients above 90 % (CC), Mean Absolute Percentage Error (MAPE) below 12 %, Concordance Correlation Coefficient to 84 %, six other statistical evaluating precision and accuracy, suggesting that forecasts will be labeled as good and could think of the use of these techniques in Colombia.},
  keywords={Artificial neural networks;Mathematical model;Biological system modeling;Computational modeling;MATLAB;Interference;Rivers;Artificial Neural Networks;Neuro-fuzzy Interference System — ANFIS;flood forecasting;flow rate;volume of flood},
  doi={10.1109/CLEI.2015.7359999},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9274199,
  author={Li, Ying and Song, You and Moukrim, Anas and Yu, Shicheng},
  booktitle={2020 IEEE Frontiers in Education Conference (FIE)}, 
  title={An Ability-oriented Approach for Teaching Programming Courses}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={This Research-to-Practice Work-In-Progress paper proposed a multidimensional ability-oriented approach for teaching program with the integration of outcome-oriented, student-centered, project-based and contest-driven. The main contributions were: (1) proposed an Ability-Driven Programming Model (ADPM) from two-dimensions of knowledge taxonomy and practice taxonomy which refined Bloom Taxonomy and defined computer programming ability from four hierarchical levels, they are basic ability, comprehensive ability, engineering ability and innovative ability; (2) designed an improved student-centered pattern to reconstructed contents to make each topic associated with six objectives in Bloom's taxonomy and explored some facts to verify the effect of both student-centered teaching and learning; (3) adopted a project-driven method based on "Conceive-Design-Implement-Operate" to solve complex engineering problems and elaborated on how to design good projects and how to measure the quality of projects in detail. Finally, analysis conducted using survey questionnaires and classroom videos indicates that use of Ability-Driven methodology has motivated students to become active learners and improved engineering practice ability. The Ability-Driven methodology provides an applicable model for a student-centered teaching pedagogy to cultivate students' engineering habits and teach them to think like an engineer.},
  keywords={Education;Computational modeling;Programming profession;Taxonomy;Training;Knowledge engineering;Teamwork;Ability-oriented;Bloom Taxonomy;Student-centered;CDIO},
  doi={10.1109/FIE44824.2020.9274199},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{9819996,
  author={Li, Yapeng and Shao, Congmin},
  booktitle={2022 5th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Research on the Shared Supply Mode of Urban Public Transportation under the Internet of Things—A Case Study Based on Hello Travel Platform}, 
  year={2022},
  volume={},
  number={},
  pages={662-668},
  abstract={As the most important basic facilities in the operation of urban economic and citizens' life and travel, urban public transportation's sufficient, balanced and high-quality supply is the requirement of the transformation of major social contradictions in the new era. Supporting by Big data and cloud computing, the rapid development of the Internet of things promotes the innovations in the production mode, management mode and property right in the supply of public transportation, which transforms the traditional thinking ways of single supply by administration and market, and has given rise to sharing economic model representing by sharing bike and gradually extended to other areas of the urban public transportation. As a successful public transportation equipment operator, we can summarize the existing public transportation sharing supply mode through the study of Hello Travel's development history and operation mode, which can provide a new development direction and mode reference for the transformation of urban public transportation supply mode.},
  keywords={Economics;Technological innovation;Computational modeling;Transforms;Production;Big Data;Data models;public transport supply;shared supply;sharing economy},
  doi={10.1109/ICAIBD55127.2022.9819996},
  ISSN={},
  month={May},}@INPROCEEDINGS{6680095,
  author={Guo, Jingzhi and Xie, Meilan},
  booktitle={2013 International Conference on Cyberworlds}, 
  title={Achieving Satisfied Virtual Exchange Rates through Multiple-Stage Virtual Money Supply}, 
  year={2013},
  volume={},
  number={},
  pages={71-76},
  abstract={An important research problem in designing an open virtual world is how to enable virtual currency exchange between multiple virtual worlds and guarantee the exchange fairness when multiple virtual currencies are adopted as virtual payment instruments in virtual trades between virtual worlds. While an existing VMX theory solved the fairness problem in a VERA algorithm based on a Pareto exchange point [3], a new expecation problem has been found such that exchange requesters might submit minimum acceptable rates (MAR) to determine whether to accept VMX systems-generated virtual currency exchange rates. When exchange requestors think the systems-generted rates are lower than MAR, they select not to accept the systems-generated rates. The withdrawal of systems-generated rates creates the expectation problem such that the fairness has been lost due to Pareto exchange point no longer exists. To solve the expectation problem, this paper has developed a new VERA-RS algorithm by extending the existing VERA algorithm based on a newly developed formal expectancy model and a novel m-stage and n-phase three-level computing framework. VERA-RS algorithm has solved expectation problem by achieving a set of satisfied virtual currency exchange rates.},
  keywords={Exchange rates;Computational modeling;Algorithm design and analysis;Instruments;Force;Time series analysis;virtual world;virtual money;virtual currency;exchange rate;virtual wealth protection;algorithm},
  doi={10.1109/CW.2013.42},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10200951,
  author={Zhang, Jing},
  booktitle={2023 International Conference on Applied Intelligence and Sustainable Computing (ICAISC)}, 
  title={Design of Visual Information Model of Blockchain Intelligent Interactive Data}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Visual information model design needs to integrate with big data sharing, intelligent interaction, authentication security, model building, optimization and energy saving, node privacy and other aspects to give play to the important role of blockchain intelligent interactive data. This paper builds a visual cognitive model around knowledge graph and intelligent interactive data, proposes multiple structures, thinking cognition, multiple modules and intelligent data, and aims at multiple visual cognitive paths of “driving task-effectiveness activity – map visualization – intelligent interaction – model processing” and “data rotation -information graph – multiple knowledge – cognitive model”. It draws the conclusion of the multi-distributed and information intelligentized non-center model structure, realizes the openness, transparency and traceability of all kinds of information data, and makes the blockchain intelligent interactive data more visualization, intelligence, humanization and technicalization. According to the intelligent type media of blockchain, large databases are stored and classified, and a partition block data model is established. A chain structure relationship is formed between block data models, and a layer-by-layer oriented structure is formed. The representation design and interaction design of blockchain intelligent interactive data visualization needs to meet the requirement that the cognitive subject and artificial intelligence can work cooperatively and integrate, so as to create a compound cognitive block model.},
  keywords={Visualization;Data privacy;Computational modeling;Data visualization;Knowledge graphs;Media;Data models;blockchain;intelligent interactive data;visual information;cognitive model;data visualization},
  doi={10.1109/ICAISC58445.2023.10200951},
  ISSN={},
  month={June},}@INPROCEEDINGS{7870189,
  author={Aydin, Mustafa and Jacob, Jeremy},
  booktitle={2016 European Intelligence and Security Informatics Conference (EISIC)}, 
  title={Providing Extensibility to Threat Modelling in Cloud-COVER’s Underlying Analysis Model}, 
  year={2016},
  volume={},
  number={},
  pages={45-51},
  abstract={Cloud-COVER is a threat modelling tool allowing users to analyse the way in which threats propagate within their cloud computing deployment. We present extensibility features which allow users to input their own threats, attributes, and connection permissions to Cloud-COVER. This allows users toshift the perspective of the tool to one which better suits their circumstances. By modelling their deployments using different viewpoints, users can ensure a more thorough threat modelling process and can identify threats which might not be identified using Cloud-COVER's default mode. We present examples of how extensibility can be applied to each of three inputs, and how users need to think about the interaction of attributes and permissions to make good use of this feature.},
  keywords={Cloud computing;Computational modeling;Data security;Cost accounting;Analytical models;Joining processes},
  doi={10.1109/EISIC.2016.016},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10263603,
  author={Hans, Nitish and Hirishikesh, P and Victoria, A Helen},
  booktitle={2023 International Conference on IoT, Communication and Automation Technology (ICICAT)}, 
  title={An Extraction Aggregation Strategy Using a Hierarchical Representation Model Based on Longformers and Transform}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The quantity of written content about medical information is staggering, and it keeps on increasing daily. Think about the internet, which is full of websites, news, constantly updated status, blogs, and a great deal more. Utilizing search to swiftly scroll through key findings is the most effective method for navigating material mainly because the results are not arranged in any specific fashion. A considerable percentage of this stuff needs to be summarized to emphasize the most significant information. Creating a custom summary with our own two hands of everything that can be effectively done by text summarization techniques. There is a critical need for this automated method. This project incorporates technologies that are capable of summarizing the text automatically. It implies paraphrasing phrases into a single thought. We propose a hierarchical document that represents an architecture for extraction aggregation that utilizes “Longformer” as a set encoder and “Transformer” as a text encoder to represent text documents properly. This model is referred to as the Long-Trans-Extr model. One of the benefits of using Longformer as a set encoder is that the model can take in lengthy documents with a maximum of 4096 tokens, which only adds a little amount of additional processing. This quick summarization tool can be used by doctors or medical practitioners for quickly analysing emergency or critical patients.},
  keywords={Training;Analytical models;Image color analysis;Computational modeling;Memory management;Transforms;Transformers;Text Summarization;Natural Language Processing;Natural Language Understanding;Deep Learning},
  doi={10.1109/ICICAT57735.2023.10263603},
  ISSN={},
  month={June},}@INPROCEEDINGS{10200806,
  author={Mishra, Shashank and Aggarwal, Mukul and Yadav, Shivam and Sharma, Yashika},
  booktitle={2023 3rd International Conference on Advances in Computing, Communication, Embedded and Secure Systems (ACCESS)}, 
  title={Comparison of Machine Learning Techniques for Sentiment Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={184-191},
  abstract={Sentiment analysis is the process of categorizing and locating the emotions represented in a textual source. Sentiment analysis can be used widely in different areas, such as customer review data, feedback data classification, survey responses, and social media comments. Tweets on Twitter contain a variety of sentiments reflecting the perception, thinking, and working background of the user. With the help of the sentiment analyzer, it can define the response of others on any matter or subject of interest. Here, we used machine learning-based NLP (natural language processing) and text analysis technology to define an automated model that can classify the sentiment of a large dataset. Here we used the following three machine-learning classifiers: logistic regression, SVM, and Bernoulli Naïve Bayes. The effectiveness and performance of these classifiers are assessed using F1 scores and accuracy. The accuracy of these models is 83%(LR), 81%(SVM), and 80%(BNB) So logistic regression model provides the best result among these.},
  keywords={Support vector machines;Analytical models;Sentiment analysis;Logistic regression;Text analysis;Social networking (online);Computational modeling;Sentiment;Svm;Logistic regression;Bernoulli Naïve Bayes;Seaborn;Token;Vector etc},
  doi={10.1109/ACCESS57397.2023.10200806},
  ISSN={},
  month={May},}@INPROCEEDINGS{6778408,
  author={Hur, Dongcheol and Wallraven, Christian and Lee, Seong-Whan},
  booktitle={2013 2nd IAPR Asian Conference on Pattern Recognition}, 
  title={Recognizing Conversational Expressions Using Latent Dynamic Conditional Random Fields}, 
  year={2013},
  volume={},
  number={},
  pages={697-701},
  abstract={Facial expressions are one of the most important elements for our social interaction. Automatic processing and recognition of facial expressions is hence one of the core areas in computer vision, computer graphics, and social signal processing. Conditional Random Fields (CRFs) and their extensions are widely used for recognizing facial expressions. Most research in this area, however, is done either with a limited set of emotional expressions (such as the six universal expressions), or it concentrates on extracting facial action units (individual muscle movements) from video sequences. Little research has been conducted to analyze the complex facial movements that occur in conversational contexts. Conversational expressions such as "agree", "disagree", "thinking", "looking confused", however, form an integral part of non-verbal communication and systems that can automatically parse and understand such expressions are a key ingredient for the development of efficient human-computer interaction systems. Since conversational expressions may consists of several sub-expressions and contain complex dynamics, however, standard CRF approaches are not suited for the task. In this paper, we conduct a detailed comparison of CRFs and Latent Dynamic Conditional Random Fields (LDCRFs) for recognizing complex conversational expressions. We show the importance of modeling sub-expression dynamics and discuss challenges for applying LDCRFs to recognize a large set of conversational expressions.},
  keywords={Databases;Computational modeling;Training;Face recognition;Hidden Markov models;Vectors;Feature extraction;Facial Expression Analysis;Sequence Modeling;Human Computer Interaction},
  doi={10.1109/ACPR.2013.98},
  ISSN={0730-6512},
  month={Nov},}@INPROCEEDINGS{10698637,
  author={Wiryawan, Drajad and Rattanto, Basil and Shaharudin, Muhammad Shabir and Suhartono, Joni and Mailangkay, Adele Bernadet Lingkan and Rumangkit, Stefanus},
  booktitle={2024 International Conference on Electrical, Computer and Energy Technologies (ICECET}, 
  title={Cloud Technology Impact on Human Behavior Based on Cognitive Theory}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The relationship between Cognitive Theory and Cloud Technology is a learning stage for humans, especially technology users, in various innovations used by users in modeling reasoning to develop human direction toward a better future. It includes learning on a large scale, such as objectively coordinated thinking, which provides for decision-making, social interaction, and access to various technological devices used. The above also focuses on human familiarity with various distributed computing services in cloud technology, including PaaS, SaaS, and IaaS. This research used a systems literature review model for over 20 years (2000 – 2023). Meanwhile, the applications used are Vos Viewer and Publish or Perish. Due to the author's limited access to IEEE, ACM, and WoS, the database used and the focus of the literature is the Scopus Database. In five years (2019–2023), the writing purpose accounted for only 55 articles, with 39 explicitly addressing cognitive theory and human behavior in the context of cloud technology. In this research, five factors influence human behavior with cloud technology: social interaction, access and connectivity, problem-solving, decision-making, and data confidentiality security. However, of the five impacts entered and obtained from the papers and journals studied, the most critical findings from this research are social interaction, data privacy and security, and decision-making. People will use cloud technology for social interaction, to protect and maintain the confidentiality of their data, and to make various decisions related to their activities. This research also shows that most references come from journals, not conference proceedings articles.},
  keywords={Cloud computing;Data privacy;Technological innovation;Databases;Computational modeling;Bibliographies;Decision making;Behavioral sciences;Security;Problem-solving;cloud;cognitive;behavior;human;impact},
  doi={10.1109/ICECET61485.2024.10698637},
  ISSN={},
  month={July},}@INPROCEEDINGS{10608031,
  author={Magboo, Ma. Sheila A. and Coronel, Andrei D.},
  booktitle={2024 International Conference on Computer, Information and Telecommunication Systems (CITS)}, 
  title={Effects of Cropping vs Resizing on the Performance of Brain Tumor Segmentation Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This study investigated the effects of image resizing vs cropping on the performance of state-of-the-art models for the brain tumor segmentation task. This is particularly important since many studies simply resize the image without thinking about potential effects of image distortion on the model's segmentation performance. Since the objective of tumor segmentation is to predict the pixels that comprise the actual tumor, image cropping was performed in order to focus more on the brain and the tumor and not on the background. This conjecture was tested using state-of-the-art models namely 2D U-Net, 2D U- Net with VGG19 as backbone, 2D U-Net with InceptionV3 ad backbone, and 2D U-Net with InceptionResNetV2 as backbone. Three different configurations were designed for this purpose. The first configuration used resized images while the second configuration used cropped images. The third configuration used pretrained weights of models of trained on the resized images and then applied them on the cropped images. Overall, the top three models are 2D U-Net with InceptionResNetV2 as backbone trained using the resized images followed by 2D U-Net trained also using the resized images and then finally by 2D U-Net trained using the cropped images. As to why cropping did not perform well in this experiment, several plausible explanations were provided in this study.},
  keywords={Image segmentation;Computational modeling;Brain modeling;Distortion;Telecommunications;Task analysis;Tumors;2D U-Net;2D U-Net InceptionResNetV2;image resizing;image cropping;brain tumor segmentation},
  doi={10.1109/CITS61189.2024.10608031},
  ISSN={},
  month={July},}@INPROCEEDINGS{9872223,
  author={Pan, Liwei and Wu, Yan and Yang, Xiaochen and Wu, Qiuxuan and She, Qinshan and Wang, Jian and Zhang, Botao and Chepinskiy, Sergey A. and Zhilenkov, Anton A. and Luo, Yanbin and Gao, Farong and Zhang, Xuecheng and Gu, Yueqin},
  booktitle={2022 IEEE International Conference on Real-time Computing and Robotics (RCAR)}, 
  title={Parameters optimization of U-Slip Model of Underwater Bionic Robot Based on RNA Genetic Algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={401-406},
  abstract={In nature, marine cephalopods (such as Mimetic octopus) not only have strong ability of thinking conversion, but also have superior ability of bipedal walking, so the robot adopts the method of octopus bipedal movement. Aiming at the locomotion analysis of the underwater bionic robot, the U-SLIP model is adopted. In order to solve the problem of the difficulty of parameters determination and the walking distance of the underwater bionic robot, a parameter optimization method for U-SLIP model of the underwater bionic robot based on RNA genetic algorithm is proposed. Firstly, the U-SLIP model is built and its dynamic differential equation is solved to get the trajectory of the center of mass. In the process of modeling, through the analysis of the parameters such as buoyancy, resistance, leg extension speed and stiffness coefficient, the gait of the swing phase and the punting phase of the robot is described. Secondly, the appropriate fitness function is designed, and the parameters of U-SLIP model are optimized by RNA genetic algorithm. Finally, the simulation based on MATLAB shows that the optimized model can not only achieve stable walking, but also walk farther in the same time, and the appropriate optimization trajectory is gotten, which the effectiveness of the algorithm for parameters optimization is verified..},
  keywords={Legged locomotion;Analytical models;Biological system modeling;RNA;Computational modeling;Optimization methods;Mathematical models},
  doi={10.1109/RCAR54675.2022.9872223},
  ISSN={},
  month={July},}@INPROCEEDINGS{6168331,
  author={Goyal, S.B. and Goyal, Aarti and Sharma, Pratima and Singhal, Neha},
  booktitle={2012 Second International Conference on Advanced Computing & Communication Technologies}, 
  title={Analyzing Object Models with Theory of Innovative Solution}, 
  year={2012},
  volume={},
  number={},
  pages={46-50},
  abstract={Object-Oriented Modeling is a modeling paradigm mainly used in computer programming that assists the programmer to address the complexity of a problem domain by considering the problem and reduce the effect on model caused by such problem and make designs more robust, more maintainable, and more reusable. It is a design strategy where system designers think in terms of 'things' instead of operations or functions. Object-Oriented software projects are becoming more popular than structured or functional technology based projects. While Object-Oriented modeling are already arriving in the marketplace but their formal foundations are still under development. Object Technology offers support to deliver products to market more quickly and to provide high quality with lower maintenance costs. Quality Assurance is an important field of software engineering and there is need for good Object-Oriented metrics and models for both process and product. The quality of object-oriented design has a decisive impact on the quality of a software product, but due to the diversity and complexity of design properties like coupling, encapsulation etc their assessment and correlation with external quality attributes like maintenance, portability etc is hard. To address these issues, we will use the innovative solution (TRIZ) to enhance quality with available Object-oriented metrics and affecting factors. TRIZ is a problem-solving, analysis and forecasting tool that is abbreviation of Russian word Teoriya Resheniya Izobretatelskikh Zadatch which typically rendered as the Theory of Inventive Problem Solving. The objective of TRIZ is development of an algorithmic approach to the invention of new systems, and the refinement of existing ones. In this paper we will apply TRIZ to Object-oriented Models to enhance the quality of Object-oriented design. This paper describes a method based on TRIZ principles and tools that can be easily applied to maintain the quality of Object-Oriented based models.},
  keywords={Object oriented modeling;Unified modeling language;Software;Analytical models;Computational modeling;Business;Programming;Database Management System;Innovation Solution;Object-oriented Model;Object Technology;Problem Solving Tool;software Engineering},
  doi={10.1109/ACCT.2012.29},
  ISSN={2327-0659},
  month={Jan},}@INPROCEEDINGS{10403173,
  author={Wu, Renkai and Liang, Pengchen and Huang, Xuan and Yang, Ziyuan and Shi, Liu and Gu, Yuandong and Zhu, Haiqin and Chang, Qing},
  booktitle={2023 IEEE International Conference on Medical Artificial Intelligence (MedAI)}, 
  title={Automatic Skin Lesion Segmentation Based on Higher-Order Spatial Interaction Model}, 
  year={2023},
  volume={},
  number={},
  pages={447-452},
  abstract={Dermoscopic image segmentation is a key step in computer-aided diagnosis of skin lesions. The current medical image segmentation model mainstream uses standard convolution and Transformers as the most important components of the model. However, standard convolution is unable to handle the problems of remote information interaction and long distance spatial dependence. Transformers is a hindrance to its application when dealing with medical clinical data, the insufficient amount of data and the large memory and time required for computation are hindering factors. Recently, HorNet, a high-order spatial interaction model that performs well in natural scenarios, has drawn our attention because the high-order interaction model has the common advantages of both convolution and Transformers. In this paper, we propose a new system that uses the HorNet model, which performs well in natural scenes, for medical image segmentation (skin lesion segmentation). To the best of our knowledge, we are the first to use a higher-order interaction model for medical image segmentation. We validate our system on three public datasets and do external validation on our own clinical dataset. The experimental results show that our system outperforms other current medical image segmentation models in several metrics. We think this is due to the higher spatial interaction capability and larger perceptual domain of gnconv in HorNet, which can fully and comprehensively capture the information of the overall medical image, which is crucial for medical image processing.},
  keywords={Image segmentation;Convolution;Computational modeling;Transformers;Skin;Lesions;Medical diagnostic imaging;Computer-aided diagnosis;Deep Learning;Higher-order spatial interaction;Skin lesion segmentation;Au-tomatic segmentation},
  doi={10.1109/MedAI59581.2023.00066},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7494248,
  author={Ren Feiyi and Yu Jinsong},
  booktitle={2015 12th IEEE International Conference on Electronic Measurement & Instruments (ICEMI)}, 
  title={Fault diagnosis methods for advanced diagnostics and prognostics testbed (ADAPT): A review}, 
  year={2015},
  volume={01},
  number={},
  pages={175-180},
  abstract={Nowadays in industrial processes, whether producers or users think highly of performance reliability and robustness of equipments. Therefore, the FDI (Fault detection and isolation) and maintenance techniques have become hot topics for health management of industrial units, as a safety guarantee indeed. As a consequence, researchers have made great efforts to develop, verify and refine diverse diagnosis techniques, meanwhile compare and screening them in order to apply them properly in practice. And then, NASA Ames has built the Advanced Diagnostics and Prognostics Testbed, a real-world system as a general platform for verification and validation (V&V) of diagnosis techniques. Until now, many researchers have developed effective diagnosis algorithms specially applied to this system. In this paper, we introduce the ADAPT and the diagnosis competition around the system, and we review a variety of diagnosis methods divided mainly in three types, model-based, optimization-based and artificial intelligence-based methods, while elaborating the first type in detail by two sorts of model: physical and graphic, of which the second attracts more and more attention of scientists in actual research. Finally, we make a comparison among them based on simplified metrics of qualification, which plays an important role in choosing appropriate methods for diagnosing a special problem.},
  keywords={Circuit faults;Adaptation models;Object oriented modeling;Mathematical model;Integrated circuit modeling;Computational modeling;Load modeling;ADAPT;diagnosis method;model-based;optimization-based},
  doi={10.1109/ICEMI.2015.7494248},
  ISSN={},
  month={July},}@ARTICLE{10258164,
  author={Charoenwong, Ben and Kirby, Robert M. and Reiter, Jonathan},
  journal={IEEE Access}, 
  title={Computer Science Abstractions to Help Reason About Decentralized Stablecoin Design}, 
  year={2023},
  volume={11},
  number={},
  pages={103201-103213},
  abstract={Computer science uses abstractions as a tool for reasoning. It is no surprise that computer science might have something valuable to lend to the world of decentralized stablecoin design, as it is a “computing” problem. In this paper, we examine the possibility of a decentralized and capital-efficient stablecoin using smart contracts that algorithmically trade to maintain stability. By exploiting traditional abstractions from computer science, we show that a capital-efficient algorithmic stablecoin cannot be provably stable. Additionally, we provide a formal exposition of the workings of Central Bank Digital Currencies, connecting this framing to the space of possible stablecoin designs. We then discuss several outstanding conjectures from both academics and practitioners and finally highlight the regulatory similarities between money-market funds and working stablecoins. Our work builds upon the current and growing interplay between the realms of engineering and financial services, and it also demonstrates how ways of thinking as a computer scientist can aid practitioners. We believe this research is vital for understanding and developing the future of financial technology.},
  keywords={Computer science;Economics;Currencies;Smart contracts;Stability analysis;Monopoly;Computational modeling;Financial management;Cryptocurrency;Smart contracts;algorithmic stablecoin;financial stability;DeFi;cryptocurrency},
  doi={10.1109/ACCESS.2023.3317891},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10638941,
  author={Yasmin, Sadaf and Mishra, Swati and Islam, Asharul and Hussain, Rashid},
  booktitle={2024 IEEE 7th International Conference on Advanced Technologies, Signal and Image Processing (ATSIP)}, 
  title={A Mobile Cloud Architecture for M-Commerce Business Application’s Execution Performance}, 
  year={2024},
  volume={1},
  number={},
  pages={632-637},
  abstract={Many researchers have come up with different ways to build a business model architecture for efficient services to run m-commerce applications. The framework for developing mobile commerce applications needs to change at the same time as the IT expansion and business transformation. We are pursuing a theoretical business framework to find an optimal solution for the seamless service-oriented m-commerce application performance. In this approach, we identify the components of m -commerce applications that could reduce mobility barriers and improve application execution time and device energy efficiency. This led us to propose a framework for m-commerce application performance that uses the Mobile Cloud Computing (MCC) solutions. This plan focuses on making the application run faster and use less energy, and making it easier for users to move around. We help mobile commerce application developers make smart RDMCA (Resource-Demanding M-commerce Applications) that provide good services for mobile commerce businesses and consumers. A theoretical proposed business framework is being set up to find an optimal solution for service-oriented m -commerce application performance. In this way, we find the important parts of the m -commerce system (signal range determiner) that help make the application run faster, use less energy, and make it easier to move around. We think that improving this framework will help mobile commerce app developers to make RDMCA’s that provide good services for both mobile commerce enterprises and end users.},
  keywords={Performance evaluation;Cloud computing;Energy consumption;Image processing;Computer architecture;Energy efficiency;Computational efficiency;Mobile Cloud Architecture;Business Performance;M-Commerce Resource-Demanding Applications},
  doi={10.1109/ATSIP62566.2024.10638941},
  ISSN={2687-878X},
  month={July},}@INPROCEEDINGS{8858854,
  author={Gupta, Prashant K. and Muhuri, Pranab K.},
  booktitle={2019 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, 
  title={Linguistic optimization problems: solution methodology using perceptual reasoning}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={A number of real-life scenarios involving decision making may be modelled as optimization problems. In these optimization problems, the human preferences and thinking constrain achieving the optimal value of the problem objective(s). If there is a single objective, then the optimization problems are called single objective optimization problems (SOOPs) else the multi-objective optimization problems (MOOPs). Various solution methodologies have been proposed for SOOPs and MOOPs, which are useful, as long as the SOOPs and MOOPs involve the numeric data. However, the data is generally in linguistic form (or words), when elicited by the human beings. Therefore, the SOOPs and MOOPs are referred as single objective linguistic optimization problems (SOLOPs) and multiobjective linguistic optimization problems (MOLOPs), respectively, in such situations, to emphasize the existence of linguistic information in optimization problems. In these LOPs, the value of the objective function(s) may not be known at all points of the decision space, and therefore, the objective function(s) as well as problem constraints are linked through if- then rules. Previously, the Tsukamoto's inference method was used to solve these types of LOPs; however, it suffers from drawbacks. As, the use of linguistic information inevitably calls for the utilization of computing with words (CWW), hence, in this paper, we discuss the solution methodologies for LOPs based on the perceptual reasoning (PR). PR is a novel CWW engine design for the CWW approach of perceptual computing. We also demonstrate the applicability of PR based solution methodology for LOPs to the case study of car purchase modelled as LOP.},
  keywords={Linguistics;Optimization;Linear programming;Firing;Cognition;Computational modeling;Fuzzy sets;Computing with words;Interval type 2 fuzzy sets;Linguistic optimization problems;Perceptual reasoning.},
  doi={10.1109/FUZZ-IEEE.2019.8858854},
  ISSN={1558-4739},
  month={June},}@INPROCEEDINGS{5326389,
  author={Zhu, Feng and Carpenter, Sandra and Kulkarni, Ajinkya and Chidambaram, Chockalingam and Pathak, Shruti},
  booktitle={2009 6th Annual International Mobile and Ubiquitous Systems: Networking & Services, MobiQuitous}, 
  title={Understanding and minimizing identity exposure in ubiquitous computing environments}, 
  year={2009},
  volume={},
  number={},
  pages={1-10},
  abstract={Various miniaturized computing devices that store our identities are emerging rapidly. They allow our identity information to be easily exposed and accessed via wireless networks. When identity information is associated with our personal and context information that is gathered by ubiquitous computing devices, personal privacy might be unprecedentedly sacrificed. People, however, have different privacy protection skills, awareness, and privacy preferences. Individuals can be uniquely identified on the basis of only a few identity elements used in combination. To the best of our knowledge, this is the first study to understand the following issues and their relations: a) what identity elements people think are important; b) what actions people claim to take to protect their identities and privacy; c) privacy concerns; d) how people expose their identities in ubiquitous computing environments; and e) how our rational identity exposure model can help to minimize identity exposure. We build a simulated ubiquitous computing shopping system, called InfoSource. It consists of two applications and our rational identity exposure model. We present our experiments and statistical analysis results. Our data show that exposure decisions depend on participants' attitudes about maintaining privacy, but they do not depend on participants' concerns and claimed actions related to identity exposure. Our RationalExposure model helped participants to minimize unnecessary exposures.},
  keywords={Ubiquitous computing;Protection;Pervasive computing;Data privacy;Wireless networks;Game theory;Internet;Computational modeling;Statistical analysis;Identity management systems;game theory;identity management;privacy;ubiqitous computing},
  doi={10.4108/ICST.MOBIQUITOUS2009.6853},
  ISSN={},
  month={July},}@INPROCEEDINGS{10169561,
  author={Ali, Haifa Ali Saeed and Vakula Rani, J},
  booktitle={2023 International Conference on Sustainable Computing and Smart Systems (ICSCSS)}, 
  title={Internet of Things and Digital Forensics: Recent Studies and Challenges}, 
  year={2023},
  volume={},
  number={},
  pages={959-966},
  abstract={The revolution of the Internet of Things (IoT) is increasing dramatically, where everything has become smart, and this new technology has helped facilitate plenty of things for humanity and made life easier in terms of applications and machines that think like humans using artificial intelligence. Currently, many applications of the Internet of Things affect our daily lives. Although the Internet of Things has brought us ease of life, it has brought many challenges related to security. However, solving these issues and challenges requires a high degree of skills. The approach that addresses the increment of cybercrimes is IoT Forensics. IoT forensics is a call for investigating and mitigating these cybercrimes. In this study, we overview the basics of IoT and present an illustrative study of digital forensics and IoT Forensics, then discussing that with some differences between IoT Forensics, Digital Forensics, and IoT Security, and an overview of the Process of IoT Forensics have been discussed. In addition, this work focuses on recent research work from 2018 onwards in terms of IoT Forensics models, frameworks, analysis, and use cases; finally, IoT and Digital Forensics Challenges and open issues have been discussed.},
  keywords={Analytical models;Humanities;Computational modeling;Digital forensics;Internet of Things;Security;Computer crime;IoT Forensics;Cybercrimes;Digital Forensics;IoT Technology;Investigators;IoT Security},
  doi={10.1109/ICSCSS57650.2023.10169561},
  ISSN={},
  month={June},}@INPROCEEDINGS{8265113,
  author={Liu, Qingwei and Han, Ming and Feng, Ling},
  booktitle={2017 13th International Conference on Semantics, Knowledge and Grids (SKG)}, 
  title={Dynamic Sale Prediction of the Time-Sensitive Products Based on Conformity}, 
  year={2017},
  volume={},
  number={},
  pages={90-97},
  abstract={In these years, many online shopping and investment becomes more time-sensitive such as crowdfunding, online auction, time-limit sale and group buying. Most of them have deadlines. Consequently, people need to make faster decisions than other products leading to more conformity in this area. Though there is much work about the conformity and social influence in social networks, there lacks work of conformity in the online shopping and investment, because in these scenarios there is usually no such "strong" connection. However, we think the conformity information is also important for the sale prediction of time-sensitive products, since conformity impacts people's purchase decisions. In this paper, we propose a model which captures the dynamic conformity and apply it to the similarity computation and sale prediction of time-sensitive products. It can be dynamically adjusted to fit the target product and the prediction moment, which means it is well self-adaptive. Since it also gives the consideration to other static and latent features in a collaborative way, it alleviates the "cold start" problem nicely and is free from the presetting hypotheses. Experiments on the real large-scale dataset shows that our method exceeds other comparison methods by 33.2% in the sale prediction.},
  keywords={Market research;Investment;Predictive models;Adaptation models;Social network services;Computational modeling;Collaboration;Conformity;sales prediction;time sensitive;Machine learning},
  doi={10.1109/SKG.2017.00023},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10257974,
  author={Zhu, Chang and Luo, Xizi and Liu, Yuxuan},
  booktitle={2023 IEEE International Conference on Image Processing and Computer Applications (ICIPCA)}, 
  title={Data Mining Study of Wordle Based on Multi-Model Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={979-984},
  abstract={As a game that spreads across the Internet and stimulates people to think and learn, data mining of Wordle's report counts and their distribution is particularly important. In this paper, an ARIMA model and a BP neural network model based on the WOA are developed to perform in-depth data mining on Wordle. For model I, this paper uses ARIMA model fitting to fit the trend of the total number of historical report results over time, and obtains the R2 of the model as 0.986. Based on this, this paper establishes a prediction model for the interval of the total number of reports, and gives the prediction interval of the total number of report results on March 1, 2023 as [21211], [21814]. For Model II, this paper defines word attributes as the following four indicators: for example, the commonness of the word, the number of occurrences of the same letter in the word. The Spearman correlation coefficient between the percentage of reported scores to the total reported scores in the Hard mode and the word attributes was calculated. Finally, in the Hard model, the percentage of reported scores out of the total reported scores was significantly correlated with how common the word was and whether it began with a vowel letter. For Model III, this paper constructed a BP Neural network model based on WOA, which, in this paper, uses word attributes as the input layer and the report distribution of words as the output layer. In the WOA, the optimal weights and thresholds of the BP neural network are obtained in this paper by continuous search and approximation. The final model has a Mean Absolute Error value of 0.38, both of which have good performance. At the same time, this paper predicts the results of “EERIE”, and the obtained distribution results are rounded to [1], [7], [20], [22], [21], [19], [10]. Through the above modelling and calculation, this paper mines Wordle's user data, which has some theoretical significance for the healthy development of Wordle.},
  keywords={Computational modeling;Image processing;Neural networks;Fitting;Games;Predictive models;Market research;Wordle;number of reports;ARIMA;word attributes;BP Neural network model},
  doi={10.1109/ICIPCA59209.2023.10257974},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{6089119,
  author={Shiah, Dah-Ming and Hung, Chin-Tun and Huang, Kuang-Hua},
  booktitle={2011 International Conference of Soft Computing and Pattern Recognition (SoCPaR)}, 
  title={Using voronoi grouping to solve set covering problem - Building an Integrated Delivering System for Taichung City}, 
  year={2011},
  volume={},
  number={},
  pages={268-273},
  abstract={The traditional set covering models did not consider the equity of users that carried by each set. We developed a new method to solve that for the Integrated Delivering System (IDS) in medical service in Taichung city. This method requires grouping the clinics in equal market share in a way that satisfy the equity conditions given. It uses Voronoi blocks as market share for each clinic within the study area and calculates the house and clinic ratios as the equity conditions. For each scan, the selected block merges with one of the adjacent blocks using five conditions with different weights. This process continues until the objective functions are met. This model opens up a new way of thinking for set covering by grouping the block objects to obtain optimal result. The result is workable and can be reproduced by computer program if the same data set existed.},
  keywords={Mathematical model;Cities and towns;Computational modeling;Urban areas;Hospitals;Pattern recognition;set covering;geography information system;IDS;spatial analysis},
  doi={10.1109/SoCPaR.2011.6089119},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{6597794,
  author={Vlachonasiou, Eleni},
  booktitle={2013 9th International Conference on Intelligent Environments}, 
  title={Digital Techniques of Representation and Theoretical Discourse: From Folded Space to Intelligent Architectural Environments}, 
  year={2013},
  volume={},
  number={},
  pages={77-83},
  abstract={The adoption of digital techniques of representation in the 21st century has often been associated with a lack of theory in architecture. This paper attempts to trace changes in architectural thinking between two different periods, to address issues of theory in architecture and to find links between these changes and the singularities of digital techniques of representation.},
  keywords={Computer architecture;Media;Artificial intelligence;Production;Proposals;History;Computational modeling;Representation;technique;digital design;emergence;intelligence},
  doi={10.1109/IE.2013.28},
  ISSN={},
  month={July},}@INPROCEEDINGS{5479642,
  author={Powell, Steven R.},
  booktitle={2010 Wireless Telecommunications Symposium (WTS)}, 
  title={Wireless telecommunications in Latin America: A comparison of the market portfolios of America Movil and Telefonica}, 
  year={2010},
  volume={},
  number={},
  pages={1-11},
  abstract={With the growth of their Latin American mobile telecommunications markets slowing, regulatory pressures intensifying, and new entrants worsening an already unfavorable competitive environment, and in order to capitalize on the opportunity to increase revenues by providing new wireless data and video services to subscribers, Telefonica and America Movil management have begun to restructure their companies and re-think their internationalization strategies. This paper focuses on the two companies' Latin American market portfolios in 2008, comparing the portfolios with respect to the attractiveness of their markets and the companies' competitive positions in them, and how they changed from 2002 to 2008. The degrees of market attractiveness and competitive strength the portfolios possessed, as well as their variability across the markets in the portfolios, are considered. The portfolio analysis technique employed in the paper may have wider applicability for formulating corporate strategy.},
  keywords={Portfolios;Telecommunication control;Costs;Europe;Computational Intelligence Society;Environmental management;Government;Investments;Regulators;Proportional control},
  doi={10.1109/WTS.2010.5479642},
  ISSN={1934-5070},
  month={April},}@INPROCEEDINGS{10650485,
  author={Li, Gang and Zhang, Cheng and Han, Delong and Gao, Letian and Zhou, Mingle},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Gradient-YOLO: Exploring the integration of gradient architecture into the YOLO network}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Object detection is an essential task in the field of computer vision. The one-stage object detection model directly completes object detection through a single forward propagation and has fast real-time object detection capabilities, making it widely used—especially the model of the You Only Look Once (YOLO) series. Improving the detection accuracy of the YOLO model has always been a research topic. The gradient architecture cascades feature information extraction and aggregates all features at the end, which can improve the feature fusion ability of the network. Combining the idea of gradient architecture, this paper proposes a YOLO based on gradient architecture: Gradient-YOLO. Specifically, this paper integrates gradient architecture into the backbone, neck, and bottleneck structures in the YOLO network, obtaining gradient backbone, gradient neck, and gradient bottleneck, respectively. By combining gradient architecture, various network parts in Gradient-YOLO can fully aggregate multi-layer features, reduce feature loss, and thus improve detection accuracy. This paper takes the mature YOLOv5 model and the latest YOLOv8 model as the baseline and combines gradient thinking to obtain Gradient-YOLOv5 and GradientYOLOv8. Moreover, conduct experimental testing on the MS COCO dataset. Regarding the mAP@.5 detection indicator, compared to YOLOv5s, Gradient-YOLOv5s increased by 5.07%. Compared to YOLOv8n, Gradient-YOLOv8n has increased by 4.63%. Therefore, the combination of gradient architecture can improve the detection accuracy of YOLO networks.},
  keywords={YOLO;Accuracy;Aggregates;Computational modeling;Computer architecture;Feature extraction;Real-time systems;Object detection;Gradient architecture;YOLO;Feature fusion},
  doi={10.1109/IJCNN60899.2024.10650485},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{8377691,
  author={Chen, Tsung Teng and Lee, Maria R.},
  booktitle={2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)}, 
  title={Deciphering Big Data Research Themes}, 
  year={2018},
  volume={01},
  number={},
  pages={432-437},
  abstract={Big Data is a relatively novel research field that has attracted high interest from the industry and academia for its wide applicability. Numerous definitions of Big Data have been given by scholars from different perspectives. We think the Big Data research field could be better appreciated by analyzing the relevant scientific articles published over the years. However, the sheer volume of the Big Data related literature needs a more efficient way to analyze them. As such, we utilize the knowledge domain analysis techniques developed by information scientists to build the intellectual structure and uncover the main research themes, which afford us a holistic view of the overall Big Data research field. Based on our analysis, the research themes of Big Data may be classified into four main categories: the first one deals with the technologies and architectures aspect of Big Data; the second one relates to the prospective applications of the Big Data analytics; the third one covers levels of parallelism in the Big Data processing stacks; the rest encompasses mostly machine learning related studies and some miscellaneous topics that may benefit from the Big Data processing capabilities.},
  keywords={Big Data;Computer architecture;Loading;Parallel processing;Computational modeling;NIST;Analytical models;Big Data, citation analysis, intellectual structure},
  doi={10.1109/COMPSAC.2018.00066},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{10499013,
  author={Gautam, Mayank and Ahuja, Sachin and Kumar, Abhishek},
  booktitle={2024 11th International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Intrusion Detection Techniques in Internet of Things: A Bird’s Eye View}, 
  year={2024},
  volume={},
  number={},
  pages={622-628},
  abstract={With many gaps and shortcomings in the field of IoT security, no matter how simple you think it is on your side what goes inside an intrusion detection system technique to detect attacks. This study explores the current state of IDS in IoT. The most important points of vulnerability are identified, and we examine ways to address them immediately. One key finding of the research is that interoperability problems between differing IoT devices and platforms loom as two big roadblocks. Besides, the lack of standardized evaluation standards or sets for intrusion detection models in IoT environments turns out to be an important gap between what is being researched currently and reality. The ambiguity of how to upscale in large IoT networks is cited as an issue left unresolved by the study. In addition, it points toward the crucial role intrusion detection plays in safeguarding IoT systems and also reveals existing areas of weakness with regard to adaptability, scalability and standardization..},
  keywords={Adaptation models;Scalability;Computational modeling;Intrusion detection;Internet of Things;Security;Standards;IoT security;intrusion detection systems (IDS) Research gaps;adaptability;scalability standardization},
  doi={10.23919/INDIACom61295.2024.10499013},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{6759121,
  author={Schrödl, Holger and Simkin, Paulina},
  booktitle={2014 47th Hawaii International Conference on System Sciences}, 
  title={Greening the Service Selection in Cloud Computing: The Case of Federated ERP Solutions}, 
  year={2014},
  volume={},
  number={},
  pages={4200-4209},
  abstract={The increasing industrial acceptance of cloud-based IT services has led to a paradigm shift in the development and operation of complex business applications. IT managers are incorporating cloud-based IT services as replacements and/or as enhancements for existing on-site solutions. This strategy leads to the concept of a federated business application, which consists of a variety of on-site and cloud-based subparts, dynamically orchestrated to a single solution. In this setting, the selection of appropriate IT services is critical. Following the discussions of environmental thinking in IT aspects like Green IT and Green IS, the issue of appropriate IT service depends on not only functionality and costs, but additionally also on the environmental impact of the service selection. To address this issue, this paper presents a service selection model for cloud-based services with a focus on the environmental aspects of the selection process. This is done by modeling a multi-criteria decision model based on the rational choice theory. The proposed model provides a selection process which leads to maximal service functionality coverage with minimal environmental impact for a given service provider setting. The application of the model is illustrated in a typical industry case.},
  keywords={Green products;Cloud computing;Computational modeling;Companies;Biological system modeling;Cloud Computing;Green IS;Service Selection;Federated ERP},
  doi={10.1109/HICSS.2014.519},
  ISSN={1530-1605},
  month={Jan},}@INPROCEEDINGS{10442827,
  author={Vashist, Ansh and Jain, Tarun and Sharma, Vijay Shankar},
  booktitle={2023 3rd International Conference on Smart Generation Computing, Communication and Networking (SMART GENCON)}, 
  title={Directed Machine Learning Approaches for Determining Alzheimer Disease}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Alzheimer's is a neurogenic disease which progress into neurological disorder that primarily affects cognitive function and memory. It's a Neurodegenerative (ND) disease, characterized by the gradual deterioration of cognitive function, memory, thinking, and behaviour. There are two most common diseases among neurodegenerative diseases: (a) Alzheimer's Disease and (b) Parkinson's Disease. We used 12 classifiers on the given dataset on UC Irvine Machine Learning Repository. The machine learning algorithms were engaged to identify Alzheimer Disease. Our research results showed that the XGB Model is the one that shows the best accuracy, of 100%, of all the 12 classifiers.},
  keywords={Support vector machines;Parkinson's disease;Computational modeling;Alzheimer's disease;Regression tree analysis;Random forests;Diseases;Alzheimer's;Disease Detection;Machine Learning;Classification;Logistic Regression;Binary Decision Tree Model;Random Forest;SGD Model;XG Boost Model;AdaBoost Model;ANN Model;Ensemble Voting Model;Gaussian Naive Baye Model;Complement Naive Baye Model;Multinomial Naive Baye Model},
  doi={10.1109/SMARTGENCON60755.2023.10442827},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9197911,
  author={Rajput, Aditi and Jain, Madhuri},
  booktitle={2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)}, 
  title={A Multi Criteria Integrated Dynamic Futuristic Group Decision Making Model for Implementation of Intelligent Transportation System in India}, 
  year={2020},
  volume={},
  number={},
  pages={1038-1043},
  abstract={In this paper, a totally new Multi-criteria Integrated Dynamic Futuristic Group Decision Making (MIDFGDM) model is developed for implementation of Intelligent Transportation System in megacities of India by the year 2025 AD. The developed model is a non-linear structure which analyzes inductive and deductive iterative dynamic futuristic thinking for allowing the consideration of generated multi futuristic decision parameters at a time. The crucial scenarios and effective action plan are generated by computing Global Futuristic Judgment (GFJ) Weights from the developed model. Any real world societal and managerial problem can be solved by using the developed model.},
  keywords={Vehicle dynamics;Transportation;Decision making;Monitoring;Computational modeling;Information systems;Intelligent Transportation System;Multi Criteria Decision Making;Traffic Congestion;Global Futuristic Judgment Weights;Scenarios.},
  doi={10.1109/ICRITO48877.2020.9197911},
  ISSN={},
  month={June},}@INPROCEEDINGS{10515330,
  author={Somanathan Pillai, Sanjaikanth E Vadakkethil and Vallabhaneni, Rohith and Pareek, Piyush Kumar and Dontu, Sravanthi},
  booktitle={2024 International Conference on Distributed Computing and Optimization Techniques (ICDCOT)}, 
  title={Financial Fraudulent Detection using Vortex Search Algorithm based Efficient 1DCNN Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Repeated loan fraud threatens financial stability and drives away clients. Financial and banking institutions must immediately recognize network fraud. The banking sector in India and other countries is using AI-driven technology and machine learning algorithms to tackle fraud and unauthorized access. Innovative thinking, increased globalization, and technical developments are raising fraud detection costs. The suggested study would help banks identify credit application fraudsters. The study automated data preprocessing using Kaggle's K-Nearest Neighbor (KNN) algorithm. A one-dimensional convolutional neural network classified. Using the Vortex Search Algorithm (VSA) to fine-tune the classifier hyperparameters improved results. VSA determined the model's hyperparameter sweet spot. The suggested model outperforms other categorization methods with 98.62% accuracy. Better lending banking fraud detection may result from the proposed approach. The VSA-based 1DCNN model detects fraud faster and more precisely.},
  keywords={Machine learning algorithms;Computational modeling;Banking;Trademarks;Stability analysis;Fraud;Classification algorithms;Fraudulent Detection;Convolution Neural Network;Vortex Search Algorithm;Financial Fraudulent},
  doi={10.1109/ICDCOT61034.2024.10515330},
  ISSN={},
  month={March},}@INPROCEEDINGS{10090213,
  author={Wu, Haoyu and Lin, Zhibin and Lin, Borong and Li, Zhenhao and Jin, Nanlin and Zhu, Xiaohui},
  booktitle={2022 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)}, 
  title={Deep Learning To Model The Complexity Of Algal Bloom}, 
  year={2022},
  volume={},
  number={},
  pages={114-122},
  abstract={Literature of studying algal growth has started to take advantages of data mining and machine learning methods, such as classification, clustering, regression, correlation analysis and principal component analysis. However, the performance of such methods might heavily rely on the data collectable for the studies sites. Moreover, some factors directly relate to algal growth, including hydrodynamics, weather and ecology, are notoriously difficult to model and predict. In this paper we present a study to model algal bloom using deep learning methods. It is assumed that algal bloom is the consequence of all factors that are more or less associated with the growth of algal. This offers a new way of thinking that even unknown factors or those factors far too complicated to model can still be inexplicitly represented by the deep learning models. We evaluate this new approach through our studies of algal bloom in the JinJi Lake, Suzhou, China. The experimental results are compared with the popular machine learning methods used in literature. It has been found that the deep learning method can achieve a better accuracy in comparison with other well applied machine learning methods.},
  keywords={Deep learning;Biological system modeling;Computational modeling;Ecosystems;Predictive models;Data models;Sensors;Machine Learning;Deep Learning;Data mining;Regression;Decision Tree;Green-blue algae},
  doi={10.1109/CyberC55534.2022.00027},
  ISSN={2833-8898},
  month={Oct},}@INPROCEEDINGS{10616950,
  author={G, Sathi and Varshney, Neeraj and Sharma, Praveen and Punitha, B.Jasmine and Sundar, R. and SubbaRao, S P V},
  booktitle={2024 4th International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={A Development of Cloud Based Robotics Design Networks for Industry Applications}, 
  year={2024},
  volume={},
  number={},
  pages={320-325},
  abstract={In modern robots, the usage of computationally expensive models involving deep neural networks, also referred to as DNNs, for tasks such as the localization of operations awareness, planning, and object recognition is becoming prominent. Nevertheless, resource-constrained machinery, such as low-power aerial vehicles, often lack the requisite internal computing resources to easily run cutting-edge simulations of neural networks. Cloud robotics appears as an answer, allowing robots to offload processing to centralized computers for greater precision models. Nonetheless, the ignored downside of cloud robots lies in the possible delay and data loss experienced during contact over crowded wireless networks. This study discusses the Robot Transferring responsibility Problem, exploring when and where robots should offload sense tasks that improve accuracy while reducing the costs involved with cloud communication. The method involves framing shifting as a sequence decision-making issue concerning robots and suggesting a remedy using sophisticated reinforcement learning. Through models and hardware tests employing advanced thinking DNNs, what was suggested sharing strategy improves vision task efficacy by 1.3 2.6 times as a result of standard strategies, allowing robots to increase their sense accuracy while incurring minimal communication via cloud costs.},
  keywords={Computers;Costs;Accuracy;Service robots;Computational modeling;Reinforcement learning;Robot sensing systems;cloud robotics;deep neural networks;Robot Transferring responsibility Problem;network congestion;cloud communication costs;Markov Decision Process;reinforcement learning;Advantage-2 Actor-Critic method;LIDAR data offloading expenses},
  doi={10.1109/ICACITE60783.2024.10616950},
  ISSN={},
  month={May},}@INPROCEEDINGS{10442800,
  author={Nieto-Chaupis, Huber},
  booktitle={2023 International Conference on Electrical, Communication and Computer Engineering (ICECCE)}, 
  title={Can artificial intelligence do the job of a theoretical physicist?}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={If Artificial Intelligence is powerful, then it would cover a wide spectrum of jobs that commonly is done by humans that might require a high level of abstraction and mathematical creation. In this paper, the possibility that Machine Learning through the criteria of Mitchell can produce original contribution at basic sciences, such for example at the theoretical physics, is investigated. Basically, it is shown that theoretical physics is essentially based in laws by which are employed mathematical apparatus based at differential equations, integrations, commutators of operators, closed-form algebra, etc. In this way, the Mitchell criteria might constitute an algorithm to generate new theoretical structures in physics. It is investigated if it is appropriate to claim that Artificial Intelligence is able to replace the human thinking to create new theoretical physics with relevance and with a solid prospectiveness.},
  keywords={Computational modeling;Large Hadron Collider;Machine learning;Solids;Mathematical models;Data models;Physics;Artificial Intelligence;Machine Learning;Algorithms},
  doi={10.1109/ICECCE61019.2023.10442800},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6362974,
  author={Berg, Celina and Erickson, Josh and Kiemele, Liam and Schröter, Adrian and Gulliver, Aaron and Coady, Yvonne and Hoeberechts, Maia and de Grasse, Claire},
  booktitle={2012 Seventh International Conference on P2P, Parallel, Grid, Cloud and Internet Computing}, 
  title={PREDICT: Parallel Resources for Early Detection of Immediate Causes of Tsunamis}, 
  year={2012},
  volume={},
  number={},
  pages={234-240},
  abstract={In this paper we propose a re-thinking of ICT infrastructure to include a framework that exploits commodity many-core systems to evaluate models. The framework permits comparison, evaluation and improvement of competing and complementary models. Our proposal focuses on the computationally intensive tasks associated with near-field parallelism to process environmental conditions in real-time to deliver informed warnings to populations at risk. By keeping a human-in-the-loop, we include new services that support crowd-sourcing within the framework, allowing integration of sensor data with media-rich voluntary participant input. Monte Carlo simulations of relevant ocean models highlight necessary precursors and likelihoods of potential threats. This paper provides a survey of existing systems, both from tsunami modeling and other domains with similar real-time constraints, and evaluates the applicability of our proposed framework, PREDICT, for near-field tsunami early warning.},
  keywords={Tsunami;Computational modeling;Mathematical model;Monte Carlo methods;Propagation;Real-time systems;Graphics processing units;tsunami warning;real-time;scalable},
  doi={10.1109/3PGCIC.2012.57},
  ISSN={},
  month={Nov},}@ARTICLE{9818939,
  author={Bardram, Jakob E.},
  journal={IEEE Pervasive Computing}, 
  title={From Sensing to Acting—Can Pervasive Computing Change the World?}, 
  year={2022},
  volume={21},
  number={3},
  pages={17-23},
  abstract={Computing technology has indeed become pervasive. Taking a quick look around me, I see computing systems in literally everything—in the cars, televisions, smartphones, restaurants, ski-lifts, heating systems, sports trackers, medical devices, etc. This has been realized by a tremendous development in hardware and software technology in terms of CPUs, memory, sensors, operating systems, network, display, etc. However, looking back at this technology development—and the research done in the field—it strikes me that something is missing. One of the grand visions was to make the computer “invisible,” as framed by Weiser. But it seems like instead of computing becoming more invisible, it is taking up more of the user’s attention. In this article, I argue that this is because (pervasive) computing has only come halfway. Much effort has been done in terms of sensing and understanding the world around the user, while much less effort has been put into helping the user actually doing anything. By providing examples mostly taken from the medical domain, this article discusses if moving from “sensing” and “thinking” to actually “doing” something is possible and what challenges are associated with this movement.},
  keywords={Sensors;Pervasive computing;Actuators;Robot sensing systems;Computational modeling;Artificial intelligence},
  doi={10.1109/MPRV.2022.3182489},
  ISSN={1558-2590},
  month={July},}@INPROCEEDINGS{10578742,
  author={Hammer, Sabine and Ottinger, Sarah and Zönnchen, Benedikt and Hohendanner, Michel and Hobelsberger, Martin and Thurner, Veronika},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={ChatGPT in Higher Education: Perceptions of Computer Science-Related Students}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={In the field of education ChatGPT has sparked both admiration and controversy. This study explores students' perspectives, specifically focusing on those in computer science-related fields. We investigated their motivations, trust, perceptions of utility, and reliability of ChatGPT by conducting two surveys-one at the beginning and another at the end of the semester. During the semester, students were encouraged to engage with ChatGPT. Our findings highlight the tool's multifaceted use in an academic settings, establishing it as a valuable resource for a variety of learning tasks. Most students have incorporated ChatGPT into their regular academic activities and view it as a beneficial aid. They perceive it as a multi-task solver and anticipate significant advancements in its writing assistance features in the near future. Many, not only attribute high accuracy to it but think that it adheres to appropriate content and structural norms. Our results suggest that active confrontation with ChatGPT enhances understanding of its capabilities, limitations and autoregressive nature. Consequently, we recommend an approach of informed engagement that includes the distinction between language processing and genuine language understanding and a carefully crafted terminology.},
  keywords={Accuracy;Terminology;Computational modeling;Focusing;Writing;Chatbots;Multitasking;ChatGPT;large language models;higher education;educational technology},
  doi={10.1109/EDUCON60312.2024.10578742},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10016193,
  author={Wang, Yifei},
  booktitle={2022 IEEE Conference on Telecommunications, Optics and Computer Science (TOCS)}, 
  title={A survey of phishing detection: from an intelligent countermeasures view}, 
  year={2022},
  volume={},
  number={},
  pages={761-769},
  abstract={The number of network attacks is increasing at an unprecedented speed, and online phishing is the most common form of network attacks and the most close to our life. In order to enable users to better understand what kind of online phishing they have suffered, and enable scholars and researchers to more quickly customize detection for different types of online phishing detection. We need an in-depth summary of the existing types of online phishing and various detection methods. This paper classifies and summarizes all kinds of phishing, mainly introduces six kinds of phishing, including E-mail phishing and search engine phishing. For phishing detection methods, this paper also summarizes and classifies existing and widely used detection methods into seven categories such as list-based heuristic machine learning, and introduces them in detail. Then the paper analyzes the big data frontier technology and detection channel direction of assisted anomaly detection, and divides it into stream processing technology, Hadoop DPI parsing keyword recognition, web crawler recognition, etc. Finally the paper discusses and thinks deeply about the methods and techniques mentioned above as well as the current situation of phishing detection, and puts forward some forward-looking suggestions on the interpretation of data processing model selection and general detection architecture.},
  keywords={Phishing;Computational modeling;Crawlers;Computer architecture;Big Data;Data processing;Data models;Online phishing;types of online phishing;phishing detection method;Big data related technologies},
  doi={10.1109/TOCS56154.2022.10016193},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10337513,
  author={Chen, Lin and Saharuddin, Norzihani},
  booktitle={2023 International Conference on Computer Engineering and Distance Learning (CEDL)}, 
  title={The Construction of the Academic Honesty Education Model for Undergraduate Students in Online Education Base on Computer Technology}, 
  year={2023},
  volume={},
  number={},
  pages={136-142},
  abstract={The national colleges and universities’ large-scale application of online education during the Covid-19. Academic dishonesty frequently occurs, leading to society’s attention to the problem of academic honesty. As a vital reserve force of academic talents, undergraduate students should pay more attention to their academic honesty. Nowadays, undergraduate students’ academic consciousness is weak, and their academic dishonesty is gradually showing new characteristics and problems under the large-scale application of online education. In the face of increasingly frequent and diverse academic dishonesty problems, various academic misconduct detection systems supported by computer technology have played a positive role in solving the problem of academic dishonesty among undergraduate students. We must study and think about improving undergraduate students’ academic honesty education with the development of online education combined with computer technology. This paper probes into the problems existing in undergraduate students’ academic honesty education under online education. Then it constructs the academic honesty education model from undergraduate students themselves, legal system, academic honesty training, and academic honesty supervision management mechanism, four aspects of standardizing undergraduate students’ academic behavior and forming an excellent academic moral atmosphere in colleges and universities.},
  keywords={Training;Ethics;Computer aided instruction;Law;Atmospheric modeling;Computational modeling;Education;Online education;Computer technology;Undergraduate students;Academic honesty;Academic dishonesty},
  doi={10.1109/CEDL60560.2023.00034},
  ISSN={},
  month={June},}@INPROCEEDINGS{10655313,
  author={Zou, Bo and Yang, Chao and Qiao, Yu and Quan, Chengbin and Zhao, Youjian},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Language-aware Visual Semantic Distillation for Video Question Answering}, 
  year={2024},
  volume={},
  number={},
  pages={27103-27113},
  abstract={Significant progress in video question answering (VideoQA) have been made thanks to thriving large image-language pretraining frameworks. Although image-language models can efficiently represent both video and language branches, they typically employ goal-free vision perception and do not interact vision with language well during the answer generation, thus omitting crucial visual cues. In this paper, we are inspired by the human recognition and learning pattern and propose VideoDistill, a framework with language-aware (i.e., goal-driven) behavior in both vision perception and answer generation. VideoDistill generates answers only from question-related visual embeddings and follows a thinking-observing-answering approach that closely resembles human behavior, distinguishing it from previous research. Specifically, we develop a language-aware gating mechanism to replace the standard cross-attention, avoiding language's direct fusion into visual representations. We incorporate this mechanism into two key components of the entire framework. The first component is a differentiable sparse sampling module, which selects frames containing the necessary dynamics and semantics relevant to the questions. The second component is a vision refinement module that merges existing spatial-temporal attention layers to ensure extracting multi-grained visual semantics associated with the questions. We conduct evaluations on various challenging video question-answering benchmarks, and VideoDistill achieves state-of-the-art performance in both general and long-form VideoQA datasets. In Addition, we verify that VideoDistill can effectively alleviate the utilization of language shortcut solutions in the EgoTaskQA dataset.},
  keywords={Visualization;Computer vision;Computational modeling;Semantics;Benchmark testing;Question answering (information retrieval);Cognition;VideoQA;Vision-Language;Multi-modal Fusion;Video Understanding;Question-Answering},
  doi={10.1109/CVPR52733.2024.02560},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10318237,
  author={Liu, Yang and Liu, Hao and Qu, Tengteng and Chen, Wei},
  booktitle={2023 IEEE International Conference on Unmanned Systems (ICUS)}, 
  title={Intention Recognition Trustworthiness Measurement using a Spatiotemporal Knowledge Graph}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The generalization ability of current intent recognition methods is insufficient, and the evaluation of confidence level of intent recognition is the key to its popularization and application in the high-reliability military and civilian fields. The spatiotemporal Knowledge Graph can uniformly represent and efficiently organize entities containing spatial location information and temporal information. Battlefield situational objectives and their relationships can be abstractly expressed as a triplet composed of two specific types of spatiotemporal entities and combat intent relationships. Using typical confrontation scenario data to train neural networks, and fusing the confidence levels of the entity and Knowledge Graph, the confidence level evaluation results of the intent triple facing the existing spatiotemporal knowledge base are calculated. The simulation test results show that the method can effectively evaluate the confidence level of intent recognition results, and the accuracy rate is improved by more than 9% compared with the KGTTM model. This method breaks the “closed” assumption of the Knowledge Graph update and completion algorithm from the level of algorithm thinking, and completes the last link of the popularization and application of intent recognition methods.},
  keywords={Analytical models;Computational modeling;Neural networks;Redundancy;Knowledge based systems;Focusing;Knowledge graphs;knowledge graph;spatiotemporal coding;intent recognition;confidence level calculation},
  doi={10.1109/ICUS58632.2023.10318237},
  ISSN={2771-7372},
  month={Oct},}@INPROCEEDINGS{7490779,
  author={Zhang, Jing and Lei, Hang},
  booktitle={2015 4th International Conference on Computer Science and Network Technology (ICCSNT)}, 
  title={Research status and prospect of Internetware reliability}, 
  year={2015},
  volume={01},
  number={},
  pages={406-411},
  abstract={There are some limitations when analyzing and studying Internetware by using traditional software reliability theory and method which is not adaptive to the open, dynamic and changeable network environment. Based on the basic principle, the characteristics and the analysis of Internetware, the theory and the technology of Internetware reliability are innovated and developed. The research status, the theoretical basis, the research emphasis and the development of Internetware are analyzed and studied. The key researches are Internetware reliability model and reliability computation method. The new research direction and research thinking of scientific analysis of Internet influencing factors, automatic extraction method, specialized computing and parallel computing for reliability are proposed. Internetware reliability analysis and research content are discussed from theory, technology and application, which has reference value for continuous research and further application in Internetware.},
  keywords={Software reliability;Computational modeling;Software;Reliability engineering;Reliability theory;Analytical models;Internetware;reliability;theory;technology;status;prospect},
  doi={10.1109/ICCSNT.2015.7490779},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6700235,
  author={Dietrich, Dietmar and Schaat, Samer and Bruckner, Dietmar and Doblhammer, Klaus and Fodor, Georg},
  booktitle={IECON 2013 - 39th Annual Conference of the IEEE Industrial Electronics Society}, 
  title={The current state of psychoanalytically-inspired AI}, 
  year={2013},
  volume={},
  number={},
  pages={6666-6671},
  abstract={Complexity of technology is constantly increasing; for the field of automation this means that economic considerations dictate a need for corresponding measures. Artificial intelligence boasts noteworthy successes in this area; however, its achievements appear modest when compared to the faculties of human intelligence. This paper will demonstrate that a new modeling approach is required via possibilities offered by the mindset and tools of computer technology, thereby demonstrating why a psychoanalytic approach seems sensible and necessary. The paramount goal of the research introduced in the following is a formal approach to describing the human psyche based on the neuro- symbolic and neuronal functional layers. Questions associated with this approach include: To what extent can the psychoanalytic model be confirmed by computer technology and the possibility of simulation? To what extent is an axiomatically developed terminology in psychoanalysis a prerequisite for the better integration of the natural-scientific way of thinking in psychoanalysis? The paper is based on the results of several fundamental research projects within the framework of ARS (Artificial Recognition System) which were funded in part nationally and in part by the EU.},
  keywords={Computational modeling;Computers;Brain modeling;Hardware;Artificial intelligence;Drives;Information theory;Cognitive Automation;Artificial General Intelligence;Cognitive Architecture;Artificial Intelligence},
  doi={10.1109/IECON.2013.6700235},
  ISSN={1553-572X},
  month={Nov},}@INPROCEEDINGS{9788172,
  author={Sasikumar, S. and Prabha, S. and Reddy Chandra, Naga Bhargava and Suravarapu, Darshitha and Goda, Rama Krishna},
  booktitle={2022 6th International Conference on Intelligent Computing and Control Systems (ICICCS)}, 
  title={Students Live Behavior Monitoring In Online Classes}, 
  year={2022},
  volume={},
  number={},
  pages={1749-1755},
  abstract={Nowadays, we all know that due to the health emergency situation most of the universities and colleges opted for the virtual education. In this pandemic the student's learning process was affected mostly. So due to that purpose most of the educational centers proposed the virtual system. Many educational centers started their classes on different virtual tools such as Discord, Google Meet, Microsoft Teams, Skype and Zoom. So, the main objective of this paper is on the impact of student learning in video conferences. Most of the teachers were familiar with those tools; However, about 24% of them stated that their academic performance has been improved. But some of the teachers were facing some of the difficulties on a psychological level due to the new teaching procedure. In this paper we are using Artificial intelligence and Machine Learning algorithms to analyze the student’s behavior. After this analysis to prove that students and teachers agree that these virtual tools are very helpful in the online classes. "The challenges of this paper are that the teacher may know the student’s learning activity rate in online classes".The primary of this project is to develop a self-contained agent that can provide information to both teachers and students. Important academic outcomes such as critical thinking and the grades students receive in a topic are closely tied to the extent of student involvement.},
  keywords={Machine learning algorithms;Pandemics;Computational modeling;Education;Psychology;Predictive models;Control systems;OpenCV;Shape predictor model;Artificial Intelligence;68 Facial landmarks data;Module description;Eye aspect ratio;Mouth aspect ratio;Head pose},
  doi={10.1109/ICICCS53718.2022.9788172},
  ISSN={2768-5330},
  month={May},}@INBOOK{9823129,
  author={Cardon, Alain},
  booktitle={Beyond Artificial Intelligence: From Human Consciousness to Artificial Consciousness}, 
  title={The Computer Representation of an Artificial Consciousness}, 
  year={2018},
  volume={},
  number={},
  pages={113-196},
  abstract={This chapter describes the computer modeling of a psychic system that generates representations for a system that has an artificial corporeality. In this model, it defines how the sensation of thinking is formed in an artificial system and how such an artificial system can experience its idea generation. Next, the chapter discusses a multiagent approach to design the artificial psychic system. Further, it describes the organizational memory of the system. The organizational memory will be organized into networks of memory agents related through concepts of semantic proximities or semantic generalizations. The concepts of proximity, specialization and generalization can be precisely defined using qualifications related to the acquaintances of the agents. The chapter finally shows that the general psyche of an artificial system, when it is distributed over multiple corporeal systems with local artificial consciousnesses, can be unified.},
  keywords={Software agents;Computational modeling;Organizations;Regulators;Task analysis;Context modeling;Computer science},
  doi={10.1002/9781119550983.ch2},
  ISSN={},
  publisher={Wiley},
  isbn={9781119551010},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9823129},}@INPROCEEDINGS{9153596,
  author={Wang, Qunyong and Chen, Dongmei and Bai, Hua and Shi, Fajian},
  booktitle={2020 Annual Reliability and Maintainability Symposium (RAMS)}, 
  title={Accurate Reliability Prediction Based on RIDM}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={The reliability of an item is the probability that it will adequately perform its specified purpose for a specified period of time under specified environmental conditions [1]. Uncertainty [2] in reliability prediction for complex electronic systems/equipment is mainly originated from the incomplete considerations on the specified environmental conditions and on the impacts to the equipment. This paper focuses on the incomplete considerations on the space radiation environment (SR see Acronyms in table 1) and their impacts on complex electronic equipment in satellites, airplanes, and ground network computers working daily in SR. Based on Risk Informed Decision Making (RIDM) analysis framework [3], this paper proposes an accurate reliability prediction method to accommodate SR and SR impacts on complex electronic equipment to avoid uncertainties originated from the incomplete considerations on SR theoretically more complete or accurate than the traditional methods, such as FIDES [4], MIL-HDBK-217 [5], etc, which has not considered SR. This paper is creative on the following 3 novel points. (1) SR reliability concept: For accurate reliability prediction, this paper proposes an SR reliability concept based on RIDM framework. The concept accommodates SR and SR impacts critical to mission success by the SR reliability definition and the RIDM 5 steps analysis method to have a close loop systematic thinking on incomplete considerations on SR. (2) SR reliability model: For an accurate reliability prediction based on the SR reliability concept, this paper proposes a new SR reliability model focused on the SR impact rate for complex electronic equipment, connecting the incomplete considerations of SR with mission success in a close loop by 1) The relationship [6] between Reliability and SR impact rate, 2) The relationship [6] between SR impact rate and TID, DD, and SEE impact rate, 3) The relationship between SEE impact rate and SEE effect rate. (3) SR reliability prediction application and verification: This paper provides 3 case studies on satellite, avionics, and ground network computer applications. Additionally, the SR impact rate for avionics of a satellite navigation receiver prototype is predicted and compared with the test results [7] with good agreement. Case studies show that for safety critical applications, the SR impact rate is significant and not negligible. And the SR reliability concept and model is practical and useful for displaying possible key contributions to SR mitigation strategies or Defense-in-depth systematically for mission success.This paper gives an example for the accurate reliability prediction based on RIDM, focusing only on accommodating SR. However, as a general systematic method, it can be applied in broader areas on more SR and non-SR stresses.},
  keywords={Reliability;Computer network reliability;Circuit faults;Built-in self-test;Space radiation;Satellites;Computational modeling;RIDM;SR reliability model;SR impact rate;Single event Effect},
  doi={10.1109/RAMS48030.2020.9153596},
  ISSN={2577-0993},
  month={Jan},}@INPROCEEDINGS{10656240,
  author={Xu, Katherine and Zhang, Lingzhi and Shi, Jianbo},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Amodal Completion via Progressive Mixed Context Diffusion}, 
  year={2024},
  volume={},
  number={},
  pages={9099-9109},
  abstract={Our brain can effortlessly recognize objects even when partially hidden from view. Seeing the visible of the hidden is called amodal completion; however, this task remains a challenge for generative AI despite rapid progress. We propose to sidestep many of the difficulties of existing approaches, which typically involve a two-step process of predicting amodal masks and then generating pixels. Our method involves thinking outside the box, literally! We go outside the object bounding box to use its context to guide a pretrained diffusion inpainting model, and then progressively grow the occluded object and trim the extra background. We overcome two technical challenges: 1) how to be free of unwanted co-occurrence bias, which tends to regenerate similar occluders, and 2) how to judge if an amodal completion has succeeded. Our amodal completion method exhibits improved photorealistic completion results compared to existing approaches in numerous successful completion cases. And the best part? It doesn't require any special training or fine-tuning of models.},
  keywords={Training;Computer vision;Generative AI;Computational modeling;Pattern recognition;Context modeling;amodal completion;diffusion model;occlusion;generative model;inpainting},
  doi={10.1109/CVPR52733.2024.00869},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10134169,
  author={Karmakar, Sona and Sivakumar, N and Pillai, Anitha S},
  booktitle={2023 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Exploring Satisfaction Level of Customers in Restaurants by Using Latent Dirichlet Allocation(LDA) Algorithm}, 
  year={2023},
  volume={},
  number={},
  pages={880-887},
  abstract={Social media has become an essential means for communicating the review/opinions of people around the world due to the rapid expansion and availability of the internet. Reviews and opinions are expressed both as text and audio. But text communication via networking media is overwhelming. Each and every second, a vast amount of information is produced online because of social media sites. However, online reviews on social media provides an excellent and trustworthy channel for examining the areas that require improvement and for understanding the needs of customers. This paper tries to understand the various topics that are discussed by customers about food with the aim of providing an insight to improve the area where there are negative comments. By doing this, customer retention will increase and gradually the business also. Topic modeling is done to find the hidden topic in a set of comments or customer reviews to find out on which topic customers are talking, thinking, or discussing more about restaurant services. It helps to read customers' mindsets, and accordingly, improvements can be made to increase consumer demand for a restaurant. So, a system is proposed to detect topics of textual reviews of different restaurants using the latent Dirichlet allocation (LDA) modelling approach. A probabilistic, statistical strategy for document designing called latent document analysis (LDA) identifies latent semantic topics in sizable corpora. The dataset used for this study was taken from Kaggle, which had 111,105 reviews. First, topics from reviews were extracted using the LDA model, then data was visualised using the LDAvis tool. The experiment's findings show that the analysis obtained a successful topic division outcome especially in long-to-short text level topic classification.},
  keywords={Adaptation models;Dictionaries;Text analysis;Social networking (online);Computational modeling;Semantics;Probabilistic logic;Online restaurant reviews;topic modeling;Latent dirichlet allocation (LDA);stop words;bag of words},
  doi={10.1109/ICICT57646.2023.10134169},
  ISSN={2767-7788},
  month={April},}@ARTICLE{10099445,
  author={Huang, Wenjie and Chella, Antonio and Cangelosi, Angelo},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={A Cognitive Robotics Implementation of Global Workspace Theory for Episodic Memory Interaction With Consciousness}, 
  year={2024},
  volume={16},
  number={1},
  pages={266-283},
  abstract={Artificial general intelligence revived in recent years after people achieved significant advances in machine learning and deep learning. This leads to the thinking of how real intelligence could be created. Consciousness theories believe that general intelligence is essentially conscious, yet no universal definition is agreed upon. In this work, global workspace (GW) theory is implemented and integrated with crucial cognitive components. With the focus on episodic memory and inspiration from the nature of episodic memory in psychology and neuroscience, the episodic memory component is implemented within the GW framework. In our experiment, the robotic agent operates in a real-world interactive context, forming episodic memory and demonstrating static, temporal, and context memory capabilities during interactions. Consciousness in this work engages in all formation, maintenance, and retrieval processes of episodic memory. The novelty and contributions of this work are: 1) this work is implementing episodic memory within the consciousness framework, suggesting the sustainable potential of such an integrated approach to cognitive agents with artificial general intelligence (AGI); 2) regarding the limited examples in consciousness-based cognitive architectures, this work attempts to contribute to the diversity of perspectives and approaches; 3) extant episodic memory implementations are suffering from various limitations, while this work summarises some key features for modeling episodic memory within a cognitive architecture; and 4) authors discuss the relationship between episodic memory, consciousness, and general intelligence, proposing the compatibility and relationship between machine consciousness and other AGI research. It is believed that a better alignment between them would further boost the fusion of diverse research for achieving desired cognitive machines.},
  keywords={Cognition;Psychology;Computational modeling;Deep learning;Cognitive robotics;Task analysis;Maintenance engineering;Cognitive robots;consciousness;episodic memory;general intelligence;global workspace (GW)},
  doi={10.1109/TCDS.2023.3266103},
  ISSN={2379-8939},
  month={Feb},}@INPROCEEDINGS{10137840,
  author={Shi, Ji and Suo, Zhongying},
  booktitle={2022 6th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Multigranulation Sequential Three-Way Decisions in Interval-Valued System}, 
  year={2022},
  volume={},
  number={},
  pages={1-11},
  abstract={Three-way decisions model adopts the idea of’’rule by three divisions’’ and “simplify complexity which provides a multi-level and multi granularity thinking framework and implementation method for solving complex uncertain problems. Within this framework, how to extend the application of the generalized model from decision system to interval-valued decision system is an important issue. In this paper, we propose multigranulation sequential three-way decision models in inter-valvalued information system. Firstly, three types of similarity relations from the view of optimistic, pessimistic and weighted are defined. Based on these similarity relations, the lower and upper approximations under multiple granular structures are computed. Then optimistic, pessimistic and weighted arithmetic strategies are adopted to compute three disjoint regions in each level of multigranulation sequential three-way decisions. Furthermore, nine types of multigranulation sequential threeway decision models were analysed. Finally, the experimental results show that the size of the probabilistic regions varies with the similarity relations and aggregation strategies.},
  keywords={Analytical models;Computational modeling;Probabilistic logic;Complexity theory;Artificial intelligence;Arithmetic;Information systems;Multigranulation;sequential three-way decisions;similarity relation;interval-valued decision system},
  doi={10.1109/ACAIT56212.2022.10137840},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10592950,
  author={Kumar, Dubasi Pavan and Bhadula, Shuchi and Al-Farouni, Mohammed and Varshney, Neeraj and Sharma, Vishal and Saraswat, Manish},
  booktitle={2024 International Conference on Communication, Computer Sciences and Engineering (IC3SE)}, 
  title={Artistic Style Transfer Using Generative Adversarial Networks: A Pix2Pix Implementation}, 
  year={2024},
  volume={},
  number={},
  pages={1351-1357},
  abstract={This investigation explores the viability of four noticeable models, specifically Pix2Pix, Neural Style Transfer (NST), Fast Neural Style Transfer (FastNST), and CycleGAN, within the space of aesthetic style exchange. The think about envelops a fastidious assessment of these models, investigating their capabilities in generating outwardly engaging and elaborately reliable pictures. Through broad tests and quantitative evaluations, Pix2Pix developed as a strong choice, accomplishing a Crest Signal-to-Noise Ratio (PSNR) of 26.78 dB, a Basic Likeness List (SSIM) of 0.832, and a Fréchet Initiation Separate (FID) of 54.21. NST, exceeding expectations in style devotion, achieved a PSNR of 29.45 dB, an SSIM of 0.905, and an FID of 72.03. FastNST, known for its real-time preparation, illustrated an adjusted execution with a PSNR of 28.12 dB, an SSIM of 0.892, and an FID of 68.54. CycleGAN, outlined for unpaired picture interpretation, accomplished a PSNR of 27.65 dB, an SSIM of 0.874, and an FID of 63.72. The results give profitable experiences into the comparative qualities and weaknesses of these models, educating their appropriateness in different artistic assignments.},
  keywords={Deep learning;Visualization;Computational modeling;Writing;Solids;Generative adversarial networks;Real-time systems;Pix2Pix;Artistic Style Transfer;Fast Neural Style Transfer;Neural Style Transfer;CycleGAN},
  doi={10.1109/IC3SE62002.2024.10592950},
  ISSN={},
  month={May},}@INPROCEEDINGS{9255595,
  author={Pristupchik, Nikita},
  booktitle={2020 International Conference on Actual Problems of Electron Devices Engineering (APEDE)}, 
  title={Open-Source CAE for Electron Beam Optics Design: Challenges and Opportunities}, 
  year={2020},
  volume={},
  number={},
  pages={95-99},
  abstract={We discuss the advantages of domain specific computer aid engineering (CAE) systems, which have to be machine-consuming, rather than human-consuming, and be able to operate at future supercomputers. We reveal some quirks of modern human-consuming commercial CAEs, and their limitations. Next, we have described the main benefits and shortcomings of the open-source software development model (from the developers' perspective), which as we think suits our needs best. We have briefly overviewed some modern software technologies, on top of which any advanced CAE could be built. Most of them are open-sourced. In addition, we justify using Matlab technical computing language for prototyping domain specific CAE systems. In conclusion, we present a prototype of a 2D preprocessor with direct editing capabilities for domain-specific CAE for electron beam optics design.},
  keywords={Open source software;Computational modeling;Electron beams;Optics;Matlab;Mathematical model;Graphical user interfaces;CAE;user experience;open-source software;design optimization;electron beam optics},
  doi={10.1109/APEDE48864.2020.9255595},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10398148,
  author={Adeel, Nazish and Kumar, Rajeev and Akella, Katyayani N S and Manickam, Valli and Khan, Mohd Waris and Nandury, Satyanarayana V.},
  booktitle={2023 6th International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={Measuring the Implications of Email Viruses Through a Unified Model of Cyber Security}, 
  year={2023},
  volume={6},
  number={},
  pages={614-621},
  abstract={The vast majority of email viruses propagate by ensuring that every address included in the address book of the victim is sent the malicious message or attachment. There are a variety of approaches that can be utilized in order to package and present these viruses. Some of them can be immediately identified as malicious based on the content of the body, the sender, who may or may not be trustworthy, and the subject lines, which are just unintelligible. It may be difficult for receivers to identify individual email messages that include malware since the malicious actor puts a lot of effort into making it appear as though the email message was sent from a respectable sender. Phishing is an attempt to steal sensitive information by impersonating a trustworthy entity, typically a business. Cybersecurity is an extremely important topic in the field of information technology. Information security is one of the most pressing problems facing our generation at the moment. When we think of cyber security, the first thing that comes to mind is cybercrime, which is expanding at an alarming rate. This is because cybercrime is the most common kind of online crime. In order to put an end to these cybercrimes, various governments and businesses are pursuing a variety of preventative measures. In spite of the many safeguards in place, a significant number of people continue to be anxious about the safety of their online activity. The difficulties surrounding the use of email viruses as a threat to cyber security are the primary focus of this article. From the point of view of email viruses, a unified approach for assessing the level of cyber security has been developed. In addition to this, it examines the most recent developments in the methods of cyber security, as well as the ethics and trends that are influencing the industry.},
  keywords={Computer viruses;Computational modeling;Electronic mail;Safety;Security;Computer crime;Viruses (medical);Email phishing;cybercrime;cyber security;security measurement},
  doi={10.1109/IC3I59117.2023.10398148},
  ISSN={},
  month={Sep.},}@ARTICLE{242440,
  author={Weichang Du},
  journal={IEEE Parallel & Distributed Technology: Systems & Applications}, 
  title={An intentional approach to parallel programming}, 
  year={1993},
  volume={1},
  number={3},
  pages={22-32},
  abstract={Unlike conventional parallel languages, intentional languages let developers think of parallelism first and then use explicit constructs to express sequentialism, instead of the other way around.<>},
  keywords={Parallel programming;Parallel processing;Space technology;Parallel languages;Programming profession;Concurrent computing;IEEE Computer Society Press;Prototypes;Computational modeling;Logic},
  doi={10.1109/88.242440},
  ISSN={1558-1861},
  month={Aug},}@INPROCEEDINGS{10263093,
  author={Gopu, Arunkumar and Nishchal, Pratyush and Mittal, Vishesh and Srinidhi, Kuna},
  booktitle={2023 IEEE International Conference on Contemporary Computing and Communications (InC4)}, 
  title={Image Captioning using Deep Learning Techniques}, 
  year={2023},
  volume={1},
  number={},
  pages={1-5},
  abstract={The automatic generation of image descriptions is leading the field of computer vision and natural language processing-based research. Image captioning is a key task that calls for a semantic understanding of the images and the capacity to create descriptions with right structure. Image captioning is a complex problem as it often demands accessing data that might not be visible in each scene. It will require logical thinking to evaluate or have in-depth knowledge about the object present in an image. In this study, we developed a multilayer Convolutional Neural Network to produce words that describe the images, and we used Long Short-Term Memory to accurately construct relevant sentences out of the words that are produced. To generate an accurate description, the Convolutional Neural Network (CNN) model first compares the targeted image against a huge dataset of training samples. In this study, we have used the Flickr 8k dataset. We have used the Bilingual Evaluation Understudy (BLEU) metric to determine how well our model is generating captions for the images. It evaluates the generated text that has been translated from one language to a different language to evaluate the effectiveness of the machine translation system. In this study, we have also used two pre-trained models (VGG16, and XceptionV3) for comparative study.},
  keywords={Training;Image databases;Computational modeling;Multimedia Web sites;Semantics;Predictive models;Feature extraction;Image Captioning;Computer Vision;Natural Language Processing;Neural Networks},
  doi={10.1109/InC457730.2023.10263093},
  ISSN={},
  month={April},}@INPROCEEDINGS{7161569,
  author={Marathe, Madhav},
  booktitle={2015 IEEE International Parallel and Distributed Processing Symposium}, 
  title={Assisting H1N1 and Ebola Outbreak Response through High Performance Networked Epidemiology}, 
  year={2015},
  volume={},
  number={},
  pages={831-831},
  abstract={Summary form only given, as follows. The H1N1 pandemic of 2009 and the ongoing Ebola outbreak in West Africa serve as a reminder of the social, economic and health burden of infectious diseases. The ongoing trends towards urbanization, global travel, climate change and a generally older and immuno-compromised population continue to make epidemic planning and control challenging. Recent quantitative changes in high performance pervasive computing have created new opportunities for collecting, integrating, analyzing and accessing information related to large urban social systems, disease surveillance and global logistics and supply chains. The advances in network and information science that build on this new capability provide entirely new ways for reasoning and controlling epidemics. In this talk I will overview of the state of the art in computational networked epidemiology with an emphasis on computational thinking and on the development of high performance computing oriented decision-support environments for planning and response in the event of epidemics. I will describe how such systems can be used to support near real-time planning and response during the 2009 H1N1 swine flu and the recent Ebola Outbreak in West Africa. Computational challenges and directions for future research will be discussed.},
  keywords={Planning;High performance computing;Africa;Urban areas;Surveillance;Supply chains;Statistics},
  doi={10.1109/IPDPS.2015.121},
  ISSN={1530-2075},
  month={May},}@ARTICLE{7355313,
  author={Yang, Jiyan and Meng, Xiangrui and Mahoney, Michael W.},
  journal={Proceedings of the IEEE}, 
  title={Implementing Randomized Matrix Algorithms in Parallel and Distributed Environments}, 
  year={2016},
  volume={104},
  number={1},
  pages={58-92},
  abstract={In this era of large-scale data, distributed systems built on top of clusters of commodity hardware provide cheap and reliable storage and scalable processing of massive data. With cheap storage, instead of storing only currently relevant data, it is common to store as much data as possible, hoping that its value can be extracted later. In this way, exabytes (1018 bytes) of data are being created on a daily basis. Extracting value from these data, however, requires scalable implementations of advanced analytical algorithms beyond simple data processing, e.g., statistical regression methods, linear algebra, and optimization algorithms. Most such traditional methods are designed to minimize floating-point operations, which is the dominant cost of in-memory computation on a single machine. In parallel and distributed environments, however, load balancing and communication, including disk and network input/output (I/O), can easily dominate computation. These factors greatly increase the complexity of algorithm design and challenge traditional ways of thinking about the design of parallel and distributed algorithms. Here, we review recent work on developing and implementing randomized matrix algorithms in large-scale parallel and distributed environments. Randomized algorithms for matrix problems have received a great deal of attention in recent years, thus far typically either in theory or in machine learning applications or with implementations on a single machine.},
  keywords={Algorithm design and analysis;Approximation methods;Approximation algorithms;Distributed databases;Machine learning algorithms;Matrix decomposition;Big data;Big data;distributed matrix algorithms;least absolute deviation;least squares;preconditioning;randomized linear algebra;subspace embedding;Big data;distributed matrix algorithms;least absolute deviation;least squares;preconditioning;randomized linear algebra;subspace embedding},
  doi={10.1109/JPROC.2015.2494219},
  ISSN={1558-2256},
  month={Jan},}@INPROCEEDINGS{8424657,
  author={Mohan, Vysakh S and R, Vinayakumar and KP, Soman and Poornachandran, Prabaharan},
  booktitle={2018 IEEE Security and Privacy Workshops (SPW)}, 
  title={S.P.O.O.F Net: Syntactic Patterns for identification of Ominous Online Factors}, 
  year={2018},
  volume={},
  number={},
  pages={258-263},
  abstract={With more emphasis on internet as a primary mechanism for information access and communication, it is highly important that the platform stays safe and secure for anyone who uses it. Online scams and cybercrimes are becoming a common threat to the technology and systems that help mitigate these issues are in high demand. Businesses all over the world invest heavily to stay secure in the cyberspace and rely on security experts in defending their business from online threats. The immense scale of the internet and the dynamicity of the threat it holds forces the adoption of automated threat detection systems. Several cybersecurity use cases exist, but the two use cases discussed here are DGA detection and Malicious URL detection. This paper addresses the drawbacks of previous rulebased and machine learning based detection methods. Here, embedding concepts from NLP is incorporated into cybersecurity use cases to propose a new in house model christened S.P.O.O.F Net, which is a combination of a Convolutional Neural Network and Long Short Term Memory Network. The proposed model is benchmarked with machine learning algorithm incorporating bi-gram feature engineering techniques and also a conventional CNN with character level embedding (same as the one used for S.P.O.O.F Net). It was observed that S.P.O.O.F Net gave better performance over the aforementioned methods with accuracy scores of 98.3% for DGA detections and 99% for malicious URL detection. This work also aims to demonstrate the possibilities of incorporating NLP concepts to cybersecurity use cases and provide future researches a new thinking curve to develop systems in this domain.},
  keywords={Uniform resource locators;Machine learning;Logic gates;Computer crime;Botnet;Logistics;convolutional neural network;long short term memory;domain generation algorithms;malicious url detection;natural language processing},
  doi={10.1109/SPW.2018.00041},
  ISSN={},
  month={May},}@INPROCEEDINGS{8778224,
  author={Kobayashi, Ryohei and Fujita, Norihisa and Yamaguchi, Yoshiki and Nakamichi, Ayumi and Boku, Taisuke},
  booktitle={2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={GPU-FPGA Heterogeneous Computing with OpenCL-Enabled Direct Memory Access}, 
  year={2019},
  volume={},
  number={},
  pages={489-498},
  abstract={Field-programmable gate arrays (FPGAs) have garnered significant interest in research on high-performance computing because their computation and communication capabilities have drastically improved in recent years due to advances in semiconductor integration technologies that rely on Moore's Law. In addition to improving FPGA performance, toolchains for the development of FPGAs in OpenCL have been developed and offered by FPGA vendors that reduce the programming effort required. These improvements reveal the possibility of implementing a concept to enable on-the-fly offloading computation at which CPUs/GPUs perform poorly to FPGAs while performing low-latency data movement. We think that this concept is key to improving the performance of heterogeneous supercomputers using accelerators such as the GPU. In this paper, we propose an OpenCL-enabled data movement method to directly access the global memory of the GPU and show how to implement cooperative GPU-FPGA computation using it. The results of experiments show that our proposed method can achieve a latency of 0.59 μs and a data transfer rate as high as 7.0 GB/s between the GPU and the FPGA, thus confirming that it is effective at realizing high-performance cooperative GPU-FPGA computation.},
  keywords={Field programmable gate arrays;Kernel;Hardware design languages;Ethernet;Graphics processing units;Hardware;Programming;GPU, FPGA, OpenCL, BSP, PCIe, DMA, I/O channels, Verilog HDL, Heterogeneous platform, Accelerator computing, Interconnect for accelerators},
  doi={10.1109/IPDPSW.2019.00090},
  ISSN={},
  month={May},}@ARTICLE{9809784,
  author={Ai, Chengwei and Tiwari, Prayag and Yang, Hongpeng and Ding, Yijie and Tang, Jijun and Guo, Fei},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Identification of DNA N4-methylcytosine Sites via Multiview Kernel Sparse Representation Model}, 
  year={2023},
  volume={4},
  number={5},
  pages={1236-1245},
  abstract={Identifying DNA N4-methylcytosine (4mC) sites is of great significance in biological research, such as chromatin structure, DNA stability, DNA–protein interaction, and controlling gene expression. However, the traditional sequencing technology to identify 4mC sites is very time-consuming. In order to detect 4mC sites, we develop a multiview learning method for achieving more effectively via merging multiple feature spaces. Furthermore, we think about whether the multiview learning method can improve the across species classification ability by fusing data of multiple species. In our study, we propose a multiview Laplacian kernel sparse representation-based classifier, called MvLapKSRC-HSIC. First, we make use of three feature extraction methods [position-specific trinucleotide propensity, nucleotide chemical property, and DNA physicochemical properties) to extract the DNA sequence features. MvLapKSRC-HSIC uses a kernel sparse representation-based classifier with graph regularization. In order to maintain the independence between various views, we add a multiview regularization term constructed by Hilbert–Schmidt independence criterion (HSIC). In the experiments, MvLapKSRC-HSIC is applied on six datasets, so as to compare with other popular methods in single-species and cross-species experiments. All experimental results show that MvLapKSRC-HSIC is superior to other outstanding methods on both single species and cross species. Importantly, MvLapKSRC-HSIC can identify a series of potential DNA 4mC sites, which have not yet been experimentally evaluate on multiple species and merit further research.},
  keywords={DNA;Kernel;Feature extraction;Training;Laplace equations;Learning systems;Support vector machines;DNA N4-methylcytosine (4mC) sites;kernel method;multiview learning;sequence classification;sparse representation-based classifier (SRC)},
  doi={10.1109/TAI.2022.3187060},
  ISSN={2691-4581},
  month={Oct},}@INPROCEEDINGS{9820616,
  author={Yang, Wenxiang and Liao, Xiangke and Dong, Dezun and Yu, Jie},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={A Quantitative Study of the Spatiotemporal I/O Burstiness of HPC Application}, 
  year={2022},
  volume={},
  number={},
  pages={1349-1359},
  abstract={Understanding the I/O characteristics of applications on supercomputers is crucial to paving the path for application optimization and system resource allocation. We collect and analyze I/O traces of applications on a production supercomputer and reconfirm that I/O bursts exist in most applications. What's more, we find that the I/O bursts not only occur in short periods of time but also originate from a minority of adjacent compute nodes allocated to the applications, which we call spatiotemporal I/O burstiness. The concentration of I/O traffic in both time and space dimension will make applications experience poor I/O performance and incur I/O inefficiency of the storage system. Although there are some solutions, such as burst buffer, can help alleviate such inefficiency, there is still no work that measures, analyzes and further predicts the application I/O characteristic in terms of spatiotemporal burstiness, which we think is vital for application-aware optimizations, including but not limited to burst buffer allocation and job scheduling. In this paper, we first propose a mathematical model to measure the spatiotemporal I/O burstiness. Then a thorough analysis on the spatiotemporal I/O characteristic of all applications on the system is elaborated. We further make use of the job's submitting path to explore the I/O characteristic similarity among jobs, based on which a machine learning classification algorithm is proposed to accurately predict the job spatiotemporal I/O burstiness in advance. With accurate job I/O characteristic at hand, some useful suggestions are put forward to hedge the impacts of the spatiotemporal I/O burstiness.},
  keywords={Distributed processing;Production;Machine learning;Supercomputers;Mathematical models;Spatiotemporal phenomena;Classification algorithms;Spatiotemporal Burstiness;I/O Behavior;Application-aware;Machine Learning},
  doi={10.1109/IPDPS53621.2022.00133},
  ISSN={1530-2075},
  month={May},}@INPROCEEDINGS{1213498,
  author={Aljundi, A.C. and Dekeyser, J.L. and Kechadi, M.T. and Scherson, I.D.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={A study of an evaluation methodology for unbuffered multistage interconnection networks}, 
  year={2003},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={Interconnection network performance is a key factor when constructing parallel computers. The choice of an interconnection network used in a parallel computer depends on a large number of performance factors which are very often application dependent. We give the outline of a performance evaluation and comparison methodology using what we think of as the most important parameters to be considered when solving such a problem. This methodology is applied on a new interconnection network called MCRB network and on Omega network.},
  keywords={Multiprocessor interconnection networks;Computer networks;Concurrent computing;Wires;Throughput;Switches;Educational institutions;Computer science;Application software;System performance},
  doi={10.1109/IPDPS.2003.1213498},
  ISSN={1530-2075},
  month={April},}@INPROCEEDINGS{10046729,
  author={Berkmans, T. John and Karthick, S.},
  booktitle={2022 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS)}, 
  title={Credit Card Fraud Detection with Data Sampling}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Credit card fraud, although not directly impacting banks, does have repercussions for the financial sector as a whole. Criminals pose a significant threat to safety since they are continually thinking up new methods to commit these types of fraud. Early detection of fraudulent behavior is therefore vital to retain customer trust and defend the firm. Since lawful transactions far outnumber fraudulent transactions, which typically make up less than 1% of all transactions, addressing the class imbalance issue in the data presents a significant challenge for developing fraud detection algorithms. It is challenging to identify a positive example (fraudulent case), and this challenge increases as more data is gathered, leading to a lower proportion of positive examples. Because of this, research is very important. Models for making predictions were trained in this study utilizing a variety of sampling strategies, including the ANN, GBM, and the RF. Models used SMOTE, RUS, DBSMOTE, and SMOTE plus ENS were all examples of Synthetic Minority Over-Sampling Technique (SMOTEENN). This research suggests that SMOTE-based sampling techniques will provide positive results. The highest recall (0.81) was achieved by the SMOTE sampling method when a DRF classifier was used. It was determined that this classifier has an accuracy score of 0.87. The Stacked Ensembling algorithm was accomplished using altogether of collected data, and its average performance was 0.78, making it the clear winner. As a fraud detection model, the Stacked Ensemble has performed well in most sampling operations.},
  keywords={Training;Costs;Artificial neural networks;Predictive models;Credit cards;Sampling methods;Data models;Disparities in data collection;ccf;data sample},
  doi={10.1109/ICPECTS56089.2022.10046729},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9755509,
  author={Pokrovskaia, Nadezhda N. and Rodionova, Elena A. and Fomina, Irina G. and Epshtein, Mikhail Z. and Fedorov, Denis A.},
  booktitle={2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus)}, 
  title={Blockchain and Smart Contracting in the Context of Digital Transformation of Service}, 
  year={2022},
  volume={},
  number={},
  pages={1727-1731},
  abstract={Banking as a highly digitalized sector is seeking for new technologies to improve the data flow processing and communications. The issues of cyber-security and safety of transaction force institutions to lead in using the reliable digital tools. The tough competition on saturated market requires the permanent renewing of infrastructure and data flows analytics, and the re-thinking of the functional role of banking institutions in the world of fin-tech, where the transactions pass in automatic regime. The cyber-security search, the speed and quality of service, and innovative growth strategy are the essential purposes that make relevant the study of the implementation of smart contracting and blockchain platforms for the cases of service institutions. The paper presents the analysis of cases of digital tools in customer services and the study of the prospects of the smart contracting and blockchain platforms as instruments to assure the increased level of user data cyber-security.},
  keywords={Instruments;Digital transformation;Customer services;Force;Education;Banking;Quality of service;blockchain;smart contracting;digital transformation;customer service;institutions;fintech;cyber-security},
  doi={10.1109/ElConRus54750.2022.9755509},
  ISSN={2376-6565},
  month={Jan},}@ARTICLE{10654535,
  author={Liu, Peide and Wang, Xue and Fu, Yingxin and Wang, Peng},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Graph model for conflict resolution for mixed-stability combinatorial foresight based on the combination of regret theory and VIKOR method}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={The graph model for conflict resolution (GMCR) is a branch of decision-making; therefore, how to scientifically abstract the evaluative thinking of decision-makers (DMs) has always been a core research point in decision science. In this context, further consideration of the heterogeneous behavior of competitors and their impact on the evolution of conflicts deserves special attention. Usually, DMs' evaluation thinking has certain ambiguity and uncertainty, and they are accustomed to giving qualitative evaluation information. Given the unique advantages of trapezoidal interval type-2 fuzzy sets (TrIT2FS) in the fusion of decision domains and transformational linguistic expressions, this paper constructs a theoretical framework for a graph model on TrIT2FS and proposes a method for calculating DMs preference ranking and a heterogeneous combinatorial foresight stability function. Firstly, the DMs will consider multiple factors in the decision evaluation process, and there are specific regret avoidance psychological behavior characteristics; thus, this paper integrates VIKOR and regret theory to solve the DM's preference ranking and expands on a new preference ranking method. Secondly, mixed stability definitions based on TrIT2FS are proposed to facilitate the description of different sanctioning behaviors of heterogeneous opponents. Subsequently, a heterogeneous combinatorial foresight stability function is proposed to quickly obtain conflict evolution solutions in complex dynamic conflict problems based on the extended mixed stability definitions. Finally, to thoroughly test the correctness and practicality of the proposed theory, the conflict between inputs and outputs of the technological transformation of enterprises under the low-carbon strategy is used as a specific application scenario and example for validation.},
  keywords={Stability analysis;Thermal stability;Linguistics;Decision making;Uncertainty;Psychology;Mathematical models;Graph model for conflict resolution (GMCR);trapezoidal interval type-2 fuzzy sets (TrIT2FS);regret theory;VIKOR;heterogeneous opponents;combinatorial foresight},
  doi={10.1109/TFUZZ.2024.3451159},
  ISSN={1941-0034},
  month={},}@ARTICLE{10323527,
  author={Yang, Sanghoon and Kim, Won Dong and Park, Hyunkyu and Min, Seojung and Han, Hyonyoung and Kim, Jung},
  journal={IEEE Robotics and Automation Letters}, 
  title={In-Hand Object Classification and Pose Estimation With Sim-to-Real Tactile Transfer for Robotic Manipulation}, 
  year={2024},
  volume={9},
  number={1},
  pages={659-666},
  abstract={Dexterous robotic grasping gains great benefits from tactile sensation, but delicate object exploration by tactile information is challenged by difficulty in rich and efficient data production. In this letter, we propose a tactile-based in-hand object perception approach, empowered by a sim-to-real approach toward a data-efficient learning process. A high-fidelity tactile input, measured by a pair of vision-based tactile sensors, was represented as a point cloud facilitating dual functionality of object classification and the associated pose estimation. For the classification, we constructed PoinTacNet, a variation of PointNet to fit into tactile data processing. A reliable simulation methodology on tactile input was employed for the pretraining of the model, transferred to the fine-tuning process facing real tactile data. Taking inspiration from human behaviors, a re-grasping strategy was imparted by means of conditional accumulation of class likelihood distribution. The result of the framework facilitates a high object classification accuracy of 83.89$\%$ on the ten objects from McMaster-Carr's CAD models, which is significantly improved by the re-grasping. In addition, a set of benchmarks displays the computational efficiency in the sim-to-real transfer. In line with the successful classification, the posture of in-hand objects is estimated using point cloud registration algorithms, achieving an average angular and translational RMSE of 5.03$^\circ$ and 2.41 mm, respectively. The proposed approach has the potential to enable robots to attain human-like haptic exploration skills for perceiving unstructured environments.},
  keywords={Robots;Tactile sensors;Robot sensing systems;Point cloud compression;Pose estimation;Three-dimensional displays;Shape;Perception for grasping and manipulation;deep learning in grasping and manipulation;transfer learning},
  doi={10.1109/LRA.2023.3334971},
  ISSN={2377-3766},
  month={Jan},}@ARTICLE{6030926,
  author={Rodriguez, Rosa M. and Martinez, Luis and Herrera, Francisco},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Hesitant Fuzzy Linguistic Term Sets for Decision Making}, 
  year={2012},
  volume={20},
  number={1},
  pages={109-119},
  abstract={Dealing with uncertainty is always a challenging problem, and different tools have been proposed to deal with it. Recently, a new model that is based on hesitant fuzzy sets has been presented to manage situations in which experts hesitate between several values to assess an indicator, alternative, variable, etc. Hesitant fuzzy sets suit the modeling of quantitative settings; however, similar situations may occur in qualitative settings so that experts think of several possible linguistic values or richer expressions than a single term for an indicator, alternative, variable, etc. In this paper, the concept of a hesitant fuzzy linguistic term set is introduced to provide a linguistic and computational basis to increase the richness of linguistic elicitation based on the fuzzy linguistic approach and the use of context-free grammars by using comparative terms. Then, a multicriteria linguistic decision-making model is presented in which experts provide their assessments by eliciting linguistic expressions. This decision model manages such linguistic expressions by means of its representation using hesitant fuzzy linguistic term sets.},
  keywords={Pragmatics;Fuzzy sets;Grammar;Semantics;Decision making;Uncertainty;Humans;Context-free grammar;fuzzy linguistic approach;hesitant fuzzy sets;linguistic decision making;linguistic information},
  doi={10.1109/TFUZZ.2011.2170076},
  ISSN={1941-0034},
  month={Feb},}@ARTICLE{10315051,
  author={He, Tao and Gao, Lianli and Song, Jingkuan and Li, Yuan-Fang},
  journal={IEEE Transactions on Image Processing}, 
  title={Toward a Unified Transformer-Based Framework for Scene Graph Generation and Human-Object Interaction Detection}, 
  year={2023},
  volume={32},
  number={},
  pages={6274-6288},
  abstract={Scene graph generation (SGG) and human-object interaction (HOI) detection are two important visual tasks aiming at localising and recognising relationships between objects, and interactions between humans and objects, respectively. Prevailing works treat these tasks as distinct tasks, leading to the development of task-specific models tailored to individual datasets. However, we posit that the presence of visual relationships can furnish crucial contextual and intricate relational cues that significantly augment the inference of human-object interactions. This motivates us to think if there is a natural intrinsic relationship between the two tasks, where scene graphs can serve as a source for inferring human-object interactions. In light of this, we introduce SG2HOI+, a unified one-step model based on the Transformer architecture. Our approach employs two interactive hierarchical Transformers to seamlessly unify the tasks of SGG and HOI detection. Concretely, we initiate a relation Transformer tasked with generating relation triples from a suite of visual features. Subsequently, we employ another transformer-based decoder to predict human-object interactions based on the generated relation triples. A comprehensive series of experiments conducted across established benchmark datasets including Visual Genome, V-COCO, and HICO-DET demonstrates the compelling performance of our SG2HOI+ model in comparison to prevalent one-stage SGG models. Remarkably, our approach achieves competitive performance when compared to state-of-the-art HOI methods. Additionally, we observe that our SG2HOI+ jointly trained on both SGG and HOI tasks in an end-to-end manner yields substantial improvements for both tasks compared to individualized training paradigms.},
  keywords={Task analysis;Visualization;Transformers;Training;Semantics;Predictive models;Multitasking;Scene graph generation;human-object interaction;one-stage network;multi-tasks training},
  doi={10.1109/TIP.2023.3330304},
  ISSN={1941-0042},
  month={},}
